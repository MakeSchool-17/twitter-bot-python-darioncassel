Operationalism
Operationalism is based on the intuition that we do not know the meaning of a concept unless we have a method of measurement for it. It is commonly considered a theory of meaning which states that “we mean by any concept nothing more than a set of operations; the concept is synonymous with the corresponding set of operations” (Bridgman 1927, 5). That drastic statement was made in The Logic of Modern Physics, published in 1927 by the American physicist P. W. Bridgman. The operationalist point of view, first expounded at length in that book, initially found many advocates among practicing physicists and those inspired by the tradition of American pragmatism or the new philosophy of logical positivism. It is highly doubtful that Bridgman intended to advance a precise and universal theory of meaning, or any systematic philosophical theory at all. His writings were primarily “reflections of a physicist”[1] rooted in experimental practice and aimed at articulating the scientific method from a first-person point of view. However, as Bridgman's ideas gained currency they were shaped into a general philosophical doctrine of “operationalism” or “operationism”, and in that form became very influential in many areas, especially in methodological debates in psychology. Both in philosophy and in psychology operationalism is nowadays commonly regarded as an extreme and outmoded position, but that is not to say that the potential of Bridgman's original ideas has been exhausted.
This article has three sections, each of which serves a different aim. Section 1 introduces Bridgman's key ideas on operational analysis, explaining their motivations and tracing the course of their development. Section 2 summarizes various critiques of operationalism, which eventually led to a general philosophical consensus against it. Section 3 gives a view on the remaining potential of Bridgman's ideas on operational analysis for philosophy of science today.
Percy Williams Bridgman (1882–1961) was a physicist at Harvard University whose pioneering work in the physics of high pressures was rewarded with a Nobel Prize in 1946.[2] His chief scientific contribution was made possible by technical prowess: in his laboratory Bridgman created pressures nearly 100 times higher than anyone else had achieved before him, and investigated the novel behavior of various materials under such high pressures. But Bridgman was placed in a predicament by his own achievements: at such extreme pressures, all previously known pressure gauges broke down; how was he even to know what levels of pressure he had in fact reached? (see Kemble, Birch and Holton 1970) As he kept breaking his own pressure records, Bridgman had to establish a succession of new measures fit for higher and higher pressures. Therefore it is no surprise that he thought seriously about the groundlessness of concepts where no methods were available for their measurement.
Another important stimulus to his philosophical thinking was his encounter with the revolutionary new physics of the early 20th century. Bridgman's concerns about the definition and meaning of scientific concepts were forged in the general climate of shock suffered by physicists at that time from a barrage of phenomena and theoretical ideas that were entirely alien to everyday expectations, culminating with quantum mechanics and its “Copenhagen” interpretation. In a popular article, Bridgman wrote: “if we sufficiently extend our range we shall find that nature is intrinsically and in its elements neither understandable nor subject to law” (1929, 444).
Especially important for Bridgman's thinking was Albert Einstein's special theory of relativity. Bridgman credited an unexpected teaching assignment in 1914 for his first real encounter with special relativity, which gave him considerable distress as he tried to clarify the confusing conceptual situation surrounding the theory (Bridgman in Frank 1956, 76). At the heart of special relativity was Einstein's recognition that judging the simultaneity of two events separated in space required a different operation from that required for judging the simultaneity of two events happening at the same place. Fixing the latter operation was not sufficient to fix the former, so a further convention was necessary, which Einstein supplied in the form of his operation of sending light beams from each of the events in question to the midpoint between their locations, to see if they arrive there at the same time. How superior this way of thinking was, compared to Isaac Newton's declaration that he would “not define Time, Space, Place or Motion, as being well known to all” (quoted in Bridgman 1927, 4)! Bridgman felt that all physicists, including himself, had been guilty of unthinking extensions of concepts, especially on the theoretical side of physics.
Bridgman's sentiment arising out of these reflections, however, was not the familiar one of happy celebration of Einstein's genius. He rather regretted the sorry state of physics which had necessitated Einstein's revolution. Einstein showed what dangerous traps we could fall into by stepping into new domains with old concepts in an unreflective way. Anyone thinking in operational terms would have recognized from the start that the meaning of “distant simultaneity” was not fixed unless an operation for judging it was specified (Bridgman 1927, 10–16). In Bridgman's view, Einstein's revolution would never have been necessary, if classical physicists had paid operational attention to what they were doing. He thought that any future toppling of unsound structures would become unnecessary if the operational way of thinking could quietly prevent such unsound structures in the first place. Operational awareness was required if physics was not to be caught off-guard again as it had been in 1905: “We must remain aware of these joints in our conceptual structure if we hope to render unnecessary the services of the unborn Einsteins” (Bridgman 1927, 24).
Bridgman's impulse was to specify every possible detail of his operations, because any detail could make an important difference. Note the following passage, inspired by the shock of learning from the special theory of relativity that the measured length of an object was not independent of its velocity:
Now suppose we have to measure a moving street car. The simplest, and what we may call the “naïve” procedure, is to board the car with our meter stick and repeat the operations we would apply to a stationary body. Notice that this procedure reduces to that already adopted in the limiting case when the velocity of the street car vanishes. But here there may be new questions of detail. How shall we jump on to the car with our stick in hand? Shall we run and jump on from behind, or shall we let it pick us up in front? Or perhaps does now the material of which the stick is composed make a difference, although previously it did not? All these questions must be answered by experiment. (Bridgman 1927, 11; emphasis added)
Bridgman found that the challenges of the unknown were amply present even in very prosaic circumstances. Therefore he chose to open his discussion of operational analysis in The Logic of Modern Physics (Bridgman 1927) with the example of the most mundane of all scientific concepts: length. He was both fascinated and troubled by the fact that “essential physical limitations” forced scientists to use different measurement operations for the same concept in different domains of phenomena. Length is measured with a ruler only when we are dealing with dimensions that are comparable to our human bodies, and when the objects of measurement are moving slowly relative to the measurer. To measure, say, the distance to the moon, we need to infer it from the amount of time that light takes to travel that distance and return, and that is also the procedure taken up in Einstein's theorizing in special relativity; “the space of astronomy is not a physical space of meter sticks, but is a space of light waves” (Bridgman 1927, 67). For even larger distances we use the unit of “light-year,” but we cannot actually use the operation of sending off a light beam to a distant speck of light in the sky and waiting for years on end until hopefully a reflected signal comes back to us (or our descendants). Much more complex reasoning and operations are required for measuring any distances beyond the solar system:
Thus at greater and greater distances not only does experimental accuracy become less, but the very nature of the operations by which length is to be determined becomes indefinite…. To say that a certain star is 105 light years distant is actually and conceptually an entire different kind of thing from saying that a certain goal post is 100 meters distant. (Bridgman 1927, 17–18; emphasis original)
Thus operational analysis reveals that length is not one homogeneous concept that applies in the whole range in which we use it:
In principle the operations by which length is measured should be uniquely specified. If we have more than one set of operations, we have more than one concept, and strictly there should be a separate name to correspond to each different set of operations. (Bridgman 1927, 10; emphases original)
In practice scientists did not recognize multiple concepts of length, and Bridgman was willing to concede that it was allowable to use the same name to represent a series of concepts, if the different measurement operations gave mutually consistent numerical results in the areas of overlap:
If we deal with phenomena outside the domain in which we originally defined our concepts, we may find physical hindrances to performing the operations of the original definition, so that the original operations have to be replaced by others. These new operations are, of course, to be so chosen that they give, within experimental error, the same numerical results in the domain in which the two sets of operations may be both applied. (Bridgman 1927, 23)
However, such numerical convergence between the results of two different operations was regarded by Bridgman as merely a “practical justification for retaining the same name” for what the two operations measured (Bridgman 1927, 16).
Even in such convergent situations, we have to be wary of the danger of slipping into conceptual confusion through the use of the same word to refer to the subjects of different operations. If we do not temper our thoughts with the operationalist conscience always referring us back to concrete measurement operations, we may get into the sloppy habit of using one word for all sorts of different situations (without even checking for the required convergence in the overlapping domains). Bridgman warned: “our verbal machinery has no built-in cutoff” (1959a, 75). Similarly we could be misled by the representation of a concept as a number into thinking that there is naturally an infinitely extendable scale for that concept, since the real-number line continues on to infinity in both directions. It would also be easy to think that physical quantities must meaningfully exist down to infinite precision, just because the numerical scale we have pinned on them is infinitely divisible. Bridgman issued a stark reminder:
Mathematics does not recognize that as the physical range increases, the fundamental concepts become hazy, and eventually cease entirely to have physical meaning, and therefore must be replaced by other concepts which are operationally quite different. For instance, the equations of motion make no distinction between the motion of a star into our galaxy from external space, and the motion of an electron about the nucleus, although physically the meaning in terms of operations of the quantities in the equations is entirely different in the two cases. The structure of our mathematics is such that we are almost forced, whether we want to or not, to talk about the inside of an electron, although physically we cannot assign any meaning to such statements. (Bridgman 1927, 63)
Bridgman thus emphasized that our concepts did not automatically extend beyond the domains in which they were originally defined. He warned that concepts in far-out domains could easily become meaningless for lack of applicable measurement operations. The case of length in the very small scale makes that danger clear. Beyond the resolution of the eye, the ruler has to be given up in favor of various micrometers and microscopes. When we get to the realm of atoms and elementary particles, it is not clear what operations could be used to measure length, and not even clear what “length” means any more.
After introducing operational analysis with that refreshing discussion of the length concept, Bridgman published a long series of critical re-assessments of various fundamental physical concepts. His ruminations on length were extended into general commentary on the nature of space, and the concept of time received a similar treatment. His views on space and time were reminiscent of Henri Poincaré's and Pierre Duhem's: Bridgman noted that clocks had to be used in the empirical determination of the basic laws of physics, but our confidence that a clock ticks regularly was founded in the basic laws of physics governing its mechanism. Suppose we are trying to test the general theory of relativity by measuring the red-shift of light coming out of a heavy body:
If the vibrating atom is a clock, then the light of the sun is shifted toward the infra-red, but how do we know that the atom is a clock (some say yes, others no)? If we find the displacement physically have we thereby proved that general relativity is physically true, or have we proved that the atom is a clock, or have we merely proved that there is a particular kind of connection between the atom and the rest of nature, leaving the possibility open that neither is the atom a clock nor general relativity true? (Bridgman 1927, 72–73)
Bridgman found these reflections liberating as well as troubling. Basic space-time concepts are not uniquely determined a priori. For example, he noted that the definition of velocity shared in classical mechanics and special relativity was not the only one in line with our intuitions of what velocity meant. Consider this alternative: “a traveler in an automobile measures his velocity by observing the clock on his instrument board and the mile stones which he passes on the road.” If we adopt such a procedure we will find that the speed of light is infinite, if special relativity is correct about time dilation: with the car going at the speed of light according to an observer standing on the road, the clock on the car will not advance at all while the car passes any number of milestones. This alternative concept of velocity would have the advantage that “there would be no limit to the velocity which can be imparted to material bodies on giving them unlimited energy”, which seems intuitively “natural and simple”. But assigning an infinite velocity to light is also “most unnatural, particularly if we favor a medium point of view.” So there was a dilemma: “all sorts of phenomena cannot at the same time be treated simply.” (Bridgman 1927, 98–100)
In the latter parts of The Logic of Modern Physics Bridgman gave a fascinating array of discussions on the concepts of force, mass, energy, light, field, and more generally the theories of thermodynamics, relativity, and quantum mechanics. These thoughts were developed further in the remaining decades of his life, and collected in subsequent volumes including The Nature of Physical Theory (1936), The Nature of Thermodynamics (1941), Reflections of a Physicist (1950, second edition 1955), The Nature of Some of Our Physical Concepts (1952), and The Way Things Are (1959a). Bridgman made a searching examination of the familiar concepts of classical physics, checking to see if they retained operational meaning in domains of phenomena that were unfamiliar to the creators of classical physics. In some cases his analysis showed that the classical concepts were operationally unsound even in the contexts in which they were originally created. Later in life he stated that his initial foray into philosophy was motivated by his “disquietude” about physics, especially electrodynamics and thermodynamics, in which “the fundamental understanding of even the acknowledged leaders in physics were inadequate” (Bridgman 1959b, 519). In contrast, he thought that on the whole the contemporary development of quantum theory went in the right direction, especially in Werner Heisenberg's version of it, which discarded classical concepts where they did not apply (e.g., space-time orbits for electrons), and crafted new concepts with clear operational meaning in new domains of phenomena. However, he was not entirely satisfied with Niels Bohr's doctrine that all the operations of physics needed to be explained in the “macroscopic language of daily life or of present-day philosophy”; rather, he thought we needed to develop a “more adequate macroscopic language” (1959b, 526).
Interestingly, Bridgman never stopped thinking about relativity. The operationalist lesson he had taken from Einstein was so dear to him that he did not shrink from criticizing Einstein himself when the latter seemed to betray his own principles in the general theory of relativity. Already in The Logic of Modern Physics he had opined: “I personally question whether the elements of Einstein's formulation, such as curvature of space-time, are closely enough connected with immediate physical experience ever to be accepted as an ultimate in a scheme of explanation, and I very much feel the need for a formulation in more intimate physical terms” (1927, 176). Years later, when Bridgman was invited by P. A. Schilpp to contribute to the Library of Living Philosophers volume on Einstein, he issued the following “indictment” against Einstein: “he has carried into general relativity theory precisely that uncritical, pre-Einsteinian point of view which he has so convincingly shown us, in his special theory, conceals the possibility of disaster” (Bridgman in Schilpp 1949, 354; reprinted in Bridgman 1955, 337). Einstein brushed aside Bridgman's objection, merely stating that for a formal system to qualify as a physical theory it was “not necessary to demand that all of its assertions can be independently interpreted and ‘tested’ ‘operationally’” (Einstein in Schilpp 1949, 679). This exchange is reminiscent of the one that Heisenberg reported, in which Einstein responded with bemused incomprehension to Heisenberg's protest that he was following a lesson from Einstein in treating only directly observable quantities in his matrix mechanics (Heisenberg 1971, 62–69). Bridgman also carried out further operational analysis of special relativity, and his late thoughts on the subject were published posthumously in A Sophisticate's Primer on Relativity (1962).
Bridgman's critique of concepts in physics also led naturally to a philosophical critique of some general conceptions underlying physics, such as simplicity, atomism, causality, determinism, and probability. He also gave critical considerations to mathematics and its application to the physical world. There was no stone Bridgman was willing to leave unturned in his relentless critique. He went as far as to declare: “arithmetic, so far as it purports to deal with actual physical objects, is also affected with the same penumbra of uncertainty as all other empirical science” (Bridgman 1927, 34).
Among physicists Bridgman's reflections found a strong echo, especially in the early days. Perhaps that was natural: it has been said, by Bridgman himself too, that operationalism arose from observing “physicists in action” (Bridgman in Frank 1956, 80). Gerald Holton (1995a, 224) recalls what an “electrifying experience” it was for himself and many other physicists to read The Logic of Modern Physics for the first time. The explanation Holton gives of the “immense power” of Bridgman's work is “not that the work brings to the reader a message never thought of before, but that it lays open, with clarity, what the reader has been trying to formulate on his or her own”.
Bridgman also extended his operationalist thinking by considering its implications outside physics. This was important to him at least from the time of The Logic of Modern Physics, in which he ventured: “many of the questions asked about social and philosophical subjects will be found to be meaningless when examined from the point of operations. It would doubtless conduce greatly to clarity of thought if the operational mode of thinking were adopted in all fields of inquiry as well as in the physical” (30–32). To Bridgman it was clear that “to adopt the operational point of view … means a far-reaching change in all our habits of thought”. He knew that in practice this would be a very difficult thing to do: “Operational thinking will at first prove to be an unsocial virtue; one will find oneself perpetually unable to understand the simplest conversation of one's friends, and will make oneself universally unpopular by demanding the meaning of apparently the simplest terms of every argument”. Perhaps this throwaway remark was a sign of things to come, as Bridgman would in the end find himself rather isolated and plagued by misunderstanding, even among those who found his philosophical ideas worth discussing, as we will see in Section 2.
Bridgman did not develop in detail his operationalist ideas in relation to any other science than physics, apparently content to leave that job to the specialists in the respective fields. Some others did take up Bridgman's call for operationalist reformulations of their fields, with interesting consequences. It could be said that operationalism did not change the practice of physics itself much from what it already was, and the physicists followed him only as far as he asserted what was common sense to them. Matters were different in other sciences that paid attention to Bridgman, and that was most significant and pronounced in the case of psychology.
Behaviorist psychologists took up operationalism (or operationism, as it was more often called in psychology) as a weapon in their fight against more traditional psychologists, especially those who prized introspection as the most important source of psychological knowledge. The Harvard psychologist Edwin Boring (1886–1968) saw Bridgman's philosophy as a modern substitute for positivism, and he seems to have coined the term “operationism” (see Walter 1990, 178). It was Boring's student Stanley Smith Stevens (1906–1973) who was perhaps the most aggressive promoter of operationism in psychology (Hardcastle 1994; Feest 2005). Stevens saw operationism as a sure method of increasing rigor in psychological experiments and discourse, asserting that “to experience is, for the purpose of science, to react discriminately”, since these reactions are what science can measure and record publically (quoted in Feest 2005, 136). Echoing Bridgman's take on Einstein, Stevens declared in 1935: “The revolution that will put an end to the possibility of revolutions is the one that defines a straightforward procedure for the definition and validation of concepts. … Such a procedure is the one which tests the meaning of concepts by appealing to the concrete operations by which the concept is determined. We may call it operationism” (quoted in Walter 1990, 180).
In his concrete research in psychology Stevens focused on psychophysics, starting with his Ph.D. dissertation on the perceived attributes of tones, written under Boring's supervision. Another notable operationist in psychology was Edward Chace Tolman (1886–1959), also a Harvard Ph.D., who taught for most of his life at the University of California at Berkeley. Starting with his research on problem-solving behavior in rats, Tolman gave an operational treatment of desire, for example operationalizing hunger in terms of “time since last feeding”. Tolman did not deny that desire was a subjective feeling, but insisted that doing scientific research on it required experimentally tractable operations that would allow scientists to get a hold on something related to that subjective experience (see Feest 2005, 136–138). In Gustav Bergmann's assessment, operationism helped behaviorism to move from its initial metaphysical Watsonian variety to its modern version (Bergmann in Frank 1956, 53).
Despite the strong popularity of operationist behaviorism in certain quarters, it never commanded a complete consensus even in American psychology. Perhaps the most unexpected opposition came from Bridgman himself. Behaviorists were wanting to use operations to attain objectivity in psychology, which for them meant taking psychological discourse away from attempts to describe private experience. This was just the wrong move in Bridgman's view, as we will see in more detail in Section 2.4 below. Bridgman engaged in some discussion with Stevens but discovered that the latter's enthusiasm for “operational ideas” was really for something that he could not agree with. By 1936 he declared privately: “I have rather washed my hands of him” (quoted in Walter 1990, 184). Bridgman's disagreement with B. F. Skinner (1904–1990) was even more severe, and resulted in a prolonged dispute between the two (Holton 2005; Walter 1990, 188–192). Operationism became a subject of great controversy in psychology, epitomized in a 1945 special issue of the Psychological Review devoted to a symposium on operationism suggested by Boring, who remained supportive of the movement at some critical distance. To some limited extent this debate still continues in psychology (see Feest 2005).
Despite the initial popularity of Bridgman's ideas, by the middle of the 20th century the common reactions among philosophers and philosophically-minded scientists were strongly critical. Operationalism received many high-profile debates, among them a symposium held at the annual meeting of the American Association for the Advancement of Science (AAAS) in 1953 (published in Frank 1956), and the Psychological Review issue mentioned above. On such occasions Bridgman attempted to refine and defend his views, but also found that the debate was moving in directions that both surprised and disturbed him. In his contribution to the AAAS symposium he exclaimed:
There would seem to be no reason why I am better fitted than anyone else to open this discussion. As I listened to the papers I felt that I have only a historical connection with this thing called “operationalism.” In short, I feel that I have created a Frankenstein, which has certainly got away from me. I abhor the word operationalism or operationism, which seems to imply a dogma, or at least a thesis of some kind. The thing I have envisaged is too simple to be dignified by so pretentious a name. (Bridgman in Frank 1956, 75–76)
Still, arguably it was not Bridgman's own ideas about operational analysis but the Frankenstein of operationalism that had a more significant impact in philosophy and science, so this survey of operationalism must deal with how other people responded to operationalism as they saw it. In the course of the discussion I will try to point out some places where there were clear misunderstandings of Bridgman's ideas, and also other places where Bridgman himself was ambivalent or ambiguous, rather than simply misunderstood.
Given the timing and contexts of the publication of Bridgman's ideas, the philosophical debates surrounding them were to a large extent framed in relation to logical positivism, which was just making its big impact on the American philosophical scene. In fact, no less than Herbert Feigl (1902–1988) came to Harvard with the express purpose of learning from Bridgman, despite the latter's warning that he did not have much to teach (Walter 1990, 164–165). Bridgman's insistence on operational meaningfulness had at least a surface resemblance to the logical positivists' verification theory of meaning. Bergmann thought Bridgman had given a “scientist's version” of the latter (Bergmann in Frank 1956, 55), and Carl Hempel regarded operationalism and logical positivism as “closely akin” to each other (Hempel in Frank 1956, 56). And it is not difficult to see how a kindred philosophical doctrine coming from a world-class scientist would have captured the logical positivists' imagination.
When subjected to the scrutiny of professional philosophers, however, Bridgman's ideas were soon exposed as unsystematic and undeveloped, as he freely admitted himself. Moreover, it became evident that his ideas did not help logical positivists solve the key problems that they were struggling with. After the initial fascination, the standard positivist (and post-positivist) reaction to operationalism was disappointment, and operationalism was often seen as a failed philosophy that did not live up to its promises.
Nowhere was the positivist disappointment with Bridgman sharper than in considerations of operationalism as a theory of meaning. There was a set of objections which together amounted to a complaint that operational definitions did not give a sufficient account of the meaning of concepts, even where there were operations clearly relevant to the concepts in question.
The core of the problem here is an overly restrictive notion of meaning, which reduces it to measurement; I will call this Bridgman's reductive doctrine of meaning. Although Bridgman was not proposing a general philosophical theory of meaning, he did make remarks that revealed an impulse to do so. Consider the following statement, the last part of which I have already quoted:
We evidently know what we mean by length if we can tell what the length of any and every object is, and for the physicist nothing more is required. To find the length of an object, we have to perform certain physical operations. The concept of length is therefore fixed when the operations by which length is measured are fixed: that is, the concept of length involves as much as and nothing more than the set of operations by which length is determined. In general, we mean by any concept nothing more than a set of operations; the concept is synonymous with the corresponding set of operations. (Bridgman 1927, 5)
Similarly, he also displayed an impulse to use operations to make a criterion of meaningfulness: “If a specific question has meaning, it must be possible to find operations by which an answer may be given to it.” (Bridgman 1927, 28)
One lesson we can take from Bridgman's troubles is that meaning is unruly and promiscuous. The kind of absolute control on the meaning of scientific concepts that Bridgman wished for is not possible. The most control that can be achieved is for the scientific community to agree on an explicit definition and to respect it. But even firm definitions can only constrain the uses of a concept. The entire world can agree to define length by the standard meter in Paris (or by the wavelength of a certain atomic radiation), and that still comes nowhere near exhausting all that we mean by length. Bridgman himself later specifically admitted that his statement that meanings were synonymous with operations was “obviously going too far when taken out of context” (1938, 117). Especially compared with the notion of “meaning as use,” often traced back to the later phase of Ludwig Wittgenstein's work,[3] it is easy to recognize the narrowness of Bridgman's initial ideas. Bridgman's later gloss on his ideas was in fact rather late-Wittgensteinian: “To know the meaning of a term used by me it is evident, I think, that I must know the conditions under which I would use the term” (1938, 116). Since measurement operations provide only one specific context in which a concept is used, operational definitions can only cover one particular aspect of meaning.
Recognizing the restrictiveness of Bridgman's early remarks on meaning gives us a useful framework for understanding one common objection to operationalism. As Donald Gillies (1972, 6–7) emphasizes, if we accept the most extreme kind of operationalism, there is no point in asking whether a measurement method is valid; if the measurement method defines the concept and there is nothing more to the meaning of the concept, the measurement method is automatically valid, as a matter of convention or even tautology. Metrological validity becomes an interesting question only if the concept possesses a broader meaning than the specification of the method of its measurement. Then the measurement method can be said to be valid if it coheres with the other aspects of the concept's meaning. That way we may also make a judgment about whether an operational definition (or any other kind of definition) is an appropriate one, depending on how well it coheres with other elements of the concept's meaning and how beneficially it controls other elements of meaning.
So far I have noted that an operational definition is not sufficient to express a concept's meaning fully. Going further than that, many critics of operationalism have argued that not every good scientific concept needs to have an operational definition. If operationalism means demanding that every concept and every inferential step should have an immediate operational significance, it constitutes an overly restrictive empiricism. At times Bridgman did appear to be making such a demand, as illustrated in the poignant episode (discussed in Section 1.3 above) in which he criticized Einstein for betraying his own operationalist lesson in the general theory of relativity. Einstein's view was that there was no reason for physicists to shrink from using a non-operational concept if that delivered good results.
Einstein was self-consciously opportunistic in his methodological eclecticism, but philosophers wanted to find a more general rationale for freeing scientific theorizing from operationalist micro-management. The crux of the problem here for the operationalist is that theoretical concepts are much too useful in science. Bridgman actually acknowledged from early on that there were good theoretical concepts that were not amenable to direct operationalization, illustrating the point with the example of stress and strain inside a solid body (1927, 53–54), and the wavefunction in quantum mechanics (Bridgman in Frank 1956, 79). Bridgman saw clearly that these theoretical concepts only had indirect connections with physical operations, but he did not see any problems with that. He in fact went so far as to say: “there need be no qualms that the operational point of view will ever place the slightest restriction on the freedom of the theoretical physicist to explore the consequences of any free mental construction” (Bridgman in Frank 1956, 79). All that was required was that the theoretical system touched the operational ground somewhere, eventually. However, in that case Bridgman's message was the same as Einstein's, as the physicist R. B. Lindsay pointed out (Lindsay in Frank 1956, 71–72).
Bridgman's position on the matter of theoretical concepts was complicated, and perhaps not entirely self-consistent (I will return to this point in Section 3.3). One common objection to operationalism is based on a misunderstanding that reveals an essential difference between Bridgman and most of his critics. It is often said that operationalism cannot be right because each scientific concept can be measured in various ways. This criticism is based on the presumption that the concept in question has unity, which means that its definition must also be unified. If there are a variety of measurement methods all of which apply to one concept, then measurement methods cannot be what supplies the unified definition; instead, some theoretical account must be given as to how the variety of operations under consideration serve to measure the same thing. Bridgman, in contrast, had no such presumption of conceptual unity. For him, the initial position to take was that if there are different methods of measurement we have different concepts, as he said about “tactual” and “optical” length being two different concepts. Now, it could be that there is one aspect of reality that different measurement operations all get at, but that is something to be demonstrated, not to be assumed at the outset. The possibility of unity can be entertained if the minimum condition of numerical convergence is met—that is, if two measurement operations have an overlapping range and their results agree in the overlap. Still, Bridgman maintained some skepticism about whether it was safe for us to infer real conceptual unity from such numerical convergence.
Bridgman's ambivalence about conceptual unity elicited a serious worry about the systematic import of scientific concepts and theories, most astutely expressed by Hempel (1966, 91–97). Bridgman's skeptical caution would result in an intolerable fragmentation of science, Hempel argued. It would result in “a proliferation of concepts of length, of temperature, and of all other scientific concepts that would not only be practically unmanageable, but theoretically endless.” Hempel's worry was that Bridgman's quest for safety was blinding him to one of the ultimate aims of science, “namely the attainment of a simple, systematically unified account of empirical phenomena” (Hempel 1966, 94). Along similar lines, Lindsay (1937, 458) had earlier argued that “such an isolation of concepts would defeat the very aim of physical science, which is to provide a simple and economical description” of physical experience “in terms of a minimum number of concepts”. Bridgman had serious doubts about the plausibility of such a simple, unified account of nature, as I will explain further in Section 3.4. But Hempel and others could genuinely envisage it. Hempel noted that with the development of science there was a continually growing and thickening network of “nomic threads” linking various “knot-concepts” with each other as further empirical laws were discovered. Hempel argued that it was essential to keep this thickening conceptual network systematic and simple; to that end, “concept formation and theory formation must go hand in hand” (Hempel 1966, 97). That, in turn, often necessitated “a modification of the operational criteria originally adopted for some of the central concepts” (Hempel 1966, 95). Operationalism would stand in the way of such flexibility.
Apart from the questions of whether operational definitions are sufficient or necessary, it is actually unclear what types of things operations are, and how they should be specified. The surface-level intuition is simple: the operations that matter are measurement operations involving physical instruments. But from the start Bridgman (1927, 5) also stated that the operations which fixed meaning were mental if the concepts in question were mental (e.g., in mathematics). And he knew that measurement operations involved more than physical manipulations of instruments; at least there are recordings and computations involved in the processing and analysis of data, and there are mental acts linking various parts of that complex procedure, too. To take the simplest example, the operation of counting is a mental operation, but it is an integral part of many “physical” procedures. He called such crucial non-physical operations “paper-and-pencil” operations. Bridgman lamented that it was the “most wide spread misconception with regard to the operational technique” to think that it demanded that all concepts in physics must find their meaning only in terms of physical operations in the laboratory (Bridgman 1938, 122–124; also Bridgman 1959b, 522). Later he gave a rough classification of operations into the instrumental, mental/verbal, and paper-and-pencil varieties (Bridgman 1959a, 3).
This issue becomes sharper when we ask the question of purpose: what are the aims of operational analysis, and which operations are suitable for achieving those aims? Having distinguished various types of operations, Bridgman also had to deal with the question of whether different types had different epistemic values, going beyond his initial intuitive fondness for instrumental operations. For example, if the point of operationalizing a concept was to make its meaning clear and precise, which meant using “operations which can be unequivocally performed” (Bridgman 1938, 119), then why were paper-and-pencil operations such as the construction of Euclidean geometric figures not just as good as instrumental operations? In the end he was willing to dispense with any ultimate privileging of instrumental operations. But he still maintained a preference for them when possible, without giving a convincing reason for that preference (Bridgman 1938, 127).
Thus Bridgman's position on the nature and function of operations was uneasy from start to finish. Various critics rightly zeroed in on this point. The most important point of contention was whether and why physical or instrumental operations had any special epistemic advantage. The Yale physicist Henry Margenau put the point succinctly:
Operationalism is an attitude that emphasizes the need of recourse, wherever feasible, to instrumental procedures when meanings are to be established. Bridgman disavows its status as a philosophy, and wisely so, for as a general view …. it cannot define the meaning of “instrumental procedure” in a manner that saves the view from being either trivial (which would be true if “instrumental” were construed to include symbolic, mental and paper-and-pencil operations) or too restrictive (if all operations are to be laboratory procedures). (Margenau in Frank 1956, 45)
As one can imagine, this dilemma also hampered attempts to use operational analysis in psychology. Operations in psychological research inevitably involved verbal instructions, reports and reactions. It was difficult to argue that these mental or verbal operations were superior in reliability or meaningfulness to the introspective reporting of mental states, which operationists tried so hard to exclude from scientific psychology.
Bridgman himself was troubled by the question regarding the nature of operations and admitted late in his life that he had not really provided “an analysis of what it is that makes an operation suitable”, or “in what terms can operations be specified” (Bridgman in Frank 1956, 77). An even deeper pessimism was expressed in Bridgman's 30-year retrospective on The Logic of Modern Physics, commissioned for Daedalus by Holton: “To me now it seems incomprehensible that I should ever have thought it within my powers … to analyze so thoroughly the functioning of our thinking apparatus that I could confidently expect to exhaust the subject and eliminate the possibility of a bright new idea against which I would be defenseless” (Bridgman 1959b, 520).
One last issue needs to be mentioned, before I complete the discussion of the critique of operationalism: the privacy of operations. This is perhaps not widely remembered now, but it was the issue on which Bridgman's position elicited the most severe incomprehension and objection, even from many who called themselves operationalists.
The emblematic moment in this dispute came during the 5th International Congress for the Unity of Science in 1939, held at Harvard University—one of the highpoints of the activities of the “Vienna Circle in exile” in America (see Holton 1995b). Bridgman was invited to address this conference, and chose to give a talk entitled “Science: Public or Private?”.[4] At this point it became clear that his enterprise was fundamentally at odds with the logical positivist project, despite the surface kinship:
The process that I want to call scientific is a process that involves the continual apprehension of meaning, the constant appraisal of significance, accompanied by a running act of checking to be sure that I am doing what I want to do, and of judging correctness or incorrectness. This checking and judging and accepting that together constitute understanding are done by me, and can be done for me by no one else. They are as private as my toothache, and without them science is dead. (Bridgman 1955, 56)
Positivists and behaviorists had embraced operationalism for precisely the opposite reason: they thought operations were public, objective and verifiable, unlike private experience. But Bridgman was insistent that operations were a matter for private experience. He could see no warrant in simply taking someone else's testimony as true or reliable, or in regarding the report of an operation performed by someone else as the same kind of thing as an operation performed and experienced by himself. In a later paper called “New Vistas for Intelligence” he declared: “Science is not truly objective unless it recognizes its own subjective or individual aspects” (Bridgman 1955, 556). As Holton puts it (2005, 74), Bridgman's drive in operational analysis was “to throw the spotlight on performable action, above all an action performed by himself. Ultimately, he was a private man, so much so that he was accused of solipsism, to which he scarcely objected.” In his epistemic individualism Bridgman was perhaps only matched by Herbert Dingle among notable 20th-century philosophers of science (see Dingle 1950).
Bridgman's individualistic bent, both in epistemology and social life, was in stark contrast to the logical positivist vision of knowledge and society, particularly the strand of positivism driven by Otto Neurath (1882–1945). The latter's aversion to the private compelled him to express even first-hand observation reports as third-person happenings in space and time, of the following type: “Otto's protocol at 3:17 o'clock: [Otto's speech-thinking at 3:16 o'clock was: (at 3:15 o'clock there was a table in the room perceived by Otto)].” (Neurath [1932–33] 1983, p. 93). Bridgman was unyielding in his opposition to Neurath's type of objectification of personal experience. To him, operations provided the best possible refuge from the ocean of uncertainty always threatening to engulf science, and the relative certainty was only possible if he was learning from his own operations, not from second-hand reports from some other person. In this regard Bridgman was closer to the strand of logical positivism represented by Moritz Schlick (1882–1936), who insisted on maintaining the notion of direct experience as the final arbiter of knowledge. Schlick ([1930] 1979) admitted that experience was fleeting and only provided momentary points of verification rather than any lasting “foundation” one could build knowledge on. Bridgman's operations had more promise in this regard, as the operations were meant to be repeatable so the descriptions of operations and their results would be lasting. However, that was not to be such a straightforward matter, as we will see in Section 3.4.
As Holton (1995a; 2005) reports from his first-hand observations of Bridgman, the privacy of operations (and the consequent privacy of science) was not an idle philosophical doctrine. In the lab he carried out as much of the work as possible with his own hands, using few assistants and crafting most of his instruments himself. Holton (1995a, 222–223) quotes the following report as typical of the way Bridgman worked: “It is easy, if all precautions are observed, to drill a hole … 17 inches long, in from 7 to 8 hours”—that is, a hole as narrow as the lead in a pencil, in a block of very hard steel. In academic life Bridgman (1955, 44) openly lamented the “intellectual fashion … of emphasizing that all our activities are fundamentally social in nature”. As for his social and political writings, they were often agonizing attempts to clarify, for himself, the place of the “intelligent individual” in society. He was unabashedly elitist, both on behalf of the gifted individual and of scientists as a group, and argued that giving appropriate special treatment to scientists would in the end benefit society (that is, all the individuals in society). Maila Walter observes (1990, 192–193): “Within the community of scientists and scientific philosophers, Bridgman had become the lone spokesman for a radical existential subjectivism”, more akin to Rheinhold Niebuhr's existentialist theology than to any commonly recognized philosophy of science. Bridgman's uncompromising individualism continued right to the end, with a self-administered euthanasia in the late stage of a painful terminal illness (see Holton 1995a, 226–227).
Is operationalism only a historical curiosity? In this final section, I would like to give a synoptic view of the relevance of operationalism to some issues that are current in philosophy of science.
As already noted, Bridgman's ideas first gained recognition in the midst of the logical-positivist preoccupation with language and meaning; therefore, operationalism was taken primarily as a doctrine about meaning and, as such, shown to be inadequate. In that context, it was reasonable for most philosophers to abandon it. Bridgman made various attempts to get beyond the popular caricature of operationalism adopted by advocates and critics alike. These attempts never received sufficient attention, but they offer some valuable lessons and show many productive directions in which his views can be interpreted and extended.
It is useful to continue listening to his retrospective given in the 1953 AAAS conference, quoted earlier. Bridgman tells us that what he advocated was merely:
an attitude or point of view generated by continued practice of operational analysis. So far as any dogma is involved here at all, it is merely the conviction that it is better, because it takes us further, to analyze into doings or happenings rather than into objects or entities. (Bridgman in Frank 1956, 76)
Already in his paper on “Operational Analysis” Bridgman (1938, 115–116) had stated that in the attempt to understand how science works, “the subject matter … is activity of one sort or another”. He equated “activity” and “operations”, the term “operation” only accentuating the directedness of the activity in question. In his last general philosophical treatise, The Way Things Are, Bridgman came back to this theme and stated that an operational analysis was only “a particular case of an analysis in terms of activities—doings or happenings”, instead of analysis “in terms of objects or static abstractions”, or “in terms of things or static elements” (1959a, 3; also 1959b, 522).
If we take our inspiration from this later Bridgman, we can take him as a guide for a new practice-oriented philosophy of science. We can put aside his reductive doctrine of meaning, his puritanical search for certainty, and his ambivalent privileging of instrumental operations over other types of operations. What Bridgman started up but never quite accomplished in a systematic and complete way was a philosophical analysis of science in terms of activities. Operations provide the philosopher (and the historian) of science with a very useful unit of analysis: actions or events, as opposed to objects, statements, beliefs, theories, paradigms, research programs, etc. The concept of operation should provide an effective framework for incorporating certain highly valuable insights about the nature of scientific practice, including the ideas of Ludwig Wittgenstein (1953) on language-games, Michael Polanyi (1958) on tacit knowledge, Marjorie Grene (1974) on the knowing agent, and Ian Hacking (1983) on direct interventions in experimental investigations.
In order to develop Bridgman's operational analysis into a full-fledged philosophy of scientific practice, there are some aspects of his thought that we need to develop and articulate further. First of all, we need a clearer and more detailed taxonomy of operations, without trying to say which types are better or worse at the outset. From this point of view it should not be regarded as a problem or an annoyance that there are different types of operations. The categories offered by Bridgman are much too broad, so we need to identify and describe specific and concrete operations, and distinguish simple and elementary ones from more complex ones. For example, the operation of length measurement with a meter-stick would be analyzable into the instrumental operations of alignment and concatenation, the perceptual operation of judging spatial coincidence, and the mental operation of counting. The operation of hypothesis-testing (in the “received view”) would be analyzable into the simpler operations of deductive prediction, experimental observation, and the comparison between deduced and observed outcomes. In the understanding of these operations we would need a detailed account of the scientist as the agent who performs the operations; here we return to Bridgman's preoccupation with the free individual, but also in essential social interaction with other individuals. A full understanding of operations would require an understanding of the agent's purposes (partly based on the fundamental aims of science), assumptions (including metaphysical principles essential for the particular type of activity in question), and skills and capabilities (including the tacit dimension). If we can achieve such a thick description of the operations that constitute scientific practice, we would be able to make good on Bridgman's promise that “it is better, because it takes us further, to analyze into doings or happenings rather than into objects or entities.”
Above I have presented a new operationalism as a promising framework for the analysis of scientific practice. Do Bridgman's ideas and attitudes also hold any current relevance for scientific practice itself? He did intend to reform scientific practice itself, not just its second-order analysis, so we must ask whether his reformist agenda has anything left in it for current science. To the casual reader, much of Bridgman's writing will seem like a series of radical complaints about the meaninglessness of various concepts and statements. But he was not interested in skeptical critique as an idle philosophical exercise. He got most worried when a concept was being extended to new situations where the familiar operations defining the concept ceased to be applicable. His arguments often had an iconoclastic flavor because he was exceptionally good at recognizing where a concept had been extended to new domains unthinkingly and most people were not even aware that the extension had been made. From the methodological lesson he took from Einstein to the insights gained in his own high-pressure physics, an important focus of Bridgman's operationalism was on regulating the extension of concepts to uncharted domains.
Bridgman reminded us forcefully that measurement operations did not have unlimited domains of application, and that our conceptual structures consequently had “joints” at which operational meanings changed. But there can be no “joints” if there is no continuous tissue around the disjointed bones. Less metaphorically: if we reduce meaning entirely to measurement operations, there are no possible grounds for assuming or demanding any continuity of meaning where there is clear discontinuity in measurement operations. When we have two different operations which give convergent results in the overlapping domain, how do we tell whether what we have is an accidental convergence of the measured values of two unrelated quantities, or a unified concept measured by two different methods? Some critics have maintained that only a recourse to theories can give us the answer (e.g., Lindsay 1937, 458; Gillies 1972, 23). That does not seem to me always necessary, as theory is not the only source of semantic continuity. There are instrumental operations that are not metrological, and these operations can provide a continuity of meaning, against which metrological validity can be judged (see Section 2.1). We can take operationalism as a useful and practicable caution not to make conceptual extensions without operational grounds.
A homespun example from the 18th century illustrates this point nicely: the efforts of the English potter Josiah Wedgwood (1730–1795) to extend the temperature scale to cover the very high temperatures in his kilns, at which mercury vaporized and glass melted. All previously known thermometers failed in that pyrometric range, so Wedgwood felt obliged to invent a whole new measurement standard (reminiscent of Bridgman in his high-pressure laboratory). Wedgwood noticed that very high temperatures made pieces of clay shrink, and created a temperature scale by assuming that the amount of contraction was proportional to temperature beyond “red heat”. As the start of his scale (red heat, defined as 0) was already beyond the boiling point of mercury, Wedgwood's scale was wholly disconnected from the temperature scale defined by mercury thermometers. Later, in response to widespread demand to clarify the meaning of his scale in more usual terms, Wedgwood made a translation of his scale into Fahrenheit degrees, by means of an intermediate standard (thermal expansion of silver) which overlapped with the high end of the mercury scale and the low end of the clay scale. (This process produced some unlikely numbers, for example 21,877°F for the temperature of his air-furnace.) It seems that Wedgwood initially did exactly what operationalist conscience would dictate: as the new instrument did not operate at all in the range of any trustworthy previous thermometers, he made a fresh scale. Why was that not the honest thing to do, and quite sufficient, too? Why did everyone, including Wedgwood himself, feel compelled to interpret the Wedgwood clay scale in terms of the mercury-Fahrenheit scale? Why was a continuous extension desired so strongly, when a disjointed set of operations seemed to serve all necessary practical purposes?
The urge for conceptual extension, in the Wedgwood case, was rooted in a widespread feeling that there was a property in the pyrometric range that was continuous in its meaning with temperature in the everyday range. Where did that feeling come from, long before there was any well-defined and agreed-upon theoretical concept of temperature? If we look closely at the situation, numerous subtle and often-unspoken connections do emerge between pyrometric temperature and everyday temperature. In the first place, we do bring objects to pyrometric domains by prolonged heating—that is to say, by a prolonged application of ordinary processes that cause the rise of temperature within the everyday domain. Likewise, the same causes of cooling that operate in the everyday domain will bring objects from pyrometric temperatures down to everyday temperatures; that is precisely what happens in calorimetric pyrometry (or, when we simply leave very hot things out in cold air for a while). These concrete physical operations provide a continuity of operational meaning between two domains that are not connected by a common measurement standard. Here again we need to articulate something that Bridgman already did imply: not all instrumental operations are measurement operations as such (for instance, we may know how to make iron melt without thereby obtaining any precise idea of the temperature at which that happens). Operational meaning even in the narrow, instrumental sense is broader than meaning specified by methods of measurement.
The connections listed above rest on very basic qualitative causal assumptions about temperature: fire raises the temperature of any ordinary objects on which it acts directly; if two objects at different temperatures are put in contact with each other, their temperatures tend to approach each other. There are semi-quantitative links as well. It is taken for granted that the consumption of more fuel should result in the generation of more heat, and that is partly based on a primitive notion of energy conservation. It is assumed that the amount of heat communicated to an object is roughly proportional to the amount of change in its temperature (barring changes of state and interfering influences), and that assumption is based on the rough but robust understanding of temperature as the “degree of heat.” So, for example, when a crucible is put on a steady fire, one assumes that the temperature of its contents will rise steadily, up to a certain maximum. That is exactly the kind of reasoning used by the chemist John Frederic Daniell (1790–1845) to criticize some of Wedgwood's results:
Now, any body almost knows, how very soon silver melts after it has attained a bright red heat, and every practical chemist has observed it to his cost, when working with silver crucibles. Neither the consumption of fuel, nor the increase of the air-draught, necessary to produce this effect, can warrant us in supposing that the fusing point of silver is 4 1/2 times higher than a red heat, fully visible in day-light. Neither on the same grounds, is it possible to admit that a full red-heat being 1077°[F], and the welding heat of iron 12,777°[F], that the fusing point of cast iron can be more than 5000° higher. The welding of iron must surely be considered as incipient fusion. (quoted in Chang 2004, 149)
Similar types of rough assumptions were also used in the extension of temperature to very low temperatures (beyond the freezing point of mercury and alcohol).
These cases illustrate that concepts can and do get extended to fresh new domains in which theories are uncertain and experience scant, even if no definite measurement operations have been worked out. We start with a concept with a secure net of uses giving it stable meaning in a restricted domain of circumstances. The extension of such a concept consists in giving it a secure net of uses, also credibly linked to the earlier net, in an adjacent domain. Such extension can happen in all kinds of ways, including theoretical fiat and metaphysical presumption, but the operational method is the most assured one. Specific, well-defined operations, whether they be instrumental, mental or paper-and-pencil type, can start a secure skeleton of meaning in the new domain. With all the elements of new meaning operationally well-defined, it also becomes possible to attempt linking them up with each other at each step along the way and check the whole meaning for coherence. (Compare such a deliberate process with the vague presumption that terms in a theoretical equation must have the same meaning in the entire mathematical range given to the variables.) Operationalism in this guise can be used as a secure method of conceptual extension, not prone to the kind of fragmentation that Hempel feared. Such operationalism would not destroy systematic unity; on the contrary, it is an optimal strategy for achieving as much systematic unity as nature would allow, in a strongly empiricist system of knowledge.
Conceptual extension is important, especially since it served as one of the key initial motivations of Bridgman's thought, but it is only part of the operationalist story. In more general terms, operationalism can be seen as a strategy for increasing the empirical content of scientific theories. Empirical content is not something we hear about very much these days in philosophy of science after the receding of Popperian and Lakatosian doctrines, but for Bridgman it was one of the key issues. If we take operationalism as a commitment to increase empirical content, Bridgman was not so much a high-handed judge who pronounced upon the meaningfulness of concepts in a black-and-white manner. Rather, he offered operational analysis as a tool of self-diagnosis and self-improvement. He was interested in advancing science, not in carping against it; like Descartes, he used skepticism as a means of achieving a more positive end. The operationalist dictum could be phrased as follows: maintain and increase the empirical content of theories by the use of operationally well-defined concepts.
What is empirical content? Karl Popper saw the amount of the empirical content of a theory as the number of states of the world that are forbidden by it. Regarding laws of nature he said: “the more they prohibit they more they say” (Popper 1972, 41). Or, somewhat more formally: “I define the empirical content of a statement p as the class of its potential falsifiers” (120). Similarly but staying away from the strict falsificationist idiom, Imre Lakatos understood empirical content as the number of empirically testable predictions. It is difficult to craft an exact quantitative measure, but we can at least say that the amount of empirical content depends on the number of empirically testable relations that a theory specifies. That, in turn, depends on the number of independently measurable parameters. Increasing the latter, or at least maintaining it, was something that Bridgman sought to achieve with his operationalism. This, I submit, was one of the key reasons why he did not like conceptual extensions that were not backed up by measurement operations in the new domain. To follow Bridgman's thinking along these lines, consider this intriguing passage, which at first glance looks like another complaint about meaninglessness. But towards the end the main point emerges as a worry about diminishing empirical content:
What is the possible meaning of the statement that the diameter of an electron is 10-13 cm? Again the only answer is found by examining the operations by which the number 10-13 was obtained. This number came by solving certain equations derived from the field equations of electrodynamics, into which certain numerical data obtained by experiment had been substituted. The concept of length has therefore now been so modified as to include that theory of electricity embodied in the field equations, and, most important, assumes the correctness of extending these equations from the dimensions in which they may be verified experimentally into a region in which their correctness is one of the most important and problematical of present-day questions in physics. To find whether the field equations are correct on a small scale, we must verify the relations demanded by the equations between the electric and magnetic forces and the space coördinates, to determine which involves measurement of lengths. But if these space coördinates cannot be given an independent meaning apart from the equations, not only is the attempted verification of the equations impossible, but the question itself is meaningless. If we stick to the concept of length by itself, we are landed in a vicious circle. As a matter of fact, the concept of length disappears as an independent thing, and fuses in a complicated way with other concepts, all of which are themselves altered thereby, with the result that the total number of concepts used in describing nature at this level is reduced in number.[6] (Bridgman 1927, 21–22)
Such a reduction in the number of operationally meaningful concepts is almost bound to result in a corresponding reduction in the number of relations that can be tested empirically. A good scientist would fight against such a reduction of empirical content.
This concern with empirical content also explains why Bridgman was not content with the mainstream post-positivist philosophical discourse on concept-formation and empirical significance, exemplified by the works of Carl Hempel and Willard Van Orman Quine. As noted in Section 2.2, Bridgman did not object to theoretical science creating a system of concepts and laws that made contact with observations only at some points. However, Quinean holism, in which the unit of empirical significance was the entire system of knowledge, had no particular concern about increasing the number of those points-of-contact with experience. Bridgman's ideal was to operationalize each and every concept if possible, and each case of de-operationalization rang alarm bells in his head.
Recognizing the importance of empirical content helps us make sense of Bridgman's complex attitude toward theoretical concepts. In a little-known section of The Logic of Modern Physics, he discussed what he called “mental constructs” in science, particularly those created in order to “enable us to deal with physical situations which we cannot directly experience through our senses, but with which we have contact indirectly and by inference” (1927, 53–60). Not all constructs are the same:
The essential point is that our constructs fall into two classes: those to which no physical operations correspond other than those which enter the definition of the construct, and those which admit of other operations, or which could be defined in several alternative ways in terms of physically distinct operations. This difference in the character of constructs may be expected to correspond to essential physical differences, and these physical differences are much too likely to be overlooked in the thinking of physicists. (Bridgman 1927, 59–60)
They were also very easily overlooked in the thinking of philosophers who debated his ideas. What Bridgman says here is entirely contrary to the common image of his doctrines. When it came to constructs, “of which physics is full,” Bridgman not only admitted that one concept could correspond to many different operations, but even suggested that such multiplicity of operational meaning was “what we mean by the reality of things not given directly by experience.” In an illustration of these ideas, Bridgman argued that the concept of stress within a solid body had physical reality, but the concept of electric field did not, since the latter only ever manifested itself through force and electric charge, by which it was defined (Bridgman 1927, 57). This comes down to the stance that a theoretical concept without direct operational meaning is worthwhile only if it serves as a mediator connecting two or more operationally meaningful concepts, creating an empirically testable relation. This is in fact not so different from Hempel's view quoted in Section 2.2, albeit with a different emphasis.
In closing, I would like to pull out an insight from Bridgman that is usually not recognized in discussions of operationalism, but actually has emerged as a significant point of contention in more recent philosophy of science. This is the issue of complexity. In Section 1.1 I have already quoted Bridgman's puzzling statement that nature is ultimately “neither understandable nor subject to law.” As it turns out, that was not an isolated off-hand remark. An important aspect of Bridgman's operationalism was a search for certainty, and it was a search made all the more desperate by a deep-rooted pessimism about the possibility of attaining any certainty in science, at least if scientists were to seek a simple and unified system of knowledge. Bridgman professed his belief that “the external world of objects and happenings is … so complex that all aspects of it can never be reproduced by any verbal structure.” He lamented: “Even in physics this is not sufficiently appreciated, as is shown, for example, by the reification of energy. The totality of situations covered by various aspects of the energy concept is too complex to be reproduced by any simple verbal device.” (Bridgman in Frank 1956, 78)
Bridgman's view on the complexity of nature also had a direct implication for the limits of operational analysis itself in providing clarity and precision. Right from The Logic of Modern Physics, Bridgman stressed that “all results of measurement are only approximate”; this obvious fact, he said, “tacitly underlies all our discussion”. This he attributed ultimately to something fundamental about the nature of human experience: “all experience seems to be of this character; we never have perfectly clean-cut knowledge of anything, but all our experience is surrounded by a twilight zone, a penumbra of uncertainty, into which we have not yet penetrated. This penumbra is as truly an unexplored region as any other region beyond experiment” (1927, 33). This indicated a fundamental limitation to the certainty of operations: “Operations themselves are, of course, derived from experience, and would be expected also to have a nebulous edge of uncertainty” (1927, 36). Bridgman remained clearly aware of the complexities revealed by operational analysis, stating late in his life that “operational analysis can always be pushed to the point where sharpness disappears” (Bridgman in Frank 1956, 78), and that “there is nothing absolute or final about an operational analysis” (Bridgman 1959b, 522). Still, he would not give up on the pushing, which was necessary to reach as much clarity as possible.
Bridgman's battle against his own skeptical and pessimistic conscience was a heroic one. After decades of operationalist thinking he arrived at “a picture of man isolated … in an oasis of phenomena which he will never be able to transcend because beyond its bounds the operations are impossible which are necessary to give meaning to his thought” (Bridgman 1955, 540). What this picture forced on him was a deep sense of humility, as expressed in his memorable statement on the scientific method: “The scientific method, as far as it is a method, is nothing more than doing one's damnedest with one's mind, no holds barred” (1955, 535). Retaining that sense of humility will help us in developing Bridgman's unfinished thoughts to create a new operationalism that does full justice to the complexity and richness of both nature and human scientific practice.
Allen, Harold J. 1980. “P. W. Bridgman and B. F. Skinner on Private Experience”, Behaviorism 8: 15–29.
Boring, Edwin G., et al. 1945. “Symposium on Operationism”, The Psychological Review 52: 241–294. Authors in this symposium include Edwin G. Boring, P. W. Bridgman, Herbert Feigl, Harold E. Israel, and B. F. Skinner. For simplicity I have given “Boring 1945” as the citation in referring to the papers in this symposium, with the author of the individual article clearly indicated in the text in each case.
Bridgman, Percy Williams. 1927. The Logic of Modern Physics. New York: Macmillan.
–––. 1929. “The New Vision of Science”, Harper's 158: 443–454. Also reprinted in Bridgman 1955, pp. 81–103.
–––. 1936. The Nature of Physical Theory. New York: Dover.
–––. 1938. “Operational Analysis”, Philosophy of Science 5: 114–131. Also reprinted in Bridgman 1955, pp. 1–26.
–––. 1941. The Nature of Thermodynamics. Cambridge, Mass.: Harvard University Press.
–––. 1949. “Einstein's Theories and the Operational Point of View”, in P. A. Schilpp, ed., Albert Einstein: Philosopher-Scientist (La Salle, Illinois: Open Court), 333-354. Also reprinted in Bridgman 1955, pp. 309–337.
–––. 1952. The Nature of Some of Our Physical Concepts. New York: Philosophical Library. Reprinted from the British Journal for the Philosophy of Science 1 (1950): 257–272; 2 (1951): 25–44, 142–160.
–––. 1955. Reflections of a Physicist. New York: Philosophical Library. This collection of essays was originally published in 1950; the 1955 edition includes some additional papers.
–––. 1958. “Quo Vadis”, in Gerald Holton, ed., Science and the Modern Mind (Boston: Beacon Press), 83–91.
–––. 1959a. The Way Things Are. Cambridge, Mass.: Harvard University Press.
–––. 1959b. “P. W. Bridgman's ‘The Logic of Modern Physics’ after Thirty Years”, Daedalus 88: 518–526.
–––. 1962. A Sophisticate's Primer on Relativity. Middletown, Conn.: Wesleyan University Press.
Chang, Hasok. 2004. Inventing Temperature: Measurement and Scientific Progress. New York: Oxford University Press.
Dingle, Herbert. 1950. “A Theory of Measurement”, British Journal for the Philosophy of Science 1: 5–26.
Feest, Uljana. 2005. “Operationism in Psychology: What the Debate Is About, What the Debate Should Be About”, Journal of the History of the Behavioral Sciences 41(2): 131–149.
Frank, Philipp G., ed. 1956. The Validation of Scientific Theories. Boston: Beacon Press; reprinted in 1961 by Collier Books, New York. Chapter 2 of this volume contains papers arising from the symposium on “The Present State of Operationalism” at the annual meeting of the American Association for the Advancement of Science in Boston in December 1953, co-sponsored by the Institute for the Unity of Science and the Philosophy of Science Association. Authors in this symposium include Henry Margenau, Gustav Bergmann, Carl G. Hempel, R. B. Lindsay, P. W. Bridgman, Raymond J. Seeger, and Adolf Grünbaum.
Gillies, Donald A. 1972. “Operationalism”, Synthese 25: 1–24.
Grene, Marjorie. 1974. The Knower and the Known. Berkeley and Los Angeles: University of California Press.
Hacking, Ian. 1983. Representing and Intervening. Cambridge: Cambridge University Press.
Hardcastle, Gary L. 1995. “S. S. Stevens and the Origins of Operationism”, Philosophy of Science 62: 404–424.
Heisenberg, Werner. 1971. Physics and Beyond, trans. by A. J. Pomerans. London: George Allen & Unwin.
Hempel, Carl G. 1966. Philosophy of Natural Science. Englewood Cliffs, N.J.: Prentice-Hall.
Holton, Gerald. 1995a. “Percy W. Bridgman, Physicist and Philosopher”, in Einstein, History, and Other Passions (Woodbury, N.Y.: American Institute of Physics Press), pp. 221–227.
–––. 1995b. “On the Vienna Circle in Exile: An Eyewitness Report”, in W. DePauli-Schimanovich et al., eds., The Foundational Debate (Dordrecht: Kluwer), pp. 269–292.
–––. 2005. “B. F. Skinner, P. W. Bridgman, and the ‘Lost Years’,” in Victory and Vexation in Science (Cambridge, Mass.: Harvard University Press), pp. 65–80.
Horwich, Paul. 1998. Meaning. Oxford: Oxford University Press.
Kemble, Edwin C., Francis Birch, and Gerald Holton. 1970. “Bridgman, Percy Williams”, The Dictionary of Scientific Biography, 2: 457–461.
Lindsay, R. B. 1937. “A Critique of Operationalism in Physics”, Philosophy of Science 4: 456–470.
Moyer, Albert E. 1991. “P. W. Bridgman's Operational Perspective on Physics”, Studies in History and Philosophy of Science 22: 237–258, 373–397.
Neurath, Otto. [1932–33] 1983. “Protocol Statements”, in Philosophical Papers 1913–1946, ed. and trans. by Robert S. Cohen and Marie Neurath (Dordrecht: Reidel), pp. 91–99.
Polanyi, Michael. 1958. Personal Knowledge. Chicago and London: University of Chicago Press.
Popper, Karl R. 1972. The Logic of Scientific Discovery, 3rd ed. London: Hutchinson.
Schilpp, Paul Arthur. 1959. Albert Einstein: Philosopher–Scientist. New York: Harper & Brothers. Originally published in 1949 by the Library of Living Philosophers.
Schlick, Moritz. [1930] 1979. “On the Foundations of Knowledge”, in Philosophical Papers, vol. 2 (1925–1936), edited by H. L. Mulder and B. F. B. van de Velde-Schlick (Dordrecht: Reidel), pp. 370–387.
Walter, Maila. 1990. Science and Cultural Crisis: An Intellectual Biography of Percy Williams Bridgman (1882–1961). Stanford: Stanford University Press.
Wittgenstein, Ludwig. 1953. Philosophical Investigations, trans. by G. E. M. Anscombe. New York: Macmillan.
Open access to the SEP is made possible by a world-wide funding initiative.
Please Read How You Can Help Keep the Encyclopedia Free
The SEP would like to congratulate the National Endowment for the Humanities on its 50th anniversary and express our indebtedness for the five generous grants it awarded our project from 1997 to 2007. Readers who have benefited from the SEP are encouraged to examine the NEH’s anniversary page and, if inspired to do so, send a testimonial to neh50@neh.gov.Evolutionary Epistemology is a naturalistic approach to epistemology, which emphasizes the importance of natural selection in two primary roles. In the first role, selection is the generator and maintainer of the reliability of our senses and cognitive mechanisms, as well as the “fit” between those mechanisms and the world. In the second role, trial and error learning and the evolution of scientific theories are construed as selection processes.
Bibliography
Academic Tools
Other Internet Resources
Related Entries
1. History, Problems, and Issues
Traditional epistemology has its roots in Plato and the ancient skeptics. One strand emerges from Plato's interest in the problem of distinguishing between knowledge and true belief. His solution was to suggest that knowledge differs from true belief in being justified. Ancient skeptics complained that all attempts to provide any such justification were hopelessly flawed. Another strand emerges from the attempt to provide a reconstruction of human knowledge showing how the pieces of human knowledge fit together in a structure of mutual support. This project got its modern stamp from Descartes and comes in empiricist as well as rationalist versions which in turn can be given either a foundational or coherentist twist. The two strands are woven together by a common theme. The bonds that hold the reconstruction of human knowledge together are the justificational and evidential relations which enable us to distinguish knowledge from true belief.
The traditional approach is predicated on the assumption that epistemological questions have to be answered in ways which do not presuppose any particular knowledge. The argument is that any such appeal would obviously be question begging. Such approaches may be appropriately labeled “transcendental.”
The Darwinian revolution of the nineteenth century suggested an alternative approach first explored by Dewey and the pragmatists. Human beings, as the products of evolutionary development, are natural beings. Their capacities for knowledge and belief are also the products of a natural evolutionary development. As such, there is some reason to suspect that knowing, as a natural activity, could and should be treated and analyzed along lines compatible with its status, i. e., by the methods of natural science. On this view, there is no sharp division of labor between science and epistemology. In particular, the results of particular sciences such as evolutionary biology and psychology are not ruled a priori irrelevant to the solution of epistemological problems. Such approaches, in general, are called naturalistic epistemologies, whether they are directly motivated by evolutionary considerations or not. Those which are directly motivated by evolutionary considerations and which argue that the growth of knowledge follows the pattern of evolution in biology are called “evolutionary epistemologies.”
Evolutionary epistemology is the attempt to address questions in the theory of knowledge from an evolutionary point of view. Evolutionary epistemology involves, in part, deploying models and metaphors drawn from evolutionary biology in the attempt to characterize and resolve issues arising in epistemology and conceptual change. As disciplines co-evolve, models are traded back and forth. Thus, evolutionary epistemology also involves attempts to understand how biological evolution proceeds by interpreting it through models drawn from our understanding of conceptual change and the development of theories. The term “evolutionary epistemology” was coined by Donald Campbell (1974).
1.1 The Evolution of Epistemological Mechanisms (EEM ) versus The Evolutionary Epistemology of Theories (EET)
There are two interrelated but distinct programs which go by the name “evolutionary epistemology.” One focuses on the development of cognitive mechanisms in animals and humans. This involves a straightforward extension of the biological theory of evolution to those aspects or traits of animals which are the biological substrates of cognitive activity, e.g., their brains, sensory systems, motor systems, etc. The other program attempts to account for the evolution of ideas, scientific theories, epistemic norms and culture in general by using models and metaphors drawn from evolutionary biology. Both programs have their roots in 19th century biology and social philosophy, in the work of Darwin, Spencer, James and others. There have been a number of attempts in the intervening years to develop the programs in detail (see Campbell 1974, Bradie 1986, Cziko 1995). Much of the contemporary work in evolutionary epistemology derives from the work of Konrad Lorenz (1977), Donald Campbell (1974, et al.), Karl Popper (1972, 1984) and Stephen Toulmin (1967, 1972).
The two programs have been labeled EEM and EET (Bradie, 1986). EEM is the label for the program which attempts to provide an evolutionary account of the development of cognitive structures. EET is the label for the program which attempts to analyze the development of human knowledge and epistemological norms by appealing to relevant biological considerations. Some of these attempts involve analyzing the growth of human knowledge in terms of selectionist models and metaphors (e.g., Popper 1972, Toulmin 1972, Hull 1988; see Renzi and Napolitano 2011 for a critique of these efforts). Others argue for a biological grounding of epistemological norms and methodologies but eschew selectionist models of the growth of human knowledge as such (e.g., Ruse 1986, Rescher 1990).
The EEM and EET programs are interconnected but distinct. A successful EEM selectionist explanation of the development of cognitive brain structures provides no warrant, in itself, for extrapolating such models to understand the development of human knowledge systems. Similarly, endorsing an EET selectionist account of how human knowledge systems grow does not, in itself, warrant concluding that specific or general brain structures involved in cognition are the result of natural selection for enhanced cognitive capacities. The two programs, though similar in design and drawing upon the same models and metaphors, do not stand or fall together.
1.2 Ontogeny versus Phylogeny
Biological development involves both ontogenetic and phylogenetic considerations. Thus, the development of specific traits, such as the opposable thumb in humans, can be viewed both from the point of view of the development of that trait in individual organisms (ontogeny) and the development of that trait in the human lineage (phylogeny). The development of knowledge and knowing mechanisms exhibits a parallel distinction. We can consider the growth of an individual's corpus of knowledge and epistemological norms or his or her brain (ontogeny) or the growth of human knowledge and establishment of epistemological norms across generations or the development of brains in the human lineage (phylogeny). The EEM/EET distinction cuts across this distinction since we may be concerned either with the ontogenetic or phylogenetic development of, e.g., the brain or the ontogenetic or phylogenetic development of norms and knowledge corpora. One might expect that since current orthodoxy maintains that biological processes of ontogenesis proceed differently from the selectionist processes of phylogenesis, evolutionary epistemologies would reflect this difference. Curiously enough, however, for the most part they do not. For example, the theory of “neural Darwinism” as put forth by Edelman (1987) and Changeaux (1985) offers a selectionist account of the ontogenetic development of the neural structures of the brain. Karl Popper's conjectures and refutations model of the development of human knowledge is a well known example of a selectionist account which has been applied both to the ontogenetic growth of knowledge in individuals as well as the trans-generational (phylogenetic) evolution of scientific knowledge. B. F. Skinner's theory of operant conditioning, which deals with the ontogenesis of individual behavior, is explicitly based upon the Darwinian selectionist model (Skinner 1981).
A third distinction concerns descriptive versus prescriptive approaches to epistemology and the growth of human knowledge. Traditionally, epistemology has been construed as a normative project whose aim is to clarify and defend conceptions of knowledge, foundations, evidential warrant and justification. Many have argued that neither the EEM programs nor the EET programs have anything at all to do with epistemology properly (i. e., traditionally) understood. The basis for this contention is that epistemology, properly understood, is a normative discipline, whereas the EEM and EET programs are concerned with the construction of causal and genetic (i.e., descriptive) models of the evolution of cognitive capacities or knowledge systems. No such models, it is alleged, can have anything important to contribute to normative epistemology (e.g., Kim 1988). The force of this complaint depends upon how one construes the relationship between evolutionary epistemology and the tradition.
There are three possible configurations of the relationship between descriptive and traditional epistemologies. (1) Descriptive epistemologies can be construed as competitors to traditional normative epistemologies. On this view, both are trying to address the same concerns and offering competing solutions. Riedl (1984) defends this position. A standard objection to such approaches is that descriptive accounts are not adequate to do justice to the prescriptive elements of normative methodologies. The extent to which an evolutionary approach contributes to the resolution of traditional epistemological and philosophical problems is a function of which approach one adopts (cf. Dretske 1971, Bradie 1986, Ruse 1986, Radnitsky and Bartley 1987, Kim 1988). (2) Descriptive epistemology might be seen as a successor discipline to traditional epistemology. On this reading, descriptive epistemology does not address the questions of traditional epistemology because it deems them irrelevant or unanswerable or uninteresting. Many defenders of naturalized epistemologies fall into this camp (e.g., Munz 1993). (3) Descriptive epistemology might be seen as complementary to traditional epistemology. This appears to be Campbell's view. On this analysis, the function of the evolutionary approach is to provide a descriptive account of knowing mechanisms while leaving the prescriptive aspects of epistemology to more traditional approaches. At best, the evolutionary analyses serve to rule out normative approaches which are either implausible or inconsistent with an evolutionary origin of human understanding.
1.4 Future Prospects
EEM programs are saddled with the typical uncertainties of phylogenetic reconstructions. Is this or that organ or structure an adaptation and if so, for what? In addition, there are the uncertainties which result from the necessarily sparse fossil record of brain and sensory organ development. The EET programs are even more problematic. While it is plausible enough to think that the evolutionary imprint on our organs of thought influences what and how we do think, it is not at all clear that the influence is direct, significant or detectible. Selectionist epistemologies which endorse a “trial and error” methodology as an appropriate model for understanding scientific change are not analytic consequences of accepting that the brain and other ancillary organs are adaptations which have evolved primarily under the influence of natural selection. The viability of such selectionist models is an empirical question which rests on the development of adequate models. Hull's (1988) is, as he himself admits, but the first step in that direction. Cziko (1995) is a manifesto urging the development of such models (cf. also the evolutionary game theory modeling approach of Harms 1997). Much hard empirical work needs to be done to sustain this line of research. Non-selectionist evolutionary epistemologies, along the lines of Ruse (1986), face a different range of difficulties. It remains to be shown that any biological considerations are sufficiently restrictive to narrow down the range of potential methodologies in any meaningful way.
Nevertheless, the emergence in the latter quarter of the twentieth century of serious efforts to provide an evolutionary account of human understanding has potentially radical consequences. The application of selectionist models to the development of human knowledge, for example, creates an immediate tension. Standard traditional accounts of the emergence and growth of scientific knowledge see science as a progressive enterprise which, under the appropriate conditions of rational and free inquiry, generates a body of knowledge which progressively converges on the truth. Selectionist models of biological evolution, on the other hand, are generally construed to be non-progressive or, at most, locally so. Rather than generating convergence, biological evolution produces diversity. Popper's evolutionary epistemology attempts to embrace both but does so uneasily. Kuhn's “scientific revolutions” account draws tentatively upon a Darwinian model, but when criticized, Kuhn retreated (cf. Kuhn 1972, pp. 172f with Lakatos and Musgrave 1970, p. 264). Toulmin (1972) is a noteworthy exception. On his account, concepts of rationality are purely “local” and are themselves subject to evolution. This, in turn, seems to entail the need to abandon any sense of “goal directedness” in scientific inquiry. This is a radical consequence which few have embraced. Pursuing an evolutionary approach to epistemology raises fundamental questions about the concepts of knowledge, truth, realism, justification and rationality.
1.5 Expanding the Circle
Although Campbell and Popper both pointed to the continuity between the evolution of human knowledge and the evolution of knowledge in non-human organisms, much of the early work in evolutionary epistemology focused on the human condition. However, recent empirical investigations by psychologists, cognitive ethologists, cognitive neuroscientists and animal behaviorists have revealed that animals, both primates and non-primates, have much more sophisticated cognitive capacities than were previously suspected (Panksepp 1998, Heyes and Huber 2000, Rogers and Kaplan 2004). From an evolutionary perspective this is not surprising given the shared evolutionary heritage that all animals share. Taking Darwin seriously means reconsidering and reassessing the nature of human knowledge in the light of our increased awareness of the cogntive capabilities of the members of other species. In addition, once a firm empirical basis of the scope and limits of animal cognitive capacities has been established we will be in a position to reassess our philosophical evaluations of the mental lives of animals and their epistemic and moral status as well. Further field research promises to revolutionize our understanding of the sense in which human beings are one among the animals.
The KLI Theory Lab of the Konrad Lorenz Institute in Vienna offers an extensive bio- and bibliographical data base covering eighteen research areas related to evolution and cognition research. The entry for “evolutionary epistemology” contains links to authors and texts as well as a brief introduction and overview of the field. It is an interactive database and the Institute encourages authors to submit their own relevant bibliographies for inclusion in the database. The database can be accessed at <http://theorylab.org>. In addition, there is a journal devoted to issues in evolutionary epistemology in addition to other applications of biological theory, Biological Theory: Integrating Development, Evolution and Cognition. Information about the journal can be found at <http://www.kli.ac.at/journal>.
2. Formal Models
Every scientific enterprise requires formal and semi-formal models which allow the quantitative characterization of its objects of study. The attempt to transform the philosophical study of knowledge into a scientific discipline which approaches knowledge as a biological phenomenon is no different. Much of the evolutionary epistemology literature has been concerned with how to conceive of knowledge as a natural phenomenon, what difference this would make to our understanding of our place in the world, and with answering objections to the project. There are, as well, a number of more technical projects which attempt to provide the theoretical tools necessary for a naturalistic epistemology.
2.1 Static Optimization Models
In the simplest sort of model, an organism has to deal with an environment that has two states, S1 and S2, and has two possible responses R1 and R2. We suppose that what the organism does in each state makes a difference to its fitness. Fitnesses are usually written characterized by a matrix W.
The individual elements of the matrix Wij are the fitness consequences of response i in state j. So, for instance, W21 denotes the fitness consequences of R2 in S1. If we let W11 and W22 equal one and W12 and W21 equal zero, then there is a clear evolutionary advantage to performing R1 in S1 and R2 in S2.
However, the organism must first detect the state of the environment, and detectors are not in general perfectly reliable. If the organism responds automatically to the detector, we can use the probabilities of responses given states to characterize the reliability of the detector. We write the probability of R1 given S1 as Pr(R1|S1). This allows us to calculate that responding to the detector rather than always choosing R1 or R2 will be advantageous just in case the following inequality holds (cf. Godfrey-Smith 1996):
Pr(R2|S2)/(1−Pr(R1|S1)) > Pr(S1)(W11−W21)/(1−Pr(S1))(W22−W12)
This simple model demonstrates that whether or not flexible responses are adaptive depends on the particular characteristics of the fitness differences that the responses make, the probability of the various states of the environment, and the reliability of the detector. The particular result is calculated assuming that detecting the environmental state and the flexible response system is free in evolutionary terms. More complete analyses would include the costs of these factors.
Static optimization models like the one outlined above can be extended in several ways. Most obviously, the number of environmental states and organismic responses can be increased, but there are other modifications that are more interesting. Signal detection theory, for instance, models the detectors and cues in more detail. In one example, a species of “sea moss” detects the presence of predatory sea slugs via a chemical cue. They respond by growing spines, which is costly. The cue in this case, the water-borne chemical, comes in a variety of concentrations, which indicate various levels of danger. Signal detection theory allows us to calculate the best threshold value of the detector for the growing of spines.
Static models depict evolutionary processes in terms of fitness costs and benefits. They are static in the sense that they model no actual process, but merely calculate the direction of change for different situations. If fitness is high, a type will increase, if low it will decrease. When fitnesses are equal, population proportions remain at stable equilibrium. Dynamic models typically employ the kinds of calculations involved in static models to depict actual change over time in population proportions. Instead of calculating whether change will occur and in what direction, dynamic models follow change.
2.2 Population Dynamics
Population dynamics, sometimes referred to as “replicator dynamics”, offers a tractable way to model the evolution of populations over time under the kinds of selective pressures that can be characterized by static optimization models. This is often necessary, since the dynamics of such populations are often difficult to predict purely on the basis of static considerations of payoff differences. The so-called “replicator dynamics” were named by Taylor and Jonker (1978) and generalized by Schuster and Sigmund (1983) and Hofbauer and Sigmund (1988). They trace their source back to the seminal work of R.A. Fisher in the 1920's and 30's. The generalization covers evolutionary models used in population genetics, evolutionary game theory, ecology, and the study of prebiotic evolution. The models can be implemented either mathematically or computationally, and can model either stepwise (discrete) or continuous evolutionary change.
Population dynamics models the evolution of populations. A population is a collection of individuals, which are categorized according to type. The types in genetics are genes, in evolutionary game theory, strategies. The types of interest in epistemological models would be types of cognitive apparatuses, or cognitive strategies — ways of responding to environmental cues, ways of manipulating representations, and so forth. Roughly, EEM models focus on the inherited and EET models focus on the learned. The evolution of the population consists in changes of the relative frequency of the different types within the population. Selection, typified by differential reproductive success, is represented as follows. Each type has a growth rate or “fitness”, designated by w, and a frequency designated by p. The frequency of type i at the next generation pi′ is simply the old frequency multiplied by the fitness and divided by the mean fitness of the population “w”.
Division by w has the effect of “normalizing” the frequencies, so that they add up to one after each is multiplied by its fitness. It also makes evident that the frequency of a type will increase just in case its fitness is higher than the current population average.
Fitness
Fitnesses, which should be understood simply as the aggregation of probable-growth factors that drive the dynamics of large populations, may depend on a variety of factors. Fitness components differ from variation components in that they affect population frequencies proportionally to those frequencies, that is to say, multiplicatively. Fitness component in biological evolution include mortality and reproductive rate. In cultural evolution, they include transmission probability and rejection probability. Within either sort of model, what matters is how fitnesses change as a result of other changing factors within the model. In the simplest cases, fitnesses are fixed and the type with the highest fitness inevitably dominates the population. In more complex cases, fitnesses may depend on variable factors like who one plays against, or the state of a variable environment. Most commonly, variable fitnesses are calculated using a payoff matrix like the one above. In general, to calculate the expected fitness of a type, one multiplies the fitness a type would have in each situation times the likelihood that individuals in the population will confront that situation and adds the resulting products.
wi = SA Pr(A)·WiA
where WiA is type i's fitness in situation A. This sort of calculation assumes that the effects of the various situations are additive. More complex situations can be modeled, of course, but additive matrices are the standard. It should be noted, however, that matrix-driven evolution can exhibit quite complex behavior. For instance, chaotic behavior is possible with as few as four strategies (Skyrms 1992).
Some relationships may be represented without a matrix. Boyd and Richerson (1985), for instance, were interested in a special kind of frequency dependent transmission bias in culture, where being common conferred an advantage due to imitators “doing as the Romans do.” In such a case, the operative fitness of the type is just the fitness as calculated according to the usual factors, and then modified as a function of the frequency of the type.
Continuity and Computation
The conceptual bases of replicator dynamics are quite straightforward. Getting results typically requires one of two approaches. In order to prove more than rudimentary mathematical results, one typically needs to derive a continuous version of the dynamics. The basic form is
dpi/dt = p(wi − w)
with fitnesses calculated as usual. Mathematical approaches have been quite productive, though the bulk of theoretical results apply primarily to population genetics. See Hofbauer and Sigmund (1988) for a compendium of such results, as well as a reasonable graduate-level introduction to the mathematical study of evolutionary processes.
The second approach is computational. With the increase in power of personal computers, computational implementation of evolutionary models become increasingly attractive. They require only rudimentary programming skills, and are in general much more flexible in the assumptions they require. The general strategy is to create an array to hold population frequencies and fitnesses, and then a series of procedures (or methods or functions) which
calculate fitnesses,
update frequencies with the new fitnesses, and
manage interface details like outputting the new state of the population to a file or the screen.
A loop then runs the routines in sequence, over and over again. Most modelers are happy to put their source code on the internet, which is probably the best place to find it.
Modeling Cultural Evolution
Part of the difficulty in understanding cognitive behavior as the product of evolution is that there are at least three very different evolutionary processes involved. First, there is the biological evolution of cognitive and perceptual mechanisms via genetic inheritance. Second, there is the cultural evolution of languages and concepts. Third, there is the trial-and-error learning process that occurs during an individual's lifetime. Moreover, there is some reason to agree with Donald T. Campbell that understanding human knowledge fully will require understanding the interaction between these processes. This requires that we be able to model both processes of biological and cultural evolution. There are by now a number of well-established models of biological evolution. Cultural evolution presents more novelty.
Perhaps the most popular attempt to understand cultural evolution is Richard Dawkins' (1976) invention of the “meme.” Dawkins observed that what lies at the heart of biological evolution is differential reproduction. Evolution in general was then the competitive dynamics of lineages of self-replicating entities. If culture was to evolve, on this view, there had to be cultural “replicators”, or entities whose differential replication in culture constituted the cultural evolutionary process. Dawkins dubbed these entities “memes”, and they were characterized as informational entities which infect our brains, “leaping from head to head” via what we ordinarily call imitation. Common examples include infectious tunes, and religious ideologies. The main difficulty with this approach has been with providing specifications for the basic entities. The identity conditions of genes can be given, in theory, in terms of sequences of base pairs in chromosomes. There appears to be no such fundamental “alphabet” for the items of cultural transmission. Consequently, the project of “memetics” as contending basis for evolutionary epistemology is on hold pending an adequate understanding of its basic ontology. [See the online Journal of Memetics for more information.]
Population models have been used to good effect in modeling cultural transmission processes. Evolutionary game theory models are frequently claimed to cover both processes in which strategies are inherited and those in which they are imitated. This application is possible in the absence of any specification of the underlying nature of strategies, for instance, whether they are to be thought of as “things” which are replicated, or whether they are properties or states of the individuals whose strategies they are. This is sometimes referred to as the “epidemiological approach”, though again, the comparison to infection is due to the quantitative tools used in analysis rather than to any presupposition regarding the underlying ontology of cultural transmission.
2.3 Multi-Level Evolution
The kind of levels involved in evolutionary epistemology are quite different than the kind of levels of selection which are discussed much more often in the “levels of selection” debate in evolutionary biology. In evolutionary biology, the “levels” of selection under discussion are levels of scale. The debate concerns whether genes are always the “units” or “targets” of selection, or whether selection can occur on higher levels, like organisms, groups, and species. The levels involved in evolutionary epistemology, on the other hand, are levels of the regulatory hierarchy involved in the control of behavior. These include the genetic bases of cognitive and perceptual hardware, concepts, languages, techniques, beliefs, preferences, and so forth. Note that in the case of evolutionary epistemology, the terms “levels” and “hierarchy” may be impressionistic. There is often no clear arrangement of levels at all.
There are at least two different approaches that have been taken to modeling multi-level evolution.
Dual Transmission Models: Boyd and Richerson (1985) adapted models from genetics to model a case in which a trait (cooperation) was affected both by genetic and cultural evolution. It was first shown that a genetically determined bias on cultural transmission could be selected for in a migratory population. The bias made it easier to pick up local customs, increasing the likelihood of imitation beyond that determined by the frequency and perceived value of the behavior. Once this bias was in place, its effect was strong enough to overcome the perceived costs involved in cooperative behavior. The model yielded two important results. First, it provided a novel mechanism according to which cooperative behavior can stabilize in migratory populations. But more importantly, it demonstrated that cultural evolution cannot be predicted purely on the basis of genetic fitnesses.
Multiple Population Models: Harms (1997) constructed a multi-level dynamic population model of bumblebee learning. Mutual information between distributions of sensor types, overt foraging behaviors, and internal foraging preferences on the one hand and environmental states on the other was assessed and compared to average fitness of the population states. It was shown that information present in overt behaviors may be underutilized, and that exaptation of sensor mechanisms for preference formation can bring about the utilization of that information.
2.4 Meaning
Full descriptive accounts of truth and justification both demand a theory of meaning. Until a sign has meaning, it cannot be true or false. Moreover, determining the meaning of justificatory claims may provide a descriptive theory of justification. Presumably, what makes a claim of justification true is the basis of that justification. If meaning is conventional, then the evolution of meaning becomes an instance of the evolution of conventions.
Models of the evolution of conventions have in one case been extended to apply to meaning conventions. Skyrms (1996, chapter 5) gave an evolutionary interpretation of David Lewis' (1969) model of rational selection of meaning conventions. Skyrms was able to show that there is strong selection on the formation of “signaling systems” in mixed populations with a full set of coordinated, countercoordinated, and uncoordinated strategies. It is significant that the structure of the model and the selective process by which meaning conventions emerge and are stabilized largely parallels the account of the evolution of meaning given by Ruth Millikan (1984).
In the simplest version, the model is constructed as follows: We imagine that there are two states of affairs T, two acts A, and two signals M. Players have an equal chance of being in either the position of sender, or receiver. Receivers must decide what to do based purely on what the sender tells them. In this purely cooperative version, each player gets one point if the receiver does A1 if the state is T1 or A2 if the state is T2.
Since players will be both sender and receiver, they must have a strategy for each situation. There are sixteen such strategies, and we suppose them to be either inherited (or learned) from biological parents, or imitated on the basis of perceived success in terms of points earned. Strategies I1 and I2 are signaling systems, in that if both players play the same one of these two strategies they will always get their payoff. I3 and I4 are anti-signaling strategies, which result in consistent miscoordination, though they do well against each other. All of the other strategies involve S3, S4, R3, or R4, which results in the same act being performed no matter what the external state is.
Sender Strategies:
Receiver Strategies:
Complete Strategies:
Simulation results showed that virtually all initial population distributions become dominated by one or the other of the two signaling system strategies. The situation becomes more complex when more realistic payoffs are introduced, for instance, that the sender incurs a cost rather than automatically sharing the benefit that the receiver gets from correct behavior for the environment. Even in such situations, however, the most likely course of evolution is domination by a signaling system.
Bibliography
Bradie, Michael (1986), “Assessing Evolutionary Epistemology,” Biology & Philosophy, 1: 401–459.
Bradie, Michael (1989), “Evolutionary Epistemology as Naturalized Epistemology,” in Issues in Evolutionary Epistemology, K. Hahlweg and C. A. Hooker (eds.), Albany, NY: SUNY Press, pp. 393–412.
Bradie, Michael (1994), “Epistemology from an Evolutionary Point of View,” in Conceptual Issues in Evolutionary Biology, Second Edition, Elliott Sober (ed.), Cambridge, MA: The MIT Press, pp. 453–475.
Boyd, Robert, and Peter J. Richerson (1985), Culture and the Evolutionary Process, Chicago: The University of Chicago Press.
Callebaut, Werner, and Rik Pinxten (eds.) (1987), Evolutionary Epistemology: A Multiparadigm Program With a Complete Evolutionary Epistemology Bibliography (Synthese Library, Volume 190), Dordrecht: D. Reidel.
Campbell, Donald T. (1956a), “Adaptive Behavior from Random Response,” Behavioral Science, 1(2): 105–110.
Campbell, Donald T. (1956b), “Perception as Substitute Trial and Error,” Psychological Review, 63(5): 331–342.
Campbell, Donald T. (1959), “Methodological Suggestions from a Comparative Psychology of Knowledge processes,” Inquiry, 2: 152–182.
Campbell, Donald T. (1960), “Blind Variation and Selective Retention in Creative Thought as in Other Knowledge Processes,” Psychological Review, 67(6): 380–400.
Campbell, Donald T. (1974), “Evolutionary Epistemology,” in The philosophy of Karl R. Popper, edited by P. A. Schilpp, LaSalle, IL: Open Court, pp. 412–463.
Campbell, Donald T. (1974b), “Unjustified Variation and Selective Retention in Scientific Discovery,” in Studies in the philosophy of biology, edited by F J. Ayala and T. Dobzhansky, London: Macmillan, pp. 139–161.
Campbell, Donald T. (1982), “The ”Blind-Variation-and-Selective-Retention“ Theme,” in The cognitive-developmental psychology of James Mark Baldwin: Current theory and research in genetic epistemology, edited by J. M. Broughton and D. J. Freeman-Moir, Norwood, NJ: Ablex, pp. 87–97.
Campbell, D. T. (1985), “Pattern Matching as an Essential in Distal Knowing,” in Naturalizing Epistemology, edited by H. Kornblith, Cambridge, MA: MIT Press, 49–70.
Campbell, Donald T. (1988), “Popper and Selection Theory,” Social Epistemology, 2(4): 371–377.
Campbell, Donald T., and Paller, Bonnie T. (1989), “Extending Evolutionary Epistemology to ”Justifying“ Scientific Beliefs (A sociological rapprochement with a fallibilist perceptual foundationalism?),” in Issues in evolutionary epistemology, K. Hahlweg and C. A. Hooker (eds.), Albany: State University of New York Press, pp. 231–257.
Changeux, Jean-Pierre (1985), Neuronal Man, New York: Pantheon.
Coleman, Martin (2002), “Taking Simmel Seriously in Evolutionary Epistemology,” Studies in History and Philosophy of Science, 33A(1): 59–78.
Cziko, G., 1995, Without Miracles: Universal Selection Theory and the Second Darwinian Revolution, Cambridge, MA: MIT Press.
Dawkins, Richard (1976), The Selfish Gene, New York: Oxford University Press.
Derksen, A. A. (2001), “Evolutionary Epistemology in Defense of the Reliability of Our Everyday Perceptual Knowledge: A Promise of Evolutionary Epistemology,” Philosophia-Naturalis, 38(2): 245–270.
Dretske, Fred (1971), “Perception From an Epistemological Point of View,” Journal of Philosophy, 68(19): 584–591
Edelman, G. M. (1987), Neural Darwinism: The Theory of Neuronal Group Selection, New York: Basic Books.
Godfrey-Smith, Peter (1996), Complexity and the Function of Mind in Nature, Cambridge: Cambridge University Press.
Gontier, Nathalie, J. P. Bendegem, and D. Aerts (eds.) (2006), Evolutionary epistemology, language and culture: a non-adaptationist, systems theoretical approach, Dordrecht: Springer.
Harms, William F. (1997), “Reliability and Novelty: Information Gain in Multi-Level Selection Systems,” Erkenntnis, 46: 335–363.
Harms, William F. (2004), Information and meaning in evolutionary processes, Cambridge: Cambridge University Press.
Heyes, Cecilia and Ludwig Huber (eds.) (2000), The Evolution of Cognition, Cambridge, MA: MIT Press.
Hofbauer, Josef, and Karl Sigmund (1988), The Theory of Evolution and Dynamical Systems, Cambridge: Cambridge University Press.
Hull, D. (1988), Science as a Process: An Evolutionary Account of the Social and Conceptual Development of Science, Chicago: The University of Chicago Press.
Hull, David L. (2001), “In Search of Epistemological Warrant” in Selection Theory and Social Construction: The Evolutionary Naturalistic Epistemology of Donald T. Campbell, Cecilia Heyes and David Hull (eds.), Albany, NY: SUNY Press, pp. 155–167.
Kim, Jagwon. (1988) “What is ‘Naturalized Epistemology’?,” Philosophical Perspectives 2. Epistemology, Atascadero: Ridgeview, pp. 381–405.
Kuhn, Thomas (1962), The Structure of Scientific Revolutions, Chicago: The University of Chicago Press.
Lakatos, I. and Musgrave, A. (eds.) (1970), Criticism and the Growth of Knowledge, Cambridge: Cambridge University Press.
Lewis, David (1969), Convention, Cambridge: Cambridge University Press.
Lorenz, Konrad (1977), Behind the Mirror, London: Methuen.
Millikan, Ruth (1984), Language, Thought, and other Biological Categories, Cambridge, MA: MIT Press.
Munz, Peter (1993), Philosophical Darwinism: On the Origin of Knowledge by Means of Natural Selection, London: Routledge.
Panksepp, Jaak (1998), Affective Neuroscience: The Foundation of Human and Animal Emotions, New York: Oxford University Press.
Plotkin, H. C. (ed.) (1982), Learning, Development, and Culture: Essays in Evolutionary Epistemology, New York: John Wiley & Sons.
Popper, Karl R. (1968), The Logic of Scientific Discovery, New York: Harper.
Popper, Karl R. (1972), Objective Knowledge: An Evolutionary Approach, Oxford: Clarendon Press.
Popper, Karl R. (1984), “Evolutionary Epistemology,” in Evolutionary Theory: Paths into the Future, J. W. Pollard (ed.), London: John Wiley & Sons Ltd.
Radnitzky, G. and Bartley, W. W. (1987), Evolutionary Epistemology, Theory of Rationality and the Sociology of Knowledge, LaSalle, Ill: Open Court.
Renzi, Barbara G. and Napolitano Giulio (2011), Evolutionary Analogies: Is the Process of Scientific Change Analogous to the Organic Change, Newcastle: Cambridge Scholars Publishing.
Rescher, Nicholas (1978), Scientific Progress: A Philosophical Essay on the Economics of Research in Natural Science, Oxford: Basil Blackwell.
Rescher, Nicholas (1989), Cognitive Economy: The Economic Dimension of the Theory of Knowledge, Pittsburgh: University of Pittsburgh Press.
Rescher, Nicholas (1990), A Useful Inheritance: Evolutionary Aspects of the Theory of Knowledge, Lanham, MD: Rowman.
Riedl, Rupert (1984), Biology of Knowledge: The Evolutionary Basis of Reason, Chichester: John Wiley & Sons.
Rogers, Lesley and Gisela Kaplan (eds.) (2004), Are Primates Superior to Non-Primates?, New York: Kluwer Academic.
Ruse, Michael (1986), Taking Darwin Seriously: A Naturalistic Approach to Philosophy, Oxford: Blackwell.
Schuster, Peter, and Karl Sigmund (1983), “Replicator Dynamics,” Journal of Theoretical Biology, 100: 533–538.
Shimony, Abner (1971), “Perception From an Evolutionary View,” Journal of Philosophy, 68(19): 571–583.
Skinner, B. F. (1981), “Selection by Consequences,” Science, 213: 501–504.
Skyrms, Brian (1992), “Chaos and the Explanatory Significance of Equilibrium: Strange Attractors in Evolutionary Game Dynamics,” PSA 1992 (2), Philosophy of Science Association, pp. 374–394.
Skyrms, Brian (1996), Evolution of the Social Contract, Cambridge: Cambridge University Press.
Taylor, P., and L. Jonker (1978), “Evolutionary Stable Strategies and Game Dynamics,” Mathematical Biosciences, 40: 145–56.
Ter Hark, Michel (2004), Popper, Otto Selz and the Rise Of Evolutionary Epistemology, Cambridge: Cambridge University Press.
Toulmin, Stephen (1967), “The Evolutionary Development of Natural Science,” American Scientist, 55: 4.
Toulmin, Stephen (1972), Human Understanding: The Collective Use and Evolution of Concepts, Princeton: Princeton University Press.
Vollmer, Gerhard (2005), “How is it that we can know this world? New arguments in evolutionary epistemology,” in Darwinism & Philosophy, V. Hösle and Christian Illies (eds.), Notre Dame, IN: University of Notre Dame Press.
Academic Tools
Other Internet Resources
Evolving Artificial Moral Ecologies, Centre for Applied Ethics, University of British Columbia
The Journal of Memetics, sponsored by the Centre for Policy Modeling (Manchester Metropolitan University), the Principia Cybernetica Project, and Systems Engineering, Policy Analysis and Management (Delft University of Technology)
Evolutionary Epistemology, entry in the Internet Encyclopedia of Philosophy.Moral luck occurs when an agent can be correctly treated as an object of moral judgment despite the fact that a significant aspect of what she is assessed for depends on factors beyond her control. Bernard Williams writes, “when I first introduced the expression moral luck, I expected to suggest an oxymoron” (Williams 1993, 251). Indeed, immunity from luck has been thought by many to be part of the very essence of morality. And yet, as Williams (1981) and Thomas Nagel (1979) showed in their now classic pair of articles, it appears that our everyday judgments and practices commit us to the existence of moral luck. The problem of moral luck arises because we seem to be committed to the general principle that we are morally assessable only to the extent that what we are assessed for depends on factors under our control (call this the “Control Principle”). At the same time, when it comes to countless particular cases, we morally assess agents for things that depend on factors that are not in their control. And making the situation still more problematic is the fact that a very natural line of reasoning suggests that it is impossible to morally assess anyone for anything if we adhere to the Control Principle.
1. Generating the Problem of Moral Luck and Kinds of Luck
3. Kinds of Moral Assessment
4. Responding to the Problem: Three Approaches
5. Conclusion
Bibliography
Academic Tools
Other Internet Resources
Related Entries
1. Generating the Problem of Moral Luck and Kinds of Luck
The idea that morality is immune from luck finds inspiration in Kant:
A good will is not good because of what it effects or accomplishes, because of its fitness to attain some proposed end, but only because of its volition, that is, it is good in itself… Even if, by a special disfavor of fortune or by the niggardly provision of a step motherly nature, this will should wholly lack the capacity to carry out its purpose—if with its greatest efforts it should yet achieve nothing and only the good will were left (not, of course, as a mere wish but as the summoning of all means insofar as they are in our control)—then, like a jewel, it would still shine by itself, as something that has its full worth in itself. Usefulness or fruitlessness can neither add anything to this worth nor take anything away from it (Kant 1784/1998, 4:394).
Thomas Nagel approvingly cites this passage in the opening of his 1979 article, “Moral Luck.” Nagel's article began as a reply to Williams' paper of the same name, and the two articles together articulated in a new and powerful way a challenge for anyone wishing to defend the Kantian idea that morality is immune from luck.
To see exactly how the challenge arises, let us begin with the Control Principle:
(CP) We are morally assessable only to the extent that what we are assessed for depends on factors under our control.
It is intuitively compelling, as is the following corollary of it:
(CP-Corollary) Two people ought not to be morally assessed differently if the only other differences between them are due to factors beyond their control.
Not only are the Control Principle and its corollary plausible in themselves, they also seem to find support in our reactions to particular cases. For example, if we find out that a woman who has just stepped on your toes was simply pushed, then our temptation to blame her is likely to evaporate. It seems that the reason for this is our unwillingness to hold someone responsible for what is not in her control. Similarly, if two drivers have taken all precautions, and are abiding by all the rules of the road, and in one case, a dog runs in front of the car and is killed, and not in the other, then, given that the dog's running out was not something over which either driver had control, it seems that we are reluctant to blame one driver more than the other. Although we might expect different reactions from the two drivers, it does not seem that one is deserving of a worse moral assessment than the other.
At the same time, it seems that there are countless cases in which the objects of our moral assessments do depend on factors beyond agents' control. Even though “moral luck” seems to be an oxymoron, everyday judgments suggest that there is a phenomenon of moral luck after all. As Nagel defines it, “Where a significant aspect of what someone does depends on factors beyond his control, yet we continue to treat him in that respect as an object of moral judgment, it can be called moral luck” (Nagel 1979, 59). To bring out the conflict with the Control Principle even more starkly, we will understand moral luck as follows:
(ML) moral luck occurs when an agent can be correctly treated as an object of moral judgment, despite the fact that a significant aspect of what he is assessed for depends on factors beyond his control.
We certainly seem to be committed to the existence of moral luck. For example, we seem to blame those who have murdered more than we blame those who have merely attempted murder, even if the reason for the lack of success in the second case is that the intended victim unexpectedly tripped and fell to the floor just as the bullet arrived at head-height. Since whether the intended victim tripped or not is not something in control of either would-be murderer, we appear to violate the Control Principle and its corollary.
It might be tempting to respond at this point that what people are really responsible for are their intentions or their “willings,” and that we are thus wrong to offer different moral assessments in this pair of cases. Adam Smith (1790/1976), for example, advocates this position, writing that
To the intention or affection of the heart, therefore, to the propriety and impropriety, to the beneficence or hurtfulness of the design, all praise or blame, all approbation or disapprobation, of any kind, which can justly be bestowed upon any action, must ultimately belong. (II.iii.intro.3.)
But this tempting response faces difficulties of its own. First, as we will see, the would-be murderers offer only one of many cases in which our intuitive moral judgment appears to depend on “results” beyond one's intentions, as Smith himself noted (II.iii.intro.5). And even more importantly, luck can affect even our “willings” and other internal states (Feinberg 1970, 34–38). As Nagel develops the point, there are other types of luck that affect not only our actions but also every intention we form and every exertion of our wills. Further, once these kinds of luck are recognized, we will see that not one of the factors on which agents' actions depend is immune to luck.
Nagel identifies four kinds of luck in all: resultant, circumstantial, constitutive, and causal.
Resultant Luck. Resultant luck is luck in the way things turn out. Examples include the pair of would-be murderers just mentioned as well as the pair of innocent drivers described above. In both cases, each member of the pair has exactly the same intentions, has made the same plans, and so on, but things turn out very differently and so both are subject to resultant luck. If in either case, we can correctly offer different moral assessments for each member of the pair, then we have a case of resultant moral luck. Williams offers a case of “decision under uncertainty”: a somewhat fictionalized Gauguin, who chooses a life of painting in Tahiti over a life with his family, not knowing whether he will be a great painter. In one scenario, he goes on to become a great painter, and in another, he fails. According to Williams, we will judge Gauguin differently depending on the outcome. Cases of negligence provide another important kind of resultant luck. Imagine that two otherwise conscientious people have forgotten to have their brakes checked recently and experience brake failure, but only one of whom finds a child in the path of his car. If in any of these cases we correctly offer differential moral assessments, then again we have cases of resultant moral luck.
Circumstantial luck. Circumstantial luck is luck in the circumstances in which one finds oneself. For example, consider Nazi collaborators in 1930's Germany who are condemned for committing morally atrocious acts, even though their very presence in Nazi Germany was due to factors beyond their control (Nagel 1979). Had those very people been transferred by the companies for which they worked to Argentina in 1929, perhaps they would have led exemplary lives. If we correctly morally assess the Nazi collaborators differently from their imaginary counterparts in Argentina, then we have a case of circumstantial moral luck.
Constitutive luck. Constitutive luck is luck in who one is, or in the traits and dispositions that one has. Since our genes, care-givers, peers, and other environmental influences all contribute to making us who we are (and since we have no control over these) it seems that who we are is at least largely a matter of luck. Since how we act is partly a function of who we are, the existence of constitutive luck entails that what actions we perform depends on luck, too. For example, if we correctly blame someone for being cowardly or self-righteous or selfish, when his being so depends on factors beyond his control, then we have a case of constitutive moral luck. Further, if a person acts on one of these very character traits over which he lacks control by, say, running away instead of helping to save his child, and we correctly blame him for so acting, then we also have a case of constitutive moral luck. Thus, since both actions and agents are objects of moral assessment, constitutive moral luck undermines the Control Principle when it comes to the assessment of both actions and agents.
Causal luck. Finally, there is causal luck, or luck in “how one is determined by antecedent circumstances” (Nagel 1979, 60). Nagel points out that the appearance of causal moral luck is essentially the classic problem of free will. The problem of free will to which Nagel refers arises because it seems that our actions—and even the “stripped-down acts of the will”—are consequences of what is not in our control. If this is so, then neither our actions nor our willing are free. And since freedom is often thought to be necessary for moral responsibility, we cannot be morally responsible even for our willings. Sometimes the problem is thought to arise only if determinism is true, but this is not the case. Even if it turns out that determinism is false, but events are still caused by prior events according to probabilistic laws, the way that one is caused to act by antecedent circumstances would seem to be equally outside of one's control (e.g., Pereboom 2002, 41–54, Watson 1982, 9). Finally, it is worth noting that some have viewed the inclusion of the category of causal luck as redundant, since what it covers is completely captured by the combination of constitutive and circumstantial luck (Latus 2001).
Upon reflection, it seems that we morally assess people differently for what they do (or who they are) when their actions and personal qualities depend on luck of all kinds. And it is not only in unusual cases like that of would-be murderers that people are subject to the various types of luck. For example, whether any of our intentions are realized in action or not depends on some factors outside of our control. Thus, if resultant luck undermines our assessments of moral responsibility, as the Control Principle suggests, then many of our everyday judgments ought to be abandoned. Still, applying the Control Principle to resultant luck continues to leave open the possibility that we are correctly assessed for things like our intentions, just not for the results of our intentions. But consideration of the other sorts of luck leads to more and more global skepticism about moral assessment. For example, circumstantial luck affects even our intentions, so it seems that we cannot be assessed in virtue of our intentions. Once again, though, we might still be able to retain the idea that we are morally assessable for something, even if only for what we would have intended in various situations. But reflection on constitutive luck and causal luck can make it seem as though we cannot be properly assessed for anything we do. For if who we are and therefore what we would have done are themselves subject to luck, then according to the Control Principle, we cannot be properly assessed even for those things. What is left as an object of assessment? As Nagel puts it, “[t]he area of genuine agency, and therefore of legitimate moral judgment, seems to shrink under this scrutiny to an extensionless point” (1979, 66.) He goes on,
I believe that in a sense the problem has no solution, because something in the idea of agency is incompatible with actions being events, or people being things. But as the external determinants of what someone has done are gradually exposed, in their effect on consequences, character, and choice itself, it becomes gradually clear that actions are events and people things. Eventually nothing remains which can be ascribed to the responsible self, and we are left with nothing but a portion of the larger sequence of events, which can be deplored or celebrated, but not blamed or praised (1979, 68).
If this is right, then we could not simply revise our everyday moral judgments in accordance with a more diligent application of the Control Principle; at best, if we adhere to the Control Principle, we should refrain from making any moral judgments. Not everyone shares this skepticism, and there is naturally a wide variety of responses to the challenge of how to reconcile our adherence to the Control Principle with our everyday judgments that commit us to the existence of moral luck. At stake are not only our seemingly ubiquitous practices of moral praise and blame, but also the resolution of other central debates in ethics, philosophy of law, and political philosophy.
2. Implications for Other Debates
Before turning to proposed solutions to the problem, it will be helpful to see just what rests on resolving the problem of moral luck.
2.1 The Justification of Laws and Punishment
Whether or not we accept, reject, or qualify the Control Principle has implications for the law, and for punishment in particular. The question of how resultant luck should affect punishment has been debated at least since Plato (The Laws IX, 876–877). According to the Control Principle, if results are not in our control, then our attributions of moral responsibility and blameworthiness should not be affected by them. And if, in addition, justified punishment tracks moral blameworthiness, then the degree of punishment allotted for crimes should not be based even in part on results. H.L.A. Hart puts this conclusion in the form of a rhetorical question: “Why should the accidental fact that an intended harmful outcome has not occurred be a ground for punishing less a criminal who may be equally dangerous and equally wicked?” (1968, 129). It turns out, however, that the idea that results should not be taken into account in determining punishment is in direct tension with a variety of criminal laws, including, for example, the differential punishment accorded attempted murder and murder in the United States. It is also in direct tension with parts of the tort law in the United States such as the differential treatment accorded the merely negligent person and the negligent person whose negligence leads to harm. Interestingly, however, the Model Penal Code takes a different approach for at least some offenses, prescribing the same punishment for attempts and completed crimes. (Model Penal Code § 2.05 cmt. at 293–95 (Official Draft and Revised Comments 1985). And this approach is favored by a number of legal theorists.
Now the line of reasoning sketched above that rejects any tracking of results in punishment depends not only on the Control Principle (or a modified version of it), but also on a thesis that limits justified punishment to the proper objects of moral blameworthiness. Both of these premises can, and have been, questioned. But the debate in legal theory about whether results should make a difference to punishment very often centers on the premise about control, and thus, the status of the Control Principle has important implications for the legal debates concerning differential punishment for attempts and completed crimes. (On this debate, see, for example, Alexander, Ferzan, and Morse (2009) Davis (1986), Feinberg (1995), Herman (1995), Kadish (1994), Lewis (1989), Moore (1997 and 2009), Ripstein (1999), and Yaffe (2010). On luck and tort law, see Waldron (1995), and for a wide-ranging discussion of moral luck and the law, Enoch (2010).)
It is also important to note that the implications of the status of the Control Principle for the law are not limited to results. For example, if we accept the Control Principle in unqualified form, and accept the premise constraining justified punishment to that for which people are morally blameworthy, then it might turn out that no one is morally blameworthy and so no punishment is ever justified.
2.2 Egalitarianism
Whether or not the Control Principle is true either in its general or in some restricted form also has implications for the debate over what, if anything, justifies egalitarianism. Let us understand egalitarianism as the view that a distribution of relevant goods that is more equal over a relevant population is more just than one that is less equal. Inspired by the work of John Rawls, some egalitarians have invoked the idea that our constitution and circumstances are out of our control in the justification of their view. For example, Rawls writes that
The existing distribution of income and wealth, say, is the cumulative effect of prior distributions of natural assets—that is, natural talents and abilities—as these have been developed or left unrealized, and their use favored or disfavored over time by social circumstances and such chance contingencies as accident and good fortune. Intuitively, the most obvious injustice of the system of natural liberty is that it permits distributive shares to be improperly influenced by these factors so arbitrary from a moral point of view. (Rawls 1971, p. 72.)
Egalitarians who treat luck in this way are sometimes called “luck egalitarians.” (For examples of various versions of luck egalitarianism, see Arneson 1997, 2001, Cohen 1989, Dworkin 1981 and 2000, Roemer 1996; for criticisms see Nozick 1974, Anderson 1999, Hurley 2001, and Scheffler 2003.) It is often difficult to see exactly how the appeal to constitutive luck is meant to function in various arguments for egalitarianism. There are two very general ways the reasoning might go: a “positive” and a “negative” way (Nozick 1974). According to one positive line of reasoning, it is first observed that one's natural talents, circumstances of birth, and so on are things that are beyond one’s control, and at the same time, if a natural “free market” system operates, these circumstances give rise to many advantages and disadvantages relative to others. By the Control Principle, one is not responsible for these advantages and disadvantages. Further, it is wrong for people to have advantages and disadvantages for which they are not responsible. Therefore, justice requires a more egalitarian redistribution of goods to rectify this wrong. Although this line of reasoning has received much criticism, it is arguable that a weaker, and so less vulnerable “negative” line of reasoning is really behind much of luck egalitarianism (see, for example, Arneson 2001).
The “negative” luck argument for egalitarianism is really a rebuttal to the objection that people should not be deprived in the name of egalitarianism of what they have earned. The argument goes like this: Take as a starting point a presumption in favor of equality of condition. Next observe, as before, that one's natural talents, circumstances of birth, and so on are things beyond one’s control, and, again, that these factors often give rise to advantages and disadvantages relative to others. Therefore, by the Control Principle, one is not responsible for many advantages and disadvantages. If one is not responsible for these, then one is not deserving of them. And if one is not deserving of them, then it is not wrong to redistribute goods in a more egalitarian way that eliminates many advantages and disadvantages.
The explicit appeal to the Control Principle in both of these lines of reasoning shows ways in which the plausibility of Luck Egalitarianism depends on the resolution of the problem of moral luck. It is also notable that some luck egalitarians attempt to draw a line between certain sorts of luck; for example, it is sometimes argued that if one suffers a great financial setback due to one’s choice to engage in high-stakes gambling, then there might be circumstances in which it would be wrong to seek to treat one in the same way as another whose equal suffering was brought on by, say, a devastating earthquake. It might be that underlying this move is acceptance of a restricted version of the Control Principle; for example, one that allows that one can be responsible for one's choices and their expected consequences, but not for the results of one's choices that are in large part beyond one's control. Here, too, it is clear that how one resolves the problem of moral luck—whether one rejects the possibility of moral luck altogether, accepts it in all forms, or accepts certain kinds and not others—has implications for the ultimate success of Luck Egalitarianism. Thus, much is at stake in the resolution of the problem of moral luck. Before turning to suggested solutions, a brief bit of ground-clearing will be necessary.
3. Kinds of Moral Assessment
The Control Principle states that we are morally assessable only to the extent that what we are morally assessed for is under our control. But it is important to recognize that there are many different kinds of moral assessment. For example, there are judgments about a person's character, for example, as “good” or “bad” (sometimes called “aretaic” judgments). There are also judgments of states of affairs that concern people's actions as “ good ”or “ bad ”(sometimes called “axiological” judgments. Then there are judgments of actions as “right” or “wrong” (sometimes called “deontic” judgments). There are also judgments of responsibility, blame, and praise. As we will see, this category can be further divided in various ways.
Distinguishing between the various notions of moral assessment allows for the possibility that the Control Principle should be read as applying to some, but not to other forms of moral assessment. For example, some argue that there is a perfectly acceptable form of moral luck which does not conflict with the true spirit of the Control Principle, namely, luck in what you are responsible for (e.g., Richards 1986, Zimmerman 2002). For example, it will be readily admitted by many that the successful murderer can be responsible for a death, whereas the one who unsuccessfully attempts murder is not responsible for a death. At the same time, both could be equally responsible, or blameworthy, in degree (Zimmerman 2002, 560) or both could be equal in their moral worth (Richards 1986, 171, Greco 1995, 91). If the most important kind of moral assessment is, say, one's moral worth, then the Control Principle can be suitably restricted to apply to assessments of moral worth. As will become clear, a number of responses to the problem of moral luck appeal to the general strategy of distinguishing among different forms of moral assessment. Most focus on two families of moral assessment: (i) the family that includes responsibility, blame, and praise for actions and/or for one's own traits or dispositions, and (ii) the family that includes the notion of the moral worth of an agent and the moral quality of her character. (But see Zimmerman 2006 for a recent discussion of luck and deontic judgments.)
4. Responding to the Problem: Three Approaches
There are three general approaches to responding to the problem of moral luck: (i) to deny that there is moral luck despite appearances, (ii) to accept the existence of moral luck while rejecting or restricting the Control Principle, or (iii) to argue that it is simply incoherent to accept or deny the existence of some type(s) of moral luck, so that with respect to at least the relevant types of moral luck, the problem of moral luck does not arise.
Some who respond to the problem of moral luck take a single approach to all kinds of luck. But many take a mixed approach; that is, they embrace one approach for one kind of luck and another approach for another kind of luck, or address only a certain type(s) of luck, while remaining silent about the other types. Is taking a mixed approach legitimate? After all, it seems that if the Control Principle is true, then there is no moral luck, and if it is false, then there can be any type of moral luck. But, alas, matters are not necessarily so simple. It is possible at least in theory to offer a principled reason for qualifying the Control Principle so that it applies only to certain sorts of factors and not others. At the same time, as we will see, providing just such a principled way of distinguishing certain kinds of luck from others turns out to be a formidable task.
4.1 Denial
Most of those who deny that one or more types of moral luck exist are those who seek to preserve the centrality of morality in our lives. But it is also possible to adopt a position of denying the possibility of moral luck while at the same time showing that the Control Principle, while true, prevents morality from playing the central role we might have hoped for it. Something like this position seems to be the one Williams adopts in his (1993) “Postscript” to “Moral Luck,” for example.
4.1.1 Denying Moral Luck and Preserving the Centrality of Morality
Let us begin with the first and larger group of those who embrace the approach of denying the existence of moral luck. One of their main tasks is to explain away the appearance of moral luck. A second main task is to paint a plausible and coherent picture of morality that avoids luck.
An important tool for those who wish to explain away the existence of moral luck is what Latus (2000) calls the “epistemic argument” (see Richards, Rescher, Rosebury, and Thomson.) To see how it goes, let us begin by focusing on resultant luck. Why do we feel differently about the successful and unsuccessful murderers? Because, according to the epistemic argument, we rarely know exactly what a person's intentions are or the strength of her commitment to a course of action. One (admittedly fallible) indicator is whether she succeeds or not. In particular, if someone succeeds, that is some evidence that the person was seriously committed to carrying out a fully formed plan. The same evidence is not usually available when the plan is not carried out. Thus, rather than indicating our commitment to cases of resultant moral luck, our differential treatment of successful and unsuccessful murderers indicates our different epistemic situations with respect to each. If we were in the unrealistic situation of knowing that both agents had exactly the same intentions, the same strength of commitment to their plans, and so on, then we would no longer be inclined to treat them differently. Thomson represents a number of those who employ this strategy when she asks, “Well do we regard Bert [a negligent driver who causes a death] with an indignation that would be out of place in respect to Carol [an equally negligent driver who does not]? Even after we have been told about how bad luck figured in his history and good luck in hers?” And Thomson answers: “I do not find it in myself to do so” (1993, 205). Not everyone shares this intuition, however, as we will see in the next section.
The epistemic argument can be extended to circumstantial luck. Consider again the Nazi sympathizer, and a counterpart who moved in 1929 to Argentina on business. The counterpart has exactly the same dispositions as the Nazi sympathizer, but lives a quiet and harmless life in Argentina. According to this line of reasoning, while it is true that the counterpart is not responsible for the same deeds as the Nazi sympathizer, he should be judged precisely for what he would have done. Richards argues that we do judge people for what they would have done, but that what they do is often our strongest evidence for what they would have done. As a result, given our limited knowledge, we might not be entitled to treat the counterpart in the same way as the Nazi sympathizer, even though they are equally morally deserving of such treatment (Richards 1986, 174 ff.). Thus, circumstantial luck, like resultant luck, affects the basis available to us when we judge agents, but does not affect what those agents deserve.
It is hard to see how the argument can be extended further to cover constitutive or causal luck. But even if the epistemic argument is limited in this way, it can still be part of a good overall strategy of responding to the problem of moral luck insofar as it is possible to take a mix-and-match approach to different kinds of luck.
A second strategy for explaining away moral luck is most naturally applied to resultant luck. Those who adopt this strategy argue that it is understandable or even appropriate to feel differently about the driver who kills a child than about the one who does not. What is not appropriate is to offer different moral assessments of their behavior (e.g., Rosebury, Richards, Wolf, Thomson).
Williams elucidates a notion of “agent-regret,” a sentiment whose “constitutive thought” is a subject's first-person thought that it would have been much better had she done otherwise. Agent regret also requires a certain sort of expression that is different from that of what we might call “bystander regret.” For example, it might include the willingness to compensate a person who was harmed by one's actions. In the case of a lorry driver who, through no fault of his own, runs over a child, Williams writes, “we feel sorry for the driver, but that sentiment co-exists with, indeed presupposes, that there is something special about his relation to this happening, something which cannot merely be eliminated by the consideration that it was not his fault” (1981, 43).
It is possible to take this thought still further and argue that it is reasonable to expect and perhaps even demand that one who kills the child respond in a different way from the other. For example, Wolf argues that there is a “nameless virtue” which consists in “taking responsibility for one's actions and their consequences” (2001, 13). It is the virtue of taking responsibility in some sense for the consequences of one's actions, even if one is not responsible for them. In some ways it is akin to the virtue of generosity in that it “involves a willingness to give more…that justice requires” (14). To take another example, Richards suggests that we often have negative feelings about those who cause harm, even when we realize that they are not deserved, and that these can be feelings we ought to have. For example, it ought to be distressing for a parent to encounter a girl who accidentally dropped your baby, even if you know that no one could have held on (1986, 178–79). The feelings that both agents and observers naturally do or even ought to have can easily be confused with judgments that commit us to the existence of moral luck. Yet once we distinguish these legitimate feelings from moral judgments, we can and should eliminate the judgments that entail a commitment to moral luck. Again, this strategy is most naturally applied to resultant luck.
Recently, critics of this strategy have objected to it on a variety of grounds. For example, it has been argued against Wolf's view, in particular, that once we acknowledge the appropriateness of greater self-blame in cases of greater harm, no good reason for denying moral luck remains, and indeed we have good reason for accepting it. (See Moore (2009, 31 ff.) It has also been argued that Wolf's description of our phenomenology is at best incomplete: it is not merely that we wish people to blame themselves more when they cause greater harm, but that we judge them to be more blameworthy. Our judgments of greater responsibility also require explaining away. (See Domsky 2004.)
A variant of this strategy employs the idea that one can justify differential treatment of, say, the negligent driver who hits a child and one who does not, even if both are equally morally blameworthy. For example, Henning Jensen (1984) argues that while both are equally culpable, there are consequentialist reasons for not subjecting the first negligent driver to the same degree of blame behavior. Since we all take some risks, and some are less likely to lead to harm than others, to blame everyone for simply taking such risks would require such a high standard of care as to risk destroying our ability to function as moral agents. On the other hand, requiring punishment for or compensation from those who do cause harm is required to provide a “restorative value” for those agents and preserve their integrity.
A third strategy is to point out that we mistakenly infer moral luck from legal luck. While there might be good reasons for the law to treat people differently even if what they do depends on factors beyond their control, we (understandably) make the mistaken inference that the law directly reflects correct moral assessment in such cases. For example, there are a number of reasons why the law might justifiably punish successful crimes more severely than merely attempted ones, including the balancing of deterrence and privacy (Rosebury 521–24). If reasons like this provide the justification for the differential treatment of such cases in the law, then it would indeed be wrong to infer that the successful and unsuccessful murderers are deserving of different moral assessments. However, the fact that we do make such a mistaken inference explains why we often commit ourselves to the existence of moral luck, when reflection can show that doing so is a mistake.
In addition to explaining how there can be an appearance of moral luck, despite the fact that there is not any, some of those who wish to deny the existence of moral luck take on the task of offering a coherent and plausible picture of morality that avoids luck.
Some of those engaged in the free will debate have denied the existence of causal, and perhaps also of constitutive, moral luck by offering a distinctive metaphysical account of human agency. (See, for example, Chisholm, Taylor, Clarke, and O'Connor. See also Pereboom who argues that such an account is coherent, but not true.) The view is known as “Agent-Causal Libertarianism,” and the basic idea is that agents themselves cause actions or at least the formation of intentions, without their being caused to do so. Thus, the agent herself as a substance, exercising her causal powers is an undetermined cause of her intentions. On some agent causal views, only the agent, as opposed to events caused by other events is the cause of the intention (e.g., O'Connor), while on another view, the agent acts in tandem with events that probabilistically cause the action (Clarke 1993). Particularly on the first sort of view, we seem to avoid the conclusion that our actions must depend on causal factors that are beyond our control. At the same time, it is not clear exactly how the move to agent causation is supposed to restore the kind of control we seek. For we might ask why we should consider the agent cause in control of her actions, while we can imagine that other substance causes (e.g., tables or billiard balls) would not be in control of what they cause. It might be stipulated that the exercise of the particular causal power to cause intentions simply is an exercise of control, but we need further details to see that the challenge has not been stipulated away. (See Clarke 2005 and Mele 2006 for recent discussions of agent causation and luck.) It is also important to note that Agent-Causal views are consistent with actions and even intentions depending in part on factors beyond one's control, such as the reasons people have available at the time of decision or action.
In a very different way, as we have seen, it is possible to take on a part of the task of describing a coherent picture of luck-free morality by identifying an object of moral assessment in the case of circumstantial luck. For example, Richards suggests that people should be assessed for what they would have done in different circumstances. More fundamentally, people should be assessed for their characters, of which their actions in different circumstances are manifestations.
Zimmerman begins where Richards leaves off, proposing to pursue “the implications of the denial of the relevance of luck to moral responsibility” to their “logical conclusion” (2002, 559). With the possible exception of some kinds of constitutive luck, Zimmerman rejects the possibility of moral luck of all four kinds while proposing a coherent picture of moral assessment. He rejects the possibility of resultant luck by first acknowledging that a man who (by luck) succeeds in his plan to cause harm is responsible for more things than one who (by luck) fails to carry out an identical plan. But, according to Zimmerman, we must distinguish between scope and degree of responsibility. Both men are responsible to the same degree, and it is this kind of moral assessment to which the Control Principle ought to apply. When it comes to circumstantial luck, things are more difficult. For when it comes to cases like those of resultant luck in which we want to hold people responsible, we can find something to hold them responsible for, namely, their plans or intentions or attempts. However, when it comes to cases of circumstantial luck, such as the Nazi collaborator and his counterpart, there are no counterpart plans or intentions or attempts that have simply failed to come to fruition. Zimmerman suggests that there is nothing that we hold the counterpart responsible for; in this case, the scope of the agent's responsibility is 0. But we can and should still hold him responsible to the same degree as the Nazi sympathizer. He is responsible tout court even if he is not responsible for anything (2002, 565). He is responsible in the sense that his moral record is affected for better or worse in virtue of something about him. For there is something in virtue of which he is responsible, namely, his being such that he would have freely performed the very same wrong actions had he been in the same circumstances as the Nazi sympathizer.
This reasoning can be extended still further to cover the case of constitutive and even one kind of causal luck. Suppose that Georg does not kill Henrik, and George does kill Henry. Further suppose that “the reason for Georg's not killing Henrik was that he was too timid, or that he had a thick skin and Henrik's insults did not upset him in the way that Henry's insults upset George, or that he was deaf and simply did not hear the insults that Henrik hurled his way. If it is nonetheless true that Georg would have freely shot and killed Henrik but for some such feature of the case over which he had no control, then, I contend, he is just as responsible, in virtue of this fact, as George is” (2002, 565). Zimmerman acknowledges that there are features of one's constitution that are essential to who one is, although he denies that timidity, thick-skinnedness, and so on count among them. However, if such features are essential, then it will not be true to say that had Georg lacked them, he would have freely killed Henrik. Since Georg is responsible, on Zimmerman's view, precisely in virtue of such counterfactuals being true, he would be absolved of responsibility if such features were essential to him. For this reason, Zimmerman concedes that “the role that luck plays in the determination of moral responsibility may not be entirely eliminable…” (2002, 575).
Finally, Zimmerman goes on to claim that his reasoning applies even to cases in which a person's actions are causally determined. If it is true that, say, Georg would have killed Henrik if his deterministic causal history, over which he has no control, had been different, then Georg is as responsible as he would have been had he killed Henrik in a world that was not determined. The upshot of the application of Zimmerman's reasoning is that we are all responsible, blameworthy, and even praiseworthy in ways we have never imagined. If Zimmerman is right, there are countless counterfactuals that apply to each and every one of us, in virtue of which we are responsible to one degree or another. The view thus takes the Control Principle extremely seriously, and applies it in the broadest possible way. The price we pay for “taking luck seriously” is that our everyday moral judgments are, if not always mistaken, at the very least radically incomplete.
A number of objections can be raised to Zimmerman's view, including (i) that at least large classes of the counterfactuals in virtue of which he thinks people are responsible lack truth value (e.g., Adams 1977, Nelkin 2004, and Zimmerman 2002, 572), and (ii) that he is simply mistaken that one can be responsible without being responsible for anything. Even if one or both of these objections are on target, Zimmerman's article is very helpful in showing what an attempt to follow out the denial of moral luck to its logical conclusion looks like.
Unlike Zimmerman, most of those who adopt the denial strategy do so only for certain sorts of moral luck. By treating all sorts of luck in the same way (with the exception of constitutive luck with respect to one's essential properties), Zimmerman challenges those who adopt this strategy to defend the drawing of the line between resultant and other sorts of luck. As we will see, this very same challenge is also issued by those who take a diametrically opposed position and accept all forms of moral luck.
4.1.2 Denying Moral Luck and Setting Aside Morality in Favor of Ethics
Before turning to the approach of accepting the existence of moral luck, it remains to consider the view ascribed earlier to Williams' “Postscript” (1993). Extracting Williams' position on “Moral Luck” is a notoriously difficult task, made easier only by Williams' own acknowledgment in the “Postscript” that his original article “may have encouraged” some misunderstandings (251). Many commentators have read Williams as advocating the position that moral luck exists and is deeply threatening to morality. There is certainly a line of reasoning in Williams' original article that suggests this (see 37–42, 51–53). But in the Postscript, Williams makes a distinction between morality and ethics that allows him to deny the existence of moral luck, thus preserving a certain integrity for morality.
Williams understands morality to embody the Kantian conception of it described above, accepting that the essence of the Control Principle is “built into” morality so understood (1993, 252). At the same time, examples like the Gauguin case described earlier show that one can be rationally justified in one's decision in virtue of its outcome. Further, such a case shows that our overall value judgment of someone's decision can depend on factors beyond the control of the agent. We must conclude, then, that there is a kind of value that competes with, if not trumps, moral value. And if that is right, then we must give up “the point of morality” so understood, namely, to “provide a shelter against luck, one realm of value (indeed, of supreme value) that is defended against contingency” (1993, 251, emphasis mine). It seems that morality can only insulate itself from luck at the expense of foregoing supreme value. Once we acknowledge this cost, we can keep morality intact (although skeptical doubts about its ability to resist luck can still be raised), but we have lost our reason to care about it. Instead, Williams suggests, we should care about ethics, where ethics is understood to address the most general question of how we ought to live.
Questions can be raised about this line of reasoning. For example, we can ask whether there is any sense in which Williams' Gauguin ought to have left his family, despite the fact that the result was so welcome. If there is not, then Williams has not shown that morality competes with, or is trumped by, some other value. From the other direction, we can ask whether Williams is right that morality loses its point if it is not the supreme source of value. Of course, even if Williams' reasoning is unsound, the conclusion could still be correct, and others have offered different routes to it.
The idea that we ought to care about ethics, understood as Williams does, finds inspiration in the work of Aristotle. Aristotle is concerned with the nature of the good life in the broadest sense—in what he calls “eudaimonia,” often translated as “happiness”. Aristotle defends the idea that happiness consists in being a virtuous person over a complete life, and, in turn, the idea that being a virtuous person requires not only that one have virtuous qualities and dispositions, but also that one act on them. Luck enters into the account in at least two ways. First, on Aristotle's account, one becomes a virtuous person by undergoing the right kind of upbringing and training. Since whether one receives this training is at least to some extent beyond one's control, one's ability to live a virtuous life is deeply dependent on luck. Second, the fact that being a virtuous person requires the performance of certain kinds of activities means that the world must cooperate in various ways in order for one to be truly virtuous, and so be truly happy. Aristotle writes that happiness “needs the external goods as well; for it is impossible, or not easy, to do noble acts without proper equipment” (1984 NE 1099a 31–33). For example, in order to engage in acts of generosity, one must have resources at one's disposal to share. And since having the right equipment is at least to some extent a matter of circumstantial luck, the value of one's life itself will depend in part on what is not in one's control. On one interpretation of Aristotle, luck enters into the account in yet a third way. Acting in accordance with virtue does not suffice for happiness, on this interpretation, although it is the “dominant component” of Aristotle's account of happiness (Irwin 1988, 445). According to this view, one must also have a minimum provision of external goods (e.g., health, security, access to resources) whose contribution to happiness is independent of their making virtuous activity possible. If this is right, then the value of one's life will depend at least in part on factors beyond one's control. In sum, while there is some dispute about whether Aristotle thought more than a life of virtuous activity is required for happiness, it is clear that luck plays a significant role in determining both whether people are truly virtuous and whether people's lives are good in the broadest sense. Hence, “the fragility of goodness” (Nussbaum).
4.2 Acceptance
All of those who accept the existence of some type of moral luck reject the Control Principle and the Kantian conception of morality that embraces it. As a result, they must either explain how we can revise our moral judgments and practices in a coherent way or show that we are not committed to the Control Principle in the first place.
4.2.1 Accepting Moral Luck and Revising our Practices
Some who accept luck argue that doing so requires a significant change in our moral practices. Browne (1992), for example, suggests that if the Control Principle is false, we ought not to respond to an agent's wrongdoing with anger and blame that is “against” him, but rather with anger that does not include hostility or the desire to punish. Nevertheless, we can still respond to the successful murderer with more of the “right” kind of anger than we feel toward the unsuccessful one. One question that might be raised here is whether we are left with enough of our ordinary conception of morality to include genuine notions of blame and responsibility.
4.2.2 Accepting Moral Luck without Revision
Others suggest that the Control Principle does not have nearly the hold on us that Nagel and Williams assume, and that rejecting it would not change our practices in a significant way. Among these are some who focus on the free will debate and others who take on the broader problem of moral luck directly.
4.2.2.1 Accepting Moral Luck and the Free Will Debate
A large group who accept moral luck do not explicitly address the problem of moral luck as so formulated because they focus on what Nagel identifies as a narrower issue, namely, that of free will. One traditional problem of free will is posed by the following line of reasoning: if determinism is true, then no one can act freely, and, assuming that freedom is necessary for responsibility, no one can be responsible for their actions. Compatibilists have argued that we can act freely and responsibly even if determinism is true. Since most do not adopt Zimmerman's radical account of moral assessment in which one can be responsible despite not being responsible for anything, they admit the existence of causal moral luck. If, as some have argued, causal luck is exhausted by constitutive and circumstantial luck, then they also accept that there can be these sorts of moral luck, as well.
A basic compatibilist strategy is to argue that agents can have control over their actions in the sense required for freedom and/or responsibility even if they do not control the causal determinants of those actions. For example, if one acts with the ability to act in accordance with good reasons (Wolf 1990) or if one acts with “guidance control” which consists in part of acting on a reasons-responsive mechanism for which one has taken responsibility, (Fischer and Ravizza 1998), one can be responsible for one's actions. The key move here is to distinguish between different kinds of factors over which one has no control. If one's actions are caused by factors that one does not control and that prevent one from having or exercising certain capacities, then one is not responsible. However, if one's actions are caused by factors that one does not control, but that do allow one to have and exercise the relevant capacities, then one can be “in control” of one's actions in the relevant sense, and so responsible for one's actions.
Interestingly, compatibilists are often silent on the question of resultant and circumstantial moral luck, although these forms of luck might represent an underutilized resource for them. For if it turns out that the luck—or lack of control—delivered by determinism is but one source of luck among others, then determinism does not embody a unique obstacle to free will and responsibility, at least when it comes to control. This is to expand the application of a widely used compatibilist strategy to show that when it comes to causal luck, compatibilists are not alone.
For within the free will debate, compatibilists are not alone in accepting the existence of certain types of luck. Many libertarians assume that our actions are caused by prior events (not themselves in our control) in accordance with probabilistic laws of nature (see, for example, Kane 1996, 1999, Nozick 1981). Given this view, it is natural to conclude that if determinism is false, there is at least one kind of luck in what sort of person one decides to be and so in what actions one performs. That is, there is luck in the sense that there is no explanation as to why a person chose to be one way rather than another. At the same time, Kane, for example, denies that there must be luck in the sense that one's choices are flukes or accidents if determinism is false. In Kane's view, what is important is to be free from luck of the second kind. For even if one's action is not determined, it can still be the case that the causes of one's action are one's own efforts and intention. And if one's action is caused by one's own efforts and intentions, then one's action is not lucky in the sense of being a fluke or accident. But while this shows that one's actions can be free of luck of an important kind, it still leaves unaddressed luck of a third kind, namely the kind at issue in the moral luck debate: the dependence of agents' choices on factors beyond their control. And it appears that on the libertarian view in question, our choices are indeed subject to luck of this sort. (See Pereboom (2002) for a discussion of the similar burdens shared by compatibilists and this sort of libertarian.) Only the agent-causal libertarians discussed above offer an account that aims specifically at eliminating a type of moral luck.
4.2.2.2 Accepting Moral Luck and Distinctive Conceptions of Morality
It is also possible to argue that we are not committed to the Control Principle by taking on the problem of moral luck directly.
One strategy is to argue that moral luck is only a problem for an overly idealized conception of human agency. But once we adopt a realistic conception of human agency, the problem evaporates. Margaret Urban Walker (1991) argues in this vein that moral luck is only problematic for a conception of moral agents as “noumenal” or pure (238). In contrast, adopting a conception of morality that applies to human beings in all of their impurity will not be threatened by moral luck. According to Walker, the Control Principle is far from obvious, and we would not want to live in a world in which it held sway. The argument appears to rest on the idea that without moral luck, we would lack several virtues that allow us to help each other in most essential ways. Our very reactions to moral luck can be virtuous. For example, by accepting that our “responsibilities outrun control,” we are able to display the virtue of dependability by accepting that we will be there for our friends, even if their needs are not in our control. In contrast, pure agents who are only responsible for what they control “may not be depended on, much less morally required, to assume a share of the ongoing and massive human work of caring, healing, restoring, and cleaning-up on which each separate life and the collective one depend.” (247). Thus, if we focus on our actual moral commitments, we will see that the Control Principle is neither attractive nor necessary for morality.
It is not obvious that a world in which people denied the existence of moral luck would be as bleak as the one Walker envisions. Moral luck skeptics have material with which to question Walker's claim. For example, those who deny resultant moral luck can still agree that agents have an obligation to minimize their risks of doing harm, and those who deny circumstantial moral luck can still agree that agents have an obligation to cultivate qualities that prepare them to act well in whatever circumstances arise.
A second strategy for rejecting the Control Principle turns Nagel's argument on its head by taking as a starting point ordinary judgments and reactions that reveal our implicit rejection of the Control Principle. Adams (1985) adopts this strategy, drawing our attention to common practices, such as blaming people for their racist attitudes even if we do not think that such people are in control of their attitudes. Since Adams focuses primarily on agents' states of mind that have intentional objects such as anger and self-righteousness, it is possible to see him as accepting the existence of constitutive moral luck in particular. But it is also possible to adopt the same sort of strategy for other sorts of luck, including resultant luck. Moore (1997 and 2009), for example, points to the fact that we resent those who succeed in causing harm more than those who do not, we feel greater guilt when we ourselves cause harm, and when we face decisions, we feel that the consequences of matter to the moral quality of our choices. According to Moore, the best explanation of these reactive attitudes, such as guilt and resentment, is that their objects are genuinely more blameworthy.
Now opponents who deny the existence of moral luck have ways of explaining away these phenomena. When it comes to cases of constitutive luck, like the case of the racist, they can say that we confuse agents' blameworthiness for their character and attitudes with blameworthiness for their actions that manifest these offending attitudes and for their failure to take steps to eliminate them. On reflection, we can see that we ought to blame the racists only for their actions or omissions, not for the attitudes themselves over which they have no control. Similarly, as we saw earlier, when it comes to resultant luck, moral luck skeptics have a variety of strong alternative explanations of our judgments and emotional responses. It is possible that there is a disagreement here at the level of intuitions: some find it easier on reflection to reject moral judgments that depend on results than others. Further, those accepting resultant moral luck face a challenge of articulating a positive theory of how exactly results affect one's moral status while at the same time accounting for our intuitions. Sverdlik (1988) argues that it is not obvious how such a challenge can be met.
At this point in the debate, those who accept moral luck offer ordinary judgments and responses in their defense, while moral luck skeptics offer alternative explanations of those practices and hold up the Control Principle itself, together with other reflective intuitive judgments, as reason to reject moral luck. We seem to have something of a stalemate. So it is no surprise that those who accept moral luck tend not to rely exclusively on ordinary judgments to make their case, but rather go on to try to undermine the Control Principle in other ways.
Another way of trying to undermine the appeal of the Control Principle itself is to show how it might be mistaken for something else that is more plausible. For example, Adams (1985) recognizes that there are limits to what we can be responsible for, and writes that the states of mind “for which we are directly responsible are those in which we are responding, consciously or unconsciously, to data that are rich enough to permit a fairly adequate ethical appreciation of the state's intentional object and of the object's place in the fabric of personal relationships” (26). Thus, according to Adams' conception of morality, adherents of the Control Principle are correct in an important respect, namely, in their understanding that what one is responsible for springs in the right way from oneself. But this requirement is more general than a strict requirement of control, and although easily confused with the Control Principle, is superior to it, on this view.
Adopting the same general strategy, Moore (1997) identifies still other principles with which the Control Principle might be confused. He points out that when we use the word “luck” in the context of moral assessment, we tend not to mean that the person lacked control over what he did, but rather that what happened was far off of “some moral baseline of the normal” (213). For example, consider two would-be murderers, one of whom fires his gun and hits his target, and the other of whom fires in the same way, from the same distance, and so on, but whose bullet is deflected by an unexpected and unusually strong wind. Moore suggests that the first gunman is not “lucky” in the ordinary sense, even though it is true that whether a hurricane-force wind arose or not was not in his control. According to Moore, there is something intuitively right about morality being immune to luck, but only if we understand “luck” in the sense of “freakishness.” Further, the successful murderer is “in control” of his action in the normal sense of the word “control,” even though he doesn't control the wind. Thus, while we do care about luck and control in making both moral and legal assessments, they aren't Nagel's concepts, on this view. Thus, according to Moore, there is no contradiction in our everyday commitments.
Now those who think we are naturally drawn to the Control Principle can respond by pointing out both the intuitive plausibility of the principle in the abstract and the cases described earlier that seem to support it. They might also accept that Adams and Moore have pointed out further necessary conditions for responsibility, while still maintaining that the Control Principle is true. Again, differing intuitions about cases and about the Control Principle have the potential to make a big difference to one's view at this point.
Michael Otsuka offers yet another principle in place of the Control Principle: One is only blameworthy in cases in which one had the kind of control that would have allowed one to be entirely blameless. Consistent with this is a kind of moral luck, however: one's blameworthiness can vary in degree as a function of harm done, where harm done may be affected by what is not in one's control. Although one cannot be blameworthy if one lacked the control necessary to avoid blameworthiness, one's degree of blameworthiness can increase if the risk one takes comes out badly due to circumstances one could do nothing to avoid. For example, in the case of the two assassins, both are blameworthy, but, Otsuka argues, the one who hits and kills his target is more blameworthy. In sketching the view, Otsuka draws a parallel with Dworkin's (1981) treatment of option luck in the debate over egalitarianism. In that debate, a distinction is drawn between option luck (“a matter of ...whether someone gains or loses through accepting an isolated risk he or she should have anticipated and might have declined”) and brute luck (“a matter of how risks fall out that are not that sense...gambles).” If one's luck is just brute-one did not assume a risk, as when one has done everything a careful driver would do, and due to sheer luck, a dog runs into the street and one drives over it-one is not blameworthy. But if one assumes a risk by knowingly and freely driving recklessly, and, as a result, one kills a dog, then one is blameworthy. And, further, one might be more blameworthy in the case in which one kills the dog than in the case in which one takes the same risk but luckily reaches home without hitting anything. It would be reasonable, on Otsuka's view, for the dog owner whose dog is killed to be more resentful than the one whose dog escapes, and this supports the conclusion that the driver who kills the dog is more blameworthy than the one who does not.
The parallel to option an brute luck is suggestive, but a defender of the unqualified Control principle has resources here. Appealing to the distinction between scope and degree, one might grant that the reckless driver is, importantly, responsible for more things (including a death), but not more blameworthy. In fact, the parallel to the treatment of option luck in the debate about distributive justice may fit best if we are interested in what we are responsible for, rather than how responsible we are. Further, we have seen reason to think that on reflection we should not blame one reckless driver more than another. One might question Otsuka's premise that degree of blameworthiness is to be understood in terms of appropriate degree of attitudes such as resentment (or even the weaker premise that the degree of blameworthiness tracks the appropriate degree of such attitudes). But even if we accept this premise, we might conclude that while it is understandable that one dog owner would be more resentful than the first, more resentment is not actually justified. This observation takes us back to the subtle nature of the dialectic.
In adjudicating this debate between those defending the Control Principle and those defending alternative principles, we can ask just how much weight should be given to our natural reactions to cases, and, in particular, to our reactive attitudes, such as resentment and guilt. At least in some cases, these can be tempered when we reflect explicitly on key features of cases, and our initial responses can be revised in light of these reflections, together with reflection on general principles.
Notably, there has recently been an attempt by philosophers to appeal to results from empirical psychology to explain away some set of intuitions or other, and this strategy has been applied in the area of moral luck in particular. For just two examples, see Domsky (2004) and Royzman and Kumar (2004) whose explanations in different ways support the preservation of our adherence to the Control Principle, and see Enoch and Guttel (2010) for a reply to both. Psychologists and experimental philosophers have also simply tried to offer explanations of our intuitions, particularly of ones that appear to conflict as we find in the debate about moral luck. For example, see Cushman and Green (2012), who offer an explanation of apparently conflicting intuitions about moral results luck in terms of two dissociable processes, and Björnsson and Persson (2012), who offer an explanation in terms of shifting explanatory perspectives. It is worth noting, however, as several of these authors do themselves, that even if we were confident in our possession of psychological explanations of our intuitions, there would still be philosophical work to do to sort out what the normative facts are. And given the variety of proposals and results, it seems we are not in a position to have that kind of confidence.
There is a final argument in favor of the acceptance of moral luck of a very different kind that might ultimately help decide the issue in one direction or the other. It explicitly encompasses every kind of luck and thus poses a deep and difficult challenge to moral luck skeptics, particularly the large group who focus exclusively on resultant luck. The main idea is that rejecting resultant luck, but not other sorts of luck, is an unstable position (Moore 1997). In a nutshell, one cannot find a principled place to draw the line at refusing to accept moral luck. In effect, this argument is Nagel's argument in reverse. Begin by observing that we lack control over everything: the results of our actions, our circumstances, our constitution, and our causal history. If we are to avoid moral skepticism, then we must accept moral luck in some areas, and if we do that, then we ought to accept it in the area of results. Particularly if we accept that we are not predisposed to accept the Control Principle in the first place, then we ought to accept luck in all areas, thereby avoiding moral skepticism.
Now even if no one has adequately defended a way of drawing a line between different sorts of luck, it is not obvious that the door has been closed on all future attempts. Thus, one way of seeing this argument is as a shift-the-burden one. Those who wish to draw a line between different sorts of moral luck must offer a deeper rationale for doing so than has yet been offered.
4.3 Incoherence
According to this approach, it is simply incoherent to accept or deny the existence of some type(s) of moral luck. This approach has been used for constitutive luck in particular.
Among those who wish to preserve the centrality of morality in our lives, many have appealed to an idea formulated by Nicholas Rescher (1993), according to which “[o]ne cannot meaningfully said to be lucky in regard to who one is, but only with respect to what happens to one. Identity must precede luck” (155). It is easy to take Rescher's point out of context without realizing that he is working with a notion of luck that differs from the notion of “lack of control.” According to Rescher, something is lucky if (i) it came about “by accident” where this seems to mean something like “unplanned” or “unexpected” or “out of the ordinary” and (ii) the outcome “has a significantly evaluative status in representing a good or bad result, a benefit or loss”(145). Taken this way, it does seem at least very odd to say that one's identity is (or is not) a matter of luck. But it is less clear that there is anything odd—let alone incoherent—about saying that one's identity is not a matter within one's control.
Could there nevertheless be some truth to Rescher's claim even if we understand “luck” as “out of one's control?” Perhaps it does not make sense, for example, to say that a person is in control of who she is. For one could argue that this would amount to saying that a person is a self-creator. And in fact the Control Principle, taken to its logical extreme, seems to lead to just such a requirement (see, e.g., Browne 1992, Nagel 1986, 118). If it turns out that self-creation is conceptually impossible as many argue (e.g., Galen Strawson 1986), then perhaps there is a sense in which it is right to say that being in control of one's constitution makes no sense. But it does not follow from this that it is meaningless to deny that one can control one's constitution.
Perhaps the best way of deploying the insight that there is something special about luck and constitution is not to say that it is meaningless to discuss it, but to say that constitutive moral luck is simply unproblematic for morality in the way that resultant moral luck is. This would be to take up the “line-drawing” challenge as described in the last section. On this line of reasoning, for purposes of moral assessment, it does not matter how you came to be; what matters is what you do with what you are. Of course, as we saw, this requires defense and explanation, but it is a way of capturing the insight that constitutive luck is relevantly different from the resultant luck that has captivated a number of commentators.
5. Conclusion
The problem of moral luck is deeply unsettling. Naturally, there is a wide variety of responses to it. On the one extreme are those who deny that there is any sort of moral luck, and on the other are those who accept every sort of moral luck. Most writers who have responded to the problem fall somewhere in between; either they explicitly take a mixed approach or they confine their arguments to a carefully delineated subset of types of moral luck while remaining uncommitted with respect to the others. The extreme positions are vulnerable to the objection that they have left some consideration or other completely unaccounted for. But those who occupy the middle also face a formidable challenge: where can one draw a principled line between acceptable and unacceptable forms of luck? As we have seen, one apparently natural place to draw a line is between resultant luck and all of the other sorts. On this view, there is no resultant moral luck, despite initial appearances, although there is moral luck of all the other kinds. Thus, occupiers of this position face the challenge of setting out a plausible rationale for drawing the line where they do. But they also face the challenge of where precisely to draw another line, namely, the line around what counts as “results.” For we can ask on which side of this line do intentions, willings, bodily movements, and so on, fall. Do results include everything that happens after the formation of an intention or the exertion of the will, for example? Or everything that follows the beginning of the formation of an intention or the beginning of the exertion of the will? Or everything that follows the “affection of the heart” of which Adam Smith wrote so eloquently? These are difficult questions for those who would draw a line at resultant luck. But difficult questions await every other proposal, too. Fortunately, there is a rich and growing literature providing a full spectrum of responses to explore.
Bibliography
Adams, R. M., 1973, “Middle Knowledge”, The Journal of Philosophy, 70: 552–554.
–––, 1985, “Involuntary Sins”, The Philosophical Review, 94: 3–31.
Adler, J., 1987, “Luckless Desert is Different Desert”, Mind, 96: 247–249.
Alexander, L., K. Ferzan, and S. Morse, 2009, Crime and Culpability: A Theory of Criminal Law, Cambridge University Press.
Anderson. E, 1999, “What is the Point of Equality”, Ethics, 109: 339–349.
Andre, J., 1983, “Nagel, Williams, and Moral Luck”, Analysis, 43: 202–207; reprinted in Statman 1993b.
Arneson, R., 2001, “Luck and Equality”, Proceedings of the Aristotelian Society, supplementary volume, 75: 73–90.
–––, forthcoming, “Rawls, Responsibility, and Distributive Justice”, in Justice, Political Liberalism, and Utilitarianism: Themes from Harsanyi and Rawls, M. Salles and J.A. Weymark (eds.), Cambridge: Cambridge University Press.
Aristotle, 1984, The Complete Works: Revised Oxford Translation, J. Barnes (ed.), Princeton: Princeton University Press.
Björnsson, G. and Persson, K., 2012, “The Explanatory Component of Moral Responsibility,” Noûs 46: 326–54.
Browne, B., 1992, “A Solution to the Problem of Moral Luck”, The Philosophical Quarterly, 42: 343–356.
Chisolm, R., 1964, “Human Freedom and the Self”, The Lindley Lecture, University of Kansas; reprinted in Watson 1982.
Clarke, R., 1993, “Toward a Credible Agent-Causal Account of Free Will”, Noûs, 27: 191–203.
–––, 2005, “Agent Causation and the Problem of Luck,” Pacific Philosophical Quarterly, 86: 408–421.
Cohen, G.A. 1989, “On the Currency of Egalitarian Justice”, Ethics, 99: 906–44.
Cushman, F. and Green, J., 2012,“Finding Faults: How Cognitive Dilemmas Illuminate Cognitive Structure,” Social Neuroscience 7: 269–79.
Davis, M., 1986, “Why Attempts Deserve Less Punishment Than Completed Crimes”, Law and Philosophy, 5: 1–32.
Domsky, D., 2004, “There is No Door: Finally Solving the Problem of Moral Luck,” The Journal of Philosophy 101: 445–464.
Dworkin, R., 1981, “What is Equality? Part 2: Equality of Resources”, Philosophy and Public Affairs, 10: 283–345.
–––, 2000, Sovereign Virtue: The Theory and Practice of Equality, Cambridge: Harvard University Press.
Enoch, D., 2010, “Moral Luck and the Law”, Philosophy Compass 5(1): 42–54.
Enoch, D. and Guttel, E., 2010, “Cognitive Biases and Moral Luck,” Journal of Moral Philosophy 7: 372–86
Enoch, D. and A. Marmor, 2007, “The Case Against Moral Luck,” Law and Philosophy 26: 405–436.
Feinberg, J., 1970, Doing and Deserving: Essays in the Theory of Responsibility, Princeton, NJ: Princeton University Press.
–––, 1995, “Equal Punishment for Failed Attempts: Some Bad But Instructive Arguments Against It”, The Arizona Law Review, 37: 117–133.
Fischer, J.M., and Ravizza, M., 1998, Responsibility and Control: A Theory of Moral Responsibility, Cambridge: Cambridge University Press.
Greco, J., 1995, “A Second Paradox Concerning Responsibility and Luck”, Metaphilosophy, 26: 81–96.
Herman, B., 1995, “Feinberg on Luck and Failed Attempts”, The Arizona Law Review, 37: 143–150.
Hurley, S., 2003, Justice, Luck, and Knowledge, Cambridge: Harvard University Press.
–––, 2001, “Luck and Equality”, Proceedings of the Aristotelian Society, supplementary volume, 75: 51–72.
Irwin, T., 1988, Aristotle's First Principles, Oxford: Clarendon Press.
Jensen, H., 1984, “Morality and Luck”, Philosophy, 59: 323–330; reprinted in Statman 1993b.
Kadish, S., 1994, “Forward: The Criminal Law and the Luck of the Draw,” Journal of Criminal Law and Criminology, 84: 2183–2237.
Kane, R., 1996, The Significance of Free Will, New York: Oxford University Press.
–––, 1999, “Responsibility, Luck, and Chance: Reflections on Free Will and Indeterminism”, The Journal of Philosophy, 96: 217–240.
Kant, I., 1784/1998, Groundwork of the Metaphysics of Morals, M. Gregor (ed. and transl.), Cambridge: Cambridge University Press.
Latus, A., 2000, “Moral and Epistemic Luck”, Journal of Philosophical Research, 25: 149–172.
–––, 2001, “Moral Luck,” The Internet Encyclopedia of Philosophy, J. Feiser (ed.).
Levi, D., 1989, “What's Luck Got to Do With It?”, Philosophical Investigations, 12: 1–13; reprinted in Statman 1993b.
Lewis, D., 1989, “The Punishment That Leaves Something to Chance”, Philosophy and Public Affairs, 96: 227–242.
Mele, A., 1999, “Ultimate Responsibility and Dumb Luck”, Social Philosophy and Policy, 16: 274–293.
–––, 2006, Free Will and Luck, Oxford: Oxford University Press.
Moore, M., 1997, Placing Blame: A Theory of the Criminal Law, Oxford: Clarendon Press, especially chapter 5.
–––, 2009, Causation and Responsibility: An Essay in Law, Morals, and Metaphysics, Oxford: Oxford University Press.
Nagel, T., 1979, Mortal Questions, New York: Cambridge University Press; page reference is to the reprint of chapter 3 in Statman 1993b.
–––, 1986, The View from Nowhere, New York: Oxford University Press.
Nelkin, D.K., 2004, “Irrelevant Alternatives and Frankfurt Counterfactuals,” Philosophical Studies, 121: 1–25.
Nozick, R., 1974, Anarchy, State, and Utopia, New York: Basic Books, Inc., Publishers.
Nussbaum, M., 1986, The Fragility of Goodness: Luck and Ethics in Greek Tragedy and Philosophy, Cambridge: Cambridge University Press; page reference is to the reprint of pages 1–8, 322–340 in Statman 1993b.
O'Connor, T., 2000, Persons and Causes: the Metaphysics of Free Will, New York: Oxford University Press.
Otsuka, M., 2009, “Moral Luck: Optional, Not Brute,” Philosophical Perspectives, 23: 373–388.
Pereboom, D., 2001, Living Without Free Will, Cambridge: Cambridge University Press.
Plato, 1997, Plato: Complete Works, J. Cooper (ed.), Indianapolis: Hackett Publishing Company.
Rawls, J., 1971, A Theory of Justice, Cambridge: Harvard University Press.
Rescher, N., 1993, “Moral Luck”, in Moral Luck, D. Statman (ed.), Albany: State University of New York Press.
Richards, N., 1986, “Luck and Desert”, Mind, 65: 198–209; page reference is to the reprint in Statman 1993b.
Ripstein, A, 1999, Equality, Responsibility, and the Law, Cambridge: Cambridge University Press.
Roemer, J 1996, Theories of Distributive Justice, Cambridge: Harvard University Press.
Rosebury, B., 1995, “Moral Responsibility and Moral Luck”, Philosophical Review, 104: 499–524.
Royzman, E. and Kumar, R., 2004, “Is Consequential Luck Morally Inconsequential?” Ratio 17: 329–44.
Scheffler, S., 2003, “What is Egalitarianism”, Philosophy and Public Affairs, 31: 5–39.
Smith, A., 1790/1976, The Theory of Moral Sentiments, D. D. Raphael and A. L. Macfie (ed.s), Oxford: Clarendon Press.
Statman, D., 1991, “Moral and Epistemic Luck”, Ratio, 4:146–156.
–––, Introduction to Moral Luck, Albany: State University of New York Press.
–––, (ed.), 1993b,Moral Luck, Albany: State University of New York Press.
Statman, D., 2005, “Doors, Keys, and Moral Luck: A Reply to Domsky,” The Journal of Philosophy, 102: 422–436
Strawson, G., 1986, Freedom and Belief, New York: Oxford University Press.
Sverdlik, S., 1988, “Crime and Moral Luck”, American Philosophical Quarterly, 25: 79–86; reprinted in Statman 1993b.
Taylor, R., 1966, Action and Purpose, Englewood Cliffs, NJ: Prentice Hall.
Thomson, J. J., 1993, “Morality and Bad Luck”, in Moral Luck, D. Statman (ed.), Albany: State University of New York Press.
Waldron, J., 1995, “Moments of Carelessness and Massive Loss”, in Philosophical Foundations of Tort Law, David Owen(ed.), Oxford: Clarendon Press.
Walker, M. U., 1991, “Moral Luck and the Virtues of Impure Agency”, Metaphilosophy, 22: 14–27; page reference is to the reprint in Statman 1993b.
Watson, G., 1982, Free Will, New York: Oxford University Press.
Williams, B., 1981, Moral Luck, Cambridge: Cambridge University Press; page reference is to the reprint of chapter 2 in Statman 1993b.
–––, 1993, “Postscript”, in Moral Luck, D. Statman (ed.), Albany: State University of New York Press.
Wolf, S., 1990, Freedom Within Reason, Oxford: Oxford University Press.
–––, 2001, “The Moral of Moral Luck”, Philosophic Exchange, 31: 4–19.
Yaffe, G. 2010, Attempts, Oxford: Oxford University Press.
Zimmerman, M., 1987, “Luck and Moral Responsibility”, Ethics, 97: 374–386; reprinted in Statman 1993b.
–––, 2002, “Taking Luck Seriously”, The Journal of Philosophy, 99: 553–576.
–––, 2006, “Moral Luck: A Partial Map,” Canadian Journal of Philosophy, 36: 585–608.
Academic Tools
Acknowledgments
I am very grateful to David Brink, Nina Davis, Derk Pereboom, and Sam Rickless for their very helpful input and constructive suggestions. I also benefited greatly from participation in the University of San Diego Institute for Law and Philosophy Roundtable on Moral Luck in April 2003.Constructive mathematics is distinguished from its traditional counterpart, classical mathematics, by the strict interpretation of the phrase “there exists” as “we can construct”. In order to work constructively, we need to re-interpret not only the existential quantifier but all the logical connectives and quantifiers as instructions on how to construct a proof of the statement involving these logical expressions.
In this article we introduce modern constructive mathematics based on the BHK-interpretation of the logical connectives and quantifiers. We discuss four major varieties of constructive mathematics, with particular emphasis on the two varieties associated with Errett Bishop and Per Martin-Löf, which can be regarded as minimal constructive systems. We then outline progress in (informal) constructive reverse mathematics, a research programme seeking to identify principles, such as Brouwer's fan theorem, that, added to the minimal constructive varieties, facilitate proofs of important analytic theorems. Finally, we describe two relatively recent constructive approaches to topology: the theory of apartness spaces, and formal topology.
1. Introduction
2. The Constructive Interpretation of Logic
6. Concluding Remarks
Academic Tools
Other Internet Resources
Related Entries
1. Introduction
Before mathematicians assert something (other than an axiom) they are supposed to have proved it true. What, then, do mathematicians mean when they assert a disjunction P ∨ Q, where P and Q are syntactically correct statements in some (formal or informal) mathematical language? A natural — although, as we shall see, not the unique — interpretation of this disjunction is that not only does (at least) one of the statements P, Q hold, but also we can decide which one holds. Thus just as mathematicians will assert P only when they have decided that P holds by proving it, they may assert P ∨ Q only when they either can produce a proof of P or else produce one of Q.
With this interpretation, however, we run into a serious problem in the special case where Q is the negation, ¬P, of P. To assert ¬P is to show that P implies a contradiction (such as 0 = 1). But it will often be that mathematicians have neither a proof of P nor one of ¬P. To see this, we need only reflect on the following Goldbach conjecture (GC):
Every even integer > 2 can be written as a sum of two primes,
which remains neither proved nor disproved despite the best efforts of many of the leading mathematicians since it was first raised in a letter from Goldbach to Euler in 1742. We are forced to conclude that, under the very natural decidability interpretation of P ∨ Q, only a stubborn optimist can retain a belief in the law of excluded middle (LEM):
For every statement P, either P or ¬P holds.
Classical logic gets round this by widening the interpretation of disjunction: it interprets P ∨ Q as ¬(¬P∧¬Q), or in other words, “it is contradictory that both P and Q be false”. In turn, this leads to the idealistic interpretation of existence, in which ∃xP(x) means ¬∀x¬P(x) (“it is contradictory that P(x) be false for every x”). It is on these interpretations of disjunction and existence that mathematicians have built the grand, and apparently impregnable, edifice of classical mathematics which serves a foundation for the physical, the social, and (increasingly) the biological sciences. However, the wider interpretations come at a cost: for example, when we pass from our initial, natural interpretation of P ∨ Q to the unrestricted use of the idealistic one, ¬(¬P∧¬Q), the resulting mathematics cannot generally be interpreted within computational models such as recursive function theory.
This point is illustrated by a well-worn example, the proposition:
There exist irrational numbers a, b such that ab is rational.
A slick classical proof goes as follows. Either √2√2 is rational, in which case we take a = b = √2; or else √2√2 is irrational, in which case we take a = √2√2 and b = √2 (see Dummett 1977 [2000], 6). But as it stands, this proof does not enable us to pinpoint which of the two choices of the pair (a, b) has the required property. In order to determine the correct choice of (a, b), we would need to decide whether √2√2 is rational or irrational, which is precisely to employ our initial interpretation of disjunction with P the statement “√2√2 is rational”.
Here is another illustration of the difference between interpretations. Consider the following simple statement about the set R of real numbers:
(*) ∀x ∈ R (x = 0 ∨ x ≠ 0),
where, for reasons that we divulge shortly, x ≠ 0 means that we can find a rational number r with 0 < r < |x|. A natural computational interpretation of (*) is that we have a procedure which, applied to any real number x, either tells us that x = 0 or else tells us that x ≠ 0. (For example, such a procedure might output 0 if x = 0, and 1 if x ≠ 0.) However, because the computer can handle real numbers only by means of finite rational approximations, we have the problem of underflow, in which a sufficiently small positive number can be misread as 0 by the computer; so there cannot be a decision procedure that justifies the statement (*). In other words, we cannot expect (*) to hold under our natural computational interpretation of the quantifier ∀ and the connective ∨.
Let's examine this from another angle. Let G(n) act as shorthand for the statement “2n + 2 is a sum of two primes”, where n ranges over the positive integers, and define an infinite binary sequence a = (a1, a2, …) as follows:
an =
{
0 if G(n) holds for all k ≤ n
1 if ¬G(n) holds for some k ≤ n.
There is no question that a is a computationally well-defined sequence, in the sense that we have an algorithm for computing an for each n: check the even numbers 4, 6, 8, …, 2n+2 to determine whether each of them is a sum of two primes; in that case, set an = 0, and in the contrary case, set an = 1. Now consider the real number whose nth binary digit is an :
If (*) holds under our computational interpretation, then we can decide between the following two alternatives:
2−1a1 + 2−2a2 + ··· = 0, which implies that an = 0 for every n;
we can find a positive integer N such that 2−1a1 + 2−2a2 + ··· > 2−N.
In the latter case, by testing a1, …, aN, we can find n ≤ N such that an = 1. Thus the computational interpretation of (*) enables us to decide whether there exists n such that an = 1; in other words, it enables us to decide the status of the Goldbach Conjecture. An example of this type, showing that a constructive proof of some classical result P would enable us to solve the Goldbach conjecture (and, by similar arguments, many other hitherto open problems, such as the Riemann hypothesis), is called a Brouwerian example for, or even a Brouwerian counterexample to, the statement P (though it is not a counterexample in the normal sense of that word).
The use of the Goldbach Conjecture here is purely dramatic. To avoid it, we define a function ƒ classically on the set of binary sequences as follows:
ƒ(a) =
{
0 if an = 0 for all n
1 if an = 1 for some n.
The argument of the preceding paragraph can then be modified to show that, under our computational interpretation, (*) provides us with a procedure for calculating ƒ(a) for any computationally well-defined binary sequence a. Now, the computability of the function ƒ can be expressed informally by the limited principle of omniscience (LPO):
For each binary sequence (a1, a2, …) either an = 0 for all n or else there exists n such that an = 1,
which is generally regarded as an essentially nonconstructive principle for several reasons. First, its recursive interpretation,
There is a recursive algorithm which, applied to any recursively defined binary sequence (a1, a2, …), outputs 0 if an = 0 for all n, and outputs 1 if an = 1 for some n,
is provably false within recursive function theory, even with classical logic (see Bridges and Richman 1987, Chapter 3); so if we want to allow a recursive interpretation of all our mathematics, then we cannot use LPO. Secondly, there is a model theory (Kripke models) in which it can be shown that LPO is not constructively derivable (Bridges and Richman 1987, Chapter 7).
Why, incidentally, do we have the word “classically” in the second sentence of the preceding paragraph? It is because, from a constructive standpoint, ƒ(a) is defined only for those binary sequences a for which we can decide either that an = 0 for all n or else that there exists (we can compute) a positive integer n with an = 1; in other words, f is a constructively well-defined function on the set of all binary sequences if and only if LPO is constructively derivable!
2. The Constructive Interpretation of Logic
It should, by now, be clear that a full-blooded computational development of mathematics disallows the idealistic interpretations of disjunction and existence upon which most classical mathematics depends. In order to work constructively, we need to return from the classical interpretations to the natural constructive ones:
∨ (or):
to prove P ∨ Q we must either have a proof of P or have a proof of Q.
∧ (and):
to prove P ∧ Q we must have both a proof of P and a proof of Q.
⇒ (implies):
a proof of P → Q is an algorithm that converts any proof of P into a proof of Q.
¬ (not):
to prove ¬P we must show that P implies 0 = 1.
∃ (there exists):
to prove ∃xP(x) we must construct an object x and prove that P(x) holds.
∀ (for each/all):
a proof of ∀x∈S P(x) is an algorithm that, applied to any object x and to the data proving that x∈S, proves that P(x) holds.
These BHK-interpretations (the name reflects their origin in the work of Brouwer, Heyting, and Kolmogorov) can be made more precise using Kleene's notion of realizability; see (Dummett 1977 [2000], 222–234; Beeson 1985, Chapter VII).
What sort of things are we looking for if we are serious about developing mathematics in such a way that when a theorem asserts the existence of an object x with a property P, then the proof of the theorem embodies algorithms for constructing x and for demonstrating, by whatever calculations are necessary, that x has the property P. Here are some examples of theorems, each followed by an informal description of the requirements for its constructive proof.
For each real number x, either x = 0 or x ≠ 0.
Proof requirement: An algorithm which, applied to a given real number x, decides whether x = 0 or x ≠ 0. Note that, in order to make this decision, the algorithm might use not only the data describing x but also the data showing that x is actually a real number.
Each nonempty subset S of R that is bounded above has a least upper bound.
Proof requirement: An algorithm which, applied to a set S of real numbers, a member s of S, and an upper bound for S,
computes an object b and shows that b is a real number;
shows that x ≤ b for each x ∈ S; and
given a real number b′ < b, computes an element x of S such that x > b′.
If ƒ is a continuous real-valued mapping on the closed interval [0, 1] such that ƒ(0)·ƒ(1) < 0, then there exists x such that 0 < x < 1 and ƒ(x) = 0.
Proof requirement: An algorithm which, applied to the function ƒ, a modulus of continuity for ƒ, and the values ƒ(0) and ƒ(1),
computes an object x and shows that x is a real number between 0 and 1; and
shows that ƒ(x) = 0.
If ƒ is a continuous real-valued mapping on the closed interval [0, 1] such that ƒ(0)·ƒ(1) < 0, then for each ε > 0 there exists x such that 0 < x < 1 and |ƒ(x)| < ε.
Proof requirement: An algorithm which, applied to the function ƒ, a modulus of continuity for ƒ, the values ƒ(0) and ƒ(1), and a positive number ε,
computes an object x and shows that x is a real number between 0 and 1; and
shows that |ƒ(x)| < ε.
We already have reasons for doubting that (A) has a constructive proof. If the proof requirements for (B) can be fulfilled, then, given any mathematical statement P, we can apply our proof of (B) to compute a rational approximation z to the supremum σ of the set
S = {0} ∪ {x ∈ R: P ∧ x = 1}
with error < ¼. We can then determine whether z > ¼, in which case σ > 0, or z < ¾, when σ < 1. In the first case, there exists x ∈ S with x > 0, so we must have x = 1 and therefore P. In the case σ < 1, we have ¬P. Thus (B) implies the law of excluded middle.
However, in Bishop's constructive theory of the real numbers, based on Cauchy sequences with a preassigned convergence rate, we can prove the following constructive least-upper-bound principle:
Let S be a nonempty subset of R that is bounded above. Then S has a least upper bound if and only if it is upper-order located, in the sense that for all real numbers α, β with α < β, either β is an upper bound for S or else there exists x ∈ S with x > α (Bishop and Bridges 1985, p. 37, Proposition (4.3)).
In passing, we mention an alternative development of the constructive theory of R based on interval arithmetic; see Chapter 2 of Bridges and Vîță 2006.
Each of statements (C) and (D), which are classically equivalent, is a version of the Intermediate Value Theorem. In these statements, a modulus of continuity for ƒ is a set Ω of ordered pairs (ε, δ) of positive real numbers with the following two properties:
for each ε > 0 there exists δ > 0 such that (ε, δ) ∈Ω
for each (ε, δ) ∈ Ω, and for all x, y ∈ [0, 1] with |x − y| < δ, we have |ƒ(x) − ƒ(y)| < ε.
Statement (C) is essentially nonconstructive, since it entails the essentially nonconstructive lesser limited principle of omniscience (LLPO):
For each binary sequence (a1,a2,…) with at most one term equal to 1, either an = 0 for all even n or else an = 0 for all odd n.
Statement (D), a weak form of (C), can be proved constructively, using an interval-halving argument of a standard type. The following stronger constructive intermediate value theorem, which suffices for most practical purposes, is proved using an approximate interval-halving argument:
Let ƒ be a continuous real-valued mapping on the closed interval [0, 1] such that ƒ(0) and ƒ(1) have opposite signs. Suppose also that ƒ is locally nonzero, in the sense that for each x ∈ [0, 1] and each r > 0, there exists y such that |x − y| < r and ƒ(y) ≠ 0. Then there exists x such that 0 < x < 1 and ƒ(x) = 0.
The situation of the intermediate value theorem is typical of many in constructive analysis, where we find one classical theorem with several constructive versions, some or all of which may be equivalent under classical logic. (See also, for example, Bridges et al. 1982.)
There is one omniscience principle whose constructive status is less clear than that of LPO and LLPO—namely, Markov's principle (MP):
For each binary sequence (an), if it is contradictory that all the terms an equal 0, then there exists a term equal to 1.
This principle is equivalent to a number of simple classical propositions, including the following:
For each real number x, if it is contradictory that x equal 0, then x ≠ 0 (in the sense we mentioned earlier).
For each real number x, if it is contradictory that x equal 0, then there exists y ∈ R such that xy = 1.
For each one-one continuous mapping ƒ : [0, 1] → R, if x ≠ y, then ƒ(x) ≠ ƒ(y).
Markov's principle represents an unbounded search: if you have a proof that all terms an being 0 leads to a contradiction, then, by testing the terms a1,a2,a3,… in turn, you are “guaranteed” to come across a term equal to 1; but this guarantee does not extend to an assurance that you will find the desired term before the end of the universe. Most practitioners of constructive mathematics view Markov's principle with at least suspicion, if not downright disbelief. Such views are reinforced by the observation that there is a Kripke Model showing that MP is not constructively derivable (Bridges and Richman 1987, 137–138.)
3. Varieties of Constructive Mathematics
The desire to retain the possibility of a computational interpretation is one motivation for using the constructive reinterpretations of the logical connectives and quantifiers that we gave above; but it is not exactly the motivation of the pioneers of constructivism in mathematics. In this section we look at some of the different approaches to constructivism in mathematics over the past 130 years.
3.1 Intuitionistic Mathematics
In the late nineteenth century, certain individuals — most notably Kronecker and Poincaré — had expressed doubts, or even disapproval, of the idealistic, nonconstructive methods used by some of their contemporaries; but it is in the polemical writings of L.E.J. Brouwer (1881–1966), beginning with his Amsterdam doctoral thesis (1907) and continuing over the next forty-seven years, that the foundations of a precise, systematic approach to constructive mathematics were laid. In Brouwer's philosophy, known as intuitionism, mathematics is a free creation of the human mind, and an object exists if and only if it can be (mentally) constructed. If one takes that philosophical stance, then one is inexorably drawn to the foregoing constructive interpretation of the logical connectives and quantifiers: for how could a proof of the impossibility of the non-existence of a certain object x describe a mental construction of x?
Brouwer was not the clearest expositor of his ideas, as is shown by the following quotation:
Mathematics arises when the subject of two-ness, which results from the passage of time, is abstracted from all special occurrences. The remaining empty form [the relation of n to n+1] of the common content of all these two-nesses becomes the original intuition of mathematics and repeated unlimitedly creates new mathematical subjects. (quoted in Kline 1972, 1199–2000)
A modern version of Brouwer's view was given by Errett Bishop (Bishop 1967, p. 2):
The primary concern of mathematics is number, and this means the positive integers. We feel about number the way Kant felt about space. The positive integers and their arithmetic are presupposed by the very nature of our intelligence and, we are tempted to believe, by the very nature of intelligence in general. The development of the positive integers from the primitive concept of the unit, the concept of adjoining a unit, and the process of mathematical induction carries complete conviction. In the words of Kronecker, the positive integers were created by God.
However obscure Brouwer's writings could be, one thing was always clear: for him, mathematics took precedence over logic. One might say, as Hermann Weyl does in the following passage, that Brouwer saw classical mathematics as flawed precisely in its use of classical logic without reference to the underlying mathematics:
According to [Brouwer's] view and reading of history, classical logic was abstracted from the mathematics of finite sets and their subsets. … Forgetful of this limited origin, one afterwards mistook that logic for something above and prior to all mathematics, and finally applied it, without justification, to the mathematics of infinite sets. This is the Fall and original sin of set theory, for which it is justly punished by the antinomies. It is not that such contradictions showed up that is surprising, but that they showed up at such a late stage of the game. (Weyl 1946)
In particular, this misuse of logic led to nonconstructive existence proofs which, in Hermann Weyl's words, “inform the world that a treasure exists without disclosing its location”.
In order to describe the logic used by the intuitionist mathematician, it was necessary first to analyse the mathematical processes of the mind, from which analysis the logic could be extracted. In 1930, Brouwer's most famous pupil, Arend Heyting, published a set of formal axioms which so clearly characterise the logic used by the intuitionist that they have become universally known as the axioms for intuitionistic logic (Heyting 1930). These axioms captured the informal BHK-interpretation of the connectives and quantifiers that we gave earlier.
Intuitionistic mathematics diverges from other types of constructive mathematics in its interpretation of the term “sequence”. Normally, a sequence in constructive mathematics is given by a rule which determines, in advance, how to construct each of its terms; such a sequence may be said to be lawlike or predeterminate. Brouwer generalised this notion of a sequence to include the possibility of constructing the terms one-by-one, the choice of each term being made freely, or subject only to certain restrictions stipulated in advance. Most manipulations of sequences do not require that they be predeterminate, and can be performed on these more general free choice sequences.
Thus, for the intuitionist, a real number x = (x1, x2, …) — essentially, a Cauchy sequence of rational numbers — need not be given by a rule: its terms x1, x2, … , are simply rational numbers, successively constructed, subject only to some kind of Cauchy restriction such as the following one used by Bishop (1967):
∀m∀n[|xm − xn| ≤ (1/m + 1/n)]
Once free choice sequences are admitted into one's mathematics, so, perhaps to one's initial surprise, are certain strong choice principles. Let P be a subset of NN × N (where N denotes the set of natural numbers and, for sets A and B, BA denotes the set of mappings from A into B), and suppose that for each a ∈ NN there exists n ∈ N such that (a,n) ∈ P. From a constructive point of view, this means that we have a procedure, applicable to sequences, that computes n for any given a. According to Brouwer, the construction of an element of NN is forever incomplete: a generic sequence a is purely extensional, in the sense that at any given moment we can know nothing about a other than a finite set of its terms. It follows that our procedure must be able to calculate, from some finite initial sequence (a0, …, aN) of terms of a, a natural number n such that P(a,n). If b ∈ NN is any sequence such that bk = ak for 0 ≤ k ≤ N, then our procedure must return the same n for b as it does for a. This means that n is a continuous function of a with respect to the topology on NN given by the metric
ρ : (a, b) inf{2−n : ak = bk for 0 ≤ k ≤ n}.
We are therefore led to the following principle of continuous choice, which we divide into a continuity part and a choice part.
CC1 : Any function from NN to N is continuous.
CC2 : If P ⊆ NN × N, and for each a ∈ NN there exists n ∈ N such that (a, n) ∈ P, then there is a function ƒ : NN → N such that (a, ƒ(a)) ∈ P for all a ∈ NN.
If P and ƒ are as in CC2, then we say that ƒ is a choice function for P.
The omniscience principles LPO and LLPO are demonstrably false under the hypotheses CC1–2; but MP is consistent with it. Among the remarkable consequences of CC1–2 are the following.
Any function from NN or 2N to a metric space is pointwise continuous.
Every mapping from a nonempty complete separable metric space to a metric space is pointwise continuous.
Every map from the real line R to itself is pointwise continuous.
Let X be a complete separable normed space, Y a normed space, and (un) a sequence of linear mappings from X to Y such that for each unit vector x of X,
φ(x) = sup{ ||un(x)|| : n ∈ N }
exists. Then there exists c > 0 such that ||un(x)|| ≤ c for all n∈N and all unit vectors x of X (Uniform boundedness principle).
Each of these statements appears to contradict known classical theorems. However, the comparison with classical mathematics should not be made superficially: in order to understand that there is no real contradiction here, we must appreciate that the meaning of such terms as “function” and even “real number” in intuitionistic mathematics is quite different from that in the classical setting. (In practice, intuitionistic mathematics cannot be compared, readily and directly, with classical mathematics.)
Brouwer's introspection over the nature of functions and the continuum led him to a second principle, which, unlike that of continuous choice, is classically valid. This principle requires a little more background for its explanation.
For any set S we denote by S* the set of all finite sequences of elements of S, including the empty sequence ( ). If α = (a1, …, an) is in S*, then n is called the length of α and is denoted by |α|. If m ∈ N, and α is a finite or infinite sequence in S of length at least m, then we denote by α(m) the finite sequence consisting of the first m terms of α. Note that α(0) = ( ). If α ∈ S* and β = α(m) for some m, we say that α is an extension of β, and that β is a restriction of α.
A subset σ of S is said to be detachable (from S) if
∀x∈S (x ∈ σ ∨ x ∉ σ).
A detachable subset σ of N* is called a fan if
it is closed under restriction: for each α ∈ N* and each n, if α(n) ∈ S, then α(k) ∈ S whenever 0 ≤ k ≤ n; and
for each α ∈ σ, the set
{ α*n ∈ S: n ∈ N }
is finite or empty, where α*n denotes the finite sequence obtained by adjoining the natural number n to the terms of α.
A path in a fan σ is a sequence α, finite or infinite, such that α(n) ∈ σ for each applicable n. We say that a path α is blocked by a subset B if some restriction of α is in B; if no restriction of α is in B, we say that α misses B. A subset B of a fan σ is called a bar for σ if each infinite path of σ is blocked by B; a bar B for σ is uniform if there exists n ∈ N such that each path of length n is blocked by B.
At last we can state Brouwer's next principle of intuitionism, the fan theorem for detachable bars (FTD):
Every detachable bar of a fan is uniform.
In its classical contrapositive form, FTD is known as König's Lemma: if for every n there exists a path of length n that misses B, then there exists an infinite path that misses B (see Dummett 1977 [2000], 49–53). (Of course, classically the condition of detachability is superfluous.) It is simple to construct a Brouwerian counterexample to König's Lemma.
Brouwer actually posited the fan theorem without the restriction of detachability of the bar. Attempts to prove that more general fan theorem constructively rely on an analysis of how we could know that a subset is a bar, and led Brouwer to a notion of bar induction; this is discussed in Section 3.6 of the entry on intuitionism in the philosophy of mathematics; another good reference for bar induction is van Atten (2004). We shall return to fan theorems in Section 4.
Of the many applications of Brouwer's principles, the most famous is his uniform continuity theorem (which follows from the pointwise continuity consequences of CC1-2 together a form of fan theorem more general than FTD):
Every mapping from a compact (that is, complete, totally bounded) metric space into a metric space is uniformly continuous.
The reader is warned once again to interpret this carefully within Brouwer's intuitionistic framework, and not to jump to the erroneous conclusion that intuitionism contradicts classical mathematics. It is more sensible to regard the two types of mathematics as incomparable. For further discussion, see the entry on intuitionistic logic.
Unfortunately — and perhaps inevitably, in the face of opposition from mathematicians of such stature as Hilbert — Brouwer's intuitionist school of mathematics and philosophy became more and more involved in what, at least to classical mathematicians, appeared to be quasi-mystical speculation about the nature of constructive thought, to the detriment of the practice of constructive mathematics itself. This unfortunate polarisation between the Brouwerians and the Hilbertians culminated in the notorious Grundlagenstreit of the 1920s, details of which can be found in the Brouwer biographies by van Dalen (1999, 2005) and van Stigt (1990).
3.2 Recursive Constructive Mathematics
In the late 1940s, the Russian mathematician A.A. Markov began the development of an alternative form of constructive mathematics (RUSS), which is, essentially, recursive function theory with intuitionistic logic (Markov 1954, Kushner 1985). In this variety the objects are defined by means of Gödel-numberings, and the procedures are all recursive; the main distinction between RUSS and the classical recursive analysis developed after, in 1936, the work of Turing, Church, and others clarified the nature of computable processes, is that the logic used in RUSS is intuitionistic.
One obstacle faced by the mathematician attempting to come to grips with RUSS is that, being expressed in the language of recursion theory, it is not easily readable; indeed, on opening a page of Kushner's excellent lectures (1985), one might be forgiven for wondering whether this is analysis or logic. (This remark should be tempered with reference to the two, relatively readable books on classical recursive analysis by Aberth (1980, 2001).) Fortunately, one can get to the heart of RUSS by an axiomatic approach due to Richman (1983) (see also Chapter 3 of Bridges and Richman 1987).
First, we define a set S to be countable if there is a mapping from a detachable subset of N onto S. With intuitionistic logic we cannot prove that every subset of N is detachable (the reader is invited to provide a Brouwerian example to demonstrate this). Countable subsets of N in Richman's axiomatic approach are the counterparts of recursively enumerable sets in the normal development of RUSS.
By a partial function on N we mean a mapping whose domain is a subset of N; if the domain is N itself, then we call the function a total partial function on N. Richman's approach to RUSS is based on intuitionistic logic and a single axiom of computable partial functions (CPF):
There is an enumeration φ0, φ1, … of the set of all partial functions from N to N with countable domains.
It is remarkable what can be deduced cleanly and quickly using this principle. For example, we can prove the following result, which almost immediately shows that LLPO, and hence LPO, are false in the recursive setting.
There is a total partial function ƒ : N × N → {0, 1} such that
for each m there exists at most one n such that ƒ(m, n) = 1; and
for each total partial function ƒ : N → {0, 1}, there exist m,k in N such that ƒ(m, 2k+ƒ(m)) = 1.
Of more interest, however, are results such as the following within RUSS.
Specker's Theorem: There exists a strictly increasing sequence (r1, r2, …) of rational numbers in the closed interval [0, 1] such that for each x ∈ R there exist N ∈ N and δ > 0 such that |x − rn| ≥ δ for all n ≥ N.
For each ε > 0, there exists a sequence (I1, I2, …) of bounded open intervals in R such that
(Such a sequence of intervals is called an ε-singular cover of R.)
There exists a pointwise continuous function ƒ : [0, 1] → R that is not uniformly continuous.
There exists a positive-valued uniformly continuous function ƒ : [0, 1] → R whose infimum is 0.
From a classical viewpoint, these results fit into place when one realises that words such as “function” and “real number” should be interpreted as “recursive function” and “recursive real number” respectively. Note that the second of the above four recursive theorems is a strong recursive counterexample to the open-cover compactness property of the (recursive) real line; and the fourth is a recursive counterexample to the classical theorem that every uniformly continuous mapping of a compact set into R attains its infimum.
3.3 Bishop's Constructive Mathematics
Progress in all varieties of constructive mathematics was relatively slow throughout the next decade and a half. What was needed to raise the profile of constructivism in mathematics was a top-ranking classical mathematician to show that a thoroughgoing constructive development of deep analysis was possible without a commitment to Brouwer's non-classical principles or to the machinery of recursive function theory. This need was fulfilled in 1967, with the appearance of Errett Bishop's monograph Foundations of Constructive Analysis (1967), the product of an astonishing couple of years in which, working in the informal but rigorous style used by normal analysts, Bishop provided a constructive development of a large part of twentieth-century analysis, including the Stone-Weierstrass Theorem, the Hahn-Banach and separation theorems, the spectral theorem for self-adjoint operators on a Hilbert space, the Lebesgue convergence theorems for abstract integrals, Haar measure and the abstract Fourier transform, ergodic theorems, and the elements of Banach algebra theory. (See also Bishop and Bridges 1985.) Thus, at a stroke, he gave the lie to the commonly-held view expressed so forcefully by Hilbert:
Taking the principle of excluded middle from the mathematician would be the same, say, as proscribing the telescope to the astronomer or to the boxer the use of his fists. (Hilbert 1928)
Not only did Bishop's mathematics (BISH) have the advantage of readability — if you open Bishop's book at any page, what you see is clearly recognisable as analysis, even if, from time to time, his moves in the course of a proof may appear strange to one schooled in the use of the law of excluded middle — but, unlike intuitionistic or recursive mathematics, it admits many different interpretations. Intuitionistic mathematics, recursive constructive mathematics, and even classical mathematics all provide models of BISH. In fact, the results and proofs in BISH can be interpreted, with at most minor amendments, in any reasonable model of computable mathematics, such as, for example, Weihrauch's Type Two Effectivity Theory (Weihrauch 2000; Bauer 2005).
How is this multiple interpretability achieved? At least in part by Bishop's refusal to pin down his primitive notion of “algorithm” or, in his words, “finite routine”. This refusal has led to the criticism that his approach lacks the precision that a logician would normally expect of a foundational system. However, this criticism can be overcome by looking more closely at what practitioners of BISH actually do, as distinct from what Bishop may have thought he was doing, when they prove theorems: in practice, they are doing mathematics with intuitionistic logic. Experience shows that the restriction to intuitionistic logic always forces mathematicians to work in a manner that, at least informally, can be described as algorithmic; so algorithmic mathematics appears to be equivalent to mathematics that uses only intuitionistic logic. If that is the case, then we can practice constructive mathematics using intuitionistic logic on any reasonably defined mathematical objects, not just some class of “constructive objects”.
This view, more or less, appears to have first been put forward by Richman (1990, 1996). Taking the logic as the primary characteristic of constructive mathematics, it does not reflect the primacy of mathematics over logic that was part of the belief of Brouwer, Heyting, Markov, Bishop, and other pioneers of constructivism. On the other hand, it does capture the essence of constructive mathematics in practice.
Thus one might distinguish between the ontological constructivism of Brouwer and others who are led to constructive mathematics through a belief that mathematical objects are mental creations, and the epistemological constructivism of Richman and those who see constructive mathematics as characterised by its methodology, based on the use of intuitionistic logic. Of course, the former approach to constructivism inevitably leads to the latter; and the latter is certainly not inconsistent with a Brouwerian ontology.
This view, more or less, appears to have first been put forward by Richman (1990, 1996). Taking the logic as the primary characteristic of constructive mathematics, it does not reflect the primacy of mathematics over logic that was part of the belief of Brouwer, Heyting, Markov, Bishop, and other pioneers of constructivism. On the other hand, it does capture the essence of constructive mathematics in practice.
Of course, to do actual mathematics we need more than just intutionistic logic. For Bishop, the building blocks of mathematics were the positive integers (see the quote from Bishop 1967 in Section 3.1 above). Myhill (1975) gave an axiomatic foundation for BISH based on primitive notions of number, set, and function. Friedman (1977) dealt with intuitionistic ZF set theory, and Bridges (1987) worked with a highly formalised constructive Morse set theory. The two main formal underpinnings of BISH a this stage are the CZF set theory of Aczel and Rathjen (2000 and forthcoming), and the type theory of Martin-Löf (1975, 1984). For an overview, see Crosilla 2009.
3.4 Martin-Löf's Constructive Type Theory
Before ending our tour of varieties of modern constructive mathematics, we visit a fourth variety, based on Per Martin-Löf's type-theory (ML). In 1968, Martin-Löf published his Notes on Constructive Mathematics, based on lectures he had given in Europe in 1966–68; so his involvement with constructivism in mathematics goes back at least to the period of Bishop's writing of Foundations of Constructive Analysis. Martin-Löf's book is in the spirit of RUSS, rather than BISH; indeed, its author did not have access to Bishop's book until his own manuscript was finished. Martin-Löf later turned his attention to his theory of types as a foundation for Bishop-style constructive mathematics.
Here, in his own words, is an informal explanation of the ideas underlying ML:
We shall think of mathematical objects or constructions. Every mathematical object is of a certain kind or type [… and] is always given together with its type. … A type is defined by describing what we have to do in order to construct an object of that type. … Put differently, a type is well-defined if we understand … what it means to be an object of that type. Thus, for instance N → N [functions from N to N] is a type, not because we know particular number theoretic functions like the primitive recursive ones, but because we think we understand the notion of number theoretic function in general. (Martin-Löf 1975)
In particular, in this system every proposition can be represented as a type: namely, the type of proofs of the proposition. Conversely, each type determines a proposition: namely, the proposition that the type in question is inhabited. So when we think of a certain type T as a proposition, we interpret the formula
x ∈ T
as “x is a proof of the proposition T”.
Martin-Löf goes on to construct new types, such as Cartesian products and disjoint unions, from old. For example, the Cartesian product
(Πx ∈ A) B(x)
is the type of functions that take an arbitrary object x of type A into an object of type B(x). In the propositions-as-proofs interpretation, where B(x) represents a proposition, the above Cartesian product corresponds to the universal proposition
(∀x ∈ A) B(x).
Martin-Löf distinguishes carefully between proofs and derivations: a proof object is a witness to the fact that some proposition has been proved; whereas a derivation is the record of the construction of a proof object. Also, he exercises two basic forms (one dare not say “types” here!) of judgement. The first is a relation between proof objects and propositions, the second a property of some propositions. In the first case, the judgement is either one that a proof object a is a witness to a proposition A, or else one that two proof objects a and b are equal and both witness that A has been proved. The first case of the second form of judgement states that a proposition A is well-formed, and the second records that two propositions A and B are equal.
There is a careful, and highly detailed, set of rules for formalising ML. We will not go into those here, but refer the reader to other sources such as Bridges & Reeves 1999. However, there is one further technical matter we would like to mention: the axiom of choice is derivable in ML.
The full axiom of choice can be stated as follows:
If A, B are inhabited sets, and S a subset of A × B such that
∀x∈A∃y∈B ((x, y) ∈ S),
(1)
then there exists a choice function ƒ : A → B such that
∀x∈A ((x, ƒ(x)) ∈ S).
Now, if this is to hold under a constructive interpretation, then for a given x ∈ A, the value ƒ(x) of the choice function will depend not only on x but also on the data proving that x belongs to A. In general, we cannot expect to produce a choice function of this sort. On the other hand, the BHK interpretation of (1) is that there is an algorithm A which, applied to any given x ∈ A, produces an element y ∈ B such that (x, y) ∈ S. If A is a completely presented (or, in Bishop's words, basic) set, one for which no work beyond the construction of each element in the set is required to prove that the element does indeed belong to A, then we might reasonably expect the algorithm A to be a choice function. In Bishop-style mathematics, basic sets are rare (N is one). In Martin-Löf's type theory, every set is completely presented and, in keeping with what we wrote above about the BHK interpretation of (1), the axiom of choice is derivable therein. In this connection, we should point the reader to the Diaconescu (1975), and Goodman and Myhill (1978), proofs that the axiom of choice entails the law of excluded middle (see also Problem 2 on page 58 of Bishop 1967). Clearly, the Diaconescu-Goodman-Myhill theorem applies under the assumption that not every set is completely presented. For an analysis of the axiom of choice in set theory and type theory see Martin-Löf 2006.
When actually doing constructive mathematics in type theory, one often needs to equip completely presented sets (types) with an equivalence relation, the combination being known as a setoid. Mappings are then functions that respect those equivalence relations.This is in close agreement with the way Bishop presented his informal theory of sets. The dependent types of Martin-Löf are useful for constructing subsets. For instance, the real numbers can be constructed using the Σ-type (see Martin-Löf 1984):
(Σx ∈ N+→Q}(Πm ∈ N+)(Πn ∈ N+)[|xm − xn| ≤ (1/m + 1/n)],
(1)
An element of this type B is thereby a pair consisting of a convergent sequence x of rationals and a proof p that it is convergent. A suitable equivalence relation ~ on R is defined by taking (x,p) ~ (y,q) to mean
∀m ∈ N+ ( |xm − ym| ≤ 2/m).
The resulting setoid of real numbers is R = (R,~). We can readily prove that
∀x ∈ R ∃n ∈ Z (n < z < n+2)
and then, using the type-theoretic axiom of choice, find a function f : R→Z such that f(x) < x < f(x)+2. However, there is no reason to believe that the function f respects the equivalence relations—that is, that f(x) = f(y) holds if x ~ y.
Every constructive proof embodies an algorithm that, in principle, can be extracted and recast as a computer program; moreover, the constructive proof is itself a verification that the algorithm is correct — that is, meets its specification. One major advantage of Martin-Löf's formal approach to constructive mathematics is that it greatly facilitates the extraction of programs from proofs. This has led to serious work on the implementation of constructive mathematics in various locations (see Martin-Löf 1980, Constable 1986, and Hayashi and Nakano 1988). Some recent implementations of type theory for proof extraction are Coq and Agda.
4. Constructive Reverse Mathematics
In the 1970s, Harvey Friedman initiated a research programme of reverse mathematics, aiming to classify mathematical theorems according to their equivalence to one of a small number of set-theoretic principles (Friedman 1975). This classification reveals interesting, sometimes remarkable, differences in proof-theoretic complexity. For example, although the Ascoli-Arzelà theorem is used in the standard proof of Peano's existence theorem for solutions of ordinary differential equations (Hurewicz 1958, page 10), a reverse-mathematical analysis shows that the former is equivalent to a strictly stronger set-theoretic principle than the one equivalent to Peano's theorem (Simpson 1984, Theorems 3.9 and 4.2). The standard treatise on classical reverse mathematics is (Simpson 1999, 2009).
Around the turn of this century, Veldman (Veldman 2005), in the Netherlands, and Ishihara (Ishihara 2005, 2006), in Japan, independently initiated a programme of constructive reverse mathematics (CRM), based on intuitionistic, rather than classical, logic. (Note, though, that the first published work in the modern era of CRM is probably that of Julian and Richman (1984), which was twenty years ahead of its time.) In this section of the article, we describe a less formal approach to CRM, in the style and framework of BISH. The aim of that CRM program is to classify the theorems in the three standard models—CLASS, INT, and RUSS—according to which principles we must, and need only, add to BISH in order to prove them.
We stress that we restrict ourselves here to informal CRM, in which we take for granted the principles of function- and set-construction described in the first chapters of (Bishop 1967, Bishop and Bridges 1985, Bridges and Richman 1987, Bridges and Vîță 2006), and we work in the informal, though rigorous, style of the practising analyst, algebraist, topologist, … .
In practice, CRM splits naturally into two parts. In the first of these, we consider a theorem T of INT or RUSS, and try to find some principle, valid in that model and other than T itself, whose addition to BISH is necessary and sufficient for a constructive proof of T. In the second part of CRM we deal with a theorem T of CLASS that we suspect is nonconstructive, and we try to prove that T is equivalent, over BISH, to one of a number of known essentially-nonconstructive principles, such as MP, LLPO, LPO, or LEM. For an example of this part of CRM, we mention our earlier proof that the classical least-upper-bound principle implies, and hence is equivalent to, LEM.
Incidentally, there is a strong argument for Brouwer being the first to deal with reverse-mathematical ideas: his Brouwerian counterexamples (see the one using the Goldbach conjecture, in Section 1 above), dating back to (Brouwer 1921), lie squarely in the second part of CRM. Even if Brouwer did not state those examples as logical equivalences, but as implications of the type
P ⇒ some nonconstructive principle,
it is hard to believe that he was unaware that the right-hand-side implied the left in such cases.
To illustrate the first part of CRM, we now concentrate on theorems of the type
BISH ⊢ FT? ⇔ T,
where FT? is some form of Brouwer's fan theorem, and T is a theorem of INT. To do so, we need to distinguish between certain types of bar for the complete binary fan 2* (the set of all finite sequences in {0, 1}).
Let α ≡ (α1, α2, …) be a finite or infinite binary sequence. The concatenation of α with another string β is
α¯β ≡ (α1, α2, …, αn, β1, …, βm).
For b in {0, 1} we write α¯b rather than α¯(b). By a c-subset of 2* we mean a subset B of 2* such that
B = {u ∈ 2* : ∀v ∈ 2*(u¯v ∈ D}
(2)
for some detachable subset D of 2*. Every detachable subset of 2* is a c-subset. On the other hand, by a Π0-subset of 2* we mean a subset B of 2* with the following property: there exists a detachable subset S of 2* × N such that
∀u∈2*∀n∈N ((u, n) ∈ S ⇒ (u¯0, n) ∈ S ∧ (u¯1, n) ∈ S)
and
B = {u ∈ 2* : ∀n∈N((u, n) ∈ S)}.
Every c-subset B of 2* is a Π0-subset: simply take S = D × N, where D is a detachable subset of 2* such that (1) holds.
If ? denotes a property of subsets of 2*, then Brouwer's fan theorem for ?-bars tells us that every bar with the property ? is a uniform bar. We are particularly interested in the fan theorem for detachable bars (already discussed in Section 3.1):
FTD: Every detachable bar of the complete binary fan is uniform;
the fan theorem for c-bars (that is, bars that are c-subsets):
FTc: Every c-bar of the complete binary fan is uniform;
the fan theorem for Π0-bars (that is, bars that are Π0-subsets):
FTΠ0: Every Π0-bar of the complete binary fan is uniform;
and the full fan theorem (already discussed in Section 3.1):
FT: Every bar of the complete binary fan is uniform.
Note that, relative to BISH,
It is not known whether any of these implications can be reversed; but Diener (2008) has shown that the negations of these four principles are equivalent over BISH.
Typically, we want to prove that FT? is equivalent, over BISH, to the proposition that, for every set S of an appropriate sort, some pointwise property of the form
∀x ∈S ∃t ∈ T P(s,t)
actually holds uniformly in the form
∃t ∈ T ∀s ∈ S P(s,t).
Our strategy for attacking this problem is two-fold. First, given a set S of the appropriate sort, we construct a ?-subset N of 2* such that
if (2) holds, then B is a bar, and
if B is a uniform bar, then (3) holds.
This, though, is only half of the solution. To prove that the implication from (3) to (2) implies FT?, we consider a ?-subset B of 2* and construct a corresponding set S such that
if B is a bar, then (2) holds, and
if (3) holds, then B is a uniform bar.
The canonical example of such results is that of Julian and Richman (1984), in which S is the set of values of a given uniformly continuous mapping f : [0, 1] → R, T is the set of positive real numbers, and
P(s,t) ≡ (s ≥ t)
The pointwise property we consider is
∀x ∈ [0, 1] ∃t > 0 (f(x) ≥ t),
its uniform version being
∃t >0 ∀x ∈ [0, 1] (f(x) ≥ t).
The Julian-Richman results are as follows.
Theorem 1:
Let f : [0, 1] → R be uniformly continuous. Then there exists a detachable subset B of 2* such that
if f(x) > 0 for each x ∈ [0, 1], then B is a bar, and
if B is a uniform bar, then inf f > 0.
Theorem 2: Let B be a detachable subset of 2*. Then there exists a uniformly continuous f : [0, 1] → R such that
if B is a bar, then f(x) > 0 for each x ∈ [0, 1], and
if inf f > 0, then B is a uniform bar.
The proofs of these two theorems are subtle and tricky; see Julian and Richman 1984, or Bridges and Richman 1987 (Chapter 6), for details. A new, but equally complex, proof can be found in Berger and Bridges 2009.
The two Julian-Richman theorems together reveal that, relative to BISH, the fan theorem FTD is equivalent to the positivity principle, POS:
Each positive-valued, uniformly continuous function on [0, 1] has a positive infimum.
It follows that POS is derivable in INT, in which the full fan theorem, not just FTD, is a standard principle. The situation is quiet the opposite in RUSS, where there exist a detachable bar of 2* that is not uniform and a positive-valued, uniformly continuous function on [0, 1] that has infimum equal to 0; see Chapters 5 and 6 of Bridges and Richman 1987.
Berger and Ishihara (2005) have taken a different, indirect route to establishing the equivalence of POS and FTc. They establish a chain of equivalences between POS, FTc, and four principles of the type “if there is at most one object with property P, then there is one such object”. The four unique-existence principles are:
CIN!: Each descending sequence of inhabited closed located subsets of a compact metric space with at most one common point has inhabited intersection (Cantor's intersection theorem with uniqueness).
MIN!: Each uniformly continuous, real-valued function on a compact metric space with at most one minimum point has a minimum point.
WKL! Each infinite tree with at most one infinite branch has an infinite branch (the weak König lemma with uniqueness).
FIX!: Each uniformly continuous function from a compact metric space into itself with at most one fixed point and with approximate fixed points has a fixed point.
In, for example, the last of these, we say that a map f of a metric space (X,ρ) into itself
has at most one fixed point if ρ(f(x),x) + ρ(f(y),y) > 0 whenever ρ(x,y) > 0;
has approximate fixed points if for each ε > 0 there exists x ∈ X such that ρ(f(x),x) < ε.
A major open problem in CRM is that of finding a form of the fan theorem that is equivalent, over BISH, to the uniform continuity theorem for [0, 1] (UCT[0,1]):
Every pointwise continuous mapping of [0, 1] into R is uniformly continuous.
the proposition for which Brouwer originally developed his proof of the fan theorem. (Note that UCT[0,1] is equivalent, relative to BISH, to the general uniform continuity theorem for metric spaces: Every pointwise continuous mapping of a complete, totally bounded metric space into a metric space is uniformly continuous. See Loeb 2005, and Bridges and Diener 2007.)
It follows from results of Berger (2006) that
BISH + UCT[0,1] ⊢ FTc.
Also, Diener and Loeb (2008) have proved that
However, we do not know if either of these implications can be replaced by a bi-implication. Perhaps UCT[0,1], and hence the full uniform continuity theorem for compact metric spaces, is equivalent, relative to BISH, to some natural, but as yet unidentified, version of the fan theorem.
For additional material on the fan theorem in constructive reverse mathematics, see, for example, Berger and Bridges 2006, 2007; Bridges 2008; Diener 2008, 2012; Diener and Loeb 2009; and Diener and Lubarsky 2013.
Interested readers may pursue the topic of constructive reverse mathematics in greater detail in the following supplementary document:
Ishihara's principle BD-N and the anti-Specker Property
5. Constructive Topology
Constructive mathematicians have tended to concentrate their efforts on the field of analysis, with considerable success—witness the wealth of functional analysis developed in Bishop 1967. This does not mean that, for example, algebra has been sidelined from the constructive enterprise: the material in the monograph by Mines et al (1986) can be regarded as a substantial algebraic counterpart to the constructive analysis carried out by Bishop. Much more recently, Lombardi and Quitté (2011) have published the first large volume of a proposed two-volume work on constructive algebra. However, not being expert in algebra, and being aware of the danger of making this article too long to hold the reader's attention, we choose not to discuss constructive analysis or algebra in any detail; rather, in the following supplementary document, we turn to constructive topology, describing two rather different approaches to that subject:
6. Concluding Remarks
The traditional route taken by mathematicians wanting to analyse the constructive content of mathematics is the one that follows classical logic; in order to avoid decisions, such as whether or not a real number equals 0, that cannot be made by a real computer, the mathematician then has to keep within strict algorithmic boundaries such as those formed by recursive function theory. In contrast, the route taken by the constructive mathematician follows intuitionistic logic, which automatically takes care of computationally inadmissible decisions. This logic (together with an appropriate set- or type-theoretic framework) suffices to keep the mathematics within constructive boundaries. Thus the mathematician is free to work in the natural style of an analyst, algebraist (e.g., Mines et al. 1988), geometer, topologist (e.g., Bridges and Vîță 2011, Sambin forthcoming), or other normal mathematician, the only constraints being those imposed by intuitionistic logic. As Bishop and others have shown, the traditional belief promulgated by Hilbert and still widely held today, that intuitionistic logic imposes such restrictions as to render the development of serious mathematics impossible, is patently false: large parts of deep modern mathematics can be, and have been, produced by purely constructive methods. Moreover, the link between constructive mathematics and programming holds great promise for the future implementation and development of abstract mathematics on the computer.
Bibliography
References
Aberth, O., 1980, Computable Analysis, New York: McGraw-Hill.
–––, 2001, Computable Calculus, New York: Academic Press.
Aczel, P., and Rathjen, M., 2001, Notes on Constructive Set Theory (Report No. 40), Stockholm: Institut Mittag-Leffler, Royal Swedish Academy of Sciences.
–––, M., forthcoming, Constructive Set Theory.
Bauer, A., 2005, “Realizability as the connection between computable and constructive Mathematics”, Lecture notes for a tutorial at a satellite seminar of CCA2005, Kyoto, Japan [available online].
Beeson, M., 1985, Foundations of Constructive Mathematics, Heidelberg: Springer Verlag.
Berger, J., 2006, “The logical strength of the uniform continuity theorem”, in Logical Approaches to Computational Barriers, A. Beckmann, U. Berger, B. Löwe, and J. V. Tucker (eds.), Heidelberg: Springer Verlag.
Berger, J., and Bridges, D.S., 2007, “A fan-theoretic equivalent of the antithesis of Specker's theorem”, Proceedings of Royal Dutch Mathematical Society (Indagationes Mathematicae) (Indag. Math. N.S.), 18(2): 195–202.
–––, 2009, “The fan theorem and positive-valued uniformly continuous functions on compact intervals”, New Zealand Journal of Mathematics, 38: 129–135.
Berger, J., and Ishihara, H., 2005, “Brouwer's fan theorem and unique existence in constructive analysis”, Mathematical Logic Quarterly, 51(4): 360–364.
Berger, J., and Schuster, P.M., 2006, “Classifying Dini's theorem”, Notre Dame Journal of Formal Logic, 47: 253–262.
Bishop, E., 1967, Foundations of Constructive Analysis, New York: McGraw-Hill.
–––, 1973, Schizophrenia in Contemporary Mathematics (American Mathematical Society Colloquium Lectures), Missoula: University of Montana; reprinted in Errett Bishop: Reflections on Him and His Research, American Mathematical Society Memoirs 39.
Bishop, E. and Bridges, D., 1985, Constructive Analysis, (Grundlehren der mathematischen Wissenschaften, 279), Heidelberg: Springer Verlag.
Bourbaki, N., 1984, Éléments d'histoire des mathématiques, Paris: Masson; English-language edition, Elements of the History of Mathematics, J. Meldrum (trans.), 2006, Berlin: Springer Verlag.
Bridges, D.S., 1987, “A constructive Morse theory of sets”, in Mathematical Logic and its Applications, D. Skordev (ed.), 61–79, New York: Plenum.
–––, 1998, “Constructive Truth in Practice”, in Truth in Mathematics, H. Dales and G. Oliveri (eds.), Oxford: Clarendon Press.
–––, 2008, “A reverse look at Brouwer's fan theorem”, in One Hundred Years of Intuitionism (1907–2007), M. van Atten, P. Boldini, M. Bourdeau, G. Heinzmann (eds.), Basel: Birkhäuser Verlag.
–––, 2009, “Constructive notions of equicontinuity”, Archive for Mathematical Logic, 48: 437–448.
–––, 2011, “The anti-Specker property, uniform sequential continuity, and a countable compactness property”, Logic Journal of the Interest Group in Pure and Applied Logics, 19(1): 174–182.
–––, 2012, “Compactness notions for apartness spaces”, Archive for Mathematical Logic, doi 10.1007/s00153-012-0279-6.
–––, forthcoming, “Precompact apartness spaces“, Logical Methods in Computer Science.
Bridges, D., Calder, A., Julian, W., Mines. R. and Richman, F., 1982, “Picard's Theorem”, Transactions of the American Mathematical Society, 269(2): 513–520.
Bridges, D., and Diener, H., 2007, “The pseudocompactness of [0, 1] is equivalent to the uniform continuity theorem”, Journal of Symbolic Logic, 72(4): 1379–1383.
Bridges, D.S., Ishihara, H., Schuster, P.M., and Vîță, L., 2005, “Strong continuity implies uniform sequential continuity”, Archive for Mathematical Logic, 44(7): 887–895.
Bridges, D., and Reeves, S., 1999, “Constructive mathematics, in theory and programming practice”, Philosophia Mathematica, 7(1): 65—104.
Bridges, D., and Richman, F., 1987, Varieties of Constructive Mathematics, London Mathematical Society Lecture Notes 97, Cambridge: Cambridge University Press.
Bridges, D. and Vîță, L., 2006, Techniques of Constructive Analysis, Heidelberg: Springer Verlag.
–––, 2011, Apartness and Uniformity—A Constructive Development, Heidelberg: Springer Verlag
Brouwer, L.E.J., 1907, Over de Grondslagen der Wiskunde, Doctoral Thesis, University of Amsterdam; reprinted with additional material, D. van Dalen (ed.), by Matematisch Centrum, Amsterdam, 1981.
–––, 1908, “De onbetrouwbaarheid der logische principes”, Tijdschrift voor Wijsbegeerte, 2: 152–158.
–––, 1921, “Besitzt jede reelle Zahl eine Dezimalbruchentwicklung?”, Mathematische Annalen, 83: 201–210.
–––, 1924, “Beweiss, dass jede volle Funcktion gleichmässig stetig ist”, Proceedings of Royal Dutch Mathematical Society, 27: 189–193.
–––, 1924A, “Bemerkung zum Beweise der gleichmässigen Stetigkeit voller Funktionen”, Proceedings of Royal Dutch Mathematical Society, 27: 644–646.
Cederquist, J., and Negri, S., 1996, “A constructive proof of the Heine-Borel covering theorem for formal reals”, in Types for Proofs and Programs (Lecture Notes in Computer Science, Volume 1158), 62–75, Berlin: Springer Verlag.
Constable, R., et al., 1986, Implementing Mathematics with the Nuprl Proof Development System, Englewood Cliffs, NJ: Prentice-Hall.
Coquand, T., 1992, “An intuitionistic proof of Tychonoff's theorem”, Journal of Symbolic Logic, 57: 28–32.
–––, 2009, “Space of valuations”, Annals of Pure and Applied Logic, 157: 97–109.
Coquand, T., and Spitters, B., 2009, “Integrals and Valuations”, Journal of Logic and Analysis, 1(3): 1–22.
Coquand, T., Sambin, G., Smith, J., and Valentini, S., 2003, “Inductively generated formal topologies”, Annals of Pure and Applied Logic, 124: 71–106.
Crosilla, L., “Set theory: Constructive and Intuitionistic ZF”, Stanford Encyclopedia of Philosophy (Spring 2009 Edition), Edward N. Zalta (ed.), URL = <http://plato.stanford.edu/archives/spr2009/entries/set-theory-constructive/>.
Curi, G., 2010, “On the existence of Stone-Čech compactification”, Journal of Symbolic Logic, 75: 1137–1146.
Dent, J.E., forthcoming, Principles of Constructive Mathematics, Ph.D. thesis, Christchurch, New Zealand: University of Canterbury.
Diaconescu, R., 1975, “Axiom of choice and complementation”, Proceedings of the American Mathematical Society, 51: 176–178
Diener, H., 2008, Compactness under Constructive Scrutiny, Ph.D. thesis, Christchurch, New Zealand: University of Canterbury.
–––, 2008a, “Generalising compactness”, Mathematical Logic Quarterly, 51(1): 49–57.
–––, 2012,“Reclassifying the antithesis of Specker's theorem”, Archive for Mathematical Logic, 51: 687–693.
Diener, H., and Loeb, I., 2009, “Sequences of Real Functions on [0, 1] in Constructive Reverse Mathematics”, Annals of Pure and Applied Logic, 157(1): 50–61.
Diener, H., and Lubarsky, R., 2013, “Separating the fan theorem and its weakenings”, in Logical Foundations of Computer Science (Lecture Notes in Computer Science, 7734), S. Artemov and A. Nerode (eds.), Berlin: Springer Verlag.
Dummett, Michael, 1977 [2000], Elements of Intuitionism (Oxford Logic Guides, 39), Oxford: Clarendon Press, 1977; 2nd edition, 2000. [Page references are to the 2nd edition.]
Friedman, H., 1975, “Some systems of second order arithmetic and their use”, in Proceedings of the 17th International Congress of Mathematicians, (Vancouver, BC, 1974).
–––, 1977, “Set theoretic foundations for constructive analysis”, Annals of Mathematics, 105 (1): 1–28.
Goodman, N.D., and Myhill, J., 1978, “Choice Implies Excluded Middle”, Zeitschrift für Logik und Grundlagen der Mathematik, 24: 461.
Hayashi, S., and Nakano, H., 1988, PX: A Computational Logic, Cambridge MA: MIT Press.
Heyting, A., 1930, “Die formalen Regeln der intuitionistischen Logik”, Sitzungsberichte der Preussische Akadademie der Wissenschaften. Berlin, 42–56.
–––, 1971, Intuitionism—an Introduction, 3rd edition, Amsterdam: North Holland.
Hilbert, D., 1925, “Über das Unendliche”, Mathematische Annalen, 95: 161–190; translation, “On the Infinite”, by E. Putnam and G. Massey, in Philosophy of Mathematics: Selected Readings, P. Benacerraf and H. Putnam (eds.), Englewood Cliffs, NJ: Prentice Hall, 1964, 134–151.
Hurewicz, W., 1958, Lectures on Ordinary Differential Equations, Cambridge, MA: MIT Press.
Ishihara, H., 1992, “Continuity properties in constructive mathematics”, Journal of Symbolic Logic, 57 (2): 557–565.
–––, 1994, “A constructive version of Banach's inverse mapping theorem”, New Zealand Journal of Mathematics, 23: 71–75.
–––, 2005, “Constructive Reverse mathematics: compactness properties”, in From Sets and Types to Analysis and Topology: Towards Practicable Foundations for Constructive Mathematics, L. Crosilla and P. Schuster (eds.), Oxford: The Clarendon Press.
–––, 2006, “Reverse mathematics in Bishop's constructive mathematics”, Philosophia Scientiae (Cahier Special), 6: 43–59.
Johnstone, P.T., 1982, Stone Spaces, Cambridge: Cambridge University Press.
–––, 2003, “The point of pointless topology”, Bulletin of the American Mathematical Society, 8: 41–53.
Joyal, A., and Tierney, M., 1984, “An extension of the Galois theory of Grothendieck”, Memoirs of the American Mathematical Society, 309: 85 pp.
Julian, W.H., and Richman, F., 1984, “A uniformly continuous function on [0, 1] that is everywhere different from its infimum”, Pacific Journal of Mathematics,111: 333–340.
Kushner, B., 1985, Lectures on Constructive Mathematical Analysis, Providence, RI: American Mathematical Society
Lietz, P., 2004, From Constructive Mathematics to Computable Analysis via the Realizability Interpretation, Dr. rer. nat. dissertation, Universität Darmstadt, Germany.
Lietz, P., and Streicher, T., “Realizability models refuting Ishihara's boundedness principle”, Annals of Pure and Applied Logic, 163(12): 1803–1807.
Loeb, I., 2005, “Equivalents of the (Weak) Fan Theorem”, Annals of Pure and Applied Logic, 132: 51–66.
Lombardi, H., Quitté, C., 2011, Algèbre Commutative. Méthodes constructives, Nanterre, France: Calvage et Mounet.
Lorenzen, P., 1955, Einführung in die operative Logik und Mathematik (Grundlehren der mathematischen Wissenschaften, Volume 78), 2nd edition, 1969, Heidelberg: Springer.
Markov, A.A., 1954, Theory of Algorithms, Trudy Mat. Istituta imeni V.A. Steklova, 42, Moskva: Izdatel'stvo Akademii Nauk SSSR.
Martin-Löf, P., 1968, Notes on Constructive Analysis, Stockholm: Almquist & Wiksell.
–––, 1975, “An intuitionistic theory of types: predicative part”, in Logic Colloquium 1973, H.E. Rose and J.C. Shepherdson (eds.), Amsterdam: North-Holland.
–––, 1980, “Constructive mathematics and computer programming”, in Proc. 6th. Int. Congress for Logic, Methodology and Philosophy of Science, L. Jonathan Cohen (ed.), Amsterdam: North-Holland.
–––, 1984, Intuitionistic Type Theory, Notes by Giovanni Sambin of a series of lectures given in Padova, June 1980, Naples: Bibliopolis.
–––, 2006, “100 years of Zermelo's axiom of choice: what was the problem with it?”, The Computer Journal, 49(3): 345–350.
Menger, K., 1940, “Topology without points”, Rice Institute Pamphlet, 27(1): 80–107 [available online].
Mines, R., Richman, F., and Ruitenburg, W., 1988, A Course in Constructive Algebra, Universitext, Heidelberg: Springer Verlag.
Moerdijk, I., 1984, “Heine-Borel does not imply the fan theorem”, Journal of Symbolic Logic, 49(2): 514–519.
Myhill, John, 1973, “Some Properties of Intuitionistic Zermelo-Fraenkel Set Theory”, in Cambridge Summer School in Mathematical Logic, A. Mathias and H. Rogers (eds.), Lecture Notes in Mathematics, 337, Heidelberg: Springer Verlag, 206-231.
–––, 1975, “Constructive Set Theory”, Journal of Symbolic Logic, 40 (3): 347–382.
Naimpally, S., 2009, Proximity Approach to Problems in Topology and Analysis, Munich: Oldenbourg Verlag.
Naimpally, S., and Warrack, B.D., 1970, Proximity Spaces (Cambridge Tracts in Math. and Math. Phys., Volume 59), Cambridge: Cambridge University Press.
Nordström, B., Peterson, K., and Smith, J.M., 1990, “Programming in Martin-Löf's Type Theory”, Oxford: Oxford University Press.
Palmgren, E., 2007, “A constructive and functorial embedding of locally compact metric spaces into locales”, Topology and its Applications, 154: 1854–1880.
–––, 2008, “Resolution of the uniform lower bound problem in constructive analysis”, Mathematical Logic Quarterly, 54: 65–69.
–––, 2009, “From intuitionistic to formal topology: some remarks on the foundations of homotopy theory”, in: Logicism, Intuitionism and Formalism—what has become of them?, S. Lindström, E. Palmgren, K. Segerberg, and V. Stoltenberg-Hansen (eds.), 237–253, Berlin: Springer Verlag.
Picardo, J., and Pultr, A., 2011, Frames and Locales: Topology without Points, Basel: Birkhäuser Verlag.
Richman, F., 1983, “Church's Thesis Without Tears”, Journal of Symbolic Logic, 48: 797–803.
–––, 1990, “Intuitionism as generalization”, Philosophia Mathematica, 5: 124–128.
–––, 1996, “Interview with a constructive mathematician”, Modern Logic, 6: 247–271.
–––, 2000, “The Fundamental Theorem of Algebra: A Constructive Treatment Without Choice”, Pacific Journal of Mathematics, 196: 213–230.
Riesz, F., 1908, “Stetigkeitsbegriff und abstrakte Mengenlehre”, Atti IV Congresso Internationale Matematica Roma II, 18–24.
Sambin, G., 1987, “Intuitionistic formal spaces—a first communication”, in Mathematical Logic and its Applications, D. Skordev (ed.), 187–204, New York: Plenum Press.
–––, forthcoming, The Basic Picture: Structures for Constructive Topology, Oxford: Oxford University Press.
Schuster, P.M., 2005, “What is continuity, constructively?”, Journal of Universal Computer Science, 11: 2076–2085
–––, 2006, “Formal Zariski topology: positivity and points”, Annals of Pure and Applied Logic, 137: 317–359.
Simpson, S.G., 1984, “Which set existence axioms are needed to prove the Cauchy/Peano theorem for ordinary differential equations”, Journal of Symbolic Logic, 49 (3): 783–802.
–––, 2009, Subsystems of Second Order Arithmetic, Second Edition, Cambridge: Cambridge University Press.
Specker, E., 1949, “Nicht konstruktiv beweisbare Sätze der Analysis”, Journal of Symbolic Logic, 14: 145–158.
Troelstra, A.S., 1978, “Aspects of Constructive Mathematics”, in Handbook of Mathematical Logic, J. Barwise (ed.), Amsterdam: North-Holland.
Troelstra, A.S., and van Dalen, D., 1988, Constructivism in Mathematics: An Introduction (two volumes), Amsterdam: North Holland.
van Atten, M., 2004, On Brouwer, Belmont: Wadsworth/Thomson Learning.
van Dalen, D., 1981, Brouwer's Cambridge Lectures on Intuitionism, Cambridge: Cambridge University Press.
–––, 1999, Mystic, Geometer and Intuitionist: The Life of L.E.J. Brouwer, vol. I, Oxford: Clarendon Press.
–––, 2005, Mystic, Geometer, and Intuitionist: The Life of L.E.J. Brouwer, Vol. 2, Oxford: Clarendon Press.
van Stigt, W.P., 1990, Brouwer's Intuitionism, Amsterdam: North-Holland.
Veldman, W., 2005, “Brouwer's Fan Theorem as an Axiom and as a Contrast to Kleene's Alternative”, preprint, Radboud University, Nijmegen, Netherlands.
Vickers, S., 2005, “Localic completion of generalized metric spaces I”, Theory and Applications of Categories, 14(15): 328–356.
Wallman, H., 1938, “Lattices of topological spaces”, Annals of Mathematics, 39: 112–126.
Weihrauch, K., 2000, Computable Analysis (EATCS Texts in Theoretical Computer Science), Heidelberg: Springer Verlag.
Weyl, H., 1946, “Mathematics and Logic”, American Mathematical Monthly, 53(1): 2–13.
Whitehead, A.N., 1919, An Enquiry Concerning the Principles of Natural Knowledge, Cambridge: Cambridge University Press, second edition, 1925.
Heijenoort, Jean van, 1967, From Frege to Gödel: A Source Book in Mathematical Logic 1879–1931, Cambridge, MA: Harvard University Press.
Hilbert, David, 1928, “Die Grundlagen der Mathematik”, Hamburger Mathematische Einzelschriften 5, Teubner, Leipzig. Reprinted in English translation in van Heijenoort 1967.
Academic ToolsClassical logic requires each singular term to denote an object in the domain of quantification—which is usually understood as the set of “existing” objects. Free logic does not. Free logic is therefore useful for analyzing discourse containing singular terms that either are or might be empty. A term is empty if it either has no referent or refers to an object outside the domain.
Tradition has generally taken it for granted that free logics are first-order—that is, that their quantifiers range over individuals—but Corine Besson (2009) has argued that internalist theories of natural kinds require second-order free logics, whose quantifiers range over kinds, and she finds precedent for this idea ranging as far back as Cocchiarella (1986). This article, however, focuses on first-order free logics.
Section 1 lays out the basics of free logic, explaining how it differs from classical predicate logic and how it is related to inclusive logic, which permits empty domains or “worlds.” Section 2 shows how free logic may be represented by each of three formal methods: axiom systems, natural deduction rules and tree rules. Varying conventions for calculating the truth values of atomic formulas containing empty singular terms yield three distinct species of free logic: negative, positive and neutral. These are surveyed in Section 3, along with supervaluations, which were developed to augment neutral logics. Section 4 is critical, examining three anomalies that infect most free logics. Section 5 samples applications to theories of description, logics of partial or non-strict functions, logics with Kripke semantics, logics of fiction and logics that are in a certain sense Meinongian. Section 6 takes a glance at free logic's history.
Bibliography
Academic Tools
Other Internet Resources
Related Entries
1. The Basics
1.1 Definition of Free Logic
Free logic is formal logic whose quantifiers are interpreted in the usual way—that is, objectually over a specified domain D—but whose singular terms may denote objects outside of D, or fail to denote at all. Singular terms include proper names (individual constants), definite descriptions, and such functional expressions as ‘2 + 2’. Since classical (i.e., Fregean) predicate logic requires that singular terms denote members of D, free logic is a “nonclassical” logic. Where D is, as usual, taken to be the class of existing things, free logic may be characterized as logic the referents of whose singular terms need not exist.
Karel Lambert (1960) coined the term ‘free logic’ as an abbreviation for ‘logic free of existence assumptions with respect to its terms, singular and general’. General terms are predicates. Lambert was suggesting that just as classical predicate logic generalized Aristotelian logic by, inter alia, admitting predicates that are satisfied by no existing thing (‘is a Martian’, ‘is non-self-identical’, ‘travels faster than light’), so free logic generalizes classical predicate logic by admitting singular terms that denote no existing thing (‘Aphrodite’, ‘the greatest integer’, ‘the present king of France’).
Because classical logic's singular terms must denote existing things (when, as usual, ‘∃’ is read as “there exists”), classical logic is unreliable in application to statements containing singular terms whose referents either do not exist or are not known to. Consider, for example, the true statement:
(S) We detect no motion of the earth relative to the ether,
using ‘the ether’ as a singular term for the light-bearing medium posited by nineteenth century physicists. The reason why (S) is true is that, as we now know, the ether does not exist. According to classical logic, however, (S) is false, because it implies the existence of the ether. Free logic allows such statements to be true despite the non-referring singular term. Indeed, it allows even statements of the form ~∃x x=t (e.g., “the ether does not exist”) to be true, though in classical logic, which presumes that t refers to an object in the quantificational domain, they are self-contradictory.
Free logic accommodates empty singular terms (those that denote no member of the quantificational domain D) by rejecting inferences whose validity depends on the classical presumption that they must denote members of D. Consider, for example, the rule of universal instantiation (specification): from the premise “Every x (in D) satisfies A” we may infer “t satisfies A.” This rule, whose formal expression is:
∀xA ⊢ A(t/x),
is invalid in free logic; for even if every object in D satisfies A, if t does not denote a member of D, A(t/x) may be false. (Here and elsewhere A(t/x) is the result of replacing all occurrences of x in A by individual constant t; if there are no such occurrences, then A(t/x) is just A.) Existential generalization (the principle that from “t satisfies A” we may infer “there exists (in D) a thing x that satisfies A”):
A(t/x) ⊢ ∃xA
is likewise invalid; for if t does not denote an object in D then the truth of A(t/x) does not guarantee that there exists in D an object that satisfies A. Though free logic rejects such classical inferences, it accepts no classically invalid inferences; hence it is strictly weaker than classical logic for a language with the same vocabulary.
To distinguish terms that denote members of D from those that do not, free logic often employs the one-place “existence” predicate, ‘E!’ (sometimes written simply as ‘E’). For any singular term t, E!t is true if t denotes a member of D, false otherwise. ‘E!’ may be either taken as primitive or (in bivalent free logic with identity) defined as follows:
E!t =df ∃x(x=t).
Using ‘E!’ we can express classical logic's blanket presumption that singular terms denote members of D as an explicit premise, E!t, for selected terms t. Thus we can formulate the following weaker analogs of universal instantiation:
∀xA, E!t ⊢ A(t/x)
and existential generalization:
A(t/x), E!t ⊢ ∃xA,
which are valid in free logic.
Classical predicate logic presumes not only that all singular terms refer to members of the quantificational domain D, but also that D is nonempty. Free logic rejects the first of these presumptions. Inclusive logic (sometimes also called empty or universally free logic) rejects them both. Thus while inclusive logic for a language containing singular terms must be free, free logics need not be inclusive.
Many existential assertions—e.g., ∃x(x=x), ∃x(Px → Px), ∃x(Px → ∀yPy)—are true in all nonempty domains and hence are valid in both classical logic and non-inclusive free logic. But since all existentially quantified formulas are false in the empty domain, none are valid in inclusive logic. Correlatively, since all universally quantified formulas are true in the empty domain, none are self-contradictory in inclusive logic. Even vacuously universally quantified formulas (formulas of the form ∀xA, where x is not free in A) are true in the empty domain. Hence the schema:
∀xA → A, where x is not free in A,
which is valid in both classical logic and non-inclusive free logic, is invalid in inclusive logic. Inclusive logic also invalidates some of the laws of confinement—e.g.,
∀x(P & A) ↔ (P & ∀xA), where x is not free in P,
that are used for prenexing formulas (giving quantifiers the widest possible scope) or purifying them (giving quantifiers the narrowest possible scope). And in inclusive logic the formula:
∀x(A ↔ x=t),
widely used in the theory of definite descriptions, is not equivalent, as it otherwise is, to:
∀x(A → x=t) & A(t/x),
since with D empty and A(t/x) false, the first but not the second is true. Where there is need for such regularities, a non-inclusive free logic may be preferable to an inclusive one. Yet because inclusivity frees logic from one more existential presumption, many free logicians favor it.
2. Formal Systems
Logics may be represented in various ways. Axiom systems, natural deduction systems and trees (or, equivalently, tableaux) are among the most common. This section presents all three for the bivalent inclusive form of free logic known as Positive Free Logic (PFL) and mentions some variants. (For the meaning of the term “positive” in this context see Section 3.2). PFL is formulated in a first-order language L without sentence letters or function symbols, whose primitive logical operators are negation (not) ‘~’, the conditional (if-then) ‘→’, the universal quantifier (for all) ‘∀’, identity ‘=’ and ‘E!’, the others being defined as usual. We assume for the sake of definiteness that the formulas of L are closed (contain no unquantified variables) and that they may be vacuously quantified (have the form ∀xA or ∃xA, where x does not occur free in A). An occurrence of a variable is quantified if it lies within the scope of an operator such as ‘∀’ or ‘∃’ that binds that variable; otherwise it is free.
2.1 Axiom Systems
PFL may be axiomatized, with modus ponens as the sole inference rule, by adding the following schemas to the tautologies of classical propositional logic:
(A1) A → ∀xA
(A2) ∀x(A → B) → (∀xA → ∀xB)
(A3) ∀xA, if A(t/x) is an axiom
(A4) ∀xA → (E!t → A(t/x))
(A5) ∀xE!x.
A note on conventions involving variables: once again, A(t/x) is the result of replacing all occurrences of x in A by individual constant t. If there are no such occurrences, then A(t/x) is just A. In (A1) the variable x is not free in A (since otherwise A would be an open formula and formulas of L are closed). However, x may be free in A or B in (A2) and in A in (A3) and (A4).
(A4) and (A5) are special axioms for free logic. The others are classical. (A4) modifies the classical principle:
(A4c) ∀xA → A(t/x)
by using ‘E!’ to restrict specification. (A4) stipulates in effect that the quantifiers range over all objects that satisfy ‘E!’, (A5) that they range only over objects that satisfy ‘E!’. Omitting (A5) and replacing (A4) with (A4c) yields classical logic. To obtain a non-inclusive free logic, we may add to (A1)-(A5) the axiom ∃xE!x—or any axiom of the form ∃xT such that for any term t, T(t/x) is a tautology.
For languages containing the identity predicate, we also need:
(A6) s=t → (A → A(t//s))
(where A(t//s) is the result of replacing one or more occurrences of s in A by t), and either
(A7) t=t
if all self-identity statements, including those whose singular term is empty, are to be true or
(A7−) ∀x(x=x)
if not (see Sections 3.1 and 3.2 below). If ‘E!’ is defined in terms of the identity predicate as indicated in Section 1.2, then (A4) takes the form:
∀xA → (∃y(y=t) → A(t/x))
and (A5) is redundant and may be omitted. ‘E!’ cannot be defined without the identity predicate (Meyer, Bencivenga and Lambert, 1982).
Free logic can be formalized without either ‘=’ or ‘E!’. (A1)–(A3) remain unchanged, but (A4) and (A5) are replaced respectively by:
(A4′) ∀y(∀xA → A(y/x))
(A5′) ∀x∀yA → ∀y∀xA.
(A4′), like (A4), restricts specification to objects within D, but it uses a quantifier instead of ‘E!’ to do so. The quantifier permutation axiom (A5′) is redundant in the presence of the identity axioms but, as Fine proved in (1983), is independent of the other axioms.
The formulas used in the axiom systems discussed so far are closed, but some free logics allow open formulas—i.e., formulas that contain free variables. These logics follow one of two conventions for variable assignments. Those that assign to each free variable a member of D are called E+-logics; those that do not are called E-logics. The following specification rule is valid in E+-logics but not in E-logics:
∀xA ⊢ A(v/x).
(Here A(v/x) is the result of replacing every occurrence of the variable x in A by a variable v that is free for x in A.) Conversely, the following substitution rule is valid in E-logics but not in E+-logics:
A ⊢ A(t/x).
But since this article employs closed formulas, the distinction between E- and E+-logics may here be ignored. (See Williamson (1999) for an illuminating discussion of problems engendered by permitting open formulas in inclusive logics.)
2.2 Natural Deduction Rules
PFL can also equivalently be formulated in a natural deduction system. The introduction and elimination rules for the operators of propositional logic and identity are as usual. The quantifier introduction and elimination rules are restricted by use of the predicate ‘E!’, as follows:
∀I:
Given a derivation of A(t/x) from E!t, where t is new and does not occur in A, discharge E!t and infer ∀xA.
∀E:
From ∀xA and E!t infer A(t/x).
∃I:
From A(t/x) and E!t infer ∃xA.
∃E:
Given ∃xA and a derivation of a formula B from A(t/x) & E!t, where t is new and does not occur in either A or B, discharge A(t/x) & E!t and infer B from ∃xA.
The variable x need not be free in A, in which case A(t/x) is just A. ‘E!’ may either be taken as primitive (in which case it requires no additional rules) or defined in terms of the identity predicate as in Section 1.2. For non-inclusive logic, we may add a rule that introduces ∃xE!x.
2.3 Tree Rules
Jeffrey-style tree rules (Jeffrey 1991) for PFL can be obtained by replacing the classical rules for existentially and universally quantified formulas with the following:
Existential Rule: If ∃xA appears unchecked on an open path, check it, and
if x is free in A, choose a new individual constant t and list both E!t and A(t/x) at the bottom of every open path beneath ∃xA, and
if x is not free in A, write A at the bottom of every open path beneath ∃xA.
Universal Rule: If ∀xA appears on an open path, then
if x is free in A, then where t is an individual constant that occurs in a formula on that path, or a new individual constant if there are none on the path, split the bottom of every open path beneath ∀xA into two branches, writing ~E!t at the bottom of the first branch and A(t/x) at the bottom of the second, and
if x is not free in A, write A at the bottom of every open path beneath ∀xA.
For languages that do not allow vacuous quantification, clause (ii) can in each case be omitted. Non-inclusive free logic needs an additional rule that introduces E!t for some new individual constant t if a path does not already contain a formula of this form.
3. Semantics
Semantics for free logics differ in how they assign truth-values to atomic formulas that are empty-termed—i.e., contain at least one empty singular term. There are three general approaches:
Negative semantics require all empty-termed atomic formulas to be false,
Positive semantics allow some empty-termed atomic formulas not of the form E!t to be true, and
Neutral (or nonvalent) semantics require all empty-termed atomic formulas not of the form E!t to be truth-valueless.
3.1 Negative Semantics
A negative semantics is a bivalent semantics on which all empty-termed atomic formulas (including identity statements) are false. The inclusive version presented here makes only minimal adjustments to classical semantics to allow for non-denoting terms.
Let the language L be defined as in Section 2. Then a negative inclusive model for L is a pair ⟨D,I⟩, where D is a possibly empty set (the domain) and I is an interpretation function that assigns referents to individual constants and extensions to predicates such that:
for each individual constant t of L, either I(t) ∈ D or I(t) is undefined, and
for each n-place predicate P of L, I(P) ⊆ Dn.
(Dn is the set of n-tuples of members of D, a 1-tuple of an object d being just d itself.) Given a model ⟨D,I⟩, we recursively define a valuation function V that assigns truth values to formulas as follows:
V(Pt1…tn)
=
T ⇔ I(t1),…, I(tn) are all defined and ⟨I(t1),…, I(tn)⟩ ∈ I(P);
F otherwise.
V(s=t)
=
T ⇔ I(s) and I(t) are both defined and I(s) = I(t);
F otherwise.
V(E!t)
=
T ⇔ I(t) is defined;
F otherwise.
V(~A)
=
T ⇔ V(A) = F;
F otherwise.
V(A → B)
=
T ⇔ V(A) = F or V(B) = T;
F otherwise.
V(∀xA)
=
T ⇔ for all d∈D, V(t,d)(A(t/x)) = T (where t is any individual constant not in A and V(t,d) is the valuation function on the model ⟨D,I*⟩ such that I* is just like I except that I*(t) = d);
F otherwise.
(The metalinguistic symbol ‘⇔’ means “if and only if.”) A logic adequate to this semantics may be axiomatized by making three changes to the axioms of PFL. The first is to add the axiom:
(A−) Pt1…tn → E!ti, where 1≤i≤n and P is any primitive n-place predicate, including ‘=’.
This expresses the convention that an atomic formula cannot be true unless its terms refer. Second, because all empty-termed identity statements are false on a negative semantics, (A7) is invalid and must be replaced by (A7−). Third, since (A2), (A3), (A−) and (A7−) together imply (A5), (A5) may be omitted. The resulting logic is known as NFL (Negative Free Logic). For languages with function symbols, negative free logic requires in addition this axiom of strictness:
E!f(t1,…,tn) → E!ti, where 1≤i≤n,
which assures that a function has a value only if each of its arguments does. Because of its unusual treatment of identity, negative free logic validates the equivalence:
t=t ↔ E!t.
(This equivalence is sometimes taken as a definition of E!t.) Identity statements in negative free logic thus have existential implications. This may be problematic in certain contexts. According to Shapiro and Weir (2000), for example, use of such an “existential” notion of identity sullies the “epistemic innocence” of some recent efforts to base neo-logicist philosophies of mathematics on free logic.
Negative free logic is also peculiar in that it validates the principle of indiscernibility of nonexistents:
(~E!s & ~E!t) → (A → A(t//s)),
where A(t//s) is the result of replacing one or more occurrences of s in A by t.
3.2 Positive Semantics
Positive semantics allow some empty-termed atomic formulas not of the form E!t to be true. They are typically bivalent, though there are variants that allow truth-value gaps or extra truth values. Only bivalent semantics are considered in this section.
Positive semantics treat formulas of the form t=t as true, whether or not t is empty. Hence they validate (A7), which affirms all self-identity statements, not merely the weaker (A7−), which affirms only self-identities between nonempty terms.
Like negative semantics, some positive semantics require each singular term to denote either a member of D or nothing at all. But then when a term fails to denote, the truth value of an atomic formula containing it cannot as usual be a function of its denotation, and the formula must be evaluated in some nonstandard way. To avoid such irregularity and yet permit empty-termed formulas to be true, other positive semantics allow singular terms to denote, and predicates to be satisfied by, nonmembers of D. These nonmembers are collected into a second or outer domain Do, in contrast to which D is described as the inner domain. The result is a dual-domain semantics.
Positive semantics with dual domains are generally the simplest. The members of the outer domain Do typically represent “non-existing” things. Depending on the application, these may be theoretical or ideal entities, error objects (in computer science), fictional objects, merely possible (or even impossible) objects, and so on. Some authors make D a subset of Do, which is the convention throughout this article; others make the two disjoint. In a bivalent dual-domain semantics each singular term denotes an object in Do though possibly not in D. Thus D, though not Do, may empty. Predicates are assigned extensions from Do, and the truth-values of atomic formulas (whether empty-termed or not) are computed in the usual Tarskian fashion: an atomic formula is true if and only if the n-tuple of objects denoted by its singular terms, taken in order, is a member of the predicate's extension. Identity statements are no exception. Statements of the form s=t are true if and only if s and t denote the same object. Hence, even if empty-termed, they may be true.
More formally, a dual-domain model for a language L of the sort defined in Section 2 is a triple ⟨D,Do,I⟩, where D is a possibly empty inner domain, Do is a nonempty outer domain such that D ⊆ Do, and I is an interpretation function such that for every individual constant t of L, I(t) ∈ Do, and for every n-place predicate P of L, I(P) ⊆ Don. Given a model ⟨D,Do,I⟩, the valuation function V assigns truth values to atomic and quantified formulas as follows:
V(Pt1…tn)
=
T ⇔ ⟨I(t1),…,I(tn)⟩ ∈ I(P);
F otherwise
V(s=t)
=
T ⇔ I(s) = I(t);
F otherwise
V(E!t)
=
T ⇔ I(t) ∈ D;
F otherwise
V(∀xA)
=
T ⇔ for all d∈D, V(t,d)(A(t/x)) = T (where t is not in A and V(t,d) is the valuation function on the model ⟨D,Do,I*⟩ such that I* is just like I except that I*(t) = d);
F otherwise
The clauses for ‘~’ and ‘ → ’ are the same as in negative free logic. PFL with classical identity — that is, the logic axiomatized by (A1)–(A7) — is sound and complete with respect to this semantics (Leblanc and Thomason 1968).
Dual-domain semantics have been criticized as ontologically extravagant. In response, some authors have advocated single-domain positive semantics, which assign no denotation to empty singular terms. In such semantics empty-termed atomic formulas require unconventional treatment. Typically such semantics determine the truth-values of atomic formulas in two different ways: a Tarksi-style calculation for formulas whose terms all refer, and a separate truth-value assignment for empty-termed atomic formulas. The details, however, tend to get complicated. Antonelli (2000), for example, advocated such a single-domain free logic, which he called proto-semantics, but more recently (2007, p. 72) he has characterized all semantics for positive free logic as “somewhat artificial” and has questioned the logical character of free quantification in general.
3.3 Neutral Semantics
Neutral semantics make all empty-termed atomic formulas not of the form E!t truth-valueless. Truth-valueless formulas are often said to have “truth-value gaps.” Neutral semantics are of two types: ordinary neutral semantics, which provide conventions for calculating the truth values of complex formulas directly from their components, even when there are empty terms, and supervaluational semantics, which calculate the truth values of complex formulas by considering all the values that their components could have if their empty terms had referents. Ordinary neutral semantics will be considered in this section, supervaluations in Section 3.4.
The uniform policy of making all empty-termed atomic formulas truth-valueless has the advantages of plausibility and simplicity at the atomic level, but it complicates the evaluation of complex formulas. How are the logical operators to function when some of the values on which they usually operate are absent? Some cases are fairly clear. The negation of a truth-valueless formula, for example, is generally taken to be truth-valueless. But:
If A is true and B truth-valueless, is A → B false or truth-valueless?
If A is false and B truth-valueless, is A → B true or truth-valueless?
Let A = (B & C), where x is free in B, B be true of some but not all members of D, and C be closed and truth-valueless. Clearly this open formula is either truth-valueless of every object in D or truth-valueless of some and false of others. In either case, is ∃xA truth-valueless or false?
At one extreme, we might want the operators to generate as many plausible truth values as possible in order to validate as many classically valid formulas as we can. At the other, one might arrange things so that all empty-termed formulas are truth-valueless, which would produce a very weak logic (Lehman 2001). But however we choose, many formulas that are valid in both classical predicate logic and the usual forms of free logic—indeed, even in propositional logic—will become invalid. The law of noncontradiction, for example:
~(A & ~A)
is truth-valueless whenever A is (unless we make negations of truth-valueless statements true) and hence becomes invalid. Of course this law and many other standard logical principles remain weakly valid—i.e., not false on any model—and it is possible to construct a logic based on weak validity rather than ordinary validity. But because any such logic will still be weaker than classical logic and because its theorems need not even be true, most logicians reject this strategy. For more on neutral free logic, see Lehman 1994, 2001, and 2002, pp. 233–237.
3.4 Supervaluations
Neutral semantics can be made to validate all the theorems of standard free logics by augmenting them with supervaluations. Supervaluations were first formalized by van Fraassen (1966). The version presented here is a variant of Bencivenga's approach (1981 and 1986).
The fundamental idea is this: when empty terms deprive a formula of truth-value, supervaluational semantics nevertheless accounts it true (or false) if all possible ways of assigning referents to those terms agree in making it true (or false). This strategy restores validity to many principles that would lose it in an ordinary neutral semantics. The following instance of the law of noncontradiction:
~(Pt & ~Pt),
for example, is truth-valueless when t is nondenoting (assuming an ordinary neutral semantics that makes the negation of a truth-valueless formula truth-valueless). Hence in such a semantics the law itself is invalid. Yet were we to assign a referent to t, that referent would either be in the extension of P or not. If it were, then Pt would be true. If it were not, then Pt would be false. In either case ~(Pt & ~Pt) would be true. Thus, since all possible ways of assigning referents to t agree in making ~(Pt & ~Pt) true, we should count ~(Pt & ~Pt) itself as true. In this way the law of noncontradiction can be preserved.
More explicitly, a supervaluation begins with a neutral model M with a single, possibly empty domain. We then construct the set of completions of M. These may be regarded as bivalent dual-domain positive models whose inner domain is the domain of M, but which also have an outer domain Do to provide referents for the empty terms. In each completion, singular terms that are nonempty in M retain their referents, and those that are empty in M denote a member of Do — D. For each n-place predicate P, the extension of P is a subset of Don and a superset of P's extension in M.
From these completions we now construct a supervaluation. A supervaluation of M is a partial assignment of truth-values to formulas that makes a formula true if all completions of M make it true, false if they all make it false, and truth-valueless if they disagree. A formula is valid on a supervaluational semantics if and only if it is true on all supervaluations. This semantics validates all and only the theorems of PFL (Bencivenga 1981, Morscher & Simons 2001, pp. 14–18).
Supervaluations employ what Bencivenga (1986) calls a “counterfactual theory” of truth: an empty-termed statement is true if it would be true on any assignment of referents to its empty terms. This has struck many critics as simply false. Moreover, the logic itself leaves much to be desired. For one thing, supervaluational consequence is too strong. Thus, for example, although the formula Pt → E!t is (quite properly) not valid on a supervaluational semantics, nevertheless since E!t is true on every supervaluation on which Pt is true, the sequent (derivability statement) Pt ⊢ E!t is improperly semantically valid. Therefore, although PFL is sound on supervaluational semantics and every semantically valid formula is a theorem of PFL, not all semantically valid sequents are provable in PFL. In fact, supervaluational consequence is not axiomatizable by any extension of free logic. This follows from a result of Woodruff (1984), who has shown that supervaluational semantics has many of the undesirable properties of second-order semantics. Jerry A. Fodor and Ernest Lapore (1996) argue, furthermore, that the completions needed to construct supervaluations are not meaning-preserving. Hence, they conclude, two alleged advantages of supervaluations—that they explain the meaningfulness of sentences with truth value gaps and that they allow us to preserve classical logic—are illusory. Finally, since supervaluations are built from completions that are in effect positive dual-domain models, we may wonder whether the detour through supervaluations is worth the trouble, since positive dual-domain models alone are simpler and more adequate to PFL.
4. Generic Anomalies
While problems noted above are specific to particular forms of free logic, there are anomalies that infect all, or nearly all, forms. This section considers three: (1) a cluster of problems related to the application of primitive predicates to empty terms, (2) the failure of substitutivity salva veritate of co-referential expressions, and (3) the inability of free logic to express sufficient conditions for existence.
4.1 Problems with Primitive Predicates
In classical logic and in positive free logic any substitution instance of a valid formula (or form of inference) is itself a valid formula (or form of inference). But in negative or neutral free logic this is not the case. A substitution instance is the result of replacing primitive non-logical symbols by possibly more complex ones of the same semantic type—n-place predicates with open formulas in n variables, and individual constants with singular terms—each occurrence of the same primitive symbol being replaced by the same possibly complex symbol. The replacement of an occurrence of a primitive n-place predicate P in some formula B by an open formula A with free variables x1,…,xn is performed as follows: where t1,…,tn are the individual constants or variables immediately following P in that occurrence, replace Pt1…tn in B by A(ti/xi)—the result of replacing xi by ti in A, for each i, 1≤i≤n.
Let P, for example, be a primitive one-place predicate. Then if the semantics is negative, Pt → E!t is valid. But now consider the substitution instance ~Pt → E!t, in which the open formula ~Px is substituted for P. This substitution instance is false when t is empty. Hence valid formulas may have invalid substitution instances. The same holds for ordinary neutral semantics that make conditionals true whenever their consequents are true.
In a negative semantics, moreover, the truth value of an empty-termed statement depends arbitrarily on our choice of primitive predicates. Consider, for example, a negative free logic interpreted over a domain of people that takes as primitive the one-place predicate ‘A’, meaning “is an adult,” and defines “is a minor” by this schema:
Mt =df ~At.
For any non-denoting name t, At is false in this theory; hence Mt is true. If we take ‘is a minor’ as primitive instead, the truth-values of At and Mt are reversed. But why should truth-values depend on primitiveness in this way?
Positive semantics avoid these anomalies. But, if bivalent, in application they force us to assign truth values to empty-termed formulas in some other way, often without sufficient reason. Consider, for example, these three formulas, all of which contain the empty singular term ‘1/0’ (where ‘/’ is the division sign):
1/0 = 1/0
1/0 > 1/0
1/0 ≤ 1/0
Assuming a bivalent positive semantics, which ones should we make true and which false? Since the semantics is positive, ‘1/0 = 1/0’ is automatically true. One might argue further that since ‘≤’ expresses a relationship weaker than ‘=’ and since ‘1/0 = 1/0’ is true, ‘1/0 ≤ 1/0’ should be true as well. But that is merely to mimic with empty terms an inference pattern that holds for denoting terms. To what extent is such mimicry justified? Suppose we do decide to make ‘1/0 ≤ 1/0’ true; should we therefore make ‘1/0 > 1/0’ false? There are no non-arbitrary criteria for answering such questions. To a large extent, of course, the answers don't matter. There are no facts here; any consistent convention will do. But that's just the problem. Some convention is needed, and establishing one can be a lot of bother for nothing.
4.2 Substitutivity Failures
Classical predicate logic has the desirable feature that co-extensive open formulas may be substituted for one another in any formula salva veritate—i.e., without changing that formula's truth value. (Open formulas A and B in n free variables x1,…,xn are coextensive if and only if ∀x1…∀xn(A ↔ B) is true.) But, as Lambert noted in 1974, this principle fails for nearly all free logics with identity. Consider, for example, the formula t=t, where t is empty, which is an instance of the open formula x=x. Now x=x is coextensive with both (x=x & E!x) and (E!x → x=x), since all three formulas are satisfied by all members of D. Hence if co-extensive open formulas could be exchanged salva veritate, (t=t & E!t) and (E!t → t=t) would have the same truth value as t=t. But on nearly all free logics this is not the case. Positive free logic and the supervaluations described in Section 3.4 make t=t true and (t=t & E!t) false; negative free logic makes t=t false and (E!t → t=t) true; and any ordinary neutral free logic whose conditionals are true whenever their antecedents are false makes t=t truth-valueless and (E!t → t=t) true. Many find this troubling because, since Frege, it has been widely held that (1) extensions of complex linguistic expressions should be functions of the extensions of their components (so that co-extensive components should be exchangeable without affecting the extension of the whole) and (2) the extension of a formula (or statement) is a truth value.
One possible response is to reject (2). Leeb (2006) develops for a version of PFL a dual-domain semantics in which the extensions of formulas are abstract states of affairs. In this semantics, co-referential open sentences are exchangeable not salve veritate, but (as he puts it) salve extensione; that is, the exchange does not alter the state of affairs designated by the statement in which it occurs. But Leeb's state-of-affairs semantics is so complex that it may discourage application.
Those who wish to retain (2) may be consoled by the following observation: though substitutivity salve veritate of co-extensive open formulas fails for nearly all free logics, a related but weaker principle, the substitutivity salve veritate of co-comprehensive open formulas, is valid for positive free logics. Open formulas A and B in n free variables x1,…,xn are co-comprehensive if every assignment of denotations in the outer domain Do to x1,…,xn satisfies A if and only if it satisfies B. Among the open formulas mentioned in the previous paragraph, for example, x=x and (E!x → x=x) are co-comprehensive in a dual-domain positive free logic, being satisfied by all members of Do, but (x=x & E!x) is not co-comprehensive with them, since it is satisfied only by the members of D. Unlike co-extensiveness, however, co-comprehensiveness is not expressible in the language of PFL. But it becomes expressible with the introduction of quantifiers over the outer domain—a strategy considered in Section 5.5.
4.3 Inexpressibility of Existence Conditions
‘Whatever thinks exists,’ ‘Any necessary being exists’, ‘That which is immediately known exists’: such statements of sufficient conditions for existence are prominent in metaphysical debates. But, somewhat surprisingly, they are not expressible in free logic. Their apparent form is ∀x(A → E!x). But because the universal quantifier ranges just over D, which is also the extension of E!, this form is valid in free logic—as it is in classical logic with E!x expressed as ∃y y=x. No statement of this form—not even ‘all impossible things exist’—can be false. Hence on free logic all such statements are equally devoid of content. Argument evaluation suffers as a result. Consider, for example, the obviously valid inference:
Its natural formalization in free logic is Ti, ∀x(Tx → E!x) ⊢ E!i. But this form is invalid. To obtain the conclusion, we must first deduce Ti → E!i by specification from the second premise and then use modus ponens with the first. But since the logic is free, specification requires the question-begging premise E!i. A remedy is not to be found in free logic alone, but once again quantification over the outer domain of a dual-domain semantics may help (see Section 5.5).
5. Some Applications
This section considers applications of free logic in theories of definite descriptions, languages that allow partial or non-strict functions, logics with Kripke semantics, logics of fiction and logics that are in a certain sense “Meinongian.” Free logic has also found application elsewhere—most prominently in theories of predication, programming languages, set theory, logics of presupposition (with neutral semantics), and definedness logics. For more on these and other applications, see Lambert 1991 and 2001b; Lehman 2002, pp. 250–253; and Nolt 2006, pp. 1039–1053.
5.1 Theories of Definite Descriptions
The earliest and most extensive applications of free logic have been to the theory of definite descriptions. A definite description is a phrase that may be expressed in the form “the x such that A,” where A is an open formula with only x free. Formally, this is written using a special logical operator, the definite description operator ‘ι’, as ιxA. Contra Russell, free logic treats definite descriptions not as merely apparent singular terms in formulas whose logical form is obtainable only by elaborate contextual definitions, but as genuine singular terms. Thus, like an individual constant, ιxA may be attached to predicates and (under appropriate conditions) substituted for variables. For any object d in the domain D, ιxA denotes d if and only if among all objects in D, d and only d satisfies A. If in D there is more than one object satisfying A, or none, ιxA is empty. The description operator therefore obeys Lambert's Law:
(LL) ∀y(y=ιxA ↔ ∀x(A ↔ x=y)), x free in A.
Adding (LL) to the free logic defined by (A1)–(A6) and (A7−) gives the minimal free definite description theory MFD. MFD is the core of virtually all free description theories, which therefore differ only in the additional principles they endorse.
There is plenty of room for variation, for MFD fails to specify truth conditions for atomic formulas (including identities) when they contain empty descriptions, and there are many ways to do it. Making all atomic formulas containing empty descriptions false yields a negative free description theory axiomatizable by adding (LL) to NFL (Burge 1974, Lambert 2001h). The result is essentially Bertrand Russell's theory of definite descriptions, but with the description operator taken as primitive rather than contextually defined.
The simplest positive free description theory makes all identities between empty terms true. Known as FD2, it may be axiomatized by adding (LL) and:
(~E!s & ~E!t) → s=t
to PFL. FD2 is akin to Gottlob Frege's theory of definite descriptions; but whereas Frege chose a single arbitrary existing object to serve as the conventional referent for empty singular terms, FD2 makes this object non-existent. FD2 is readily modeled in a dual-domain positive semantics with just one object in the outer domain.
On FD2 all empty descriptions are intersubstitutable salve veritate. But this result is subject to counterexamples in ordinary language. This statement:
The golden mountain is a possible object,
for instance, is true, while this one:
The set of all non-self-membered sets is a possible object,
is false—though each applies the same predicate phrase ‘is a possible object’ to an empty description. Thus we may prefer a more flexible positive free description theory on which identities between empty terms may be false. The literature presents a surprising diversity of these (Lambert 2001a, 2003c, 2003d, 2003h; Bencivenga 2002, pp. 188–193; Lehman 2002, pp. 237–250).
5.2 Logics with Partial or Non-Strict Functions
Some logics employ primitive n-place function symbols—symbols that combine with n singular terms to form a complex singular term. Thus, for example, the plus sign ‘+’ is a two-place function symbol that, when placed between, say, ‘2’ and ‘3’, forms a complex singular term, ‘2 + 3’ that denotes the number five. Similarly, ‘2’ is a one-place function symbol that, when placed after term denoting a number, forms a complex singular term that denotes that number's square. Semantically, the extension of a function symbol is a function whose arguments are members of the quantificational domain D, and the resulting complex term denotes the result of applying that function to the referents of the n component singular terms, taken in the order listed. Since classical logic requires every singular term (including those formed by function symbols) to refer to to an object in D, for each such function symbol f, it requires that:
∀x1…∀xn∃y(y = f(x1, …, xn)).
Hence classical logic prohibits primitive function symbols whose extensions are partial functions—functions whose value is for some arguments undefined. Such, for example, is the binary division sign ‘/’, since when placed between two numerals the second of which is ‘0’, it forms an empty singular term. Similarly, the limit function symbol ‘lim’ yields an empty singular term when applied to the name of a non-coverging sequence. Classical logic can accomodate function symbols for partial functions via elaborate contextual definitions. But then (as with Russellian definite descriptions) the form in which these function symbols are usually written is not their logical form. Free logic provides a more elegant solution. Because it allows empty singular terms, symbols for partial functions may simply be taken as primitive.
In applications of free logic involving partial functions, the existence predicate ‘E!’ is often replaced by the postfix definedness predicate ‘↓’. For any singular term t, t↓ is true if and only if t has some definite value in D. Thus, for example, the formula ‘(1/0)↓’ is false. While some writers (e.g., Feferman (1995)) distinguish ‘↓’ from ‘E!’, the literature as a whole does not, and ‘↓’ is often merely a syntactic variant of ‘E!’.
In addition to partial functions, positive free logics can also readily handle non-strict functions. A non-strict function is a function that may yield a value even if not all of its arguments are defined. The binary function f such that f(x,y) = x, for instance, can yield a value even if the y-term is empty. So, for example, the formula f(1, 1/0) = 1 can be regarded as true. Logics for non-strict functions must be positive because in a negative or neutral logic empty-termed atomic formulas, such as f(1, 1/0) = 1, cannot be true. Free logics involving non-strict functions find application in some programming languages (Gumb 2001, Gumb and Lambert 1991). Such logics may employ a dual-domain semantics in which the referents of empty functional expressions such as ‘1/0’ are regarded as error objects—objects that correspond in the running of a program to error messages. Thus, for example, an instruction to calculate f(1, 1/0) might return the value 1, but an instruction to calculate f(1/0, 1) would return an error message.
5.3 Logics with Kripke Semantics
Kripke semantics for quantified modal logics, tense logics, deontic logics, intuitionistic logics, and so on, are often free. This is because they index truth to certain objects that we shall call “worlds,” and usually some things that we have names for do not exist in some of these worlds. Worlds may be conceived in various ways: they may, for example, be understood as possible universes in alethic modal logic, times or moments in tense logic, permissible conditions in deontic logic, or epistemically possible states of knowledge in intuitionistic logic. Associated with each world w is a domain Dw, of objects (intuitively, the set of objects that exist at w). An object may exist in (or “at”) more than one world but need not exist in all. Thus, for example, Kripke semantics for tense logic represents the fact that Bertrand Russell existed at one time but exists no longer by Russell's being a member of the domains of certain “worlds”—that is, times (specifically, portions of the last two centuries)—but not others (the present, for example, or all future times). Two natural assumptions are made here: that the same object may exist in more than one world (this is the assumption of transworld identity), and that some singular terms—proper names, in particular—refer to not only to an object at a given world, but to that same object at every world. Such terms are called rigid designators. Any logic that combines rigid designators with quantifiers over the domains of worlds in which their referents do not exist must be free.
Kripke semantics gives predicates different extensions in different worlds. Thus, for example, the extension of the predicate ‘is a philosopher’ was empty in all worlds (times) before the dawn of civilization and more recently has varied. For rigidly designating terms, this raises the question of how to evaluate atomic formulas at worlds in which their referents do not exist. Is the predicate ‘is a philosopher’ satisfied, for example, by Russell in worlds (times) in which he does not exist—times such as the present? The general answers given to such questions determine whether a Kripke semantics is positive, negative or neutral.
For negative or neutral semantics, the extension at w of an n-place predicate P is a subset of Dwn. An atomic formula can be true at w only if all its singular terms have referents in Dw; if not, it is false (in negative semantics) or truth-valueless (in neutral semantics). In a positive semantics, atomic formulas that are empty-termed at w may nevertheless be true at w. Predicates are usually interpreted over the union U of domains of all the worlds, which functions as a kind of outer domain for each world, so that the extension of an n-place predicate P at a world w is a subset of Un. Some applications, however, require predicates to be true of—and singular terms to be capable of denoting—objects that exist in no world. If so, we may collect these objects into an outer domain that is a superset of U. (They might be fictional objects, timeless Platonic objects, impossible objects, or the like.)
Quantified formulas, like all formulas, are true or false only relative to a world. Thus ∃xA, for example, is true at a world w if and only if some object in Dw satisfies A. Except in intuitionistic logic, where it has a specialized interpretation, the universal quantifier is interpreted similarly: ∀xA is true at w if and only if all objects in Dw satisfy A. Kripke semantics often specify that for each w, Dw is nonempty, so that the resulting free logic is non-inclusive—but we shall not do so.
Any of various free modal or tense logics can be formalized by adding to a language L of the sort defined in Section 2 the sentential operator ‘□’. If A is a formula, so is □A. In alethic modal logic, this operator is read “it is necessarily the case that.” More generally, it means “it is true in all accessible worlds that,” where accessibililty from a given world is a different relation for different modalities: possibility for alethic logics, permissibility for deontic logics, various temporal relations for tense logics, and so on. A typical bivalent Kripke model M for such a language consists of a set of worlds, a binary accessibility relation R defined on that set; an assignment to each world w of a domain Dw; an “outer” domain Do of objects (which typically is either U or a superset thereof); and a two-place interpretation function I that assigns denotations at worlds to individual constants and extensions at worlds to predicates. For each individual constant t and world w, I(t,w)∈ Do. In such a model, a singular term is a rigid designator if and only if for all worlds w1 and w2, I(t,w1) = I(t,w2). For every n-place predicate P, I(P,w) ⊆ Dwn if the semantics is negative or neutral; if it is positive, I(P,w) ⊆ Don. Truth values at the worlds of a model M are assigned by a two-place valuation function V (where V(A,w) is read “the truth value V assigns to formula A at world w”) as follows:
V(Pt1…tn,w)
=
T ⇔ ⟨I(t1,w),…,I(tn,w)⟩ ∈ I(P,w);
F otherwise.
V(s=t,w)
=
T ⇔ I(s,w) = I(t,w);
F otherwise.
V(E!t,w)
=
T ⇔ I(t,w) ∈ Dw;
F otherwise.
V(~A,w)
=
T ⇔ V(A,w) = F;
F otherwise.
V(A → B,w)
=
T ⇔ V(A,w) = F or V(B,w) = T;
F otherwise.
V(□A,w)
=
T ⇔ for all u such that wRu, V(A,u) = T;
F otherwise.
V(∀xA,w)
=
T ⇔ for any d ∈ Dw, V(t,d)(A(t/x),w) = T (where t is not in A and V(t,d) is the valuation function for the model just like M except that its interpretation function I* is such that for each world w, I*(t,w) = d);
F otherwise.
Under the stipulations that admissible models make all individual constants rigid designators and that I(P,w) ⊆ Don, the standard free logic PFL, together with the modal axioms and rules appropriate to whatever structure we assign to R, is sound and complete on this semantics.
Modal semantics thus defined call for free logic whenever worlds are allowed to have differing domains—that is whenever we may have worlds u and w such that Du ≠ Dw. For in that case there must be an object d that exists in one of these domains (let it be Dw), but not the other, so that any singular term t that rigidly designates d must be empty at world u. Hence ~∃x(x=t) (which is self-contradictory in classical logic) must be true at world u. Such a semantics also requires free logic when Do contains objects not in U, for in that case rigid designators of these objects are empty in all worlds. Finally, this semantics calls for inclusive logic if any world has an empty domain. Thus, given this semantics, the only way to make the resulting logic unfree is to require that domains be fixed—i.e., that all worlds have the same domain D, that D be non-empty, and that Do = D.
Just this trio of requirements was in effect proposed by Saul Kripke in his ground-breaking (1963) paper on modal logic as one of two strategies for retaining classical quantification. (The other, more draconian, strategy was to allow differing domains but ban individual constants and treat open formulas as if they were universally quantified.) But such fixed-domain semantics validate the implausible formula:
∀x□∃y(y = x),
which asserts that everything exists necessarily and the equally implausible Barcan formula:
∀x□A → □∀xA
(named for Ruth Barcan, later Ruth Barcan Marcus, who discussed it as early as the late 1940s). To see its implausibility, consider this instance: ‘If everything is necessarily a product of the big bang, then necessarily everything is a product of the big bang’. It may well be true that everything (in the actual world) is necessarily a product of the big bang—i.e., that nothing in this world would have existed without it. But it does not seem necessary that everything is a product of the big bang, for other universes are possible in which things that do not exist in the actual world have other ultimate origins. Because of the restrictiveness and implausibility of fixed-domain semantics, many modal logicians loosen Kripke's strictures and adopt free logics.
We may also drop the assumption that singular terms are rigid designators and thus allow nonrigid designators. On the semantics considered here, these are singular terms t such that for some worlds w1 and w2, I(t,w1) ≠ I(t,w2). Definite descriptions, understood attributively, are the best examples. Thus the description “the oldest person” designates different people at different times (worlds)—and no one at times before people existed (“worlds” w at which I(t,w) is undefined).
Nonrigid designators, if empty at some worlds, require free logics even with fixed domains. (Thus classical logic with nonrigid designators is possible only if we require for each singular term t that at each world w, t denotes some object in Dw.) On some semantics for nonrigid designators, the quantifier rule must differ from that given above, and other adjustments must be made. For details, see Garson 1991, Cocchiarella 1991, Schweitzer 2001 and Simons 2001.
Intuitionistic logic, too, has a Kripke semantics, though special valuation clauses are needed for ‘~’, ‘→’ and ‘∀’ in order to accommodate the special meanings these operators have for intuitionists, and ‘□’ is generally not used. The usual first-order intuitionistic logic, the Heyting predicate calculus (HPC)—also called the intuitionistic predicate calculus—has the theorem ∃x(x=t) and hence is not free. But intuitionists admit the existence only of objects that can in some sense be constructed, while classical mathematicians posit a wider range of objects. Therefore users of HPC cannot legitimately name all the objects that classical mathematicians can. Worse, they cannot legitimately name objects whose constructibility has yet to be determined. Yet some Kripke-style semantics for HPC do allow use of names for such objects (semantically, names of objects that “exist” at worlds accessible from the actual world but not at the actual world itself). Some such semantics, though intended for HPC, have turned out, unexpectedly, not to be adequate for HPC. An obvious fix, advocated by Posy (1982), is to adopt a free intuitionistic logic. For more on this issue, see Nolt 2007.
5.4 Logics of Fiction
Because fictions use names that do not refer to literally existing things, free logic has sometimes been employed in their analysis. So long as we engage in the pretense of a story, however, there is no special need for it. It is true, for example, in Tolkien's The Lord of the Rings that Gollum hates the sun, from which we can legitimately infer that in the story there exists something that hates the sun. Thus quantifiers may behave classically so long as we consider only what occurs and what exists “in the story.” (The general logic of fiction, however, is often regarded as nonclassical, for two reasons: (1) a story may be inconsistent and hence require a paraconsistent logic, and (2) the objects a story describes are typically (maybe always) incomplete; that is, the story does not determine for each such object o and every property P whether or not o has P.)
The picture changes, however, when we distinguish what is true in the story from what is literally true. For this purpose logics of fiction often deploy a sentence operator that may be read “in the story.” Here we shall use ‘Sx’ to mean “in the story x,” where ‘x’ is to be replaced by the name of a specific story. Anything within the scope of this operator is asserted to be true in the named story; what is outside its scope is to be understood literally. (For a summary of theories of what it means to be true in a story, see Woods 2006.)
With this operator the statement ‘In the story, The Lord of the Rings, Gollum hates the sun’ may be formalized as follows:
SThe Lord of the Rings(Gollum hates the sun).
The statement that in The Lord of the Rings something hates the sun is:
SThe Lord of the Rings∃x(x hates the sun).
This second statement follows from the first, even though Gollum does not literally exist. But it does not follow that there exists something such that it, in The Lord of the Rings, hates the sun:
∃xSThe Lord of the Rings(x hates the sun),
and indeed that statement is not true, for, literally, Gollum does not exist. Since the sun, however, exists both literally and in the story, the statement:
∃xSThe Lord of the Rings(Gollum hates x)
is true and follows by free existential generalization from ‘SThe Lord of the Rings(Gollum hates the sun)’ together with the true premise ‘E!the sun’. Thus free logic may play a role in reasoning that mixes fictional and literal discourse.
Terms for fictional entities also occur in statements that are entirely literal, making no mention of what is true “in the story.” Consider, for example, the statement:
(G) Gollum is more famous than Gödel.
Mark Sainsbury (2005, ch. 6) holds that reference failure invariably makes such statements false and hence that they are best represented in a negative free logic. Others, however—including Orlando 2008 and Dumitru and Kroon 2008—question Sainsbury's treatment, maintaining that statements like (G) are both atomic and true. If so, they require a positive free logic. The logic must be free because it deals with an empty singular term, and it must be positive, because only on a positive semantics can empty-termed atomic statements be true. One must still decide, however, whether the name ‘Gollum’ is to be understood as having no referent or as having a referent that does not exist.
If ‘Gollum’ has no referent, then (G) might be handled by a single-domain positive semantics. But that semantics would have to treat atomic formulas non-standardly; it could not, as usual, stipulate that (G) is true just in case the pair ⟨Gollum, Gödel⟩ is a member of the extension of the predicate ‘is more famous than’; for if there is no Gollum, there is no such pair. On such a semantics ‘Gollum is more famous than Gödel’ would not imply that something is more famous than Gödel.
If, on the other hand, terms such as ‘Gollum’ refer to non-existent objects, then those objects could inhabit the outer domain of a dual-domain positive free logic. If so, atomic formulas have their standard truth conditions: (G) is true just in case ⟨Gollum, Gödel⟩ is a member of the extension of ‘is more famous than’. Moreover, if we allow quantifiers over that outer domain, then ‘Something is more famous than Gödel’ (where the quantifier ranges over the outer domain) does follow from ‘Gollum is more famous than Gödel’, though ‘There literally exists something more famous than Gödel’ (where the quantifier ranges over the inner domain) does not. Meinongian logics of fiction employ this strategy.
5.5 Meinongian Logics
Alexius Meinong is best known for his view that some objects that do not exist nevertheless have being. His name has been associated with various developments in logic. Some free logicians use it to describe any dual-domain semantics. For others, Meinongian logic is something much more elaborate: a rich theory of all the sorts of objects we can think about—possible or impossible, abstract or concrete, literal or fictional, complete or incomplete. In this section the term is used to describe logics stronger than the first type but possibly weaker than the second: positive free logics with an extra set of quantifiers that range over the outer domain of a dual-domain semantics.
Whether such logics can legitimately be considered free is controversial. On older conceptions, free logic forbids any quantification over non-existing things (see Paśniczek 2001 and Lambert's reply in Morscher and Hieke 2001, pp. 246–8). But by anybody's definition, Meinongian logics in the sense intended here at least contain free logics when the inner domain is interpreted as the set of existing things. Moreover, on the strictly semantic definition used in this article (Section 1.1), which is also that of Lehman 2002, whether the members of D exist is irrelevant to the question of whether a logic is free. For a defense of this definition, see Nolt 2006, pp. 1054–1057.
Historically, quantification over domains containing objects that do not exist has been widely dismissed as ontologically irresponsible. Quine (1948) famously maintained that existence is just what an existential quantifier expresses. Yet nothing forces us to interpret “existential” quantification over every domain as expressing existence—or being of any sort. Semantically, an existential quantifier on a variable x is just a logical operator that takes open formulas on x into truth values; the value is T if and only if the open formula is satisfied by at least one object in the quantifier's domain. That the objects in the domain have or lack any particular ontological status is a philosophical interpretation of the formal semantics. Alex Orenstein (1990) argues that “existential” is a misnomer and that we should in general call such quantifiers “particular.” That suggestion is followed in the remainder of this section.
Quantifiers ranging over the outer domain of a dual-domain semantics are called outer quantifiers, and those ranging over the inner domain inner quantifiers. If the inner particular quantifier is interpreted to mean “there exists” and the members of the outer domain are possibilia, then the outer particular quantifier may mean something like “there is possible a thing such that” or “for at least one possible thing.” We shall use the generalized product symbol ‘Π’ for the outer universal quantifier and the generalized sum symbol ‘Σ’ for its particular dual. This notation enables us to formalize, for example, the notoriously puzzling but obviously true statement ‘Some things don't exist’ (Routley 1966) as:
Σx~E!x.
Since in a dual-domain semantics all singular terms denote members of the outer domain, the logic of outer quantifiers is not free but classical. With ‘E!’ as primitive, the free inner quantifiers can be defined in terms of the classical outer ones as follows:
∀xA =df Πx(E!x → A)
∃xA =df Σx(E!x & A).
The outer quantifiers, however, cannot be defined in terms of the inner.
Logics with both inner and outer quantifiers have various applications. They enable us, for example, to formalize substantive sufficient conditions for existence and hence adequately express the argument of Section 4.3, as follows:
Ti, Πx(Tx → E!x) ⊢ E!i.
This form is valid. The co-comprehensiveness of open formulas A and B in n free variables x1,…,xn (see Section 4.2), can likewise be formalized as:
Πx1…Πxn(A ↔ B).
Richard Grandy's (1972) theory of definite descriptions holds that ιxA=ιxB is true if and only if A and B are co-comprehensive and thus is readily expressible in a Meinongian logic. Free logics with outer quantifiers have also been employed in logics that are Meinongian in the richer sense of providing a theory of objects (including, in some cases, fictional objects) that is inspired by Meinong's work (Routley 1966 and 1980, Parsons 1980, Jacquette 1996, Paśniczek 2001, Priest 2005 and 2008, pp. 295–7).
6. History
Inclusive logic was conceived and formalized before free logic per se was. Thus, since inclusive logic with singular terms is de facto free, the inventors of inclusive logics were, perhaps unwittingly, the inventors of free logic. Bertrand Russell suggested the idea of an inclusive logic in (1919, p. 201, n.). Andrezej Mostowski (1951) seems to have been among the first to formalize such a logic (but see Morscher and Simons 2001, p. 27, note 3). Theodore Hailperin (1953), Czeslaw Lejewski (1954) and W. V. O. Quine (1954) made important early contributions. It was Quine who dubbed such logics “inclusive.”
Henry S. Leonard (1956) was the first to develop a free logic per se, though he used a defective definition of ‘E!’. Karel Lambert began his prolific series of contributions to the field in (1958), critiquing Leonard's definition, and then coining the term “free logic” in (1960). The early systems of free logic were positive. Negative free logic was developed by Rolf Schock in a series of papers during the 1960s, culminating in (1968). Timothy Smiley suggested the idea of a neutral free logic in (1960), but the first thoroughgoing treatment appeared in Lehman 1994. Supervaluations were described in Mehlberg 1958, pp. 256–260, as a device for handling, not neutral free logic, but vagueness. But their formalization and application to free logic began with van Fraassen 1966, in which the term “supervaluation” was introduced. Dual-domain semantics were discussed in lectures by Lambert, Nuel Belnap and others as early as the late 1950s, but it appears that Church 1965 and Cocchiarella 1966 were the first published accounts.
Bibliography
Antonelli, Gian Aldo, 2000, “Proto-Semantics for Positive Free Logic,” Journal of Philosophical Logic, 29 (3): 277–294.
–––, 2007, “Free Quantification and Logical Invariance,” Rivista de Estetica (New Series), 33 (1): 61–73.
Bencivenga, Ermanno, 1981, “Free Semantics” in Boston Studies in the Philosophy of Science, 47: 38–41; revised version reprinted in Lambert 1991, pp. 98–110.
–––, 1986, “Free Logics,” in D. Gabbay and F. Guenthner (eds.), Handbook of Philosophical Logic, vol. III: Alternatives to Classical Logic, Dordrecht: D. Reidel, pp. 373–426
–––, 2002, “Free Logics,” in D. Gabbay and F. Guenthner (eds.), Handbook of Philosophical Logic, 2nd edition, vol. 5, Dordrecht: Kluwer, pp. 147–196. (This is a republication of Bencivenga 1986.)
Besson, Corine, 2009, “Externalism, Internalism, and Logical Truth,” Review of Symbolic Logic, 2 (1): 1–29.
Burge, Tyler, 1974, “Truth and Singular Terms,” Noûs, 8: 309–25; reprinted in Lambert 1991, pp. 189–204.
Church, Alonzo, 1965, review of Lambert 1963 in Journal of Symbolic Logic, 30: 103–104.
Cocchiarella, Nino B., 1966, “A Logic of Actual and Possible Objects” (abstract), Journal of Symbolic Logic, 31: 688–689.
–––, 1986, Logical Investigations of Predication Theory and the Problem of Universals, Napoli, Italy: Bibliopolis.
–––, 1991, “Quantification, Time and Necessity,” in Lambert 1991, pp. 242–256.
Dumitru, Mircea and Frederick Kroon, 2008, “What to Say When There Is Nothing to Talk about (Qué decir cuando no hay nada de quehablar),” Crítica: Revista Hispanoamericana de Filosofía, 40 (120): 97–109.
Feferman, Solomon, 1995, “Definedness,” Erkenntnis, 43 (3): 295–320.
Fine, Kit, 1983, “The Permutation Principle in Quantificational Logic,” Journal of Philosophical Logic, 12: 33–7.
Fodor, Jerry A., and Ernest Lepore, 1996, “What Cannot be Evaluated Cannot be Evaluated and it Cannot be Supervalued Either,” Journal of Philosophy, 93 (10): 516–535.
Garson, James W., 1991, “Applications of Free Logic to Quantified Intensional Logic,” in Lambert 1991, pp. 111–142.
Grandy, Richard E., 1972, “A Definition of Truth for Theories with Intensional Definite Description Operators,” Journal of Philosophical Logic, 1: 137–55; reprinted in Lambert 1991, pp. 171–188.
Gumb, Raymond D., 2001, “Free Logic in Program Specification and Verification,” in Morscher and Hieke 2001, pp. 157–93.
Gumb, Raymond D., and Karel Lambert, 1991, “Definitions in Nonstrict Positive Free Logic,” Modern Logic, 7: 25–55 and 435–440 (errata).
Hailperin, Theodore, 1953, “Quantification Theory and Empty Individual Domains,” Journal of Symbolic Logic, 18: 197–200.
Hintikka, Jaakko, 1959, “Towards a Theory of Definite Descriptions,” Analysis, 19: 79–85.
Jacquette, Dale, 1996, Meinogian Logic: The Semantics of Existence and Nonexistence, Berlin: Walter de Gruyter.
–––, (ed.), 2006, Philosophy of Logic (Series: Volume 5 of the Handbook of the Philosophy of Science), Amsterdam: Elsevier.
Jeffrey, Richard, 1991, Formal Logic: Its Scope and Limits, 3rd edition, New York: McGraw-Hill.
Kripke, Saul 1963, “Semantical Considerations on Modal Logic,” Acta Philosophical Fennica, 16: 83–94.
Lambert, Karel, 1958, “Notes on E!,” Philosophical Studies, 9: 60–63.
–––, 1960, “The Definition of E! in Free Logic,” in Abstracts: The International Congress for Logic, Methodology and Philosophy of Science, Stanford: Stanford University Press.
–––, 1963, “Existential Import Revisited,” Notre Dame Journal of Formal Logic, 4: 288–292.
–––, 1974, “Predication and Extensionality,” Journal of Philosophical Logic, 3: 255–264.
–––, (ed.), 1991, Philosophical Applications of Free Logic, New York: Oxford University Press.
–––, 2001a, “Free Logic and Definite Descriptions,” in Morscher and Hieke 2001, pp. 37–47.
–––, 2001b, “Free Logics,” in Lou Goble (ed.), The Blackwell Guide to Philosophical Logic, Oxford: Blackwell Publishing, pp. 258–279.
–––, 2003a, Free Logic: Selected Essays, Cambridge: Cambridge University Press.
–––, 2003b, “Existential Import, E! and ‘The’” in Lambert 2003a, pp. 16–32.
–––, 2003c, “Foundations of the Hierarchy of Positive Free Definite Description Theories” in Lambert 2003a, pp. 69–91.
–––, 2003d, “The Hilbert-Bernays Theory of Definite Descriptions” in Lambert 2003a, pp. 44–68.
–––, 2003e, “Nonextensionality” in Lambert 2003a, pp. 107–121.
–––, 2003f, “The Philosophical Foundations of Free Logic” in Lambert 2003a, pp. 122–175.
–––, 2003g, “Predication and Extensionality” in Lambert 2003a, pp. 92–106.
–––, 2003h, “Russell's Version of the Theory of Definite Descriptions” in Lambert 2003a, pp. 1–15.
Leblanc, Hughes, 1971, “Truth Value Semantics for a Logic of Existence,” Notre Dame Journal of Formal Logic, 12: 153–68.
Leblanc, Hughes and Richmond H. Thomason, 1968, “Completeness Theorems for Some Presupposition-Free Logics,” Fundamenta Mathematicae, 62: 125–64; reprinted in Leblanc's Existence, Truth and Provability, Albany: State University of New York Press, 1982, pp. 22–57.
Leeb, Hans-Peter, 2006, “State-of-Affairs Semantics for Positive Free Logic,” Journal of Philosophical Logic, 35 (2): 183–208.
Lehman, Scott, 1994, “Strict Fregean Free Logic,” Journal of Philosophical Logic, 23 (3): 307–336.
–––, 2001, “No Input, No Output Logic,” in Morscher and Hieke 2001, pp. 147–54.
–––, 2002, “More Free Logic,” in D. Gabbay and F. Guenthner (eds.), Handbook of Philosophical Logic, 2nd edition, vol. 5, Dordrecht: Kluwer, pp. 197–259.
Lejewski, Czeslaw, 1954, “Logic and Existence,” British Journal for the Philosophy of Science, 5 (18): 104–19; reprinted in Dale Jacquette (ed.), Philosophy of Logic: An Anthology, Oxford: Blackwell, 2002, pp. 147–55.
Leonard, H. S., 1956, “The Logic of Existence,” Philosophical Studies, 7: 49–64.
Mehlberg, Henryk, 1958, The Reach of Science, Toronto: University of Toronto Press.
Meyer, Robert K., Ermanno Bencivenga and Karel Lambert, 1982, “The Ineliminability of E! in Free Quantification Theory without Identity,” Journal of Philosophical Logic, 11: 229–231.
Meyer, Robert K. and Karel Lambert, 1968, “Universally Free Logic and Standard Quantification Theory,” Journal of Symbolic Logic, 33: 8–26.
Morscher, Edgar and Alexander Hieke (eds.), 2001, New Essays in Free Logic: In Honour of Karel Lambert (Applied Logic Series, vol., 23), Dordrecht: Kluwer.
Morscher, Edgar and Peter Simons, 2001, “Free Logic: A Fifty-Year Past and an Open Future,” in Morscher and Hieke 2001, pp. 1–34.
Mostowski, Andrezej, 1951, “On the Rules of Proof in the Pure Functional Calculus of the First Order,” Journal of Symbolic Logic, 16: 107–111.
Nolt, John, 2006, “Free Logics,” in Jacquette 2006, pp. 1023–1060.
–––, 2007, “Reference and Perspective in Intuitionistic Logic,” Journal of Logic, Language and Information, 16 (1): 91–115.
Orenstein, Alex, 1990, “Is Existence What Existential Quantification Expresses?” in Robert B. Barrett and Roger F. Gibson (eds.), Perspectives on Quine, Cambridge: Blackwell, 1990, pp. 245–270.
Orlando, Eleonora, 2008, “Names without Fictional Objects (Ficción sin metafísica),” Crítica: Revista Hispanoamericana de Filosofía, 40 (120): 111–127.
Parsons, Terence, 1980, Nonexistent Objects, New Haven: Yale University Press.
Paśniczek, Jacek, 1998, The Logic of Intentional Objects: A Meinongian Version of Classical Logic, Dordrecht: Kluwer.
–––, 2001, “Can Meinongian Logic Be Free?” in Morscher and Hieke 2001, pp. 227–36.
Posy, Carl J., 1982, “A Free IPC is a Natural Logic: Strong Completeness for Some Intuitionistic Free Logics,” Topoi, 1: 30–43; reprinted in Lambert 1991, pp. 49–81.
Priest, Graham, 2005, Towards Non-Being, Oxford: Oxford University Press.
–––, 2008, An Introduction to Non-Classical Logic: From If to Is, 2nd edition, Cambridge: Cambridge University Press.
Quine, W. V. O., 1948, “On What There Is,” Review of Metaphysics, 48: 21–38; reprinted as Chapter 1 of Quine 1963).
–––, 1954, “Quantification and the Empty Domain,” Journal of Symbolic Logic, 19: 177–179.
–––, 1963, From a Logical Point of View, 2nd edition, New York: Harper & Row.
Routley, Richard, 1966, “Some Things Do Not Exist,” Notre Dame Journal of Formal Logic, 7: 251–276.
–––, 1980, Exploring Meinong's Jungle and Beyond, Canberra: Australian National Unversity.
Russell, Bertrand, 1919, Introduction to Mathematical Philosophy, New York: Simon & Schuster.
Sainsbury, R. M., 2005, Reference without Referents, Oxford: Clarendon Press.
Schock, Rolf, 1968, Logics without Existence Assumptions, Stockholm: Almqvist & Wiskell.
Schweitzer, Paul, 2001, “Free Logic and Quantification in Syntactic Modal Contexts,” in Morscher and Hieke 2001, pp. 69–85.
Shapiro, Stewart, and Alan Weir, 2000, “‘Neo-Logicist’ Logic is Not Epistemically Innocent,” Philosophia Mathematica, 3 (8): 160–189.
Simons, Peter, 2001, “Calculi of Names: Free and Modal,” in Morscher, Edgar and Alexander Hieke 2001, pp. 49–65.
Smiley, Timothy, 1960, “Sense without Denotation,” Analysis, 20: 125–135.
van Fraassen, Bas C., 1966, “Singular Terms, Truth Value Gaps and Free Logic,” Journal of Philosophy, 63: 481–95; reprinted in Lambert 1991, pp. 82–97.
Williamson, Timothy, 1999, “A Note on Truth, Satisfaction and the Empty Domain,” Analysis, 59 (1): 3–8.
Woods, John, 2006, “Fictions and their Logic,” in Jacquette 2006, pp. 1061–1126.
Woodruff, Peter W., 1984, “On Supervaluations in Free Logic,” Journal of Symbolic Logic, 49: 943–950.
Academic ToolsIdentity
Much of the debate about identity in recent decades has been about personal identity, and specifically about personal identity over time, but identity generally, and the identity of things of other kinds, have also attracted attention. Various interrelated problems have been at the centre of discussion, but it is fair to say that recent work has focussed particularly on the following areas: the notion of a criterion of identity; the correct analysis of identity over time, and, in particular, the disagreement between advocates of perdurance and advocates of endurance as analyses of identity over time; the notion of identity across possible worlds and the question of its relevance to the correct analysis of de re modal discourse; the notion of contingent identity; the question of whether the identity relation is, or is similar to, the composition relation; and the notion of vague identity. A radical position, advocated by Peter Geach, is that these debates, as usually conducted, are void for lack of a subject matter: the notion of absolute identity they presuppose has no application; there is only relative identity. Another increasingly popular view is the one advocated by Lewis: although the debates make sense they cannot genuinely be debates about identity, since there are no philosophical problems about identity. Identity is an utterly unproblematic notion. What there are, are genuine problems which can be stated using the language of identity. But since these can be restated without the language of identity they are not problems about identity. (For example, it is a puzzle, an aspect of the so-called “problem of personal identity”, whether the same person can have different bodies at different times. But this is just the puzzle whether a person can have different bodies at different times. So since it can be stated without the language of personal “identity”, it is not a problem about identity, but about personhood.) This article provides an overview of the topics indicated above, some assessment of the debates and suggestions for further reading.
To say that things are identical is to say that they are the same. “Identity” and “sameness” mean the same; their meanings are identical. However, they have more than one meaning. A distinction is customarily drawn between qualitative and numerical identity or sameness. Things with qualitative identity share properties, so things can be more or less qualitatively identical. Poodles and Great Danes are qualitatively identical because they share the property of being a dog, and such properties as go along with that, but two poodles will (very likely) have greater qualitative identity. Numerical identity requires absolute, or total, qualitative identity, and can only hold between a thing and itself. Its name implies the controversial view that it is the only identity relation in accordance with which we can properly count (or number) things: x and y are to be properly counted as one just in case they are numerically identical (Geach 1973).
Numerical identity is our topic. As noted, it is at the centre of several philosophical debates, but to many seems in itself wholly unproblematic, for it is just that relation everything has to itself and nothing else – and what could be less problematic than that? Moreover, if the notion is problematic it is difficult to see how the problems could be resolved, since it is difficult to see how a thinker could have the conceptual resources with which to explain the concept of identity whilst lacking that concept itself. The basicness of the notion of identity in our conceptual scheme, and, in particular, the link between identity and quantification has been particularly noted by Quine (1964).
Numerical identity can be characterised, as just done, as the relation everything has to itself and to nothing else. But this is circular, since “nothing else” just means “no numerically non-identical thing”. It can be defined, equally circularly (because quantifying over all equivalence relations including itself), as the smallest equivalence relation (an equivalence relation being one which is reflexive, symmetric and transitive, for example, having the same shape). Other circular definitions are available. Usually it is defined as the equivalence relation (or: the reflexive relation) satisfying Leibniz's Law, the principle of the indiscernibility of identicals, that if x is identical with y then everything true of x is true of y. Intuitively this is right, but only picks out identity uniquely if “what is true of x” is understood to include “being identical with x”; otherwise it is too weak. Circularity is thus not avoided. Nevertheless, Leibniz's Law appears to be crucial to our understanding of identity, and, more particularly, to our understanding of distinctness: we exhibit our commitment to it whenever we infer from “Fa” and “Not-Fb” that a is not identical with b. Strictly, what is being employed in such inferences is the contrapositive of Leibniz's Law (if something true of a is false of b, a is not identical with b), which some (in the context of the discussion of vague identity) have questioned, but it appears as indispensable to our grip on the concept of identity as Leibniz's Law itself.
The converse of Leibniz's Law, the principle of the identity of indiscernibles, that if everything true of x is true of y, x is identical with y, is correspondingly trivial if “what is true of x” is understood to include “being identical with y” (as required if Leibniz's Law is to characterise identity uniquely among equivalence relations). But often it is read with “what is true of x” restricted, e.g., to qualitative, non-relational, properties of x. It then becomes philosophically controversial. Thus it is debated whether a symmetrical universe is possible, e.g., a universe containing two qualitatively indistinguishable spheres and nothing else (Black 1952).
Leibniz's Law has itself been subject to controversy in the sense that the correct explanation of apparent counter-examples has been debated. Leibniz's Law must be clearly distinguished from the substitutivity principle, that if “a” and “b” are codesignators (if “a=b” is a true sentence of English) they are everywhere substitutable salva veritate. This principle is trivially false. “Hesperus” contains eight letters, “Phosphorus” contains ten, but Hesperus (the Evening Star) is Phosphorus (the Morning Star). Again, despite the identity, it is informative to be told that Hesperus is Phosphorus, but not to be told that Hesperus is Hesperus (“On Sense and Reference” in Frege 1969). Giorgione was so-called because of his size, Barbarelli was not, but Giorgione was Barbarelli (Quine, “Reference and Modality”, in 1963) . It is a necessary truth that 9 is greater than 7, it is not a necessary truth that the number of planets is greater than 7, although 9 is the number of planets. The explanation of the failure of the substitutivity principle can differ from case to case. In the first example, it is plausible to say that “‘Hesperus’ contains eight letters” is not about Hesperus, but about the name, and the same is true, mutatis mutandis, of “‘Phosphorus’ contains ten letters”. Thus the names do not have the same referents in the identity statement and the predications. In the Giorgione/Barbarelli example this seems less plausible. Here the correct explanation is plausibly that “is so-called because of his size” expresses different properties depending on the name it is attached to, and so expresses the property of being called “Barbarelli” because of his size when attached to “Barbarelli” and being called “Giorgione” because of his size when attached to “Giorgione”. It is more controversial how to explain the Hesperus/Phosphorus and 9/the number of planets examples. Frege's own explanation of the former was to assimilate it to the “Hesperus”/“Phosphorus” case: in “It is informative to be told that Hesperus is Phosphorus” the names do not stand for their customary referent but for their senses. A Fregean explanation of the 9/number of planets example may also be offered: “it is necessary that” creates a context in which numerical designators stand for senses rather than numbers.
For present purposes the important point to recognise is that, however these counter-examples to the substitutivity principle are explained, they are not counter-examples to Leibniz's Law, which says nothing about substitutivity of codesignators in any language.
The view of identity just put forward (henceforth “the classical view”) characterises it as the equivalence relation which everything has to itself and to nothing else and which satisfies Leibniz's Law. These formal properties ensure that, within any theory expressible by means of a fixed stock of one- or many-place predicates, quantifiers and truth-functional connectives, any two predicates which can be regarded as expressing identity (i.e., any predicates satisfying the two schemata “for all x, Rxx” and “for all x, for all y, Rxy → (Fx → Fy)” for any one-place predicate in place of “F”) will be extensionally equivalent. They do not, however, ensure that any two-place predicate does express identity within a particular theory, for it may simply be that the descriptive resources of the theory are insufficiently rich to distinguish items between which the equivalence relation expressed by the predicate holds (“Identity” in Geach 1972).
Following Geach, call a two-place predicate with these properties in a theory an “I-predicate” in that theory. Relative to another, richer, theory the same predicate, interpreted in the same way, may not be an I-predicate. If so it will not, and did not even in the poorer theory, express identity. For example, “having the same income as” will be an I-predicate in a theory in which persons with the same income are indistinguishable, but not in a richer theory.
Quine (“Identity, Ostension and Hypostasis”in his 1963) has suggested that when a predicate is an I-predicate in a theory only because the language in which the theory is expressed does not allow one to distinguish items between which it holds, one can reinterpret the sentences of the theory so that the I-predicate in the newly interpreted theory does express identity. Every sentence will have just the same truth-conditions under the new interpretation and the old, but the references of its subsentential parts will be different. Thus, Quine suggests, if one has a language in which one speaks of persons and in which persons of the same income are indistinguishable the predicates of the language may be reinterpreted so that the predicate which previously expressed having the same income comes now to express identity. The universe of discourse now consists of income groups, not people. The extensions of the monadic predicates are classes of income groups, and, in general, the extension of an n-place predicate is a class of n-member sequences of income groups (Quine 1963: 65–79). Any two-place predicate expressing an equivalence relation could be an I-predicate relative to some sufficiently impoverished theory, and Quine's suggestion will be applicable to any such predicate if it is applicable at all.
But it remains that it is not guaranteed that a two-place predicate that is an I-predicate in the theory to which it belongs expresses identity. In fact, no condition can be stated in a first-order language for a predicate to express identity, rather than mere indiscernibility by the resources of the language. However, in a second-order language, in which quantification over all properties (not just those for which the language contains predicates) is possible and Leibniz's Law is therefore statable, identity can be uniquely characterised. Identity is thus not first-order, but only second-order definable.
This situation provides the basis for Geach's radical contention that the notion of absolute identity has no application and that there is only relative identity. This section contains a brief discussion of Geach's complex view. (For more details see the entry on relative identity, Deutsch 1997, Dummett 1981 and 1991, Hawthorne 2003 and Noonan 1997.) Geach maintains that since no criterion can be given by which a predicate expressing an I-predicate may be determined to express, not merely indiscernibility relative to the language to which it belongs, but also absolute indiscernibility, we should jettison the classical notion of identity (1991). He dismisses the possibility of defining identity in a second-order language on the ground of the paradoxical nature of unrestricted quantification over properties and aims his fire particularly at Quine's proposal that an I-predicate in a first-order theory may always be interpreted as expressing absolute identity (even if such an interpretation is not required). Geach objects that Quine's suggestion leads to a “Baroque Meinongian ontology” and is inconsistent with Quine's own expressed preference for “desert landscapes” (“Identity” in Geach 1972: 245).
We may usefully state Geach's thesis using the terminology of absolute and relative equivalence relations. Let us say that an equivalence relation R is absolute if and only if, if x stands in it to y, there cannot be some other equivalence relation S, holding between anything and either x or y, but not holding between x and y. If an equivalence relation is not absolute it is relative. Classical identity is an absolute equivalence relation. Geach's main contention is that any expression for an absolute equivalence relation in any possible language will have the null class as its extension, and so there can be no expression for classical identity in any possible language. This is the thesis he argues against Quine.
Geach also maintains the sortal relativity of identity statements, that “x is the same A as y” does not “split up” into “x is an A and y is an A and x=y”. More precisely stated, what Geach denies is that whenever a term “A” is interpretable as a sortal term in a language L (a term which makes (independent) sense following “the same”) the expression (interpretable as) “x is the same A as y” in language L will be satisfied by a pair <x,y> only if the I-predicate of L is satisfied by <x,y>. Geach's thesis of the sortal relativity of identity thus neither entails nor is entailed by his thesis of the inexpressibility of identity. It is the sortal relativity thesis that is the central issue between Geach and Wiggins (1967 and 1980). It entails that a relation expressible in the form “x is the same A as y” in a language L, where “A” is a sortal term in L, need not entail indiscernibility even by the resources of L.
Geach's argument against Quine exists in two versions, an earlier and a later.
In its earlier version the argument is merely that following Quine's suggestion to interpret a language in which some expression is an I-predicate so that the I-predicate expresses classical identity sins against a highly intuitive methodological programme enunciated by Quine himself, namely that as our knowledge expands we should unhesitatingly expand our ideology, our stock of predicables, but should be much more wary about altering our ontology, the interpretation of our bound name variables (1972: 243).
Geach's argument is that in view of the mere possibility of carving out of a language L, in which the relational expressions, E1, E2, E3… are not I-predicates, sub-languages L1, L2, L3… in which these expressions are I-predicates, if Quine's suggested proposal of reinterpretation is possible for each Ln, the user of L will be committed to any number of entities not quantified over in L, namely, for each Ln, those entities for which the I-predicate of Ln (En) gives a criterion of absolute identity. This will be so because any sentence of L will retain its truth conditions in any Ln to which it belongs, reinterpreted as Quine proposes, but “of course, it is flatly inconsistent to say that as a member of a large theory a sentence retains its truth-conditions but not its ontological commitment” (1973:299).
The crucial premiss of this argument is thus that sameness of truth-conditions entails sameness of ontological commitment. But this is not true. The ontological commitments of a theory (according to Quine, whose notion this is) are those entities that must lie within the domain of quantification of the theory if the theory is to be true; or, the entities the predicates of the theory have to be true of if the theory is to be true. A theory is not ontologically committed, we may say, to whatever has to be in the universe for it to be true, but only to whatever has to be in its universe for it to be true. Thus there is no argument from sameness of truth-conditions to sameness of ontological commitments.
The later version of Geach's argument needs a different response. The difference between the earlier version and the later one is that in the later (to be found in Geach 1973) Geach's claim is not merely that Quine's thesis about possible reinterpretation has a consequence which is unpalatable, but that it leads to an out-and-out logical absurdity, the existence of what he calls “absolute surmen” (entities for which having the same surname constitutes a criterion of absolute identity, ie., entails indiscernibility in all respects). Because Geach is now making this stronger claim, the objection that his argument depends upon the incorrect assumption that sameness of truth-conditions entails sameness of ontological commitment is no longer relevant. In order to make out his case Geach has to establish just two points. First, that there are sentences of English supplemented by the predicate “is the same surman as” (explained to mean “is a man and has the same surname as”), which are evidently true and which, considered as sentences of that fragment of English in which “is the same surman as” is an I-predicate, when this is interpreted in the way Quine suggests, can be true only if absolute surmen exist. And secondly, that the existence of absolute surmen is absurd.
But in the end Geach fails to establish these two points. Quine would say that, for the fragment of English in question, the domain of the variables can be considered to consist of classes of men with the same surname and the predicates interpreted as holding of such classes. Thus, the predicate “is the same surman as” will no longer be true of pairs of men if we adopt Quine's suggestion (I am writing, remember in English, not in the fragment of English under discussion), but rather of pairs of classes of men with the same surname – these then will be Geach's “absolute surmen”. Now, Geach attempts to rule this out by the argument that “whatever is a surman is by definition a man.” But this argument fails. The predicate “is a man” will also be in the language-fragment in which “is the same surman as” is the I-predicate; and so it, too, will, be reinterpreted, if we follow Quine's suggestion, as holding of classes of men with the same surname. Thus the sentence “Whatever is a surman is a man” will be true in the language fragment interpreted in Quine's way, just as it is in English as a whole. What will not be true, however, is that whatever the predicate “is a surman” is true of, as it occurs in the language-fragment reinterpreted in Quine's way, is a thing of which “is a man”, as it occurs in English as a whole, is true of. But Geach has no right to demand that this should be the case. Even so, this demand can be met. For the domain of the interpretation of the language fragment in which “is the same surman as” is the I-predicate can, in fact, be taken to consist of men, namely, to be a class containing exactly one representative man for each class of men with the same surname. Thus, as Geach says, absolute surmen will be just some among men (1973:100). Geach goes on, “there will, for example, be just one surman with the surname “Jones”, but if this is an absolute surman, and he is a certain man, then which of the Jones boys is he?” But this question, which is, of course, only answerable using predicates which belong to the part of English not included in the language fragment in which “is the same surman as” is the I-predicate, is not an impossible one to answer. It is merely that the answer will depend upon the particular interpretation that the language fragment has, in fact, been given. Geach is, therefore not entitled to go on, “Surely we have run into an absurdity.” It thus seems that his argument for the non-existence of absolute identity fails.
Geach's argument for his second thesis, that of the sortal relativity of identity, is that it provides the best solution to a variety of well known puzzles about identity and counting at a time and over time. The most well known puzzle is that of the cat on the mat, which comes in two versions.
The first version goes like this. (Wiggins 1968 contains the first appearance of this version in present-day philosophical literature; an equivalent puzzle is that of Dion and Theon, see Burke 1995). Suppose a cat, Tibbles, is sitting on a mat. Now consider that portion of Tibbles that includes everything except its tail – its “tail complement” – and call it “Tib”. Tib is smaller than Tibbles so they are not identical. But what if we now amputate the cat's tail? (A time-reversed, or “growing”, version can be considered in which a tail is grafted on to a tailless cat; the same responses considered below will be available, but may differ in relative plausibility.) Tibbles and Tib will now coincide. If Tibbles is still a cat, it is hard to see by what criterion one could deny that Tib is a cat. Yet they are distinct individuals, since they have different histories. But there is just one cat on the mat. So they cannot be distinct cats. They must be the same cat, even though they are distinct individuals; and so identity under the sortal concept cat must be a relative identity relation.
The second version (presented in Geach 1980, compare Unger 1980) goes as follows. Tibbles is sitting on the mat and is the only cat sitting on the mat. But Tibbles has at least 1,000 hairs. Geach continues: “Now let c be the largest continuous mass of feline tissue on the mat. Then for any of our 1,000 hairs, say hn, there is a proper part cn of c which contains precisely all of c except that hair hn; and every such part cn differs in a describable way both from any other such part say cm, and from c as a whole. Moreover, fuzzy as the concept cat may be, it is clear that not only is c a cat, but also any part cn is a cat: cn would clearly be a cat were the hair hn to be plucked out, and we cannot reasonably suppose that plucking out a hair generates a cat, so cn must already have been a cat.”
The conclusion, of course, is the same as in the previous version of the argument: there is only one cat on the mat so all the distinct entities that qualify as cats must be the same cat.
This version of the argument can be resisted by insisting that the concept of a cat is maximal, i.e. no proper part of a cat is a cat. The first version may be resisted in a variety of ways. Some deny the existence of the tail-complement at all (van Inwagen 1981, Olson 1995); others deny that the tail-complement survives the amputation (Burke 1995). Another possibility is to say that certain of the historical and/or modal predicates possessed by Tibbles and not Tib are essential to being a cat, so that Tib is not (predicatively) a cat (Wiggins 1980). Again, it can be accepted that both Tib and Tibbles are cats, but deny that in counting them as one we are counting by identity (even cat identity), rather, we are counting by “almost identity” (Lewis 1993). Another possibility is to accept that both Tib and Tibbles are cats, but deny that they are distinct: rather “Tib” and “Tibbles” are two names of the same cat-stage (Hawley 2001, Sider 2001).
There is, then, no very compelling argument for Geach's sortal relativity thesis to be based on such examples, given the variety of responses available, some of which will be returned to below. On the other hand, no alternative solution to the puzzle of the cat on the mat stands out as clearly superior to the rest, or clearly superior to the sortal relativity thesis as a solution. We should conclude that this component of Geach's position, though not proven, is not refuted either; and, possibly that the linguistic data provide no basis for a decision for or against.
4. Criteria of identity
A notion that Geach deploys extensively, and which is also in common use by his opponents, is that of a criterion of identity, a standard by which identity is to be judged. This section will attempt to untangle some of the complexities this notion involves.
The notion of a criterion of identity was introduced into philosophical terminology by Frege (1950) and strongly emphasised by Wittgenstein (1958). Exactly how it is to be interpreted and the extent of its applicability are still matters of debate.
A considerable obstacle to understanding contemporary philosophical usage of the term, however, is that the notion does not seem to be a unitary one. In the case of abstract objects (the case discussed by Frege) the criterion of identity for Fs is thought of as an equivalence relation holding between objects distinct from Fs. Thus the criterion of identity for directions is parallelism of lines, that is, the direction of line a is identical with the direction of line b if and only if line a is parallel to line b. The criterion of identity for numbers is equinumerosity of concepts, that is, the number of Fs is identical with the number of Gs if and only if there are exactly as many Fs as Gs. The relation between the criterion of identity for Fs and the criterion of application for the concept F (the standard for the application of the concept to an individual) is then that to be an F is just to be something for which questions of identity and distinctness are to settled by appeal to the criterion of identity for Fs. (Thus, when Frege went on to give an explicit definition of numbers as extensions of concepts he appealed to it only to deduce what has come to be called Hume's principle – his statement of his criterion of identity for numbers in terms of equinumerosity of concepts, and emphasised that he regarded the appeal to extensions as inessential.) In the case of concrete objects, however, things seem to stand differently. Often the criterion of identity for a concrete object of type F is said to be a relation R such that for any Fs, x and y, x=y if and only if Rxy. In this case the criterion of identity for Fs is not stated as a relation between entities distinct from Fs and the criterion of identity cannot plausibly be thought of as determining the criterion of application. Another example of the lack of uniformity in the case of the notion of a criterion of idenity in contemporary philosophy is, in the case of concrete objects, a distinction customarily made between a criterion of diachronic identity and a criterion of synchronic identity; the former taking the form “x is at t the same F as y is at t′ if and only if…”, where what fills the gap is some statement of a relation holding between objects x and y and times t and t′. (In the case of persons, for example, a candidate criterion of diachronic identity is: x is at t the same person as y is at t′ if and only if x at t is psychologically continuous with y at t′.) A criterion of synchronic identity, by contrast, will typically specify how the parts of an F-thing existing at a time must be related, or how one F at a time is marked off from another.
One way of bringing system into the discussion of criteria of identity is to make use of the distinction between one-level and two-level criteria of identity (Williamson 1990). The Fregean criteria of identity for directions and numbers are two-level. The objects for which the criterion is given are distinct from, and can be pictured as at a higher level than, the objects between which the relation specified holds. On the other hand, the criterion of identity for sets given by the Axiom of Extensionality (sets are the same if they have the same members) and Davidson's criterion of event identity (events are the same if they have the same causes and effects) (“The Individuation of Events” in his 1980) are one-level: the objects for which the criterion of identity is stated are the same as those between which the criterial relation obtains. Not all criteria of identity can be two-level (on pain of infinite regress), and it is tempting to think that the distinction between objects for which a two-level criterion is appropriate and those for which a one-level criterion is appropriate coincides with that between abstract and concrete objects. However, a more general application of the two-level notion is possible. In fact, it can be applied to any type of object K, such that the criterion of identity for Ks can be thought of as an equivalence relation between a distinct type of object, K*s, but some such objects may intuitively be regarded as concrete.
How general this makes its application is a matter of controversy. In particular, if persisting things are thought of as composed of (instantaneous) temporal parts (see discussion below), the problem of supplying a diachronic criterion of identity for concrete objects can be regarded as the problem of providing a two-level criterion. But if persisting things are not thought of in this way then not all persisting things can be provided with two-level criteria. (Though some can. For example, it is quite plausible that the criterion of identity over time for persons should be thought of as given by a relation between bodies.)
Any two-level criterion can be restated in a one-level form (though, of course, not conversely). For example, to say that the direction of line a is identical with the direction of line b if and only if line a is parallel to line b is to say that directions are the same if and only if the lines they are of are parallel, which is the form of a one-level criterion. A way of unifying the various different ways of talking of criteria of identity is thus to take as the paradigmatic form of a statement of a criterion of identity a statement of the form: for any x, for any y, if x is an F and y is an F then x=y if and only if Rxy (Lowe 1989, 1997).
If the notion is interpreted in this way then the relation between the criterion of identity and the criterion of application will be that of one-way determination. The criterion of identity will be determined by, but not determine, the criterion of application.
For, in general, a one-level criterion of identity for Fs will be equivalent to a conjunction of a statement of necessary, and a statement of sufficient, conditions.
A statement of necessary conditions will take the form:
(1) for any x, for any y, if x is an F and y is an F then x=y only if Rxy,
which is equivalent to:
(2) for any x, if x is an F then Rxx.
But (2), of course, says nothing about F-identity; rather it simply specifies a necessary condition of being an F. So, therefore, does (1). Once the criterion of application for the concept of an F is specified (i.e. the necessary and sufficient conditions for its application), there is no need for any further specification of F-identity in a statement of form (1).
What of sufficient conditions of F-identity?
A specification of a sufficient condition, corresponding to a one-level criterion of F-identity, would presumably have to take the form:
(3) for any x, for any y, if x is an F and y is an F then x=y if Rxy.
This is equivalent to:
(4) for any x and y, if Rxy and it is not the case that x=y then (x is not an F or y is not an F).
(4), which denies the existence of distinct R-related Fs, cannot be represented as specifying either a necessary or a sufficient condition of Fness in identity-free terms. But what (4) does do is to specify a necessary condition on a concept being the concept of an F. In this respect it is like the proposition “there is at most one divine being” (i.e., there are no distinct, coexistent, divine beings), which specifies a condition any concept has to satisfy to be that of a divine being.
However, a specification of the necessary and sufficient conditions of divinity, together with the facts, will determine the truth-value of “there is at most one divine being”.
The same is true, mutatis mutandis, of the concept of an F and assertions of form (4). Once the necessary and sufficient conditions of being an F have been laid down, no further stipulation is required to determine which assertions of form (4) are true. In short, specifying the necessary and sufficient conditions of being an F leaves no more room for further specification of the sufficient conditions of F-identity than it does for further specification of necessary conditions of F-identity.
This conclusion is, of course, in agreement with Lewis's view that there are no genuine problems about identity as such (Lewis 1986, Ch. 4), but it is in tension with the thought that sortal concepts, as distinct from adjectival concepts, are to be characterised by their involvement of criteria of identity as well as criteria of application.
A conception of identity criteria which allows this characterisation of the notion of a sortal concept, and which has so far not been mentioned, is that of Dummett (1981). Dummett denies that a criterion of identity must always be regarded as a criterion of identity for a type of object. There is a basic level, he suggests, at which what a criterion of identity is a criterion of, is the truth of a statement in which no objects are referred to. Such a statement can be expressed using demonstratives and pointing gestures, for instance, by saying “This is the same cat as that”, pointing first to a head and then a tail. In such a statement, which he calls a statement of identification, in Dummett's view, there need be no reference to objects made by the use of the demonstratives, any more than reference is made to any object in a feature-placing sentence like “It's hot here”. A statement of identification is merely, as it were, a feature-placing relational statement, like “This is darker than that”. A grasp of a sortal concept F involves both grasp of the truth-conditions of such statements of identification involving “F” and also grasp of the truth-conditions of what Dummett calls “crude predications” involving “F”, statements of the form “this is F”, in which the demonstrative again does not serve to refer to any object. Adjectival terms, which have only a criterion of application and no criterion of identity, are ones which have a use in such crude predications, but no use in statements of identification. Sortal terms, as just noted, have a use in both contexts, and sortal terms may share their criteria of application but differ in their criteria of identity since grasp of the truth-conditions of the crude predication “This is F” does not determine grasp of the truth-conditions of the statement of identification “This is the same F as that” (thus I can know when it is right to say “This is a book” without knowing when it is right to say “This is the same book as that”).
On Dummett's account, then, it may be possible to accept that whenever a criterion of identity for a type of object is to be given it must be (expressible as) a two-level criterion. Essentially one-level criteria (one-level criteria not expressible in a two-level form) are redundant, replaceable by (what we might call) Dummettian zero-level criteria.
Criteria of identity can be employed synchronically, as in the examples just given, to determine whether two coexistent objects are parts of the same object of a kind, or diachronically, to determine identity over time. Identity over time is a controversial notion, however, because time involves change. Heraclitus argued that one could not bathe in the same river twice because new waters were ever flowing in. Hume argued that identity over time was a fiction we substitute for a collection of related objects. Such views can be seen as based on a misunderstanding of Leibniz's Law: if a thing changes something is true of it at the later time that is not true of it at the earlier, so it is not the same. The answer is that what is true of it at the later time is, say, “being muddy at the later time”, which was always true of it; similarly, what is true of it at the earlier time, suitably expressed, remains true of it. But the question remains how to characterise identity through time and across change given that there is such a thing.
One topic which has always loomed large in this debate has been the issue (in the terminology of Lewis 1986, Ch. 4) of perdurance versus endurance. (Others, for which there is no space for discussion here, include the debate over Ship of Theseus and reduplication or fission problems and associated issues about “best candidate” or “no rival candidate” accounts of identity over time, and the debate over Humean supervenience – see articles on relative identity, personal identity, Hawley 2001 and Sider 2001.)
According to one view, material objects persist by having temporal parts or stages, which exist at different times and are to be distinguished by the times at which they exist – this is known as the view that material objects perdure. Other philosophers deny that this is so; according to them, when a material object exists at different times, it is wholly present at those times, for it has no temporal parts, but only spatial parts, which likewise are wholly present at the different times they exist. This is known as the view that material objects endure.
Perdurance theorists, as Quine puts it, reject the point of view inherent in the tenses of our natural language. From that point of view persisting things endure and change through time, but do not extend through time, but only through space. Thus persisting things are to be sharply distinguished from events or processes, which precisely do extend through time. One way of describing the position of the perdurance theorist, then, is to say that he denies the existence of a distinct ontological category of persisting things, or substances. Thus, Quine writes, “physical objects, conceived thus four-dimensionally in space-time, are not to be distinguished from events, or, in the concrete sense of the term, processes. Each comprises simply the content, however heterogeneous, of some portion of space-time, however disconnected or gerrymandered” (1960:171).
In recent controversy two arguments have been at the centre of the endurance/perdurance debate, one employed by perdurance theorists and the other by endurance theorists (for other arguments and issues see the separate article on temporal parts, Hawley 2001 and Sider 2001).
An argument for perdurance which has been hotly debated is due to David Lewis (1986). If perdurance is rejected, the ascription of dated or tensed properties to objects must be regarded as assertions of irreducible relations between objects and times. If Tabby is fat on Monday, that is a relation between Tabby and Monday, and if perdurance is rejected it is an irreducible relation between Tabby and Monday. According to perdurance theory, however, while it is still, of course, a relation between Tabby and Monday it is not irrreducible; it holds between Tabby and Monday because the temporal part of Tabby on Monday, Tabby-on-Monday, is intrinsically fat. If perdurance is rejected, however, no such intrinsic possessor of the property of fatness can be recognised: Tabby's fatness on Monday must be regarded as an irreducible state of affairs.
According to Lewis, this consequence of the rejection of the perdurance theory is incredible. Whether he is right about this is the subject of intense debate (Haslanger 2003).
Even if Lewis is right, however, the perdurance theory may still be found wanting, since it does not secure the most commonsensical position: that fatness is a property of a cat (Haslanger 2003). According to perdurance theory, rather, it is a property of a (temporal) cat part. Those known as stage theorists (Hawley 2001, Sider 2001), accepting the ontology of perdurance theory, but modifying its semantics, offer a way to secure this desirable result. Every temporal part of a cat is a cat, they say, so Tabby-on-Monday (which is what we refer to by “Tabby”, on Monday) is a cat and is fat, just as we would like. Stage theorists have to pay a price for this advantage over perdurance theory, however. For they must accept either that our reports of the cross-temporal number of cats are not always reports of the counting of cats (as when I say, truly, that I have only ever owned three cats) or that two cat-stages (cats) may be counted as one and the same cat, so that counting cats is not always counting in accordance with absolute identity.
An argument against the perdurance theory that has been the focus of interest is one presented in various guises by a number of writers, including Wiggins (1980), Thomson (1983) and van Inwagen (1990). Applied to persons (it can equally well be applied to other persisting things), it asserts that persons have different properties, in particular, different modal properties, from the summations of person-stages with which the perdurance theory identifies them. Thus, by Leibniz's Law, this identification must be mistaken. As David Wiggins states the argument: “Anything that is part of a Lesniewskian sum [a mereological whole defined by its parts] is necessarily part of it…But no person or normal material object is necessarily in the total state that will correspond to the person- or object-moment postulated by the theory under discussion” (1980: 168).
To elaborate a little. I might have died when I was five years old. But that maximal summation of person-stages which, according to perdurance theory, is me and has a temporal extent of at least fifty years, could not have had a temporal extent of a mere five years. So I cannot be such a summation of stages.
This argument illustrates the interdependence of the various topics discussed under the rubric of identity. Whether it is valid, of course, depends on the correct analysis of modal predication, and, in particular, on whether it should be analysed in terms of “identity across possible worlds” or in terms of Lewisean counterpart theory. This is the topic to which we next turn.
In the interpretation of modal discourse recourse is often made to the idea of “identity across possible worlds”. If modal discourse is interpreted in this way it becomes natural to regard a statement ascribing a modal property to an individual as asserting the identity of that individual across worlds: “John might have been a millionaire”, on this view, asserts that there is a possible world in which an individual identical with John is a millionaire. “John could not have been a millionaire” asserts that in any world in which an individual identical with John exists that individual is not a millionaire.
However, though this is perhaps the most natural way to interpret de re modal statements (once it has been accepted that the apparatus of possible worlds is to be used as an interpretative tool), there are well-known difficulties that make the approach problematic.
For example, it seems reasonable to suppose that a complex artefact like a bicycle could have been made of different parts. On the other hand, it does not seem right that the same bicycle could have been constructed out of completely different parts.
But now consider a series of possible worlds, beginning with the actual world, each containing a bicycle just slightly different from the one in the previous world, the last world in the sequence being one in which there is a bicycle composed of completely different parts from the one in the actual world. One cannot say that each bicycle is identical with the one in the neighbouring world, but not identical with the corresponding bicycle in distant worlds, since identity is transitive. Hence it seems one must either adopt an extreme mereological essentialism, according to which no difference of parts is possible for an individual, or reject the interpretation of de re modal discourse as asserting identity across possible worlds.
This and other problems with cross-world identity suggest that some other weaker relation, of similarity or what David Lewis calls counterparthood, should be employed in a possible world analysis of modal discourse. Since similarity is not transitive this allows us to say that the bicycle might have had some different parts without having to say that it might have been wholly different. On the other hand, such a substitution does not seem unproblematic, for a claim about what I might have done hardly seems, at first sight, to be correctly interpretable as a claim about what someone else (however similar to me) does in another possible world (Kripke 1980, note 13).
An assessment of the counterpart theoretic analysis is vital not just to understanding modal discourse, however, but also to getting to the correct account of identity over time. For, as we have just seen, the argument against perdurance theory outlined at the end of the last section depends on the correct interpretation of modal discourse. In fact, it is invalid on a counterpart theoretic analysis which allows different counterpart relations (different similarity relations) to be invoked according to the sense of the singular term which is the subject of the de re modal predication (Lewis 1986, Ch. 4), since the counterpart relation relevant to the assessment of a de re modal predication with a singular term whose sense determines that it refers to a person will be different from that relevant to the assessment of a de re modal predication with a singular term whose sense determines that it refers to a sum of person-stages. “I might have existed for only five years” means on the Lewisean account “There is a person in some possible world similar to me in those respects important to personhood who exists for only five years”; “The maximal summation of person stages of which this current stage is a stage might have existed for only five years” means “There is a summation of person stages similar to this one in those respects important to the status of an entity as a summation of stages which exists for only five years”. Since the two similarity relations in question are distinct the first modal statement may be true and the second false even if I am identical with the sum of stages in question.
Counterpart theory is also significant to the topic of identity over time in another way, since it provides the analogy to which the stage theorist (who regards all everyday reference as reference to momentary stages rather than to perdurers) appeals to explain de re temporal predication. Thus, according to the stage theorist, just as “I might have been fat” does not require the existence of a possible world in which an object identical with me is fat, but only the existence of a world in which a (modal) counterpart of me is fat, so “I used to be fat” does not require the existence of a past time at which someone identical with (the present momentary stage which is) me was fat, but only the existence of a past time at which a (temporal) counterpart of me was fat. The problem of identity over time for things of a kind, for stage theorists, is just the problem of characterizing the appropriate temporal counterpart relation for things of that kind.
For a more detailed discussion of the topic, see the entry transworld identity. Whether de re modal discourse is to be interpreted in terms of identity across possible worlds or counterpart theoretically (or in some other way entirely) is also relevant to our next topic, that of contingent identity.
Before Kripke's writings (1980), it seemed a platitude that statements of identity could be contingent – when they contained two terms differing in sense but identical in reference and so were not analytic. Kripke challenged this platitude, though, of course, he did not reject the possibility of contingent statements of identity. But he argued that when the terms flanking the sign of identity were what he called rigid designators, an identity statement, if true at all, had to be necessarily true, but need not be knowable a priori, as an analytic truth would be. Connectedly, Kripke argued that identity and distinctness were themselves necessary relations: if an object is identical with itself it is necessarily so, and if it is distinct from another it is necessarily so.
Kripke's arguments were very persuasive, but there are examples that suggest that his conclusion is too sweeping – that even identity statements containing rigid designators can be, in a sense, contingent. The debate over contingent identity is concerned with the assessment and proper analysis of these examples.
One of the earliest examples is provided by Gibbard (1975). Consider a statue, Goliath, and the clay, Lumpl, from which it is composed. Imagine that Lumpl and Goliath coincide in their spatiotemporal extent. It is tempting to conclude that they are identical. But they might not have been. Goliath might have been rolled into a ball and destroyed; Lumpl would have continued to exist. The two would have been distinct. Thus it seems that the identity of Lumpl and Goliath, if admitted, must be acknowledged as merely contingent.
One reaction to this argument available to the convinced Kripkean is simply to deny that Lumpl and Goliath are identical. But to accept this is to accept that purely material entities, like statues and lumps of clay, of admittedly identical material constitution at all times, may nonetheless be distinct, though distinguished only by modal, dispositional or counterfactual properties. To many, however, this seems highly implausible, which provides the strength of the argument for contingent identity.
David Lewis (in “Counterparts of Persons and their Bodies” in his 1983) suggests that the identity of a person with his body (assuming the person and the body, like Goliath and Lumpl, are at all times coincident) is contingent, since bodily interchange is a possibility. He appeals to counterpart theory, modified to allow a variety of counterpart relations, to explain this. Contingent identity then makes sense, since “I and my body might not have been identical” now translates into counterpart theory as “There is a possible world, w, a unique personal counterpart x in w of me and a unique bodily counterpart y in w of my body, such that x and y are not identical”.
What is crucial to making sense of contingent identity is an acceptance that modal predicates are inconstant in denotation (that is, stand for different properties when attached to different singular terms or different quantifying expressions). Counterpart theory provides one way of explaining this inconstancy, but is not necessarily the only way (Gibbard 1975, Noonan 1991, 1993). However, whether the examples of contingent identity in the literature are persuasive enough to make it reasonable to accept the certainly initially surprising idea that modal predications are inconstant in denotation is still a matter of considerable controversy.
Finally, in this section, it is worth noting explicitly the interdependence of the topics under discussion: only if the possibility of contingent identity is secured, by counterpart theory or some other account of de re modality which does not straightforwardly analyse de re modal predication in terms of identity across possible worlds, can perdurance theory (or stage theory) as an account of identity across time be sustained against the modal arguments of Wiggins, Thomson and van Inwagen.
A thesis that has a long pedigree but has only recently been gathering attention in the contemporary literature is the “Composition as Identity” thesis. The thesis comes in a weak and a strong form. In its weak form the thesis is that the mereological composition relation is analogous in a number of important ways to the identity relation and so deserves to be called a kind of identity. In its strong form the thesis is that the composition relation is strictly identical with the identity relation, viz. that the parts of a whole are literally (collectively) identical with the whole itself. The strong thesis was considered by Plato in Parmenides and versions of the thesis have been discussed by many historical figures since (Harte 2002, Normore and Brown 2014). The progenitor of the modern version of the thesis is Baxter (1988a, 1988b, 2001) but it is most often discussed under the formulation of it given by Lewis (1991), who first considers the strong thesis before rejecting it in favour of the weak thesis.
Both the strong and the weak versions of the thesis are motivated by the fact that there is an especially intimate relation between a whole and its parts (a whole is “nothing over and above” its parts), buttressed by claims that identity and composition are alike in various ways. Lewis (1991: 85) makes five likeness claims:
Ontological Innocence. If one believes that some object x exists, one does not gain a commitment to a further object by believing that something identical with x exists. Likewise, if one believes that some objects x1, x2, …, xn exist, one does not gain a commitment to a further object by claiming that something composed of x1, x2, …, xn exists.
Automatic Existence. If some object x exists, then it automatically follows that something identical with x exists. Likewise, if some objects x1, x2, …, xn exist, then it automatically follows that something composed of x1, x2, …, xn exists.
Unique Composition. If something y is identical with x, then anything identical with x is identical with y, and anything identical with y is identical with x. Likewise, if some things y1, y2, …, yn compose x, then any things that compose x are identical with y1, y2, …, yn, and anything identical with x is composed of y1, y2, …, yn.
Exhaustive Description. If y is identical with x, then an exhaustive description of y is an exhaustive description of x, and vice versa. Likewise, if y1, y2, …, yn compose x, then an exhaustive description of y1, y2, …, yn is an exhaustive description of x, and vice versa.
Same Location. If y is identical with x, then necessarily, x and y fill the same region of spacetime. Likewise, if y1, y2, …, yn compose x, then necessarily, y1, y2, …, yn and x fill the same region of spacetime.
Clearly not all will agree with each of Lewis's likeness claims. Anyone who denies unrestricted mereological composition, for example, will deny 2. And the defender of strong pluralism in the material constitution debate (i.e. one who defends the view that there can be all-time coincident entities) will deny 3. And some endurantists who think that ordinary material objects can have distinct parts at distinct times will deny 5. But there is a more general problem with 1, as van Inwagen has made clear (1994: 213). Consider a world w1 that contains just two simples s1 and s2. Now consider the difference between someone p1 who believes that s1 and s2 compose something and someone p2 who does not. Ask: how many objects do p1 and p2 believe there to be in w1? The answer, it seems, is that p1 believes that there are three things and p2 only two. So how can a commitment to the existence of fusions be ontologically innocent? One recent suggestion is that although a commitment to the existence of fusions is not ontologically innocent, it almost is: to commit oneself to fusions is to commit oneself to further entities, but because they are not fundamental entities they are not ones that matter for the purpose of theory choice (Cameron 2014, Schaffer 2008, Williams 2010, and see also Hawley 2014).
If one believes Lewis's likeness claims one will be tempted by at least the weak Composition as Identity thesis. If composition is a type of identity this gives some kind of explanation of why the parallels between the two hold. But the strong thesis, that the composition relation is the identity relation, gives a fuller explanation. So why not hold the strong thesis? Because, many think, there are additional challenges that face anyone who wishes to defend the strong thesis.
The classical identity relation is one that can only have single objects as relata (as in: “George Orwell = Eric Blair”). If we adopt a language that allows the formation of plural terms we can unproblematically define a plural identity relation that holds between pluralities of objects too. Plural identity statements such as “the hunters are identical with the gatherers” are understood to mean that for all x, x is one of the hunters iff x is one of the gatherers. But, according to the strong Composition as Identity thesis, there can also be true hybrid identity statements that relate pluralities and single objects. That is, sentences such as “the bricks = the wall” are taken by the defender of strong Composition as Identity to be well-formed sentences that express strict identities.
The first challenge facing the defender of the strong thesis is the least troublesome. It is the syntactic problem that hybrid identity statements are ungrammatical in English (Van Inwagen, 1994: 211). Whilst “George Orwell is identical with Eric Blair” and “the hunters are identical with the gatherers” are well-formed, it seems that “the bricks are identical with the wall” is not. However, there is in fact some doubt about whether hybrid identity statements are ungrammatical in English, and some have pointed out that this is anyway a mere grammatical artefact of English that is not present in other languages (e.g. Norwegian and Hungarian). So it seems that the most this challenge calls for is a mild form of grammatical revisionism. And we have, at any rate, formal languages that allow hybrid constructions to be made in which to express the claims made by the defender of the strong Composition as Identity thesis. (Sider 2007, Cotnoir 2013) (NB The claims regarding Norwegian and Hungarian are to be found in these two papers.)
The second challenge is more troublesome. It is the semantic problem of providing coherent truth-conditions for hybrid identity statements. The standard way to provide the truth-conditions for the classical identity relation is to say that an identity statement of the form “a=b” is true iff “a” and “b” have the same referents. But this account clearly does not work for hybrid identity statements, for there is no (single) referent for a plural term. Moreover, the standard way of giving the truth-conditions for plural identity statements (mentioned above) does not work for hybrid identity statements either. To say that “x is one of the ys” is to say that x is (classically) identical with one of the things in the plurality, i.e., that x is identical with y1, or identical with y2… or identical with yn. But then “the bricks = the wall” is true only if the wall is (classically) identical with one of the bricks, i.e. with b1, or with b2… or with bn, which it isn't.
The third challenge is the most troublesome of all. In section 2 it was noted that Leibniz's Law (and its contrapositive) appear to be crucial to our understanding of identity and distinctness. But it seems that the defender of strong Composition as Identity must deny this. After all, the bricks are many, but the wall is one. The onus is thus on the defender of strong Composition as Identity to explain why we should think the “are” in hybrid identity statements really expresses the relation of identity.
The second and the third challenges have been thought by many to be insurmountable (Lewis, for example, rejects strong Composition as Identity on the basis of them). But, in recent semantic work in this area, accounts have emerged that promise to answer both challenges. (Wallace 2011a, 2011b, Cotnoir 2013). Whether they do so, however, remains to be seen.
9. Vague identity
Like the impossibility of contingent identity, the impossibility of vague identity appears to be a straightforward consequence of the classical concept of identity (Evans 1978, see also Salmon 1982). For if a is only vaguely identical with b, something is true of it – that it is only vaguely identical with b – that is not true of b, so, by Leibniz's Law, it is not identical with b at all. Of course, there are vague statements of identity – “Princeton is Princeton Borough” (Lewis 1988) – but the conclusion appears to follow that such vagueness is only possible when one or both of the terms flanking the sign of identity is an imprecise designator. Relatedly, it appears to follow that identity itself must be a determinate relation.
But some examples suggest that this conclusion is too sweeping – that even identity statements containing precise designators may be, in some sense, indeterminate. Consider Everest and some precisely defined hunk of rock, ice and snow, Rock, of which it is indeterminate whether its boundaries coincide with those of Everest. It is tempting to think that “Everest” and “Rock” are both precise designators (if “Everest” is not, is anything? (Tye 2000)) and that “Everest is Rock” is nonetheless in some sense indeterminate.
Those who take this view have to respond to Evans's original argument, about which there has been intense debate (see separate article on vagueness, Edgington 2000, Lewis 1988, Parsons 2000, van Inwagen 1990, Williamson 2002 and 2003), but also to more recent variants. There is no space to go into these matters here, but one particular variant of the Evans argument worth briefly noting is given by Hawley (2001). Alpha and Omega are (two?) people, the first of whom steps into van Inwagen's (1990) fiendish cabinet which disrupts whatever features are relevant to personal identity, and the second of whom then steps out:
(1) It is indeterminate whether Alpha steps out of the cabinet
(2) Alpha is such that it is indeterminate whether she steps out of the cabinet
(3) It is not indeterminate whether Omega steps out of the cabinet
(4) Omega is not such that it is indeterminate whether she steps out of the cabinet
(5) Alpha is not identical to Omega.
This argument differs from the standard version of Evans's argument by not depending upon identity-involving properties (e.g. being such that it is indeterminate whether she is Omega) to establish distinctness, and this removes some sources of controversy. Others, of course, remain.
The debate over vague identity is too vast to survey here, but to finish we can relate this debate to the previously discussed debate about identity over time.
For some putative cases of vagueness in synchronic identity it seems reasonable to accept the conclusion of Evans's argument and locate the indeterminacy in language (see the “Reply” by Shoemaker in Shoemaker and Swinburne 1984 for the following example). A structure consists of two halls, Alpha Hall and Beta Hall, linked by a flimsy walkway, Smith is located in Alpha Hall, Jones in Beta Hall. The nature of the structure is such that the identity statement “The building in which Smith is located is the building in which Jones is located” is neither true nor false because it is indeterminate whether Alpha Hall and Beta Hall count as two distinct buildings or merely as two parts of one and the same building. Here it is absolutely clear what is going on. The term “building” is vague in a way that makes it indeterminate whether it applies to the whole structure or just to the two halls. Consequently, it is indeterminate what “the building in which Smith is located” and “the building in which Jones is located” denote.
Perdurance theorists, who assimilate identity over time to identity over space, can accommodate vagueness in identity over time in the same way. In Hawley's example they can say that there are several entities present: one that exists before and after the identity-obscuring occurrences in the cabinet, one that exists only before, and one that exists only after. It is indeterminate which of these is a person and so it is indeterminate what the singular terms “Alpha” and “Omega” refer to.
This involves taking on an ontology that is larger than we ordinarily recognise, but that is not uncongenial to the perdurance theorist, who is happy to regard any, however spatiotemporally disconnected, region as containing a physical object (Quine 1960:171).
But what of endurance theorists?
One option for them is to adopt the same response and to accept a multiplicity of entities partially coinciding in space and time where to common sense there seems to be only one. But this is to give up on one of the major advantages claimed by the endurance theorist, his consonance with common sense.
The endurance theorist has several other options. He may simply deny the existence of the relevant entities and restrict his ontology to entities which are not complex; he may insist that any change destroys identity so that in a strict and philosophical sense Alpha is distinct from Omega; or he may reject the case as one of vagueness, insisting that, though we do not know the answer, either Alpha is Omega or she is not.
However, the most tempting option for the endurance theorist, which keeps closest to common sense, is to accept that the case is one of vagueness, deny the multiplicity of entities embraced by the perdurance theorist and reject Evans's argument against vague identity.
That this is so highlights the fact that there is no easy solution to the problem consonant in every respect with common sense. Locating the vagueness in language requires us to acknowledge a multiplicity of entities of which we would apparently otherwise have to take no notice. Whilst locating it in the world requires an explanation of how, contrary to Evans's argument, the impossibility of vague identity is not a straightforward consequence of the classical conception of identity, or else the abandonment of that conception.
Baxter, D. L. M., 1988a. “Identity in the Loose and Popular Sense”, Mind, 97: 576–582.
Baxter, D. L. M., 1988b. “Many-One Identity ”, Philosophical Papers, 17: 193–216.
Baxter, D. L. M., 2001. “Instantiation as Partial Identity ”, The Australasian Journal of Philosophy, 79(4): 449–464.
Black, M., 1952. “The Identity of Indiscernibles.”, Mind, 61(242): 153–164.
Burke, M., 1995. “Dion and Theon: an essentialist solution to an ancient problem”, The Journal of Philosophy, 91: 129–139.
Cameron, R., 2014. “Parts Generate the Whole, but They are Not Identical to It”, Composition as Identity, ed. A. J. Cotnoir and D. L. M. Baxter. Oxford: Oxford University Press.
Cotnoir, A. J., 2013. “Composition as General Identity”, Oxford Studies in Metaphysics, 8, 294–322.
Davidson, D., 1980. Essays on Actions and Events, Oxford: Clarendon Press.
Deutsch, H., 1997. “Identity and General Similarity”, Philosophical Perspectives, 12: 177–200.
Dummett, M., 1981. The Interpretation of Frege's Philosophy, Cambridge, Massachusetts: Harvard University Press.
–––, 1991. “Does Quantification involve Identity?” in H.A. Lewis (ed.), Peter Geach: Philosophical encounters, Dordrecht: Kluwer Academic Publishers.
Edgington, D., 2000. “Indeterminacy De Re”, Philosophical Topics, 28: 27–43.
Evans, G., 1978. “Can there be vague objects?”, Analysis, 38: 208.
Frege, G., 1950. The foundations of arithmetic, Trans. J.L Austin. Oxford: Basil Blackwell.
–––, 1969. Translations from the philosophical writings of Gottlob Frege, Trans. P. Geach and M. Black, Oxford: Blackwell.
Geach, P., 1972. Logic Matters, Oxford: Basil Blackwell.
–––, 1973. “Ontological relativity and relative identity”, in M.K. Munitz (ed.), Logic and Ontology, New York: New York University Press.
–––, 1980. Reference and Generality 3rd edition. Ithaca, NY: Cornell University Press.
–––, 1991. “Replies”, in H.A. Lewis (ed.), Peter Geach: Philosophical encounters, Dordrecht: Kluwer Academic Publishers.
Gibbard, A., 1975. “Contingent identity”, Journal of Philosophical Logic, 4: 187–221.
Harte, V., 2002. Plato on parts and wholes: The metaphysics of structure, Oxford: Oxford University Press.
Haslanger, S., 2003. “Persistence through time”, in M.J. Loux and D.W. Zimmerman (eds.), The Oxford handbook of metaphysics, Oxford: Oxford University Press.
Hawley, K., 2001. How things persist, Oxford: Oxford University Press.
–––, 2014. “Ontological Innocence”, Composition as Identity, ed. A. J. Cotnoir and D. L. M. Baxter. Oxford: Oxford University Press.
Hawthorne, J., 2003. “Identity”, in M.J. Loux and D.W. Zimmerman (eds.), The Oxford handbook of metaphysics, Oxford: Oxford University Press.
Kripke, S., 1980. Naming and Necessity, Oxford: Basil Blackwell.
Lewis, D., 1983. Philosophical Papers, vol. 1. Oxford: Oxford University Press.
–––, 1986. On the plurality of worlds, Oxford: Basil Blackwell.
–––, 1988. “Vague identity: Evans misunderstood”, Analysis, 48: 128–30.
–––, 1991. Parts of Classes, Oxford: Basil Blackwell.
–––, 1993. “Many but almost one”, in J. Bacon et al., (eds.), Ontology, Causality and Mind, Cambridge: Cambridge University Press, pp. 23–42.
Lowe, E.J., 1989. “What is a criterion of identity?”, Philosophical Quarterly, 39: 1–29.
–––, 1997. “Objects and criteria of identity”, in B. Hale and C. Wright (eds.), A Companion to the Philosophy of Language, Oxford: Blackwell.
Mackie, P., 2006. How Things Might Have Been: Individuals, Kinds and Essential Properties, Oxford: Oxford University Press.
Noonan, H.W., 1991. “Indeterminate Identity, Contingent Identity and Abelardian Predicates”, The Philosophical Quarterly, 41: 183–193.
–––, 1993. “Constitution is Identity”, Mind, 102: 133–146.
–––, 1997. “Relative Identity”, in B. Hale and C. Wright (eds.), A Companion to the Philosophy of Language, Oxford: Blackwell.
Normore, C. G., and D. J. Brown., 2014. “On Bits and Pieces in the History of Philosophy.”, In Composition as Identity, ed. A. J. Cotnoir and D. L. M. Baxter. Oxford: Oxford University Press.
Olson, E., 1995. “Why I have no hands”, Theoria, 61: 182–97.
–––, 2007. What are We?, Oxford: Oxford University Press.
Quine, W.V.O., 1960. Word and Object, Cambridge, Mass.: MIT Press.
–––, 1963. From a Logical Point of View, New York: Harper and Row.
–––, 1964. “Review of P.T. Geach, Reference and Generality”, Philosophical Review, 73: 100–104.
Salmon, N., 1982. Reference and Essence, Oxford: Basil Blackwell.
Schaffer, J., 2008. “Truthmaker Commitments”, Philosophical Studies, 141: 7–19.
Shoemaker, S. and Swinburne, R., 1984. Personal Identity, Oxford: Blackwell.
Sider, T., 2001. Four-dimensionalism: An Ontology of Persistence and Time, Oxford: Oxford University Press.
–––, 2007. “Parthood”, The Philosophical Review, 116: 51–91.
Thomson, J., 1983. “Parthood and Identity across Time”, Journal of Philosophy, 80: 201–220.
Tye, M., 2000. “Vagueness and reality”, Philosophical Topics, 28: 195–209.
Unger, P., 1980. “The problem of the many”, Midwest Studies in Philosophy, 5: 411–67.
van Inwagen, P., 1981. “The doctrine of arbitrary undetached parts”, Pacific Philosophical Quarterly, 62: 123–37.
–––, 1990. Material Beings, Ithaca, NY: Cornell University Press.
–––, 1994. “Composition as identity”, Philosophical perspectives, 8(1), 207–220.
Wallace, M., 2011a. “Composition as Identity: Part 1”, Philosophy Compass, 6(11), 804–816.
–––, 2011b. “Composition as Identity: Part 2”, Philosophy Compass, 6(11), 817–827.
Wiggins, D., 1967. Identity and Spatiotemporal Continuity, Oxford: Basil Blackwell.
–––, 1968. “On being in the same place at the same time”, Philosophical Review, 77: 90–5.
–––, 1980. Sameness and Substance, Oxford: Basil Blackwell.
Williams, J. R. G., 2010. “Fundamental and Derivative Truths”, Mind, 119: 103–141.
Williamson, T., 1990. Identity and discrimination, Oxford: Basil Blackwell.
–––, 2002. “Vagueness, Identity and Leibniz's Law”, in P. Giaretta, A. Bottani and M. Carrara (eds.), Individuals, Essence and Identity: Themes of Analytic Metaphysics, Dordrecht: Kluwer.
–––, 2003. “Vagueness in Reality”, in M.J. Loux and D.W. Zimmerman (eds.), The Oxford handbook of metaphysics, Oxford: Oxford University Press.
Wittgenstein, L., 1958. Philosophical Investigations, 2nd edition, G.E.M. Anscombe and R. Rhees (eds.), trans. by G.E.M. Anscombe, Oxford: Basil Blackwell.
Open access to the SEP is made possible by a world-wide funding initiative.
Please Read How You Can Help Keep the Encyclopedia Free
The SEP would like to congratulate the National Endowment for the Humanities on its 50th anniversary and express our indebtedness for the five generous grants it awarded our project from 1997 to 2007. Readers who have benefited from the SEP are encouraged to examine the NEH’s anniversary page and, if inspired to do so, send a testimonial to neh50@neh.gov.Narrowly speaking, the correspondence theory of truth is the view that truth is correspondence to, or with, a fact—a view that was advocated by Russell and Moore early in the 20th century. But the label is usually applied much more broadly to any view explicitly embracing the idea that truth consists in a relation to reality, i.e., that truth is a relational property involving a characteristic relation (to be specified) to some portion of reality (to be specified). This basic idea has been expressed in many ways, giving rise to an extended family of theories and, more often, theory sketches. Members of the family employ various concepts for the relevant relation (correspondence, conformity, congruence, agreement, accordance, copying, picturing, signification, representation, reference, satisfaction) and/or various concepts for the relevant portion of reality (facts, states of affairs, conditions, situations, events, objects, sequences of objects, sets, properties, tropes). The resulting multiplicity of versions and reformulations of the theory is due to a blend of substantive and terminological differences.
The correspondence theory of truth is often associated with metaphysical realism. Its traditional competitors, pragmatist, as well as coherentist, verificationist, and other epistemic theories of truth, are often associated with idealism, anti-realism, or relativism. In recent years, these traditional competitors have been virtually replaced (at least from publication-space) by deflationary theories of truth and, to a lesser extent, by the identity theory (note that these new competitors are typically not associated with anti-realism). Still more recently, two further approaches have received considerable attention. One is truthmaker theory: it is sometimes viewed as a competitor to, sometimes as a more liberal version of, the correspondence theory. The other is pluralism: it incorporates a correspondence account as one, but only one, ingredient of its overall account of truth.
Bibliography
Academic Tools
1. History of the Correspondence Theory
The correspondence theory is often traced back to Aristotle’s well-known definition of truth (Metaphysics 1011b25): “To say of what is that it is not, or of what is not that it is, is false, while to say of what is that it is, and of what is not that it is not, is true”—but virtually identical formulations can be found in Plato (Cratylus 385b2, Sophist 263b). It is noteworthy that this definition does not highlight the basic correspondence intuition. Although it does allude to a relation (saying something of something) to reality (what is), the relation is not made very explicit, and there is no specification of what on the part of reality is responsible for the truth of a saying. As such, the definition offers a muted, relatively minimal version of a correspondence theory. (For this reason it has also been claimed as a precursor of deflationary theories of truth.) Aristotle sounds much more like a genuine correspondence theorist in the Categories (12b11, 14b14), where he talks of underlying things that make statements true and implies that these things (pragmata) are logically structured situations or facts (viz., his sitting and his not sitting are said to underlie the statements “He is sitting” and “He is not sitting”, respectively). Most influential is Aristotle’s claim in De Interpretatione (16a3) that thoughts are “likenessess” (homoiomata) of things. Although he nowhere defines truth in terms of a thought’s likeness to a thing or fact, it is clear that such a definition would fit well into his overall philosophy of mind. (Cf. Crivelli 2004; Szaif 2006.)
1.1 Metaphysical and Semantic Versions
In medieval authors we find a division between “metaphysical” and “semantic” versions of the correspondence theory. The former are indebted to the truth-as-likeness theme suggested by Aristotle’s overall views, the latter are modeled on Aristotle’s more austere definition from Metaphysics 1011b25.
The metaphysical version presented by Thomas Aquinas is the best known: “Veritas est adaequatio rei et intellectus” (Truth is the equation of thing and intellect), which he restates as: “A judgment is said to be true when it conforms to the external reality”. He tends to use “conformitas” and “adaequatio”, but also uses “correspondentia”, giving the latter a more generic sense (De Veritate, Q.1, A.1-3; cf. Summa Theologiae, Q.16). Aquinas credits the Neoplatonist Isaac Israeli with this definition, but there is no such definition in Isaac. Correspondence formulations can be traced back to the Academic skeptic Carneades, 2nd century B.C., whom Sextus Empiricus (Adversos Mathematicos, vii, 168) reports as having taught that a presentation “is true when it is in accord (symphonos) with the object presented, and false when it is in discord with it”. Similar accounts can be found in various early commentators on Plato and Aristotle (cf. Künne 2003, chap. 3.1), including some Neoplatonists: Proklos (In Tim., II 287, 1) speaks of truth as the agreement or adjustment (epharmoge) between knower and the known. Philoponus (In Cat., 81, 25-34) emphasizes that truth is neither in the things or states of affairs (pragmata) themselves, nor in the statement itself, but lies in the agreement between the two. He gives the simile of the fitting shoe, the fit consisting in a relation between shoe and foot, not to be found in either one by itself. Note that his emphasis on the relation as opposed to its relata is laudable but potentially misleading, because x’s truth (its being true) is not to be identified with a relation, R, between x and y, but with a general relational property of x, taking the form (∃y)(xRy & Fy). Further early correspondence formulations can be found in Avicenna (Metaphysica, 1.8-9) and Averroes (Tahafut, 103, 302). They were introduced to the scholastics by William of Auxerre, who may have been the intended recipient of Aquinas’ mistaken attribution (cf. Boehner 1958; Wolenski 1994).
Aquinas’ balanced formula “equation of thing and intellect” is intended to leave room for the idea that “true” can be applied not only to thoughts and judgments but also to things or persons (e.g. a true friend). Aquinas explains that a thought is said to be true because it conforms to reality, whereas a thing or person is said to be true because it conforms to a thought (a friend is true insofar as, and because, she conforms to our, or God’s, conception of what a friend ought to be). Medieval theologians regarded both, judgment-truth as well as thing/person-truth, as somehow flowing from, or grounded in, the deepest truth which, according to the Bible, is God: “I am the way and the truth and the life” (John 14, 6). Their attempts to integrate this Biblical passage with more ordinary thinking involving truth gave rise to deep metaphysico-theological reflections. The notion of thing/person-truth, which thus played a very important role in medieval thinking, is disregarded by modern and contemporary analytic philosophers but survives to some extent in existentialist and continental philosophy.
Medieval authors who prefer a semantic version of the correspondence theory often use a peculiarly truncated formula to render Aristotle’s definition: A (mental) sentence is true if and only if, as it signifies, so it is (sicut significat, ita est). This emphasizes the semantic relation of signification while remaining maximally elusive about what the “it” is that is signified by a true sentence and de-emphasizing the correspondence relation (putting it into the little words “as” and “so”). Foreshadowing a favorite approach of the 20th century, medieval semanticists like Ockham (Summa Logicae, II) and Buridan (Sophismata, II) give exhaustive lists of different truth-conditional clauses for sentences of different grammatical categories. They refrain from associating true sentences in general with items from a single ontological category. (Cf. Moody 1953; Adams McCord 1987; Perler 2006.)
Authors of the modern period generally convey the impression that the correspondence theory of truth is far too obvious to merit much, or any, discussion. Brief statements of some version or other can be found in almost all major writers; see e.g.: Descartes 1639, ATII 597; Spinoza, Ethics, axiom vi; Locke, Essay, 4.5.1; Leibniz, New Essays, 4.5.2; Hume, Treatise, 3.1.1; and Kant 1787, B82. Berkeley, who does not seem to offer any account of truth, is a potentially significant exception. Due to the influence of Thomism, metaphysical versions of the theory are much more popular with the moderns than semantic versions. But since the moderns generally subscribe to a representational theory of the mind (the theory of ideas), they would seem to be ultimately committed to spelling out relations like correspondence or conformity in terms of a psycho-semantic representation relation holding between ideas, or sentential sequences of ideas (Locke’s “mental propositions”), and appropriate portions of reality, thereby effecting a merger between metaphysical and semantic versions of the correspondence theory.
1.2 Object-Based and Fact-Based Versions
It is helpful to distinguish between “object-based” and “fact-based” versions of correspondence theories, depending on whether the corresponding portion of reality is said to be an object or a fact (cf. Künne 2003, chap. 3).
Traditional versions of object-based theories assumed that the truth-bearing items (usually taken to be judgments) have subject-predicate structure. An object-based definition of truth might look like this:
A judgment is true if and only if its predicate corresponds to its object (i.e., to the object referred to by the subject term of the judgment).
Note that this actually involves two relations to an object: (i) a reference relation, holding between the subject term of the judgment and the object the judgment is about (its object); and (ii) a correspondence relation, holding between the predicate term of the judgment and a property of the object. Owing to its reliance on the subject-predicate structure of truth-bearing items, the account suffers from an inherent limitation: it does not cover truthbearers that lack subject-predicate structure (e.g. conditionals, disjunctions), and it is not clear how the account might be extended to cover them. The problem is obvious and serious; it was nevertheless simply ignored in most writings. Object-based correspondence was the norm until relatively recently.
Object-based correspondence became the norm through Plato’s pivotal engagement with the problem of falsehood, which was apparently notorious at its time. In a number of dialogues, Plato comes up against an argument, advanced by various Sophists, to the effect that false judgment is impossible—roughly: To judge falsely is to judge what is not. But one cannot judge what is not, for it is not there to be judged. To judge something that is not is to judge nothing, hence, not to judge at all. Therefore, false judgment is impossible. (Cf. Euthydemus 283e-288a; Cratylus 429c-e; Republic 478a-c; Theaetetus 188d-190e.) Plato has no good answer to this patent absurdity until the Sophist (236d-264b), where he finally confronts the issue at length. The key step in his solution is the analysis of truthbearers as structured complexes. A simple sentence, such as “Theaetetus sits.”, though simple as a sentence, is still a complex whole consisting of words of different kinds—a name (onoma) and a verb (rhema)—having different functions. By weaving together verbs with names the speaker does not just name a number of things, but accomplishes something: meaningful speech (logos) expressive of the interweaving of ideas (eidon symploken). The simple sentence is true when Theaetetus, the person named by the name, is in the state of sitting, ascribed to him through the verb, and false, when Theaetetus is not in that state but in another one (cf. 261c-263d; see Denyer 1991; Szaif 1998). Only things that are show up in this account: in the case of falsehood, the ascribed state still is, but it is a state different from the one Theaetetus is in. The account is extended from speech to thought and belief via Plato’s well known thesis that “thought is speech that occurs without voice, inside the soul in conversation with itself” (263e)—the historical origin of the language-of-thought hypothesis. The account does not take into consideration sentences that contain a name of something that is not (“Pegasus flies”), thus bequeathing to posterity a residual problem that would become more notorious than the problem of falsehood.
Aristotle, in De Interpretatione, adopts Plato’s account without much ado—indeed, the beginning of De Interpretatione reads like a direct continuation of the passages from the Sophist mentioned above. He emphasizes that truth and falsehood have to do with combination and separation (cf. De Int. 16a10; in De Anima 430a25, he says: “where the alternative of true and false applies, there we always find a sort of combining of objects of thought in a quasi-unity”). Unlike Plato, Aristotle feels the need to characterize simple affirmative and negative statements (predications) separately—translating rather more literally than is usual: “An affirmation is a predication of something toward something, a negation is a predication of something away from something” (De Int. 17a25). This characterization reappears early in the Prior Analytics (24a). It thus seems fair to say that the subject-predicate analysis of simple declarative sentences—the most basic feature of Aristotelian term logic which was to reign supreme for many centuries—had its origin in Plato’s response to a sophistical argument against the possibility of falsehood. One may note that Aristotle’s famous definition of truth (see Section 1) actually begins with the definition of falsehood.
Fact-based correspondence theories became prominent only in the 20th century, though one can find remarks in Aristotle that fit this approach (see Section 1)—somewhat surprisingly in light of his repeated emphasis on subject-predicate structure wherever truth and falsehood are concerned. Fact-based theories do not presuppose that the truth-bearing items have subject-predicate structure; indeed, they can be stated without any explicit reference to the structure of truth-bearing items. The approach thus embodies an alternative response to the problem of falsehood, a response that may claim to extricate the theory of truth from the limitations imposed on it through the presupposition of subject-predicate structure inherited from the response to the problem of falsehood favored by Plato, Aristotle, and the medieval and modern tradition.
The now classical formulation of a fact-based correspondence theory was foreshadowed by Hume (Treatise, 3.1.1) and Mill (Logic, 1.5.1). It appears in its canonical form early in the 20th century in Moore (1910-11, chap. 15) and Russell: “Thus a belief is true when there is a corresponding fact, and is false when there is no corresponding fact” (1912, p. 129; cf. also his 1905, 1906, 1910, and 1913). The self-conscious emphasis on facts as the corresponding portions of reality—and a more serious concern with problems raised by falsehood—distinguishes this version from its foreshadowings. Russell and Moore’s forceful advocacy of truth as correspondence to a fact was, at the time, an integral part of their defense of metaphysical realism. Somewhat ironically, their formulations are indebted to their idealist opponents, F. H. Bradley (1883, chaps. 1&2), and H. H. Joachim (1906), the latter was an early advocate of the competing coherence theory, who had set up a correspondence-to-fact account of truth as the main target of his attack on realism. Later, Wittgenstein (1921) and Russell (1918) developed “logical atomism”, which introduces an important modification of the fact-based correspondence approach (see below, Section 7.1). Further modifications of the correspondence theory, bringing a return to more overtly semantic and broadly object-based versions, were influenced by Tarski’s (1935) technical work on truth (cf. Field 1972, Popper 1972).
2. Truthbearers, Truthmakers, Truth
2.1 Truthbearers
Correspondence theories of truth have been given for beliefs, thoughts, ideas, judgments, statements, assertions, utterances, sentences, and propositions. It has become customary to talk of truthbearers whenever one wants to stay neutral between these choices. Five points should be kept in mind:
The term “truthbearer” is somewhat misleading. It is intended to refer to bearers of truth or falsehood (truth-value-bearers), or alternatively, to things of which it makes sense to ask whether they are true or false, thus allowing for the possibility that some of them might be neither.
One distinguishes between secondary and primary truthbearers. Secondary truthbearers are those whose truth-values (truth or falsehood) are derived from the truth-values of primary truthbearers, whose truth-values are not derived from any other truthbearers. Consequently, the term “true” is usually regarded as ambiguous, taking its primary meaning when applied to primary truthbearers and various secondary meanings when applied to other truthbearers. This is, however, not a brute ambiguity, since the secondary meanings are supposed to be derived, i.e. definable from, the primary meaning together with additional relations. For example, one might hold that propositions are true or false in the primary sense, whereas sentences are true or false in a secondary sense, insofar as they express propositions that are true or false (in the primary sense). The meanings of “true”, when applied to truthbearers of different kinds, are thus connected in a manner familiar from what Aristotelians called “analogical” uses of a term—nowadays one would call this “focal meaning”; e.g., “healthy” in “healthy organism” and “healthy food”, the latter being defined as healthy in the secondary sense of contributing to the healthiness (primary sense) of an organism.
It is often unproblematic to advocate one theory of truth for bearers of one kind and another theory for bearers of a different kind (e.g., a deflationary theory of truth, or an identity theory, applied to propositions, could be a component of some form of correspondence theory of truth for sentences). Different theories of truth applied to bearers of different kinds do not automatically compete. The standard segregation of truth theories into competing camps (found in textbooks, handbooks, and dictionaries) proceeds under the assumption—really a pretense—that they are intended for primary truthbearers of the same kind.
Confusingly, there is little agreement as to which entities are properly taken to be primary truthbearers. Nowadays, the main contenders are public language sentences, sentences of the language of thought (sentential mental representations), and propositions. Popular earlier contenders—beliefs, judgments, statements, and assertions—have fallen out of favor, mainly for two reasons:
The problem of logically complex truthbearers. A subject, S, may hold a disjunctive belief (the baby will be a boy or the baby will be a girl), while believing only one, or neither, of the disjuncts. Also, S may hold a conditional belief (if whales are fish, then some fish are mammals) without believing the antecedent or the consequent. Also, S will usually hold a negative belief (not everyone is lucky) without believing what is negated. In such cases, the truth-values of S’s complex beliefs depend on the truth-values of their constituents, although the constituents may not be believed by S or by anyone. This means that a view according to which beliefs are primary truthbearers seems unable to account for how the truth-values of complex beliefs are connected to the truth-values of their simpler constituents—to do this one needs to be able to apply truth and falsehood to belief-constituents even when they are not believed. This point, which is equally fundamental for a proper understanding of logic, was made by all early advocates of propositions (cf. Bolzano 1837, I.§§22, 34; Frege 1879, §§2-5; Husserl 1900, I.§11; Meinong 1902, §6). The problem arises in much the same form for views that would take judgments, statements, or assertions as primary truthbearers. The problem is not easily evaded. Talk of unbelieved beliefs (unjudged judgments, unstated statements, unasserted assertions) is either absurd or simply amounts to talk of unbelieved (unjudged, unstated, unasserted) propositions or sentences. It is noteworthy, incidentally, that quite a few philosophical proposals (concerning truth as well as other matters) run afoul of the simple observation that there are unasserted and unbelieved truthbearers (cf. Geach 1960 & 1965).
The duality of state/content a.k.a. act/object. The noun “belief” can refer to the state of believing or to its content, i.e., to what is believed. If the former, the state of believing, can be said to be true or false at all, which is highly questionable, then only insofar as the latter, what is believed, is true or false. Similarly for nouns referring to mental acts or their objects (contents), such as “judgment”, “statement”, and “assertion”.
Mental sentences were the preferred primary truthbearers throughout the medieval period. They were neglected in the first half of the 20th century, but made a comeback in the second half through the revival of the representational theory of the mind (especially in the form of the language-of-thought hypothesis, cf. Fodor 1975). Somewhat confusingly (to us now), for many centuries the term “proposition” (propositio) was reserved exclusively for sentences, written, spoken or mental. This use was made official by Boethius in the 6th century, and is still found in Locke’s Essay in 1705 and in Mill’s Logic in 1843. Some time after that, e.g., in Moore’s 1901-01, “proposition” switched sides, the term now being used for what is said by uttering a sentence, for what is believed, judged, stated, assumed (etc.)—with occasional reversions to medieval usage, e.g. in Russell (1918, 1919).
2.2 Truthmakers
Talk of truthmakers serves a function similar, but correlative, to talk of truthbearers. A truthmaker is anything that makes some truthbearer true. Different versions of the correspondence theory will have different, and often competing, views about what sort of items true truthbearers correspond to (facts, states of affairs, events, things, tropes, properties). It is convenient to talk of truthmakers whenever one wants to stay neutral between these choices. Four points should be kept in mind:
The notion of a truthmaker is tightly connected with, and dependent on, the relational notion of truthmaking: a truthmaker is whatever stands in the truthmaking relation to some truthbearer. Despite the causal overtones of “maker” and “making”, this relation is usually not supposed to be a causal relation.
The terms “truthmaking” and “truthmaker” are ambiguous. For illustration, consider a classical correspondence theory on which x is true if and only if x corresponds to some fact. One can say (a) that x is made true by a fact, namely the or a fact x corresponds to. One can also say (b) that x is made true by x’s correspondence to a fact. Both uses of “is made true by” are correct and both occur in discussions of truth. But they are importantly different and must be distinguished. The (a)-use is usually the intended one; it expresses a relation peculiar to truth and leads to a use of “truthmaker” that actually picks out the items that would normally be intended by those using the term. The (b)-use does not express a relation peculiar to truth; it is just an instance (for “F” = “true”) of the generic formula “what makes an F-thing an F” that can be employed to elicit the definiens of a proposed definition of F. Compare: what makes an even number even is its divisibility by 2; what makes a right action right is its having better consequences than available alternative actions. Note that anyone proposing a definition or account of truth can avail themselves of the notion of truthmaking in the (b)-sense; e.g., a coherence theorist, advocating that a belief is true if and only if it coheres with other beliefs, can say: what makes a true belief true is its coherence with other beliefs. So, on the (b)-use, “truthmaking” and “truthmaker” do not signal any affinity with the basic idea underlying the correspondence theory of truth, whereas on the (a)-use these terms do signal such an affinity.
Talk of truthmaking and truthmakers goes well with the basic idea underlying the correspondence theory; hence, it might seem natural to describe a traditional fact-based correspondence theory as maintaining that the truthmakers are facts and that the correspondence relation is the truthmaking relation. However, the assumption that the correspondence relation can be regarded as (a species of) the truthmaking relation is dubious. Correspondence appears to be a symmetric relation (if x corresponds to y, then y corresponds to x), whereas it is usually taken for granted that truthmaking is an asymmetric relation, or at least not a symmetric one. It is hard to see how a symmetric relation could be (a species of) an asymmetric or non-symmetric relation (cf. David 2009.)
Talk of truthmaking and truthmakers is frequently employed during informal discussions involving truth but tends to be dropped when a more formal or official formulation of a theory of truth is produced (one reason being that it seems circular to define or explain truth in terms of truthmakers or truthmaking). However, in recent years, the informal talk has been turned into an official doctrine: “truthmaker theory”. This theory should be distinguished from informal truthmaker talk: not everyone employing the latter would subscribe to the former. Moreover, truthmaker theory should not simply be assumed to be a version of the correspondence theory; indeed, some advocates present it as a competitor to the correspondence theory (see below, Section 8.5).
2.3 Truth
The abstract noun “truth” has various uses. (a) It can be used to refer to the general relational property otherwise referred to as being true; though the latter label would be more perspicuous, it is rarely used, even in philosophical discussions. (b) The noun “truth” can be used to refer to the concept that “picks out” the property and is expressed in English by the adjective “true”. Some authors do not distinguish between concept and property; others do, or should: an account of the concept might differ significantly from an account of the property. To mention just one example, one might maintain, with some plausibility, that an account of the concept ought to succumb to the liar paradox (see the entry on the liar paradox), otherwise it wouldn’t be an adequate account of our concept of truth; this idea is considerably less plausible in the case of the property. Any proposed “definition of truth” might be intend as a definition of the property or of the concept or both; its author may or may not be alive to the difference. (c) The noun “truth” can be used, finally, to refer to some set of true truthbarers (possibly unknown), as in: “The truth is out there”, and: “The truth about this matter will never be known”.
3. Simple Versions of the Correspondence Theory
The traditional centerpiece of any correspondence theory is a definition of truth. Nowadays, a correspondence definition is most likely intended as a “real definition”, i.e., as a definition of the property, which does not commit its advocate to the claim that the definition provides a synonym for the term “true”. Most correspondence theorists would consider it implausible and unnecessarily bold to maintain that “true” means the same as “corresponds with a fact”. Some simple forms of correspondence definitions of truth should be distinguished (“iff” means “if and only if”; the variable, “x”, ranges over whatever truthbearers are taken as primary; the notion of correspondence might be replaced by various related notions):
(1)
x is true iff x corresponds to some fact;
x is false iff x does not correspond to any fact.
(2)
x is true iff x corresponds to some state of affairs that obtains;
x is false iff x corresponds to some state of affairs that does not obtain.
Both forms invoke portions of reality—facts/states of affairs—that are typically denoted by that-clauses or by sentential gerundives, viz. the fact/state of affairs that snow is white, or the fact/state of affairs of snow’s being white. (2)’s definition of falsehood is committed to there being (existing) entities of this sort that nevertheless fail to obtain, such as snow’s being green. (1)’s definition of falsehood is not so committed: to say that a fact does not obtain means, at best, that there is no such fact, that no such fact exists. It should be noted that this terminology is not standardized: some authors use “state of affairs” much like “fact” is used here (e.g. Armstrong 1997). The question whether non-obtaining beings of the relevant sort are to be accepted is the substantive issue behind such terminological variations. The difference between (2) and (1) is akin to the difference between Platonism about properties (embraces uninstantiated properties) and Aristotelianism about properties (rejects uninstantiated properties).
Advocates of (2) hold that facts are states of affairs that obtain, i.e., they hold that their account of truth is in effect an analysis of (1)’s account of truth. So disagreement turns largely on the treatment of falsehood, which (1) simply identifies with the absence of truth.
The following points might be made for preferring (2) over (1): (a) Form (2) does not imply that things outside the category of truthbearers (tables, dogs) are false just because they don’t correspond to any facts. One might think this “flaw” of (1) is easily repaired: just put an explicit specification of the desired category of truthbearers into both sides of (1). However, some worry that truthbearer categories, e.g. declarative sentences or propositions, cannot be defined without invoking truth and falsehood, which would make the resultant definition implicitly circular. (b) Form (2) allows for items within the category of truthbearers that are neither true nor false, i.e., it allows for the failure of bivalence. Some, though not all, will regard this as a significant advantage. (c) If the primary truthbearers are sentences or mental states, then states of affairs could be their meanings or contents, and the correspondence relation in (2) could be understood accordingly, as the relation of representation, signification, meaning, or having-as-content. Facts, on the other hand, cannot be identified with the meanings or contents of sentences or mental states, on pain of the absurd consequence that false sentences and beliefs have no meaning or content. (d) Take a truth of the form ‘p or q’, where ‘p’ is true and ‘q’ false. What are the constituents of the corresponding fact? Since ‘q’ is false, they cannot both be facts (cf. Russell 1906-07, p. 47f.). Form (2) allows that the fact corresponding to ‘p or q’ is an obtaining disjunctive state of affairs composed of a state of affairs that obtains and a state of affairs that does not obtain.
The main point in favor of (1) over (2) is that (1) is not committed to counting non-obtaining states of affairs, like the state of affairs that snow is green, as constituents of reality.
(One might observe that, strictly speaking, (1) and (2), being biconditionals, are not ontologically committed to anything. Their respective commitments to facts and states of affairs arise only when they are combined with claims to the effect that there is something that is true and something that is false. The discussion assumes some such claims as given.)
Both forms, (1) and (2), should be distinguished from:
(3)
x is true iff x corresponds to some fact that exists;
x is false iff x corresponds to some fact that does not exist,
which is a confused version of (1), or a confused version of (2), or, if unconfused, signals commitment to Meinongianism, i.e., the thesis that there are things/facts that do not exist. The lure of (3) stems from the desire to offer more than a purely negative correspondence account of falsehood while avoiding commitment to non-obtaining states of affairs. Moore at times succumbs to (3)’s temptations (1910-11, pp. 267 & 269, but see p. 277). It can also be found in the 1961 translation of Wittgenstein (1921, 4.25), who uses “state of affairs” (Sachverhalt) to refer to (atomic) facts. The translation has Wittgenstein saying that an elementary proposition is false, when the corresponding state of affairs (atomic fact) does not exist—but the German original of the same passage looks rather like a version of (2). Somewhat ironically, a definition of form (3) reintroduces Plato’s problem of falsehood into a fact-based correspondence theory, i.e., into a theory of the sort that was supposed to provide an alternative solution to that very problem (see Section 1.2).
A fourth simple form of correspondence definition was popular for a time (cf. Russell 1918, secs. 1 & 3; Broad 1933, IV.2.23; Austin 1950, fn. 23), but seems to have fallen out of favor:
(4)
x is true iff x corresponds (agrees) with some fact;
x is false iff x mis-corresponds (disagrees) with some fact.
This formulation attempts to avoid (2)’s commitment to non-obtaining states of affairs and (3)’s commitment to non-existent facts by invoking the relation of mis-correspondence, or disagreement, to account for falsehood. It differs from (1) in that it attempts to keep items outside the intended category of x’s from being false: supposedly, tables and dogs cannot mis-correspond with a fact. Main worries about (4) are: (a) its invocation of an additional, potentially mysterious, relation, which (b) seems difficult to tame: Which fact is the one that mis-corresponds with a given falsehood? and: What keeps a truth, which by definition corresponds with some fact, from also mis-corresponding with some other fact, i.e., from being a falsehood as well?
In the following, I will treat definitions (1) and (2) as paradigmatic; moreover, since advocates of (2) agree that obtaining states of affairs are facts, it is often convenient to condense the correspondence theory into the simpler formula provided by (1), “truth is correspondence to a fact”, at least as long as one is not particularly concerned with issues raised by falsehood.
4. Arguments for the Correspondence Theory
The main positive argument given by advocates of the correspondence theory of truth is its obviousness. Descartes: “I have never had any doubts about truth, because it seems a notion so transcendentally clear that nobody can be ignorant of it...the word ‘truth’, in the strict sense, denotes the conformity of thought with its object” (1639, AT II 597). Even philosophers whose overall views may well lead one to expect otherwise tend to agree. Kant: “The nominal definition of truth, that it is the agreement of [a cognition] with its object, is assumed as granted” (1787, B82). William James: “Truth, as any dictionary will tell you, is a property of certain of our ideas. It means their ‘agreement’, as falsity means their disagreement, with ‘reality’” (1907, p. 96). Indeed, The Oxford English Dictionary tells us: “Truth, n. Conformity with fact; agreement with reality”.
In view of its claimed obviousness, it would seem interesting to learn how popular the correspondence theory actually is. There are some empirical data. The PhilPapers Survey (conducted in 2009; cf. Bourget and Chalmers 2014), more specifically, the part of the survey targeting all regular faculty members in 99 leading departments of philosophy, reports the following responses to the question: “Truth: correspondence, deflationary, or epistemic?” Accept or lean toward: correspondence 50.8%; deflationary 24.8%; other 17.5%; epistemic 6.9%. The data suggest that correspondence-type theories may enjoy a weak majority among professional philosophers and that the opposition is divided. This fits with the observation that typically, discussions of the nature of truth take some version of the correspondence theory as the default view, the view to be criticized or to be defended against criticism.
Historically, the correspondence theory, usually in an object-based version, was taken for granted, so much so that it did not acquire this name until comparatively recently, and explicit arguments for the view are very hard to find. Since the (comparatively recent) arrival of apparently competing approaches, correspondence theorists have developed negative arguments, defending their view against objections and attacking (sometimes ridiculing) competing views.
5. Objections to the Correspondence Theory
Objection 1: Definitions like (1) or (2) are too narrow. Although they apply to truths from some domains of discourse, e.g., the domain of science, they fail for others, e.g. the domain of morality: there are no moral facts.
The objection recognizes moral truths, but rejects the idea that reality contains moral facts for moral truths to correspond to. Logic provides another example of a domain that has been “flagged” in this way. The logical positivists recognized logical truths but rejected logical facts. Their intellectual ancestor, Hume, had already given two definitions of “true”, one for logical truths, broadly conceived, the other for non-logical truths: “Truth or falsehood consists in an agreement or disagreement either to the real relations of ideas, or to real existence and matter of fact” (Hume, Treatise, 3.1.1, cf. 2.3.10; see also Locke, Essay, 4.5.6, for a similarly two-pronged account but in terms of object-based correspondence).
There are four possible responses to objections of this sort: (a) Noncognitivism, which says that, despite appearances to the contrary, claims from the flagged domain are not truth-evaluable to begin with, e.g., moral claims are commands or expressions of emotions disguised as truthbearers; (b) Error theory, which says that all claims from the flagged domain are false; (c) Reductionism, which says that truths from the flagged domain correspond to facts of a different domain regarded as unproblematic, e.g., moral truths correspond to social-behavioral facts, logical truths correspond to facts about linguistic conventions; and (d) Standing firm, i.e., embracing facts of the flagged domain.
The objection in effect maintains that there are different brands of truth (of the property being true, not just different brands of truths) for different domains. On the face of it, this conflicts with the observation that there are many obviously valid arguments combining premises from flagged and unflagged domains. The observation is widely regarded as refuting non-cognitivism, once the most popular (concessive) response to the objection.
In connection with this objection, one should take note of the recently developed “multiple realizability” view of truth, according to which truth is not to be identified with correspondence to fact but can be realized by correspondence to fact for truthbearers of some domains of discourse and by other properties for truthbearers of other domains of discourse, including “flagged” domains. Though it retains important elements of the correspondence theory, this view does not, strictly speaking, offer a response to the objection on behalf of the correspondence theory and should be regarded as one of its competitors (see below, Section 8.2).
Objection 2: Correspondence theories are too obvious. They are trivial, vacuous, trading in mere platitudes. Locutions from the “corresponds to the facts”-family are used regularly in everyday language as idiomatic substitutes for “true”. Such common turns of phrase should not be taken to indicate commitment to a correspondence theory in any serious sense. Definitions like (1) or (2) merely condense some trivial idioms into handy formulas; they don’t deserve the grand label “theory”: there is no theoretical weight behind them (cf. Woozley 1949, chap. 6; Davidson 1969; Blackburn 1984, chap. 7.1).
In response, one could point out: (a) Definitions like (1) or (2) are “mini-theories”—mini-theories are quite common in philosophy—and it is not at all obvious that they are vacuous merely because they are modeled on common usage. (b) There are correspondence theories that go beyond these definitions. (c) The complaint implies that definitions like (1) and/or (2) are generally accepted and are, moreover, so shallow that they are compatible with any deeper theory of truth. This makes it rather difficult to explain why some thinkers emphatically reject all correspondence formulations. (d) The objection implies that the correspondence of S’s belief with a fact could be said to consist in, e.g., the belief’s coherence with S’s overall belief system. This is wildly implausible, even on the most shallow understanding of “correspondence” and “fact”.
Objection 3: Correspondence theories are too obscure.
Objections of this sort, which are the most common, protest that the central notions of a correspondence theory carry unacceptable commitments and/or cannot be accounted for in any respectable manner. The objections can be divided into objections primarily aimed at the correspondence relation and its relatives (3.C1, 3.C2), and objections primarily aimed at the notions of fact or state of affairs (3.F1, 3.F2):
3.C1: The correspondence relation must be some sort of resemblance relation. But truthbearers do not resemble anything in the world except other truthbearers—echoing Berkeley’s “an idea can be like nothing but an idea”.
3.C2: The correspondence relation is very mysterious: it seems to reach into the most distant regions of space (faster than light?) and time (past and future). How could such a relation possibly be accounted for within a naturalistic framework? What physical relation could it possibly be?
3.F1: Given the great variety of complex truthbearers, a correspondence theory will be committed to all sorts of complex “funny facts” that are ontologically disreputable. Negative, disjunctive, conditional, universal, probabilistic, subjunctive, and counterfactual facts have all given cause for complaint on this score.
3.F2: All facts, even the most simple ones, are disreputable. Fact-talk, being wedded to that-clauses, is entirely parasitic on truth-talk. Facts are too much like truthbearers. Facts are fictions, spurious sentence-like slices of reality, “projected from true sentences for the sake of correspondence” (Quine 1987, p. 213; cf. Strawson 1950).
6. Correspondence as Isomorphism
Some correspondence theories of truth are two-liner mini-theories, consisting of little more than a specific version of (1) or (2). Normally, one would expect a bit more, even from a philosophical theory (though mini-theories are quite common in philosophy). One would expect a correspondence theory to go beyond a mere definition like (1) or (2) and discharge a triple task: it should tell us about the workings of the correspondence relation, about the nature of facts, and about the conditions that determine which truthbearers correspond to which facts.
One can approach this by considering some general principles a correspondence theory might want to add to its central principle to flesh out her theory. The first such principle says that the correspondence relation must not collapse into identity—“It takes two to make a truth” (Austin 1950, p. 118):
Nonidentity:
No truth is identical with a fact correspondence to which is sufficient for its being a truth.
It would be much simpler to say that no truth is identical with a fact. However, some authors, e.g. Wittgenstein 1921, hold that a proposition (Satz, his truthbearer) is itself a fact, though not the same fact as the one that makes the proposition true (see also King 2007). Nonidentity is usually taken for granted by correspondence theorists as constitutive of the very idea of a correspondence theory—authors who advance contrary arguments to the effect that correspondence must collapse into identity regard their arguments as objections to any form of correspondence theory (cf. Moore 1901/02, Frege 1918-19, p. 60).
Concerning the correspondence relation, two aspects can be distinguished: correspondence as correlation and correspondence as isomorphism (cf. Pitcher 1964; Kirkham 1992, chap. 4). Pertaining to the first aspect, familiar from mathematical contexts, a correspondence theorist is likely to adopt claim (a), and some may in addition adopt claim (b), of:
Correlation:
(a) Every truth corresponds to exactly one fact;
(b) Different truths correspond to different facts.
Together, (a) and (b) say that correspondence is a one-one relation. This seems needlessly strong, and it is not easy to find real-life correspondence theorists who explicitly embrace part (b): Why shouldn’t different truths correspond to the same fact, as long as they are not too different? Explicit commitment to (a) is also quite rare. However, correspondence theorists tend to move comfortably from talk about a given truth to talk about the fact it corresponds to—a move that signals commitment to (a).
Correlation does not imply anything about the inner nature of the corresponding items. Contrast this with correspondence as isomorphism, which requires the corresponding items to have the same, or sufficiently similar, constituent structure. This aspect of correspondence, which is more prominent (and more notorious) than the previous one, is also much more difficult to make precise. Let us say, roughly, that a correspondence theorist may want to add a claim to her theory committing her to something like the following:
Structure:
If an item of kind K corresponds to a certain fact, then they have the same or sufficiently similar structure: the overall correspondence between a true K and a fact is a matter of part-wise correspondences, i.e. of their having corresponding constituents in corresponding places in the same structure, or in sufficiently similar structures.
The basic idea is that truthbearers and facts are both complex structured entities: truthbearers are composed of (other truthbearers and ultimately of) words, or concepts; facts are composed of (other facts or states of affairs and ultimately of) things, properties, and relations. The aim is to show how the correspondence relation is generated from underlying relations between the ultimate constituents of truthbearers, on the one hand, and the ultimate constituents of their corresponding facts, on the other. One part of the project will be concerned with these correspondence-generating relations: it will lead into a theory that addresses the question how simple words, or concepts, can be about things, properties, and relations; i.e., it will merge with semantics or psycho-semantics (depending on what the truthbearers are taken to be). The other part of the project, the specifically ontological part, will have to provide identity criteria for facts and explain how their simple constituents combine into complex wholes. Putting all this together should yield an account of the conditions determining which truthbearers correspond to which facts.
Correlation and Structure reflect distinct aspects of correspondence. One might want to endorse the former without the latter, though it is hard to see how one could endorse the latter without embracing at least part (a) of the former.
The isomorphism approach offers an answer to objection 3.C1. Although the truth that the cat is on the mat does not resemble the cat or the mat (the truth doesn’t meow or smell, etc.), it does resemble the fact that the cat is on the mat. This is not a qualitative resemblance; it is a more abstract, structural resemblance.
The approach also puts objection 3.C2 in some perspective. The correspondence relation is supposed to reduce to underlying relations between words, or concepts, and reality. Consequently, a correspondence theory is little more than a spin-off from semantics and/or psycho-semantics, i.e. the theory of intentionality construed as incorporating a representational theory of the mind (cf. Fodor 1989). This reminds us that, as a relation, correspondence is no more—but also no less—mysterious than semantic relations in general. Such relations have some curious features, and they raise a host of puzzles and difficult questions—most notoriously: Can they be explained in terms of natural (causal) relations, or do they have to be regarded as irreducibly non-natural aspects of reality? Some philosophers have claimed that semantic relations are too mysterious to be taken seriously, usually on the grounds that they are not explainable in naturalistic terms. But one should bear in mind that this is a very general and extremely radical attack on semantics as a whole, on the very idea that words and concepts can be about things. The common practice to aim this attack specifically at the correspondence theory seems misleading. As far as the intelligibility of the correspondence relation is concerned, the correspondence theory will stand, or fall, with the general theory of reference and intentionality.
It should be noted, though, that these points concerning objections 3.C1 and 3.C2 are not independent of one’s views about the nature of the primary truthbearers. If truthbearers are taken to be sentences of an ordinary language (or an idealized version thereof), or if they are taken to be mental representations (sentences of the language of thought), the above points hold without qualification: correspondence will be a semantic or psycho-semantic relation. If, on the other hand, the primary truthbearers are taken to be propositions, there is a complication:
On a broadly Fregean view of propositions, propositions are constituted by concepts of objects and properties (in the logical, not the psychological, sense of “concept”). On this view, the above points still hold, since the relation between concepts, on the one hand, and the objects and properties they are concepts of, on the other, appears to be a semantic relation, a concept-semantic relation.
On the so-called Russellian view of propositions (which the early Russell inherited mostly from early Moore), propositions are constituted, not of concepts of objects and properties, but of the objects and properties themselves (cf. Russell 1903). On this view, the points above will most likely fail, since the correspondence relation would appear to collapse into the identity relation when applied to true Russellian propositions. It is hard to see how a true Russellian proposition could be anything but a fact: What would a fact be, if not this sort of thing? So the principle of Nonidentity is rejected, and with it goes the correspondence theory of truth: “Once it is definitely recognized that the proposition is to denote, not a belief or form of words, but an object of belief, it seems plain that a truth differs in no respect from the reality with which it was supposed merely to correspond” (Moore 1901-02, p. 717). A simple, fact-based correspondence theory, applied to propositions understood in the Russellian way, thus reduces to an identity theory of truth, on which a proposition is true iff it is a fact, and false, iff it is not a fact. See below, Section 8.3; and the entries on propositions, singular propositions, and structured propositions in this encyclopedia.
But Russellians don’t usually renounce the correspondence theory entirely. Though they have no room for (1) from Section 3, when applied to propositions as truthbearers, correspondence will enter into their account of truth for sentences, public or mental. The account will take the form of Section 3’s (2), applied to categories of truthbearers other than propositions, where Russellian propositions show up on the right-hand side in the guise of states of affairs that obtain or fail to obtain. Commitment to states of affairs in addition to propositions is sometimes regarded with scorn, as a gratuitous ontological duplication. But Russellians are not committed to states of affairs in addition to propositions, for propositions, on their view, must already be states of affairs. This conclusion is well nigh inevitable, once true propositions have been identified with facts. If a true proposition is a fact, then a false proposition that might have been true would have been a fact, if it had been true. So, a (contingent) false proposition must be the same kind of being as a fact, only not a fact—an unfact; but that just is a non-obtaining state of affairs under a different name. Russellian propositions are states of affairs: the false ones are states of affairs that do not obtain, and the true ones are states of affairs that do obtain.
The Russellian view of propositions is popular nowadays. Somewhat curiously, contemporary Russellians hardly ever refer to propositions as facts or states of affairs. This is because they are much concerned with understanding belief, belief attributions, and the semantics of sentences. In such contexts, it is more natural to talk proposition-language than state-of-affairs-language. It feels odd (wrong) to say that someone believes a state of affairs, or that states of affairs are true or false. For that matter, it also feels odd (wrong) to say that some propositions are facts, that facts are true, and that propositions obtain or fail to obtain. Nevertheless, all of this must be the literal truth, according to the Russellians. They have to claim that “proposition” and “state of affairs”, much like “evening star” and “morning star”, are different names for the same things—they come with different associations and are at home in somewhat different linguistic environments, which accounts for the felt oddness when one name is transported to the other’s environment.
Returning to the isomorphism approach in general, on a strict or naïve implementation of this approach, correspondence will be a one-one relation between truths and corresponding facts, which leaves the approach vulnerable to objections against funny facts (3.F1): each true truthbearer, no matter how complex, will be assigned a matching fact. Moreover, since a strict implementation of isomorphism assigns corresponding entities to all (relevant) constituents of truthbearers, complex facts will contain objects corresponding to the logical constants (“not”, “or”, “if-then”, etc.), and these “logical objects” will have to be regarded as constituents of the world. Many philosophers have found it hard to believe in the existence of all these funny facts and funny quasi-logical objects.
The isomorphism approach has never been advocated in a fully naïve form, assigning corresponding objects to each and every wrinkle of our verbal or mental utterings. Instead, proponents try to isolate the “relevant” constituents of truthbearers through meaning analysis, aiming to uncover the logical form, or deep structure, behind ordinary language and thought. This deep structure might then be expressed in an ideal-language (typically, the language of predicate logic), whose syntactic structure is designed to mirror perfectly the ontological structure of reality. The resulting view—correspondence as isomorphism between properly analyzed truthbearers and facts—avoids assigning strange objects to such phrases as “the average husband”, “the sake of”, and “the present king of France”; but the view remains committed to logically complex facts and to logical objects corresponding to the logical constants.
Austin (1950) rejects the isomorphism approach on the grounds that it projects the structure of our language onto the world. On his version of the correspondence theory (a more elaborated variant of (4) applied to statements), a statement as a whole is correlated to a state of affairs by arbitrary linguistic conventions without mirroring the inner structure of its correlate (cf. also Vision 2004). This approach appears vulnerable to the objection that it avoids funny facts at the price of neglecting systematicity. Language does not provide separate linguistic conventions for each statement: that would require too vast a number of conventions. Rather, it seems that the truth-values of statements are systematically determined, via a relatively small set of conventions, by the semantic values (relations to reality) of their simpler constituents. Recognition of this systematicity is built right into the isomorphism approach.
Critics frequently echo Austin’s “projection”-complaint, 3.F2, that a traditional correspondence theory commits “the error of reading back into the world the features of language” (Austin 1950, p. 155; cf. also, e.g., Rorty 1981). At bottom, this is a pessimistic stance: if there is a prima facie structural resemblance between a mode of speech or thought and some ontological category, it is inferred, pessimistically, that the ontological category is an illusion, a matter of us projecting the structure of our language or thought into the world. Advocates of traditional correspondence theories can be seen as taking the opposite stance: unless there are specific reasons to the contrary, they are prepared to assume, optimistically, that the structure of our language and/or thought reflects genuine ontological categories, that the structure of our language and/or thought is, at least to a significant extent, the way it is because of the structure of the world.
7. Modified Versions of the Correspondence Theory
7.1 Logical Atomism
Wittgenstein (1921) and Russell (1918) propose modified fact-based correspondence accounts of truth as part of their program of logical atomism. Such accounts proceed in two stages. At the first stage, the basic truth-definition, say (1) from Section 3, is restricted to a special subclass of truthbearers, the so-called elementary or atomic truthbearers, whose truth is said to consist in their correspondence to (atomic) facts: if x is elementary, then x is true iff x corresponds to some (atomic) fact. This restricted definition serves as the base-clause for truth-conditional recursion-clauses given at the second stage, at which the truth-values of non-elementary, or molecular, truthbearers are explained recursively in terms of their logical structure and the truth-values of their simpler constituents. For example: a sentence of the form ‘not-p’ is true iff ‘p’ is false; a sentence of the form ‘p and q’ is true iff ‘p’ is true and ‘q’ is true; a sentence of the form ‘p or q’ is true iff ‘p’ is true or ‘q’ is true, etc. These recursive clauses (called “truth conditions”) can be reapplied until the truth of a non-elementary, molecular sentence of arbitrary complexity is reduced to the truth or falsehood of its elementary, atomic constituents.
Logical atomism exploits the familiar rules, enshrined in the truth-tables, for evaluating complex formulas on the basis of their simpler constituents. These rules can be understood in two different ways: (a) as tracing the ontological relations between complex facts and constituent simpler facts, or (b) as tracing logico-semantic relations, exhibiting how the truth-values of complex sentences can be explained in terms of their logical relations to simpler constituent sentences together with the correspondence and non-correspondence of simple, elementary sentences to atomic facts. Logical atomism takes option (b).
Logical atomism is designed to go with the ontological view that the world is the totality of atomic facts (cf. Wittgenstein 1921, 2.04); thus accommodating objection 3.F2 by doing without funny facts: atomic facts are all the facts there are—although real-life atomists tend to allow conjunctive facts, regarding them as mere aggregates of atomic facts. An elementary truth is true because it corresponds to an atomic fact: correspondence is still isomorphism, but it holds exclusively between elementary truths and atomic facts. There is no match between truths and facts at the level of non-elementary, molecular truths; e.g., ‘p’, ‘p or q’, and ‘p or r’ might all be true merely because ‘p’ corresponds to a fact). The trick for avoiding logically complex facts lies in not assigning any entities to the logical constants. Logical complexity, so the idea goes, belongs to the structure of language and/or thought; it is not a feature of the world. This is expressed by Wittgenstein in an often quoted passage (1921, 4.0312): “My fundamental idea is that the ‘logical constants’ are not representatives; that there can be no representatives of the logic of facts”; and also by Russell (1918, p. 209f.): “You must not look about the real world for an object which you can call ‘or’, and say ‘Now look at this. This is ‘or’’”.
Though accounts of this sort are naturally classified as versions of the correspondence theory, it should be noted that they are strictly speaking in conflict with the basic forms presented in Section 3. According to logical atomism, it is not the case that for every truth there is a corresponding fact. It is, however, still the case that the being true of every truth is explained in terms of correspondence to a fact (or non-correspondence to any fact) together with (in the case of molecular truths) logical notions detailing the logical structure of complex truthbearers. Logical atomism attempts to avoid commitment to logically complex, funny facts via structural analysis of truthbearers. It should not be confused with a superficially similar account maintaining that molecular facts are ultimately constituted by atomic facts. The latter account would admit complex facts, offering an ontological analysis of their structure, and would thus be compatible with the basic forms presented in Section 3, because it would be compatible with the claim that for every truth there is a corresponding fact. (For more on classical logical atomism, see Wisdom 1931-1933, Urmson 1953, and the entries on Russell's logical atomism and Wittgenstein's logical atomism in this encyclopedia.)
While Wittgenstein and Russell seem to have held that the constituents of atomic facts are to be determined on the basis of a priori considerations, Armstrong (1997, 2004) advocates an a posteriori form of logical atomism. On his view, atomic facts are composed of particulars and simple universals (properties and relations). The latter are objective features of the world that ground the objective resemblances between particulars and explain their causal powers. Accordingly, what particulars and universals there are will have to be determined on the basis of total science.
Problems: Logical atomism is not easy to sustain and has rarely been held in a pure form. Among its difficulties are the following: (a) What, exactly, are the elementary truthbearers? How are they determined? (b) There are molecular truthbearers, such as subjunctives and counterfactuals, that tend to provoke the funny-fact objection but cannot be handled by simple truth-conditional clauses, because their truth-values do not seem to be determined by the truth-values of their elementary constituents. (c) Are there universal facts corresponding to true universal generalizations? Wittgenstein (1921) disapproves of universal facts; apparently, he wants to re-analyze universal generalizations as infinite conjunctions of their instances. Russell (1918) and Armstrong (1997, 2004) reject this analysis; they admit universal facts. (d) Negative truths are the most notorious problem case, because they clash with an appealing principle, the “truthmaker principle” (cf. Section 8.5), which says that for every truth there must be something in the world that makes it true, i.e., every true truthbearer must have a truthmaker. Suppose ‘p’ is elementary. On the account given above, ‘not-p’ is true iff ‘p’ is false iff ‘p’ does not correspond to any fact; hence, ‘not-p’, if true, is not made true by any fact: it does not seem to have a truthmaker. Russell finds himself driven to admit negative facts, regarded by many as paradigmatically disreputable portions of reality. Wittgenstein sometimes talks of atomic facts that do not exist and calls their very nonexistence a negative fact (cf. 1921, 2.06)—but this is hardly an atomic fact itself. Armstrong (1997, chap. 8.7; 2004, chaps. 5-6) holds that negative truths are made true by a second-order “totality fact” which says of all the (positive) first-order facts that they are all the first-order facts.
Atomism and the Russellian view of propositions (see Section 6). By the time Russell advocated logical atomism (around 1918), he had given up on what is now referred to as the Russellian conception of propositions (which he and G. E. Moore held around 1903). But Russellian propositons are popular nowadays. Note that logical atomism is not for the friends of Russellian propositions. The argument is straightforward. We have logically complex beliefs some of which are true. According to the friends of Russellian propositions, the contents of our beliefs are Russellian propositions, and the contents of our true beliefs are true Russellian propositions. Since true Russellian propositions are facts, there must be at least as many complex facts as there are true beliefs with complex contents (and at least as many complex states of affairs as there are true or false beliefs with complex contents). Atomism may work for sentences, public or mental, and for Fregean propositions; but not for Russellian propositions.
Logical atomism is designed to address objections to funny facts (3.F1). It is not designed to address objections to facts in general (3.F2). Here logical atomists will respond by defending (atomic) facts. According to one defense, facts are needed because mere objects are not sufficiently articulated to serve as truthmakers. If a were the sole truthmaker of ‘a is F’, then the latter should imply ‘a is G’, for any ‘G’. So the truthmaker for ‘a is F’ needs at least to involve a and Fness. But since Fness is a universal, it could be instantiated in another object, b, hence the mere existence of a and Fness is not sufficient for making true the claim ‘a is F’: a and Fness need to be tied together in the fact of a’s being F. Armstrong (1997) and Olson (1987) also maintain that facts are needed to make sense of the tie that binds particular objects to universals.
In this context it is usually emphasized that facts do not supervene on, hence, are not reducible to, their constituents. Facts are entities over and above the particulars and universals of which they are composed: a’s loving b and b’s loving a are not the same fact even though they have the very same constituents.
Another defense of facts, surprisingly rare, would point out that many facts are observable: one can see that the cat is on the mat; and this is different from seeing the cat, or the mat, or both. The objection that many facts are not observable would invite the rejoinder that many objects are not observable either. (See Austin 1961, Vendler 1967, chap. 5, and Vision 2004, chap. 3, for more discussion of anti-fact arguments; see also the entry facts in this encyclopedia.)
Some atomists propose an atomistic version of definition (1), but without facts, because they regard facts as slices of reality too suspiciously sentence-like to be taken with full ontological seriousness. Instead, they propose events and/or objects-plus-tropes (a.k.a. modes, particularized qualities, moments) as the corresponding portions of reality. It is claimed that these items are more “thingy” than facts but still sufficiently articulated—and sufficiently abundant—to serve as adequate truthmakers (cf. Mulligan, Simons, and Smith 1984).
7.2 Logical “Subatomism”
Logical atomism aims at getting by without logically complex truthmakers by restricting definitions like (1) or (2) from Section 3 to elementary truthbearers and accounting for the truth-values of molecular truthbearers recursively in terms of their logical structure and atomic truthmakers (atomic facts, events, objects-plus-tropes). More radical modifications of the correspondence theory push the recursive strategy even further, entirely discarding definitions like (1) or (2), and hence the need for atomic truthmakers, by going, as it were, “subatomic”.
Such accounts analyze truthbearers, e.g., sentences, into their subsentential constituents and dissolve the relation of correspondence into appropriate semantic subrelations: names refer to, or denote, objects; predicates (open sentences) apply to, or are satisfied by objects. Satisfaction of complex predicates can be handled recursively in terms of logical structure and satisfaction of simpler constituent predicates: an object o satisfies ‘x is not F’ iff o does not satisfy ‘x is F’; o satisfies ‘x is F or x is G’ iff o satisfies ‘x is F’ or o satisfies ‘x is G’; and so on. These recursions are anchored in a base-clause addressing the satisfaction of primitive predicates: an object o satisfies ‘x is F’ iff o instantiates the property expressed by ‘F’. Some would prefer a more nominalistic base-clause for satisfaction, hoping to get by without seriously invoking properties. Truth for singular sentences, consisting of a name and an arbitrarily complex predicate, is defined thus: A singular sentence is true iff the object denoted by the name satisfies the predicate. Logical machinery provided by Tarski (1935) can be used to turn this simplified sketch into a more general definition of truth—a definition that handles sentences containing relational predicates and quantifiers and covers molecular sentences as well. Whether Tarski’s own definition of truth can be regarded as a correspondence definition, even in this modified sense, is under debate (cf. Popper 1972; Field 1972, 1986; Kirkham 1992, chaps. 5-6; Soames 1999; Künne 2003, chap. 4; Patterson 2008.)
Subatomism constitutes a return to (broadly) object-based correspondence. Since it promises to avoid facts and all similarly articulated, sentence-like slices of reality, correspondence theorists who take seriously objection 3.F2 favor this approach: not even elementary truthbearers are assigned any matching truthmakers. The correspondence relation itself has given way to two semantic relations between constituents of truthbearers and objects: reference (or denotation) and satisfaction—relations central to any semantic theory. Some advocates envision causal accounts of reference and satisfaction (cf. Field 1972; Devitt 1982, 1984; Schmitt 1995; Kirkham 1992, chaps. 5-6). It turns out that relational predicates require talk of satisfaction by ordered sequences of objects. Davidson (1969, 1977) maintains that satisfaction by sequences is all that remains of the traditional idea of correspondence to facts; he regards reference and satisfaction as “theoretical constructs” not in need of causal, or any, explanation.
Problems: (a) The subatomistic approach accounts for the truth-values of molecular truthbearers in the same way as the atomistic approach; consequently, molecular truthbearers that are not truth-functional still pose the same problems as in atomism. (b) Belief attributions and modal claims pose special problems; e.g., it seems that “believes” is a relational predicate, so that “John believes that snow is white” is true iff “believes” is satisfied by John and the object denoted by “that snow is white”; but the latter appears to be a proposition or state of affairs, which threatens to let in through the back-door the very sentence-like slices of reality the subatomic approach was supposed to avoid, thus undermining the motivation for going subatomic. (c) The phenomenon of referential indeterminacy threatens to undermine the idea that the truth-values of elementary truthbearers are always determined by the denotation and/or satisfaction of their constituents; e.g., pre-relativistic uses of the term “mass” are plausibly taken to lack determinate reference (referring determinately neither to relativistic mass nor to rest mass); yet a claim like “The mass of the earth is greater than the mass of the moon” seems to be determinately true even when made by Newton (cf. Field 1973).
Problems for both versions of modified correspondence theories: (a) It is not known whether an entirely general recursive definition of truth, one that covers all truthbearers, can be made available. This depends on unresolved issues concerning the extent to which truthbearers are amenable to the kind of structural analyses that are presupposed by the recursive clauses. The more an account of truth wants to exploit the internal structure of truthbearers, the more it will be hostage to the (limited) availability of appropriate structural analyses of the relevant truthbearers. (b) Any account of truth employing a recursive framework may be virtually committed to taking sentences (maybe sentences of the language of thought) as primary truthbearers. After all, the recursive clauses rely heavily on what appears to be the logico-syntactic structure of truthbearers, and it is unclear whether anything but sentences can plausibly be said to possess that kind of structure. But the thesis that sentences of any sort are to be regarded as the primary truthbearers is contentious. Whether propositions can meaningfully be said to have an analogous (albeit non-linguistic) structure is under debate (cf. Russell 1913, King 2007). (c) If clauses like “‘p or q’ is true iff ‘p’ is true or ‘q’ is true” are to be used in a recursive account of our notion of truth, as opposed to some other notion, it has to be presupposed that ‘or’ expresses disjunction: one cannot define “or” and “true” at the same time. To avoid circularity, a modified correspondence theory (be it atomic or subatomic) must hold that the logical connectives can be understood without reference to correspondence truth.
7.3 Relocating Correspondence
Definitions like (1) and (2) from Section 3 assume, naturally, that truthbearers are true because they, the truthbearers themselves, correspond to facts. There are however views that reject this natural assumption. They propose to account for the truth of truthbearers of certain kinds, propositions, not by way of their correspondence to facts, but by way of the correspondence to facts of other items, the ones that have propositions as their contents. Consider the state of believing that p (or the activity of judging that p). The state (the activity) is not, strictly speaking, true or false; rather, what is true or false is its content, the proposition that p. Nevertheless, on the present view, it is the state of believing that p that corresponds or fails to correspond to a fact. So truth/falsehood for propositions can be defined in the following manner: x is a true/false proposition iff there is a belief state B such that x is the content of B and B corresponds/fails to correspond to a fact.
Such a modification of fact-based correspondence can be found in Moore (1927, p. 83) and Armstrong (1973, 4.iv & 9). It can be adapted to atomistic (Armstrong) and subatomistic views, and to views on which sentences (of the language of thought) are the primary bearers of truth and falsehood. However, by taking the content-carrying states as the primary corresponders, it entails that there are no truths/falsehoods that are not believed by someone. Most advocates of propositions as primary bearers of truth and falsehood will regard this as a serious weakness, holding that there are very many true and false propositions that are not believed, or even entertained, by anyone. Armstrong (1973) combines the view with an instrumentalist attitude towards propositions, on which propositions are mere abstractions from mental states and should not be taken seriously, ontologically speaking.
8. The Correspondence Theory and Its Competitors
8.1 Traditional Competitors
Against the traditional competitors—coherentist, pragmatist, and verificationist and other epistemic theories of truth—correspondence theorists raise two main sorts of objections. First, such accounts tend to lead into relativism. Take, e.g., a coherentist account of truth. Since it is possible that ‘p’ coheres with the belief system of S while ‘not-p’ coheres with the belief system of S*, the coherentist account seems to imply, absurdly, that contradictories, ‘p’ and ‘not-p’, could both be true. To avoid embracing contradictions, coherentists often commit themselves (if only covertly) to the objectionable relativistic view that ‘p’ is true-for-S and ‘not-p’ is true-for-S*. Second, the accounts tend to lead into some form of idealism or anti-realism, e.g., it is possible for the belief that p to cohere with someone’s belief system, even though it is not a fact that p; also, it is possible for it to be a fact that p, even if no one believes that p at all or if the belief does not cohere with anyone’s belief system. Cases of this sort are frequently cited as counterexamples to coherentist accounts of truth. Dedicated coherentists tend to reject such counterexamples, insisting that they are not possible after all. Since it is hard to see why they would not be possible, unless its being a fact that p were determined by the belief’s coherence with other beliefs, this reaction commits them to the anti-realist view that the facts are (largely) determined by what we believe.
This offers a bare outline of the overall shape the debates tend to take. For more on the correspondence theory vs. its traditional competitors see, e.g., Vision 1988; Kirkham 1992, chaps. 3, 7-8; Schmitt 1995; Künne 2003, chap. 7; and essays in Lynch 2001. Walker 1989 is a book-lenght discussion of coherence theories of truth. See also the entries on pragmatism, relativism, the coherence theory of truth, in this encyclopedia.
8.2 Pluralism
The correspondence theory is sometimes accused of overreaching itself: it does apply, so the objection goes, to truths from some domains of discourse, e.g., scientific discourse and/or discourse about everyday midsized physical things, but not to truths from various other domains of discourse, e.g., ethical and/or aesthetic discourse (see the first objection in Section 5 above). Alethic pluralism grows out of this objection, maintaining that truth is constituted by different properties for true propositions from different domains of discourse: by correspondence to fact for true propositions from the domain of scientific or everyday discourse about physical things; by some epistemic property, such as coherence or superassertibility, for true propositions from the domain of ethical and aesthetic discourse, and maybe by still other properties for other domains of discourse. This suggests a position on which the term “true” is multiply ambiguous, expressing different properties when applied to propositions from different domains. However, contemporary pluralists reject this problematic idea, maintaining instead that truth is “multiply realizable”. That is, the term “true” is univocal, it expresses one concept or property, truth (being true), but one that can be realized by or manifested in different properties (correspondence to fact, coherence or superassertibility, and maybe others) for true propositions from different domains of discourse. Truth itself is not to be identified with any of its realizing properties. Instead, it is characterized, quasi axiomatically, by a set of alleged “platitudes”, including, according to Crispin Wright’s (1999) version, “transparency” (to assert is to present as true), “contrast” (a proposition may be true without being justified, and v.v.), “timelesness” (if a proposition is ever true, then it always is), “absoluteness” (there is no such thing as a proposition being more or less true), and others.
Though it contains the correspondence theory as one ingredient, alethic pluralism is nevertheless a genuine competitor, for it rejects the thesis that truth is correspondence to reality. Moreover, it equally contains competitors of the correspondence theory as further ingredients.
Alethic pluralism in its contemporary form is a relatively young position. It was inaugurated by Crispin Wright (1992; see also 1999) and was later developed into a somewhat different form by Lynch (2009). Critical discussion is still at a relatively nascent stage (but see Vision 2004, chap. 4, for extended discussion of Wright). It will likely focus on two main problem areas.
First, it seems difficult to sort propositions into distinct kinds according to the subject matter they are about. Take, e.g., the proposition that killing is morally wrong, or the proposition that immoral acts happen in space-time. What are they about? Intuitively, their subject matter is mixed, belonging to the physical domain, the biological domain, and the domain of ethical discourse. It is hard to see how pluralism can account for the truth of such mixed propositions, belonging to more than one domain of discourse: What will be the realizing property?
Second, pluralists are expected to explain how the platitudes can be “converted” into an account of truth itself. Lynch (2009) proposes to construe truth as a functional property, defined in terms of a complex functional role which is given by the conjunction of the platitudes (somewhat analogous to the way in which functionalists in the philosophy of mind construe mental states as functional states, specified in terms of their functional roles—though in their case the relevant functional roles are causal roles, which is not a feasible option when it comes to the truth-role). Here the main issue will be to determine (a) whether such an account really works, when the technical details are laid out, and (b) whether it is plausible to claim that properties as different as correspondence to a fact, on the one hand, and coherence or superassertibilty, on the other, can be said to play one and the same role—a claim that seems required by the thesis that these different properties all realize the same property, being true.
For more on pluralism, see e.g. the essays in Monnoyer (2007) and in Pedersen & Wright (2013); and the entry on pluralist theories of truth in this encyclopedia.
8.3 The Identity Theory of Truth
According to the identity theory of truth, true propositions do not correspond to facts, they are facts: the true proposition that snow is white = the fact that snow is white. This non-traditional competitor of the correspondence theory threatens to collapse the correspondence relation into identity. (See Moore 1901-02; and Dodd 2000 for a book-length defense of this theory and discussion contrasting it with the correspondence theory; and see the entry the identity theory of truth: in this encyclopedia.)
In response, a correspondence theorist will point out: (a) The identity theory is defensible only for propositions as truthbearers, and only for propositions construed in a certain way, namely as having objects and properties as constituents rather than ideas or concepts of objects and properties; that is, for Russellian propositions. Hence, there will be ample room (and need) for correspondence accounts of truth for other types of truthbearers, including propositions, if they are construed as constituted, partly or wholly, of concepts of objects and properties. (b) The identity theory is committed to the unacceptable consequence that facts are true. (c) The identity theory rests on the assumption that that-clauses always denote propositions, so that the that-clause in “the fact that snow is white” denotes the proposition that snow is white. The assumption can be questioned. That-clauses can be understood as ambiguous names, sometimes denoting propositions and sometimes denoting facts. The descriptive phrases “the proposition…” and “the fact…” can be regarded as serving to disambiguate the succeeding ambiguous that-clauses—much like the descriptive phrases in “the philosopher Socrates” and “the soccer-player Socrates” serve to disambiguate the ambiguous name “Socrates” (cf. David 2002).
8.4 Deflationism About Truth
At present the most noticeable competitors to correspondence theories are deflationary accounts of truth (or ‘true’). Deflationists maintain that correspondence theories need to be deflated; that their central notions, correspondence and fact (and their relatives), play no legitimate role in an adequate account of truth and can be excised without loss. A correspondence-type formulation like
(5) “Snow is white” is true iff it corresponds to the fact that snow is white,
is to be deflated to
(6) “Snow is white” is true iff snow is white,
which, according to deflationists, says all there is to be said about the truth of “Snow is white”, without superfluous embellishments (cf. Quine 1987, p. 213).
Correspondence theorists protest that (6) cannot lead to anything deserving to be regarded as an account of truth. It is concerned with only one particular sentence (“Snow is white”), and it resists generalization. (6) is a substitution instance of the schema
(7) “p” is true iff p,
which does not actually say anything itself (it is not truth-evaluable) and cannot be turned into a genuine generalization about truth, because of its essential reliance on the schematic letter “p”, a mere placeholder. The attempt to turn (7) into a generalization produces nonsense along the lines of “For every x, “x” is true iff x”, or requires invocation of truth: “Every substitution instance of the schema ““p” is true iff p” is true”. Moreover, no genuine generalizations about truth can be accounted for on the basis of (7). Correspondence definitions, on the other hand, do yield genuine generalizations about truth. Note that definitions like (1) and (2) in Section 3 employ ordinary objectual variables (not mere schematic placeholders); the definitions are easily turned into genuine generalizations by prefixing the quantifier phrase “For every x”, which is customarily omitted in formulations intended as definitions.
It should be noted that the deflationist’s starting point, (5), which lends itself to deflating excisions, actually misrepresents the correspondence theory. According to (5), corresponding to the fact that snow is white is sufficient and necessary for “Snow is white” to be true. Yet, according to (1) and (2), it is sufficient but not necessary: “Snow is white” will be true as long as it corresponds to some fact or other. The genuine article, (1) or (2), is not as easily deflated as the impostor (5).
The debate turns crucially on the question whether anything deserving to be called an “account” or “theory” of truth ought to take the form of a genuine generalization (and ought to be able to account for genuine generalizations involving truth). Correspondence theorists tend to regard this as a (minimal) requirement. Deflationists argue that truth is a shallow (sometimes “logical”) notion—a notion that has no serious explanatory role to play: as such it does not require a full-fledged account, a real theory, that would have to take the form of a genuine generalization.
There is now a substantial body of literature on truth-deflationism in general and its relation to the correspondence theory in particular; the following is a small selection: Quine 1970, 1987; Devitt 1984; Field 1986; Horwich 1990 & 19982; Kirkham 1992; Gupta 1993; David 1994, 2008; Schmitt 1995; Künne 2003, chap. 4; Rami 2009. Relevant essays are contained in Blackburn and Simmons 1999; Schantz 2002; Armour-Garb and Beall 2005; and Wright and Pedersen 2010. See also the entry the deflationary theory of truth in this encyclopedia.
8.5 Truthmaker Theory
This approach centers on the truthmaker or truthmaking principle: Every truth has a truthmaker; or alternatively: For every truth there is something that makes it true. The principle is usually understood as an expression of a realist attitude, emphasizing the crucial contribution the world makes to the truth of a proposition. Advocates tend to treat truthmaker theory primarily as a guide to ontology, asking: To entities of what ontological categories are we committed as truthmakers of the propositions we accept as true? Most advocates maintain that propositions of different logical types can be made true by items from different ontological categories: e.g., propositions of some types are made true by facts, others just by individual things, others by events, others by tropes (cf., e.g. Armstrong 1997). This is claimed as a significant improvement over traditional correspondence theories which are understood—correctly in most but by no means all cases—to be committed to all truthmakers belonging to a single ontological category (albeit disagreeing about which category that is). All advocates of truthmaker theory maintain that the truthmaking relation is not one-one but many-many: some truths are made true by more than one truthmaker; some truthmakers make true more than one truth. This is also claimed as a significant improvement over traditional correspondence theories which are often portrayed as committed to correspondence being a one-one relation. This portrayal is only partly justified. While it is fairly easy to find real-life correspondence theorists committing themselves to the view that each truth corresponds to exactly one fact (at least by implication, talking about the corresponding fact), it is difficult to find real-life correspondence theorists committing themselves to the view that only one truth can correspond to a given fact (but see Moore 1910-11, p. 256).
A truthmaker theory may be presented as a competitor to the correspondence theory or as a version of the correspondence theory. This depends considerably on how narrowly or broadly one construes “correspondence theory”, i.e. on terminological issues. Some advocates would agree with Dummett (1959, p. 14) who said that, although “we have nowadays abandoned the correspondence theory of truth”, it nevertheless “expresses one important feature of the concept of truth…: that a statement is true only if there is something in the world in virtue of which it is true”. Other advocates would follow Armstrong who tends to present his truthmaker theory as a liberal form of correspondence theory; indeed, he seems committed to the view that the truth of a (contingent) elementary proposition consists in its correspondence with some (atomic) fact (cf. Armstrong 1997; 2004, pp. 22-3, 48-50).
It is not easy to find a substantive difference between truthmaker theory and various brands of the sort of modified correspondence theory treated above under the heading “Logical Atomism” (see Section 7.1). Logical atomists, such as Russell (1918) and Wittgenstein (1921), will hold that the truth or falsehood of every truth-value bearer can be explained in terms of (can be derived from) logical relations between truth-value bearers, by way of the recursive clauses, together with the base clauses, i.e., the correspondence and non-correspondence of elementary truth-value bearers with facts. This recursive strategy could be pursued with the aim to reject the truthmaker principle: not all truths have truthmakers, only elementary truths have truthmakers (here understood as corresponding atomic facts). But it could also be pursued—and this seems to have been Russell’s intention at the time—with the aim to secure the truthmaker principle, even though the simple correspondence definition has been abandoned: not every truth corresponds to a fact, only elementary truths do, but every truth has a truthmaker; where the recursive clauses are supposed to show how truthmaking without correspondence, but grounded in correspondence, comes about.
There is one straightforward difference between truthmaker theory and most correspondence theories. The latter are designed to answer the question “What is truth?”. Simple (unmodified) correspondence theories center on a biconditional, such as “x is true iff x corresponds to a fact”, intended to convey a definition of truth (at least a “real definition” which does not commit them to the claim that the term “true” is synonymous with “corresponds to a fact”—especially nowadays most correspondence theorists would consider such a claim to be implausibly and unnecessarily bold). Modified correspondence theories also aim at providing a definition of truth, though in their case the definition will be considerably more complex, owing to the recursive character of the account. Truthmaker theory, on the other hand, centers on the truthmaker principle: For every truth there is something that makes it true. Though this principle will deliver the biconditional “x is true iff something makes x true” (since “something makes x true” trivially implies “x is true”), this does not yield a promising candidate for a definition of truth: defining truth in terms of truthmaking would appear to be circular. Unlike most correspondence theories, truthmaker theory is not equipped, and usually not designed, to answer the question “What is truth?”—at least not if one expects the answer to take the form of a feasible candidate for a definition of truth.
There is a growing body of literature on truthmaker theory; see for example: Russell 1918; Mullligan, Simons, and Smith 1984; Fox 1987; Armstrong 1997, 2004; Merricks 2007; and the essays in Beebe and Dodd 2005; Monnoyer 2007; and in Lowe and Rami 2009. See also the entry on truthmakers in this encyclopedia.
9. More Objections to the Correspondence Theory
Two final objections to the correspondence theory deserve separate mention.
9.1 The Big Fact
Inspired by an allegedly similar argument of Frege’s, Davidson (1969) argues that the correspondence theory is bankrupt because it cannot avoid the consequence that all true sentences correspond to the same fact: the Big Fact. The argument is based on two crucial assumptions: (i) Logically equivalent sentences can be substituted salva veritate in the context ‘the fact that...’; and (ii) If two singular terms denoting the same thing can be substituted for each other in a given sentence salva veritate, they can still be so substituted if that sentence is embedded within the context ‘the fact that...’. In the version below, the relevant singular terms will be the following: ‘(the x such that x = Diogenes & p)’ and ‘(the x such that x = Diogenes & q)’. Now, assume that a given sentence, s, corresponds to the fact that p; and assume that ‘p’ and ‘q’ are sentences with the same truth-value. We have:
s corresponds to the fact that p
which, by (i), implies
s corresponds to the fact that [(the x such that x = Diogenes & p) = (the x such that x = Diogenes)],
which, by (ii), implies
s corresponds to the fact that [(the x such that x = Diogenes & q) = (the x such that x = Diogenes)],
which, by (i), implies
s corresponds to the fact that q.
Since the only restriction on ‘q’ was that it have the same truth-value as ‘p’, it would follow that any sentence s that corresponds to any fact corresponds to every fact; so that all true sentences correspond to the same facts, thereby proving the emptiness of the correspondence theory—the conclusion of the argument is taken as tantamount to the conclusion that every true sentence corresponds to the totality of all the facts, i.e, the Big Fact, i.e., the world as a whole.
This argument belongs to a type now called “slingshot arguments” (because a giant opponent is brought down by a single small weapon, allegedly). The first versions of this type of argument were given by Church (1943) and Gödel (1944); it was later adapted by Quine (1953, 1960) in his crusade against quantified modal logic. Davidson is offering yet another adaption, this time involving the expression “corresponds to the fact that”. The argument has been criticized repeatedly. Critics point to the two questionable assumptions on which it relies, (i) and (ii). It is far from obvious why a correspondence theorist should be tempted by either one of them. Opposition to assumption (i) rests on the view that expressibility by logically equivalent sentences may be a necessary, but is not a sufficient condition for fact identity. Opposition to assumption (ii) rests on the observation that the (alleged) singular terms used in the argument are definite descriptions: their status as genuine singular terms is in doubt, and it is well-known that they behave rather differently than proper names for which assumption (ii) is probably valid (cf. Follesdal 1966/2004; Olson 1987; Künne 2003; and especially the extended discussion and criticism in Neale 2001.)
The objection that may well have been the most effective in causing discontent with the correspondence theory is based on an epistemological concern. In a nutshell, the objection is that a correspondence theory of truth must inevitably lead into skepticism about the external world, because the required correspondence between our thoughts and reality is not ascertainable. Ever since Berkeley’s attack on the representational theory of the mind, objections of this sort have enjoyed considerable popularity. It is typically pointed out that we cannot step outside our own minds to compare our thoughts with mind-independent reality. Yet—so the objection continues—on the correspondence theory of truth, this is precisely what we would have to do to gain knowledge. We would have to access reality as it is in itself, independently of our cognition, and determine whether our thoughts correspond to it. Since this is impossible, since all our access to the world is mediated by our cognition, the correspondence theory makes knowledge impossible (cf. Kant 1800, intro vii). Assuming that the resulting skepticism is unacceptable, the correspondence theory has to be rejected, and some other account of truth, an epistemic (anti-realist) account of some sort, has to be put in its place (cf., e.g., Blanshard 1941.)
This type of objection brings up a host of issues in epistemology, the philosophy of mind, and general metaphysics. All that can be done here is to hint at a few pertinent points (cf. Searle 1995, chap. 7; David 2004, 6.7). The objection makes use of the following line of reasoning: “If truth is correspondence, then, since knowledge requires truth, we have to know that our beliefs correspond to reality, if we are to know anything about reality”. There are two assumptions implicit in this line of reasoning, both of them debatable.
(i) It is assumed that S knows x, only if S knows that x is true—a requirement not underwritten by standard definitions of knowledge, which tell us that S knows x, only if x is true and S is justified in believing x. The assumption may rest on confusing requirements for knowing x with requirements for knowing that one knows x.
(ii) It is assumed that, if truth = F, then S knows that x is true, only if S knows that x has F. This is highly implausible. By the same standard it would follow that no one who does not know that water is H2O can know that the Nile contains water—which would mean, of course, that until fairly recently nobody knew that the Nile contained water (and that, until fairly recently, nobody knew that there were stars in the sky, whales in the sea, or that the sun gives light). Moreover, even if one does know that water is H2O, one’s strategy for finding out whether the liquid in one’s glass is water does not have to involve chemical analysis: one could simply taste it, or ask a reliable informant. Similarly, as far as knowing that x is true is concerned, the correspondence theory does not entail that we have to know that a belief corresponds to a fact in order to know that it is true, or that our method of finding out whether a belief is true has to involve a strategy of actually comparing a belief with a fact—although the theory does of course entail that one obtains knowledge only if one obtains a belief that corresponds to a fact.
More generally, one might question whether the objection still has much bite once the metaphors of “accessing” and “comparing” are spelled out with more attention to the psychological details of belief formation and to epistemological issues concerning the conditions under which beliefs are justified or warranted. For example, it is quite unclear how the metaphor of “comparing” applies to knowledge gained through perceptual belief-formation. A perceptual belief that p may be true, and by having acquired that belief, one may have come to know that p, without having “compared” (the content of) one’s belief with anything.
One might also wonder whether its competitors actually enjoy any significant advantage over the correspondence theory, once they are held to the standards set up by this sort of objection. For example, why should it be easier to find out whether one particular belief coheres with all of one’s other beliefs than it is to find out whether a belief corresponds with a fact?
In one form or other, the “No independent access to reality”-objection against correspondence theoretic approaches has been one of the, if not the, main source and motivation for idealist and anti-realist stances in philosophy (cf. Stove 1991). However, the connection between correspondence theories of truth and the metaphysical realism vs. anti-realism (or idealism) debate is less immediate than is often assumed. On the one hand, deflationists and identity theorists can be, and typically are, metaphysical realists while rejecting the correspondence theory. On the other hand, advocates of a correspondence theory can, in principle, be metaphysical idealists (e.g. McTaggart 1921) or anti-realists, for one might advocate a correspondence theory while maintaining, at the same time, (a) that all facts are constituted by mind or (b) that what facts there are depends somehow on what we believe or are capable of believing, or (c) that the correspondence relation between true propositions and facts depends somehow on what we believe or are capable of believing (claiming that the correspondence relation between true beliefs or true sentences and facts depends on what we believe can hardly count as a commitment to anti-realism). Keeping this point in mind, one can nevertheless acknowledge that advocacy of a correspondence theory of truth comes much more naturally when combined with a metaphysically realist stance and usually signals commitment to such a stance.
Bibliography
Adams McCord, M., 1987, William Ockham, Notre Dame: Notre Dame University Press.
Alston, W. P., 1996, A Realist Conception of Truth, Ithaca and London: Cornell University Press.
Armour-Garb, B. and Beall, J. C., eds., 2005, Deflationary Truth, Chicago: Open Court.
Armstrong, D. M., 1973, Belief, Truth and Knowledge, Cambridge: Cambridge University Press.
–––, 1997, A World of States of Affairs, Cambridge: Cambridge University Press.
–––, 2004, Truth and Truthmakers, Cambridge: Cambridge University Press.
Austin, J. L., 1950, ‘Truth’, reprinted in Philosophical Papers, 3rd ed., Oxford: Oxford University Press 1979, 117-33.
–––, 1961, ‘Unfair to Facts’, reprinted in Philosophical Papers, 3rd ed., Oxford: Oxford University Press 1979, 154-74.
Averroes, Tahafut Al-Tahafut, trans. by S. Van Den Berg, The Incoherence of the Incoherence, London: Luzac & Co. 1954.
Baylis, C. A., 1948, ‘Facts, Propositions, Exemplification and Truth’, Mind, 57: 459-79.
Beebe, H. and Dodd, J., eds., 2005, Truthmakers: The Contemporary Debate, Oxford: Clarendon Press.
Blackburn, S., 1984, Spreading the Word: Groundings in the Philosophy of Language, Oxford: Clarendon Press.
Blackburn, S., and Simmons, K., eds., 1999, Truth, Oxford: Oxford University Press.
Blanshard, B., 1941, The Nature of Thought, vol. 2, New York: The Macmillan Company.
Boehner, P., 1945, ‘Ockham’s Theory of Truth’, in Collected Articles on Ockham, St. Bonaventure, N.Y.: Franciscan Institute 1958.
Bolzano, B., 1837, Wissenschaftslehre, Seidel: Sulzbach. Translated as Theory of Science, edited by Paul Rusnock and Rolf George, Oxford: Oxford University Press 2014.
Bourget, D. and Chalmers, D., 2014, ‘What Do Philosophers Believe?’, Philosophical Studies, 170: 465-500.
Bradley, F. H., 1883, The Principles of Logic, Oxford: Oxford University Press.
Broad, C. D., 1933, Examination of McTaggart’s Philosophy, vol. 1, Cambridge: Cambridge University Press.
Buridan, J., Sophismata, in Summulae de dialectica, translated by G. Klima, New Haven: Yale University Press 2001.
Church, A., 1943, ‘Review of Carnap’s Introduction to Semantics’, Philosophical Review, 52: 298-304.
Crivelli, P., 2004, Aristotle on Truth, Cambridge: Cambridge University Press.
David, M., 1994, Correspondence and Disquotation: An Essay on the Nature of Truth, Oxford: Oxford University Press.
–––, 2002, ‘Truth and Identity’, in J. K. Campbell, M. O’Rourke, and D. Shier, eds., Meaning and Truth: Investigations in Philosophical Semantics, New York-London: Seven Bridges Press, 124-41. [Preprint available online]
–––, 2004, ‘Theories of Truth’, in I. Niiniluoto, M. Sintonen and J. Wolenski, eds., Handbook of Epistemology, Dordrecht: Kluwer Academic Publishers, 331-414.
–––, 2004a, ‘Don’t Forget About the Correspondence Theory of Truth’, in F. Jackson and G. Priest, eds., Lewisian Themes: The Philosophy of David K. Lewis, Oxford: Clarendon Press, 43-48.
–––, 2008, ‘Quine’s Ladder: Two and a Half Pages from the Philosophy of Logic’, in French, Uehling, Wettstein, eds., Midwest Studies in Philosophy, 32: 274-312. [Preprint available online]
–––, 2009, ‘Truth-Making and Correspondence’, in E. J. Lowe and A. Rami, eds., Truth and Truth-Making, Stocksfield: Acumen Press/Montreal: McGill-Queen's University Press, 137-57.
Davidson, D., 1969, ‘True to the Facts’, The Journal of Philosophy, 66: 748-64.
–––, 1977, ‘Reality Without Reference’, Dialectica, 31: 247-53.
Denyer, N., 1991, Language, Thought and Falsehood in Ancient Greek Philosophy, London and New York: Routledge.
Descartes, R., 1639, ‘Letter to Mersenne: 16 October 1639’, in The Philosophical Writings of Descartes, vol. 3, Cambridge: Cambridge University Press 1991, 138-40.
Devitt, M., 1982, Designation, New York: Columbia University Press.
–––, 1984, Realism and Truth, 2nd ed., Oxford: Blackwell 1991.
Dodd, J., 2000, An Identity Theory of Truth, New York: St. Martin’s Press.
Dummett, M., 1959, ‘Truth’; reprinted in Truth and Other Enigmas, Cambridge, Mass.: Harvard University Press, 1-28.
Englebretsen, G., 2006, Bare Facts and Truth: An Essay on the Correspondence Theory of Truth, Aldershot Hants: Ashgate Publishing Company.
Field, H., 1972, ‘Tarski‘s Theory of Truth’, The Journal of Philosophy, 69: 347-75.
–––, 1973, ‘Theory Change and the Indeterminacy of Reference’, The Journal of Philosophy, 70: 462-81.
–––, 1986, ‘The Deflationary Concept of Truth’, in G. Macdonald and C. Wright, eds., Fact, Science and Morality: Essays on A. J. Ayer’s ‘Language, Truth & Logic’, Oxford: Basil Blackwell, 55-117.
Fodor, J., 1975, The Language of Thought, Cambridge, Mass.: Harvard University Press.
Follesdal, D., 1966/2004, Referential Opacity and Modal Logic, New York and London: Routledge.
Forbes, G., 1986, ‘Truth, Correspondence and Redundancy’, in G. Macdonald and C. Wright, eds., Fact, Science and Morality: Essays on A. J. Ayer‘s ‘Language, Truth & Logic’, Oxford: Basil Blackwell, 27-54.
Fox, J. F., 1987, ‘Truthmaker’, Australasian Journal of Philosophy, 65: 188-207.
Frege, G., 1879, Begriffsschrift, Louis Nebert: Halle.
–––, 1918-19, ‘Der Gedanke: Eine logische Untersuchung’, Beiträge zur Philosophie des deutschen Idealismus, 1, 58-77. English translation: ‘Thoughts’, in Collected Papers, edited by B. McGuinness, Oxford: Basil Blackwell 1984.
Fumerton, R., 2002, Realism and the Correspondence Theory of Truth, Lanham: Rowman & Littlefield.
Geach, P. T. , 1960, ‘Ascriptivism’; reprinted in Logic Matters, Oxford: Basil Blackwell 1981: 250-254.
–––, 1965, ‘Assertion’; reprinted in Logic Matters, Oxford: Basil Blackwell 1981: 254-269.
Gödel, K., 1944, ‘Russell’s Mathematical Logic’, in P. A. Schilpp, ed., The Philosophy of Bertrand Russell, Evanston, Ill.: Northwestern University.
Gupta, A., 1993, ‘A Critique of Deflationism’, Philosophical Topics, 21: 57-81.
Hochberg, H., 1978, Thought, Fact and Reference: The Origins and Ontology of Logical Atomism, Minneapolis: University of Minnesota Press.
Horgan, T. E. and Potrc, M., 2008, Austere Realism: Contextual Semantics Meets Minimal Ontology, Cambridge, Mass.: The MIT Press.
Horwich, P., 1990, 19982, Truth, Oxford: Blackwell; 2nd ed.: Oxford: Oxford Clarendon Press.
Hume, D., 1739-40, A Treatise of Human Nature, Oxford: Clarendon Press 1978.
Husserl, E., 1900, Logische Untersuchungen. Erster Teil: Prolegomena zur reinen Logik, Halle a. S.: Max Niemeyer.
James, W., 1907, Pragmatism, in Pragmatism and The Meaning of Truth, Cambridge, Mass.: Harvard University Press, 1975.
Joachim, H. H., 1906, The Nature of Truth, 2nd ed., Oxford: Oxford University Press 1936.
Kant, I., 1787, Critique of Pure Reason, New York: St. Martin’s Press 1929.
–––, 1800, The Jäsche Logic, in Lectures on Logic, Cambridge: Cambridge University Press 1992.
King, J. C., 2007, The Nature and Structure of Content, Oxford: Oxford University Press.
Kirkham, R. L., 1992, Theories of Truth: A Critical Introduction, Cambridge, Mass.: MIT Press.
Künne, W., 2003, Conceptions of Truth, Oxford: Clarendon Press.
Lowe, E. G. and Rami, A., eds., 2009, Truth and Truth-Making, Stocksfield: Acumen Press/Montreal: McGill-Queen’s University Press.
Lynch, M. P., 2009, Truth as One and Many, Oxford: Clarendon Press.
Lynch, M. P., ed., 2001, The Nature of Truth: From the Classic to the Contemporary, Cambridge, Mass.: The MIT Press.
McTaggart, J., 1921, The Nature of Existence, Cambridge: Cambridge Univesity Press.
Meinong, A., 1902, Über Annahmen, J. A. Barth: Leipzig. Second edition (1910) translated as On Assumptions, edited by James Heanue, Berkeley: University of California Press 1983.
Merricks, T., 2007, Truth and Ontology, Oxford: Clarendon Press.
Mill, J. St., 1843, System of Logic, J. M. Robson, ed., London & New York: Routledge 1996.
Monnoyer, J.-M., ed., 2007, Metaphysics and Truthmakers, Frankfurt: Ontos Verlag.
Moody, E. A., 1953, Truth and Consequence in Medieval Logic, Amsterdam: North Holland Publishing Comp.
Moore, G. E., 1901-02, ‘Truth and Falsity’; reprinted in Selected Writings, edited by T. Baldwin, London and New York: Routledge 1993, 20-22.
–––, 1910-11, Some Main Problems of Philosophy, London: George Allen & Unwin, 1953.
–––, 1927, ‘Facts and Propositions’, in Philosophical Papers, London: George Allen & Unwin, 1959: 60-88.
Mulligan, K., Simons, P., and Smith, B., 1984, ‘Truth Makers’, Philosophy and Phenomenological Research, 44: 287-321. [Preprint available online]
Neale, S., 2001, Facing Facts, Oxford: Clarendon Press.
Ockham, W., Summa Logicae, in Ockham’s Theory of Propositions: Part II of the Summa Logicae, translated by A. J. Freddoso and H. Schuurman, South Bend: St. Augustines Press 2009.
O’Connor, D. J., 1975, The Correspondence Theory of Truth, London: Hutchinson.
Olson, K. R., 1987, An Essay on Facts (CSLI Lecture Notes), Stanford: CSLI Publications.
Patterson, D., 2003, ‘What is a Correspondence Theory of Truth?’, Synthese, 137: 421-44.
Patterson, D., ed., 2008, New Essays on Tarski and Philosophy, Oxford: Oxford University Press.
Pedersen, N. and Wright, Cory D., eds., 2013, Truth and Pluralism: Current Debates, Oxford: Oxford University Press.
Perler, D., 2006, ‘Der propositionale Wahrheitsbegriff im Spätmittelalter’, in M. Enders and J. Szaif, eds., Die Geschichte des philosophischen Begriffs der Wahrheit, Berlin-New York: De Gruyter, 191-210.
Philoponus, In Aristotelis Categorias Commentaria, edited by A. Busse, Berlin 1898.
Pitcher, G., 1964, ‘Introduction’, in G. Pitcher, ed., Truth, Englewood Cliffs: Prentice-Hall, 1-15.
Popper, K., 1972, ‘Philosophical Comments on Tarski’s Theory of Truth’, in Objective Knowledge: An Evolutionary Approach, Oxford: Clarendon Press, 319-40.
Prior, A. N., 1967, ‘Correspondence Theory of Truth’, in P. Edwards, ed., The Encyclopedia of Philosophy, vol. 2, New York: Macmillan Publishing Co. & The Free Press, 223-32.
Proklos, In Platonis Timaeum Commentaria, edited by E. Diehl, Leipzig, 1904.
Quine, W. V. O., 1953, ‘Three Grades of Modal Involvement’, reprinted in Ways of Paradox, 2nd ed., Cambridge, Mass.: Harvard University Press 1976.
–––, 1960, Word and Object; Cambridge, Mass.: The MIT Press.
–––, 1970, Philosophy of Logic; 2nd ed.: Cambridge, Mass.: Harvard University 1986.
–––, 1987, Quiddities: An Intermittently Philosophical Dictionary, Cambridge, Mass.: Harvard University Press.
Rami, A., 2009, Wahrheit und Deflation: Eine kritische Untersuchung deflationärer Wahrheitstheorien, Paderborn: Mentis.
Rorty, R., 1981, Philosophy and the Mirror of Nature, Princeton: Princeton University Press.
Russell, B., 1903, The Principles of Mathematics, London: Allen and Unwin.
–––, 1905, ‘The Nature of Truth’, in The Collected Works of Bertrand Russell, vol. 4, edited by A. Urquhaut, London and New York: Routledge 1994, 492-506.
–––, 1906-07, ‘On the Nature of Truth’, Proceedings of the Aristotelian Society, 7: 28-49.
–––, 1908, ‘William James’s Conception of Truth’; reprinted in Philosophical Essays, New York: Simon and Schuster 1966, 112-130.
–––, 1910, Principia Mathematica to *56, with A. N. Whitehead, Cambridge: Cambridge University Press 1962.
–––, 1912, Problems of Philosophy, reprinted at Oxford: Oxford University Press 1971.
–––, 1913, Theory of Knowledge: The 1913 Manuscript; London: George Allen & Unwin 1984.
–––, 1918, ‘The Philosophy of Logical Atomism’, in Logic and Knowledge: Essays 1901-1950, edited by R. C. Marsh, London: George Allen and Unwin 1956, 177-281.
–––, 1919, ‘On Propositions’; reprinted in Logic and Knowledge: Essays 1901-1950, edited by R. C. Marsh, London: George Allen and Unwin 1956, 283-320.
Schantz, R., ed., 2002, What is Truth?, Berlin-New York: De Gruyter.
Schmitt, F. F., 1995, Truth: A Primer, Boulder: Westview Press.
Searle, J. R., 1995, The Construction of Social Reality, New York: The Free Press.
Sher, G., 1985, ‘On the Possibility of a Substantive Theory of Truth’, Synthese, 117: 133-172.
Simons, P., 1985, ‘The Old Problem of Complex and Fact’, Teoria, 5: 205-25.
Smith, B., 1989, ‘Constraints on Correspondence’, in H. Rutte, W. Sauer, W. Gombocz, eds., Traditionen und Perspektiven der analytischen Philosophie, Vienna: Hölder, Pichler, Tempski, 415-30. [Preprint available online]
–––, 1999, ‘Truthmaker Realism’, Australasian Journal of Philosophy, 77: 274-91. [Preprint available online]
Soames, S., 1999, Understanding Truth, Oxford-New York: Oxford University Press.
Strawson, P. F., 1950, ‘Truth’; reprinted in G. Pitcher, ed., Truth, Englewood Cliffs: Prentice-Hall 1964, 32-53.
Stove, D., 1991, The Plato Cult and Other Philosophical Follies, Oxford: Blackwell.
Szaif, J., 1996, Platons Begriff der Wahrheit, Freiburg/München: Verlag Karl Albert.
Szaif, J., 2006, ‘Die Geschichte des Wahrheitsbegriffs in der klassischen Antike’, in M. Enders and J. Szaif, eds., Die Geschichte des philosophischen Begriffs der Wahrheit, Berlin-New York: De Gruyter, 1-32.
Tarski, A., 1935, ‘The Concept of Truth in Formalized Languages’, in Logic, Semantics, Metamathematics, 2nd ed., Indianapolis: Hackett 1983, 152-278.
Taylor, B., 1976, ‘States of Affairs’, in G. Evans and J. McDowell, eds., Truth and Meaning: Essays in Semantics, Oxford: Clarendon, 263-84.
Urmson, J. O., 1956, Philosophical Analysis: Its Development Between the Two World Wars, Oxford: Clarendon Press.
Vendler, Z., 1967, Linguistics in Philosophy, Ithaca: Cornell University Press.
Vision, G., 1988, Modern Anti-Realism and Manufactured Truth, London & New York: Routledge.
–––, 2004, Veritas: The Correspondence Theory and Its Critics, Cambridge, Mass.: The MIT Press.
Walker, R. C. S., 1989, The Coherence Theory of Truth: Realism, Anti-Realism, Idealism, London & New York: Routledge.
Wisdom, J., 1931-33, ‘Logical Constructions I-V’, in Mind, 40: 188-216, 460-475; Mind, 41: 441-464; Mind, 42: 43-66, 186-202.
Wittgenstein, L., 1921, Tractatus Logico-Philosophicus, in Annalen der Naturphilosophie. English translation by D. F. Pears & B. F. McGuinnes, London & Henley: Routledge & Kegan Paul 1961.
–––, 1914-16, Notebooks 1914-1916, edited by G. H. von Wright & G. E. Anscombe, Oxford: Basil Blackwell 1961.
Wolenski, J., 1994, ‘Contributions to the History of the Classical Truth-Definition’, in Logic, Methodology and Philosophy of Science, 9: 481-95.
Wolenski, J. and Simons, P., 1989, ‘De Veritate: Austro-Polish Contributions to the Theory of Truth From Brentano to Tarksi’, in K. Szaniawski, ed., The Vienna Circle and the Lvov-Warsaw School, Dordrecht: Kluwer, 481-95.
Woozley, A. D., 1949, Theory of Knowledge, London: Hutchinson.
Wright, Cory D. and Pedersen, N., eds., 2010, New Waves in Truth, New York: Palgrave Macmillan.
Wright, Crispin, 1992, Truth and Objectivity, Cambridge, Mass.: Harvard University Press.
–––, 1999, ‘Truth: A Traditional Debate Reviewed’; reprinted in Saving the Differences: Essays on Themes from ‘Truth and Objectivity’, Cambridge, Mass.: Harvard University Press 2003, 241-87.
Academic Tools
Related Entries
belief | facts | language of thought hypothesis | liar paradox | logical atomism: Russell's | logic and ontology | Meinong, Alexius | Moore, George Edward | object | pragmatism | properties | propositions | propositions: singular | propositions: structured | realism | relativism | Russell, Bertrand | states of affairs | Tarski, Alfred | tropes | truth | truth: axiomatic theories of | truth: coherence theory of | truth: deflationary theory of | truth: identity theory of | truthlikeness | truthmakers | Wittgenstein, Ludwig | Wittgenstein, Ludwig: logical atomismThe Language of Thought Hypothesis (LOTH) postulates that thought and thinking take place in a mental language. This language consists of a system of representations that is physically realized in the brain of thinkers and has a combinatorial syntax (and semantics) such that operations on representations are causally sensitive only to the syntactic properties of representations. According to LOTH, thought is, roughly, the tokening of a representation that has a syntactic (constituent) structure with an appropriate semantics. Thinking thus consists in syntactic operations defined over such representations. Most of the arguments for LOTH derive their strength from their ability to explain certain empirical phenomena like productivity and systematicity of thought and thinking.
1. What is the Language of Thought Hypothesis?
4. Nativism and LOTH
Bibliography
Academic Tools
Other Internet Resources
Related Entries
1. What is the Language of Thought Hypothesis?
LOTH is an empirical thesis about the nature of thought and thinking. According to LOTH, thought and thinking are done in a mental language, i.e., in a symbolic system physically realized in the brain of the relevant organisms. In formulating LOTH, philosophers have in mind primarily the variety of thoughts known as ‘propositional attitudes’. Propositional attitudes are the thoughts described by such sentence forms as ‘S believes that P’, ‘S hopes that P’, ‘S desires that P’, etc., where ‘S’ refers to the subject of the attitude, ‘P’ is any sentence, and ‘that P’ refers to the proposition that is the object of the attitude. If we let ‘A’ stand for such attitude verbs as ‘believe’, ‘desire’, ‘hope’, ‘intend’, ‘think’, etc., then the propositional attitude statements all have the form: S As that P.
LOTH can now be formulated more exactly as a hypothesis about the nature of propositional attitudes and the way we entertain them. It can be characterized as the conjunction of the following three theses (A), (B) and (C):
Representational Theory of Mind (RTM) (cf. Field 1978:37, Fodor 1987:17):
Representational Theory of Thought: For each propositional attitude A, there is a unique and distinct (i.e. dedicated)[1] psychological relation R, and for all propositions P and subjects S, S As that P if and only if there is a mental representation #P# such that
S bears R to #P#, and
#P# means that P.
Representational Theory of Thinking: Mental processes, thinking in particular, consists of causal sequences of tokenings of mental representations.
Mental representations, which, as per (A1), constitute the direct “objects” of propositional attitudes, belong to a representational or symbolic system which is such that (cf. Fodor and Pylyshyn 1988:12–3)
representations of the system have a combinatorial syntax and semantics: structurally complex (molecular) representations are systematically built up out of structurally simple (atomic) constituents, and the semantic content of a molecular representation is a function of the semantic content of its atomic constituents together with its syntactic/formal structure, and
the operations on representations (constituting, as per (A2), the domain of mental processes, thinking) are causally sensitive to the syntactic/formal structure of representations defined by this combinatorial syntax.
Functionalist Materialism. Mental representations so characterized are, at some suitable level, functionally characterizable entities that are (possibly, multiply) realized by the physical properties of the subject having propositional attitudes (if the subject is an organism, then the realizing properties are presumably the neurophysiological properties of the brain).
The relation R in (A1), when RTM is combined with (B), is meant to be understood as a computational/functional relation. The idea is that each attitude is identified with a characteristic computational/functional role played by the mental sentence that is the direct “object” of that kind of attitude. (Scare quotes are necessary because it is more appropriate to reserve ‘object’ for a proposition as we have done above, but as long as we keep this in mind, it is harmless to use it in this way for LOT sentences.) For instance, what makes a certain mental sentence an (occurrent) belief might be that it is characteristically the output of perceptual systems and input to an inferential system that interacts decision-theoretically with desires to produce further sentences or action commands. Or equivalently, we may think of belief sentences as those that are accessible only to certain sorts of computational operations appropriate for beliefs, but not to others. Similarly, desire-sentences (and sentences for other attitudes) may be characterized by a different set of operations that define a characteristic computational role for them. In the literature it is customary to use the metaphor of a “belief-box” (cf. Schiffer 1981) as a blanket term to cover whatever specific computational role belief sentences turn out to have in the mental economy of their possessors. (Similarly for “desire-box”, etc.)
The Language of Thought Hypothesis is so-called because of (B): token mental representations are like sentences in a language in that they have a syntactically and semantically regimented constituent structure. Put differently, the mental representations that are the direct “objects” of attitudes are structurally complex symbols whose complexity lends itself to a syntactic and semantic analysis. This is also why the LOT is sometimes called Mentalese.
It is (B2) that makes LOTH a species of the so-called Computational Theory of Mind (CTM). This is why LOTH is sometimes called the Computational/Representational Theory of Mind or Thought (CRTM/CRTT) (cf. Rey 1991, 1997). Indeed, LOTH seems to be the most natural product when RTM is combined with a view that treats mental processes or thinking as computational when computation is understood traditionally or classically (this is a recent term emphasizing the contrast with connectionist processing, which we will discuss later).
According to LOTH, when someone believes that P, there is a sense in which the immediate “object” of one's belief can be said to be a complex symbol, a sentence in one's LOT physically realized in the neurophysiology of one's brain, that has both syntactic structure and a semantic content, namely the proposition that P. So, contrary to the orthodox view that takes the belief relation as a dyadic relation between an agent and a proposition, LOTH takes it to be a triadic relation among an agent, a Mentalese sentence, and a proposition. The Mentalese sentence can then be said to have the proposition as its semantic/intentional content. Within the framework of LOTH, it is only in this sense can it be said that what is believed is a proposition, and thus the proper object of the attitude.
This triadic view seems to have several advantages over the orthodox dyadic view. It is a puzzle in the dyadic view how intentional organisms can stand in direct relation to abstract objects like propositions in such a way as to influence their causal powers. According to folk psychology (ordinary commonsense psychology that we rely on daily in our dealings with others), it is because those states have the propositional content they do that they have the causal powers they do. LOTH makes this relatively non-mysterious by introducing a physical intermediary that is capable of having the relevant causal powers in virtue of its syntactic structure that encodes its semantic content. Another advantage of this is that the thought processes can be causally guided by the syntactic forms of the sentences in a way that respect their semantic contents. This is the virtue of (B) to which we'll come back below. Mainly because of these features, LOTH is said to be poised to scientifically vindicate folk psychology if it turns out to be true.
2. Status of LOTH
LOTH has primarily been advanced as an empirical thesis (although some have argued for the truth of LOTH on a priori or conceptual grounds following the natural conceptual contours of folk psychology—see Davies 1989, 1991; Lycan 1993; Rey 1995; Jacob 1997; Markic 2001 argues against Jacob. Harman 1973 develops and defends LOTH on both empirical and conceptual grounds). It is not meant to be taken as an analysis of what the folk mean (or, for that matter, what the scientists ought to mean) when they talk about various propositional attitudes and their role in thinking. In this regard, LOT theorists typically view themselves as engaged in some sort of a proto-science, or at least in some empirical research program continuous with scientific psychology. Indeed, as we will see in more detail below, when Jerry Fodor first explicitly articulated and elaborated LOTH in some considerable detail in his (1975), he basically defended it on the ground that it was assumed by our best scientific theories or models in cognitive psychology and psycholinguistics. This empirical status generally accorded to LOTH should be kept firmly in mind when assessing its plausibility and especially its prospects in the light of new evidence and developments in scientific psychology. Nevertheless, it would be more appropriate to see LOTH more as a foundational thesis rather than as an ongoing research project guided by a set of concrete empirical methods, specific theses and principles. In this regard, LOTH stands to specific scientific theories of the (various aspects of the) mind somewhat like the “Atomic Hypothesis” stands to a whole bunch specific scientific theories about the particulate nature of the world (some of which may be—and certainly historically, have been—incompatible with each other).
When viewed this way, scientific theories advanced within the LOTH framework are not, strictly speaking, committed to preserving the folk taxonomy of the mental states in any very exact way. Notions like belief, desire, hope, fear, etc. are folk notions and, as such, it may not be utterly plausible to expect (eliminativist arguments aside) that a scientific psychology will preserve the exact contours of these concepts. On the contrary, there is every reason to believe that scientific counterparts of these notions will carve the mental space somewhat differently. For instance, it has been noted that the folk notion of belief harbors many distinctions. For example, it has both a dispositional and an occurrent sense. In the occurrent sense, it seems to mean something like consciously entertaining and accepting a thought (proposition) as true. There is quite a bit of literature and controversy on the dispositional sense.[2] Beliefs are also capable of being explicitly stored in long term memory as opposed to being merely dispositional or tacit. Compare, for instance: I believe that there was a big surprise party for my 24th birthday vs. I have always believed that lions don't eat their food with forks and knives, or that 13652/4=3413, even though until now these latter two thoughts had never occurred to me. There is furthermore the issue of degree of belief: while I may believe that George will come to dinner with his new girlfriend even though I wouldn't bet on it, you, thinking that you know him better than I do, may nevertheless go to the wall for it. It is unlikely that there will be one single construct of scientific psychology that will exactly correspond to the folk notion of belief in all these ways.
For LOTH to vindicate folk psychology it is sufficient that a scientific psychology with a LOT architecture come up with scientifically grounded psychological states that are recognizably like the propositional attitudes of folk psychology, and that play more or less similar roles in psychological explanations.[3]
3. Scope of LOTH
LOTH is an hypothesis about the nature of thought and thinking with propositional content. As such, it may or may not be applicable to other aspects of mental life. Officially, it is silent about the nature of some mental phenomena such as experience, qualia,[4] sensory processes, mental images, visual and auditory imagination, sensory memory, perceptual pattern-recognition capacities, dreaming, hallucinating, etc. To be sure, many LOT theorists hold views about these aspects of mental life that sometimes make it seem that they are also to be explained by something similar to LOTH.[5]
For instance, Fodor (1983) seems to think that many modular input systems have their own LOT to the extent to which they can be explained in representational and computational terms. Indeed, many contemporary psychological models treat perceptual input systems in just these terms.[6] There is indeed some evidence that this kind of treatment might be appropriate for many perceptual processes. But it is to be kept in mind that a system may employ representations and be computational without necessarily satisfying any or both of the clauses in (B) above in any full-fledged way. Just think of finite automata theory where there are plenty of examples of a computational process defined over states or symbols which lack full-blown syntactic and/or semantic structural complexity. (For a useful discussion of varieties of computational processes and their classification, see Piccinini 2008.) Whether sensory or perceptual processes are to be treated within the framework of full-blown LOTH is again an open empirical question. It might be that the answer to this question is affirmative. If so, there may be more than one LOT realized in different subsystems or mechanisms in the mind/brain. So LOTH is not committed to there being a single representational system realized in the brain, nor is it committed to the claim that all mental representations are complex or language-like, nor would it be falsified if it turns out that most aspects of mental life other than the ones involving propositional attitudes don't require a LOT.
Similarly, there is strong evidence that the mind also exploits an image-like representational medium for certain kinds of mental tasks.[7] LOTH is non-committal about the existence of an image-like representational system for many mental tasks other than the ones involving propositional attitudes. But it is committed to the claim that propositional thought and thinking cannot be successfully accounted for in its entirety in purely imagistic terms. It claims that a combinatorial sentential syntax is necessary for propositional attitudes and a purely imagistic medium is not adequate for capturing that.[8]
There are in fact some interesting and difficult issues surrounding these claims. The adequacy of an imagistic system seems to turn on the nature of syntax at the sentential level. For instance, Fodor, in Chapter 4 of his (1975) book, allows that many lexical items in one's LOT may be image-like; he introduces the notion of a mental image/picture under description to avoid some obvious inadequacies of pictures (e.g., what makes a picture a picture of an overweight woman rather than a pregnant one, or vice versa, etc.). This is an attempt to combine discursive and imagistic representational elements at the lexical level. There may even be a well defined sense in which pictures can be combined to produce structurally complex pictures (as in British Empiricism: image-like simple ideas are combined to produce complex ideas, e.g., the idea of a unicorn—see also Prinz 2002). But what is absolutely essential for LOTH, and what Fodor insists on, is the claim that there is no adequate way in which a purely image-like system can capture what is involved in making judgments, i.e., in judging propositions to be true. This seems to require a discursive syntactic approach at the sentential level. The general problem here is the inadequacy of pictures or image-like representations to express propositions. I can judge that the blue box is on top of the red one without judging that the red box is under the blue one. I can judge that Mary kisses John without judging that John kisses Mary, and so on for indefinitely many such cases. It is hard to see how images or pictures can do that without using any syntactic structure or discursive elements, to say nothing of judging, e.g., conditionals, disjunctive or negative propositions, quantifications, negative existentials, etc.[9]
Moreover, there are difficulties with imagistic representations arising from demands on processing representations. As we will see below, (B2) turns out to provide the foundations for one of the most important arguments for LOTH: it makes it possible to mechanize thinking understood as a semantically coherent thought process, which, as per (A2), consists of a causal sequence of tokenings of mental representations. It is not clear, however, how an equivalent of (B2) could be provided for images or pictures in order to accommodate operations defined over them, even if something like an equivalent of (B1) could be given. On the other hand, there are truly promising attempts to integrate discursive symbolic theorem-proving with reasoning with image-like symbols. They achieve impressive efficiency in theorem-proving or in any deductive process defined over the expressions of such an integrated system. Such attempts, if they prove to be generalizable to psychological theorizing, are by no means threats to LOTH; on the contrary, such systems have every feature to make them a species of a LOT system: they satisfy (B).[10]
4. Nativism and LOTH
In the book (1975) in which Fodor introduced the LOTH, he also argued that all concepts are innate. As a result, the connection between LOTH and an implausibly strong version of conceptual nativism looked very much internal. This historical coincidence has led some people to think that LOTH is essentially committed to a very strong form of nativism, so strong in fact that it seems to make a reductio of itself (see, for instance, P.S. Churchland 1986, H. Putnam 1988, A. Clark 1994). The gist of his argument was that since learning concepts is a form of hypothesis formation and confirmation, it requires a system of mental representations in which formation and confirmation of hypotheses are to be carried out, but then there is a non-trivial sense in which one already has (albeit potentially) the resources to express the extension of the concepts to be learned.
In his LOT 2 (2008), Fodor continues to claim that concepts cannot be learned and that the very idea of concept learning is “confused”:
Now, according to HF [the Hypothesis Formation and Confirmation model], the process by which one learns C must include the inductive evaluation of some such hypothesis as ‘The C things are the ones that are green or triangular’. But the inductive evaluation of that hypothesis itself requires (inter alia) bringing the property green or triangular before the mind as such. ... Quite generally, you can't represent anything as such and such unless you already have the concept such and such. All that being so, it follows, on pain of circularity, that ‘concept learning’ as HF understands it can't be a way of acquiring concept C. ... Conclusion: If concept learning is as HF understands it, there can be no such thing. This conclusion is entirely general; it doesn't matter whether the target concept is primitive (like GREEN) or complex (like GREEN OR TRIANGULAR). (LOT 2, 2008:139)
Note that this argument and the predecessors Fodor articulated in his previous writings and especially in his (1975) are entirely general, applicable to any hypothesis that identifies concepts with mental representations whether or not these representations belong to a LOT.
The crux of the issue seems to be that learning concepts is a rational process. There seem to be non-arbitrary semantic and epistemic liaisons between the target concept to be acquired and its “evidence” base. This evidence base needs to be represented and rationally tied to the target concept. This target concept needs also to be expressed in terms of representations one already possesses. Fodor thinks that any model of concept learning understood in this sense will have to be a form of hypothesis formation and confirmation. But not every form of concept acquisition is learning. There are non-rational ways of acquiring concepts whose explanation need not be at the cognitive level (e.g., brute triggering mechanisms that can be activated in sorts of ways that can presumably be explained at the sub-cognitive or neurophysiological levels). If concepts cannot be learned, then they are either innate or non-rationally acquired. Whereas early Fodor used to think that concepts must therefore be innate (maybe he thought that non-learning concept acquisition forms are limited to sensory or certain classes of perceptual concepts), he now thinks that they may be acquired but the explanation of this is not the business of cognitive psychology.
Whatever one may think of the merits of Fodor's arguments for concept nativism or of his recent anti-learning stance, it should be emphasized that LOTH per se has very little to do with it. LOTH is not committed to such a strong version of nativism, especially about concepts. It also need not be committed to any anti-learning stance about concepts. It is certainly plausible to assume that LOTH will turn out to have some empirically (as well as theoretically/a priori) motivated nativist commitments about the structural organization and dynamic management of the entire representational system. But this much is to be expected especially in the light of recent empirical findings and trends. This, however, does not constitutes a reductio. It is an open empirical question how much nativism is true about concepts, and LOTH should be so taken as to be capable of accommodating whatever turns out to be true in this matter. LOTH, therefore, when properly conceived, is independent of any specific proposal about conceptual nativism.[11]
5. Naturalism and LOTH
One of the most attractive features of LOTH is that it is a central component of an ongoing research program in philosophy of psychology to naturalize the mind, that is, to give a theoretical framework in which the mind could naturally be seen as part of the physical world without postulating irreducibly psychic entities, events, processes or properties. Fodor, historically the most important defender of LOTH, once identified the major mysteries in philosophy of mind thus:
How could anything material have conscious states? How could anything material have semantical properties? How could anything material be rational? (where this means something like: how could the state transitions of a physical system preserve semantical properties?). (1991: 285, Reply to Devitt)
LOTH is a full-blown attempt to give a naturalist answer to the third question, an attempt to solve at least part of the problem underlying the second one, and is almost completely silent about the first.[12]
According to RTM, propositional attitudes are relations to meaningful mental representations whose causally sequenced tokenings constitute the process of thinking. This much can, in principle, be granted by an intentional realist who might nevertheless reject LOTH. Indeed, there are plenty of theorists who accept RTM in some suitable form (and also happily accept (C) in many cases) but reject LOTH either by explicitly rejecting (B) or simply by remaining neutral about it. Among some of the prominent philosophers who choose the former option are Searle (1984, 1990, 1992), Stalnaker (1984), Lewis (1972), Barwise and Perry (1983).[13] Some who want to remain neutral include Loar (1982a, 1982b), Dretske (1981), Armstrong (1980), and many contemporary functionalists including some connectionists.[14]
But RTM per se doesn't so much propose a naturalistic solution to intentionality and mechanization of thinking as simply assert a framework to emphasize intentional realism and, perhaps, with (C), a declaration of a commitment to naturalism or physicalism at best. How, then, is the addition of (B) supposed to help? Let us first try to see in a bit more detail what the problem is supposed to be in the first place to which (B) is proposed as a solution. Let us start by reflecting on thinking and see what it is about thinking that makes it a mystery in Fodor's list. This will give rise to one of the most powerful (albeit still nondemonstrative) arguments for LOTH.
RTM's second clause (A2), in effect, says that thinking is at least the tokenings of states that are (a) intentional (i.e. have representational/propositional content) and (b) causally connected. But, surely, thinking is more. There could be a causally connected series of intentional states that makes no sense at all. Thinking, therefore, is causally proceeding from states to states that makes semantic sense: the transitions among states must preserve some of their semantic properties to count as thinking. In the ideal case, this property would be the truth value of the states. But in most cases, any interesting intentional or epistemic property would do (e.g., warrantedness, degree of confirmation, semantic coherence given a certain practical context like satisfaction of goals in a specific context, etc.). In general, it is hard to spell out what this requirement of “making sense” comes to. The intuitive idea, however, should be clear. Thinking is not proceeding from thoughts to thoughts in arbitrary fashion: thoughts that are causally connected are in some fashion semantically (rationally, epistemically) connected too. If this were not so, there would be little point in thinking—thinking couldn't serve any useful purpose. Call this general phenomenon, then, the semantic coherence of causally connected thought processes. LOTH is offered as a solution to this puzzle: how is thinking, conceived this way, physically possible? This is the problem of thinking, thus the problem of mechanization of rationality in Fodor's version. How does LOTH propose to solve this problem and bring us one big step closer to the naturalization of the mind?
5.2 Syntactic Engine Driving a Semantic Engine: Computation
The two most important achievements of 20th century that are at the foundations of LOTH as well as most of modern Artificial Intelligence (AI) research and most of the so-called information processing approaches to cognition are (i) the developments in modern symbolic (formal) logic, and (ii) Alan Turing's idea of a Turing Machine and Turing computability. It is putting these two ideas together that gives LOTH its enormous explanatory power within a naturalistic framework. Modern logic showed that most of deductive reasoning can be formalized, i.e. most semantic relations among symbols can be entirely captured by the symbols' formal/syntactic properties and the relations among them. And Turing showed, roughly, that if a process has a formally specifiable character then it can be mechanized. So we can appreciate the implications of (i) and (ii) for the philosophy of psychology in this way: if thinking consists in processing representations physically realized in the brain (in the way the internal data structures are realized in a computer) and these representations form a formal system, i.e., a language with its proper combinatorial syntax (and semantics) and a set of derivations rules formally defined over the syntactic features of those representations (allowing for specific but powerful programs to be written in terms of them), then the problem of thinking, as described above, can in principle be solved in completely naturalistic terms, thus the mystery surrounding how a physical device can ever have semantically coherent state transitions (processes) can be removed. Thus, given the commitment to naturalism, the hypothesis that the brain is a kind of computer trafficking in representations in virtue of their syntactic properties is the basic idea of LOTH (and the AI vision of cognition).
Computers are environments in which symbols are manipulated in virtue of their formal features, but what is thus preserved are their semantic properties, hence the semantic coherence of symbolic processes. Slightly paraphrasing Haugeland (cf. 1985: 106), who puts the same point nicely in the form of a motto:
The Formalist Motto:
If you take care of the syntax of a representational system, its semantics will take care of itself.
This is in virtue of the mimicry or mirroring relation between the semantic and formal properties of symbols. As Dennett once put it in describing LOTH, we can view the thinking brain as a syntactically driven engine preserving semantic properties of its processes, i.e. driving a semantic engine. What is so nice about this picture is that if LOTH is true we have a naturalistically adequate causal treatment of thinking that respects the semantic properties of the thoughts involved: it is in virtue of the physically coded syntactic/formal features that thoughts cause each other while the coherence of their semantic properties is preserved precisely in virtue of this.
Whether or not LOTH actually turns out to be empirically true in the details or in its entire vision of rational thinking, this picture of a syntactic engine driving a semantic one can at least be taken to be an important philosophical demonstration of how Descartes' challenge can be met (cf. Rey 1997: chp.8). Descartes claimed that rationality in the sense of having the power “to act in all the contingencies of life in the way in which our reason makes us act” cannot possibly be possessed by a purely physical device: “The rational soul … could not be in any way extracted from the power of matter … but must … be expressly created” (1637/1970: 117–18). Descartes was completely puzzled by just this rational character and semantic coherence of thought processes so much so that he failed to even imagine a possible mechanistic explication of it. He thus was forced to appeal to Divine creation. But we can now see/imagine at least a possible mechanistic/naturalistic scenario.[15]
5.3 Intentionality and LOTH
But where do the semantic properties of the mental representations come from in the first place? How can they mean anything? This is Brentano's challenge to a naturalist. Brentano's bafflement was with the intentionality of the human mind, its apparently mysterious power to represent things, events, properties in the world. He thought that nothing physical can have this property: “The reference to something as an object is a distinguishing characteristic of all mental phenomena. No physical phenomenon exhibits anything similar” (Brentano 1874/1973: 97). This problem of intentionality is the second problem or mystery in Fodor's list quoted above. I said that LOTH officially offers only a partial solution to it and perhaps proposes a framework within which the remainder of the solution can be couched and elaborated in a naturalistically acceptable way.
Recall that RTM contains a clause (A1b) that says that the immediate “object” of a propositional attitude that P is a mental representation #P# that means that P. Again, (B1) attributes a compositional semantics to the syntactically complex symbols belonging to one's LOT that are, as per (C), realized by the physical properties of a thinking system. According to LOTH, the semantic content of propositional attitudes is inherited from the semantic content of the mental symbols. So Brentano's questions for a LOT theorist becomes: how do the symbols in one's LOT get their meanings in the first place? There are two levels or stages at which this question can be raised and answered:
(1) At the level of atomic symbols (non-logical primitives): how do the atomic symbols represent what they do?
(2) At the level of molecular symbols (phrasal complexes or sentences): how do molecular symbols represent what they do?
There have been at least two major lines LOT theorists have taken regarding these questions. The one that is least committal might perhaps be usefully described as the official position regarding LOTH's treatment of intentionality. Most LOT theorists seem to have taken this line. The official line doesn't propose any theory about the first stage, but simply assumes that the first question can be answered in a naturalistically acceptable way. In other words, officially LOTH simply assumes that the atomic symbols/expressions in one's LOT have whatever meanings they have.[16]
But, the official line continues, LOTH has a lot to say about the second stage, the stage where the semantic contents are computed or assigned to complex (molecular) symbols on the basis of their combinatorial syntax or grammar together with whatever meanings atomic symbols are assumed to have in the first stage. This procedure is familiar from a Tarski-style[17] definition of truth conditions of sentences. The truth-value of complex sentences in propositional logic are completely determined by the truth-values of the atomic sentences they contain together with the rules fixed by the truth-tables of the connectives occurring in the complex sentences. Example: ‘P and Q’ is true just in case both ‘P’ and ‘Q’ are true, but false otherwise. This process is similar but more complex in first-order languages, and even more so for natural languages—in fact, we don't have a completely working compositional semantics for the latter at the moment. So, if we have a semantic interpretation of atomic symbols (if we have symbols whose reference and extension are fixed at the first stage by whatever naturalistic mechanism turns out to govern it), then the combinatorial syntax will take over and effectively determine the semantic interpretation (truth-conditions) of the complex sentences they are constituents of. So officially LOTH would only contribute to a complete naturalization project if there is a naturalistic story at the atomic level.
Early Fodor (1975, 1978, 1978a, 1980), for instance, envisaged a science of psychology which, among other things, would reasonably set for itself the goal of discovering the combinatorial syntactic principles of LOT and the computational rules governing its operations, without worrying much about semantic matters, especially about how to fix the semantics of atomic symbols (he probably thought that this was not a job for LOTH). Similarly, Field (1978) is very explicit about the combinatorial rules for assigning truth-conditions to the sentences of the internal code. In fact, Field's major argument for LOTH is that, given a naturalistic causal theory of reference for atomic symbols, about which he is optimistic (Field 1972), it is the only naturalistic theory that has a chance of solving Brentano's puzzle. For the moment, this is not much more than a hope, but, according to the LOT theorist, it is a well-founded hope based on a number of theoretical and empirical assumptions and data. Furthermore, it is a framework defining a naturalistic research program in which there have been promising successes.[18]
As I said, this official and, in a way, least committal line has been the more standard way of conceiving LOTH's role in the project of naturalizing intentionality. But some have gone beyond it and explored the ways in which the resources of LOTH can be exploited even in answering the first question (1) about the semantics of atomic symbols.
Now, there is a weak version of an answer to (1) on the part of LOTH and a strong version. On the weak version, LOTH may be untendentiously viewed as inevitably providing some of the resources in giving the ultimate naturalistic theory in naturalizing the meaning of atomic symbols. The basic idea is that whatever the ultimate naturalistic theory turns out to be true about atomic expressions, computation as conceived by LOTH will be part of it. For instance, it may be that, as with nomic covariation theories of meaning (Fodor 1987, 1990a; Dretske 1981), the meaning of an atomic predicate may consist in its potential to get tokened in the presence of (or, in causal response to) something that instantiates the property the predicate is said to express. A natural way of explicating this potential may partly but ultimately rely on certain computational principles the symbol may be subjected to within a LOT framework, or principles that in some sense govern the “behavior” of the symbol. Insofar as computation is naturalistically understood in the way LOTH proposes, a complete answer to the first question about the semantics of atomic symbols may plausibly involve an explicatory appeal to computation within a system of symbols. This is the weak version because it doesn't see LOTH as proposing a complete solution to the first question (1) above, but only helping it.
A strong version would have it that LOTH provides a complete naturalistic solution to both questions: given the resources of LOTH we don't need to look any further to meet Brentano's challenge. The basic idea lies in so-called functional or conceptual role semantics, according to which a concept is the concept it is precisely in virtue of the particular causal/functional potential it has in interacting with other concepts. Each concept may be thought of as having a certain distinctive set of epistemic/semantic relations or liaisons to other concepts. We can conceive of this set as determining a certain “conceptual role” for each concept. We can then take these roles to determine the semantic identity of concepts: concepts are the concepts they are because they have the conceptual roles they have; that is to say, among other things, concepts represent whatever they do precisely in virtue of these roles. The idea then is to reduce each conceptual role to causal/functional role of atomic symbols (now conceived as primitive terms in LOTH), and then use the resources of LOTH to reduce it in turn to computational role. Since computation is naturalistically well-defined, the argument goes, and since causal interactions between thoughts and concepts can be understood completely in terms of computation, we can completely naturalize intentionality if we can successfully treat meanings as arising out of thoughts/concepts' internal interactions with each other. In other words, the strong version of LOTH would claim that atomic symbols in LOT have the content they do in virtue of their potential for causal interactions with other tokens, and cashing out this potential in mechanical/naturalistic terms is what, among other things, LOTH is for. LOTH then comes as a naturalistic rescuer for conceptual role semantics.
It is not clear whether any one holds this strong version of LOTH in this rather naive form. But certainly some people have elaborated the basic idea in quite subtle ways, for which Cummins (1989: chp.8) is perhaps the best example. (But also see Block 1986 and Field 1978.) But even in the best hands, the proposal turns out to be very problematic and full of difficulties nobody seems to know how to straighten out. In fact, some of the most ardent critics of taking LOTH as incorporating a functional role semantics turn out to be some of the most ardent defenders of LOTH understood in a weak, non-committal sense we have explored above—see Fodor (1987: chp.3), Fodor and Lepore (1991), Fodor's attack (1978b) on AI's way of doing procedural semantics is also relevant here. Haugeland (1981), Searle (1980, 1984), and Putnam (1988) quite explicitly take LOTH to involve a program for providing a complete semantic account of mental symbols, which they then attack accordingly.[19]
It is also possible, in fact, quite natural, to combine conceptual role semantics (internalist) with causal/informational psychosemantics (externalist). The result is sometimes known as two-factor theories. If this turns out to be the right way to naturalize intentionality, then, given what is said above about the potential resources of LOTH in contributing to both factors, it is easy to see why many theorists who worry about naturalizing intentionality are attracted to LOTH.
As indicated previously, LOTH is almost completely silent about consciousness and the problem of qualia, the third mystery in Fodor's list in the quote above. But the naturalist's hope is that this problem too will be solved, if not by LOTH, then by something else. On the other hand, it is important to emphasize that LOTH is neutral about the naturalizability of consciousness/qualia. If it turns out that qualia cannot be naturalized, this would by no means show that LOTH is false or defective in some way. In fact, there are people who seem to think that LOTH may well turn out to be true even though qualia can perhaps not be naturalized (e.g., Block 1980, Chalmers 1996, McGinn 1991).
Finally, it should be emphasized that LOTH has no particular commitment to every symbolic activity's being conscious. Conscious thoughts and thinking may be the tip of a computational iceberg. Nevertheless, there are ways in which LOTH can be helpful for an account of state consciousness that seeks to explain a thought's being conscious in terms of a higher order thought which is about the first order thought. So, to the extent to which thought and thinking are conscious, to that extent LOTH can perhaps be viewed as providing some of the necessary resources for a naturalistic account of state consciousness—for elaboration see Rosenthal (1997) and Lycan (1997).
6. Arguments for LOTH
We have already seen two major arguments, perhaps historically the most important ones, for LOTH: First, we have noted that if LOTH is true then all the essential features of the common sense conception of propositional attitudes will be explicated in a naturalistic framework which is likely to be co-opted by scientific cognitive psychology, thus vindicating folk psychology. Second, we have discussed that, if true, LOTH would solve one of the mysteries about thinking minds: how is thinking (as characterized above) possible? How is rationality mechanically possible? Then we have also seen a third argument that LOTH would partially contribute to the project of naturalizing intentionality by offering an account of how the semantic properties of whole attitudes are fixed on the basis of their atomic constituents. But there have been many other arguments for LOTH. In this section, I will describe only those arguments that have been historically more influential and controversial.
When Fodor first formulated LOTH with significant elaboration in his (1975), he introduced his major argument for it along with its initial formulation in the first chapter. It was basically this: our best scientific theories and models of different aspects of higher cognition assume a framework that requires a computational/representational medium for them to be true. More specifically, he analyzed the basic form of the information processing models developed to account for three types of cognitive phenomena: perception as the fixation of perceptual beliefs, concept learning as hypothesis formation and confirmation, and decision making as a form of representing and evaluating the consequences of possible actions carried out in a situation with a preordered set of preferences. He rightly pointed out that all these psychological models treated mental processes as computational processes defined over representations. Then he drew what seems to be the obvious conclusion: if these models are right in at least treating mental processes as computational, even if not in detail, then there must be a LOT over which they are defined, hence LOTH.
In Fodor's (1975), the arguments for different aspects of LOTH are diffused and the emphasis, with the book's slogan “no computation without representation”, is put on the RTM rather than on (B) or (C). But all the elements are surely there.
People seem to be capable of entertaining an infinite number of thoughts, at least in principle, although they in fact entertain only a finite number of them. Indeed adults who speak a natural language are capable of understanding sentences they have never heard uttered before. Here is one: there is a big lake of melted gold on the dark side of the moon. I bet that you have never heard this sentence before, and yet, you have no difficulty in understanding it: it is one you in fact likely believe false. But this sentence was arbitrary, there are infinitely many such sentences I can in principle utter and you can in principle understand. But understanding a sentence is to entertain the thought/proposition it expresses. So there are in principle infinitely many thoughts you are capable of entertaining. This is sometimes expressed by saying that we have an unbounded competence in entertaining different thoughts, even though we have a bounded performance. But this unbounded capacity is to be achieved by finite means. For instance, storing an infinite number of representations in our heads is out of the question: we are finite beings. If human cognitive capacities (capacities to entertain an unbounded number of thoughts, or to have attitudes towards an unbounded number of propositions) are productive in this sense, how is this to be explained on the basis of finitary resources?
The explanation LOTH offers is straightforward: postulate a representational system that satisfies at least (B1). Indeed, recursion is the only known way to produce an infinite number of symbols from a finite base. In fact, given LOTH, productivity of thought as a competence mechanism seems to be guaranteed.[20]
Systematicity of thought consists in the empirical fact that the ability to entertain certain thoughts is intrinsically connected to the ability to entertain certain others. Which ones? Thoughts that are related in a certain way. In what way? There is a certain initial difficulty in answering such questions. I think, partly because of this, Fodor (1987) and Fodor and Pylyshyn (1988), who are the original defenders of this kind of argument, first argue for the systematicity of language production and understanding: the ability to produce/understand certain sentences is intrinsically connected to the ability to produce/understand certain others. Given that a mature speaker is able to produce/understand a certain sentence in her native language, by psychological law, there always appear to be a cluster of other sentences that she is able to produce/understand. For instance, we don't find speakers who know how to express in their native language the fact that John loves the girl but not the fact that the girl loves John. This is apparently so, moreover, for expressions of any n-place relation.
Fodor and Pylyshyn bring out the force of this psychological fact by comparing learning languages the way we actually do with learning a language by memorizing a huge phrase book. In the phrase book model, there is nothing to prevent someone learning how to say ‘John loves the girl’ without learning how to say ‘the girl loves John.’ In fact, that is exactly the way some information booklets prepared for tourists help them to cope with their new social environment. You might, for example, learn from a phrase book how to say ‘I'd like to have a cup of coffee with sugar and milk’ in Turkish without knowing how to say/understand absolutely anything else in Turkish. In other words, the phrase book model of learning a language allows arbitrarily punctate linguistic capabilities. In contrast, a speaker's knowledge of her native language is not punctate, it is systematic. Accordingly, we do not find, by nomological necessity, native speakers whose linguistic capacities are punctate.
Now, how is this empirical truth (in fact, a law-like generalization) to be explained? Obviously if this is a general nomological fact, then learning one's native language cannot be modeled on the phrase book model. What is the alternative? The alternative is well known. Native speakers master the grammar and vocabulary of their language. But this is just to say that sentences are not atomic, but have syntactic constituent structure. If you have a vocabulary, the grammar tells you how to combine systematically the words into sentences. Hence, in this way, if you know how to construct a particular sentence out of certain words, you automatically know how to construct many others. If you view all sentences as atomic, then, as Fodor and Pylyshyn say, the systematicity of language production/understanding is a mystery, but if you acknowledge that sentences have syntactic constituent structure, systematicity of linguistic capacities is what you automatically get; it is guaranteed. This is the orthodox explanation of linguistic systematicity.
From here, according to Fodor and Pylyshyn, establishing the systematicity of thought as a nomological fact is one step away. If it is a law that the ability to understand a sentence is systematically connected to the ability to understand many others, then it is similarly a law that the ability to think a thought is systematically connected to the ability to think many others. For to understand a sentence is just to think the thought/proposition it expresses. Since, according to RTM, to think a certain thought is just to token a representation in the head that expresses the relevant proposition, the ability to token certain representations is systematically connected to the ability to token certain others. But then, this fact needs an adequate explanation too. The classical explanation LOTH offers is to postulate a system of representations with combinatorial syntax exactly as in the case of the explanation of the linguistic systematicity. This is what (B1) offers.[21] This seems to be the only explanation that does not make the systematicity of thought a miracle, and thus argues for the LOT hypothesis.
However, thought is not only systematic but also compositional: systematically connected thoughts are also always semantically related in such a way that the thoughts so related seem to be composed out of the same semantic elements. For instance, the ability to think ‘John loves the girl’ is connected to the ability to think ‘the girl loves John’ but not to, say, ‘protons are made up of quarks’ or to ‘2+2=4.’ Why is this so? The answer LOTH gives is to postulate a combinatorial semantics in addition to a combinatorial syntax, where an atomic constituent of a mental sentence makes (approximately) the same semantic contribution to any complex mental expression in which it occurs. This is what Fodor and Pylyshyn call ‘the principle of compositionality’.[22]
In brief, it is an argument for LOTH that it offers a cogent and principled solution to the systematicity and compositionality of cognitive capacities by postulating a system of representations that has a combinatorial syntax and semantics, i.e., a system of representations that satisfies at least (B1).
6.4 Argument from the Systematicity of Thinking (Inferential Coherence)
Systematicity of thought does not seem to be restricted solely to the systematic ability to entertain certain thoughts. If the system of mental representations does have a combinatorial syntax, then there is a set of rules, psychosyntactic formation rules, so to speak, that govern the construction of well-formed expressions in the system. It is this fact, (B1), that guarantees that if you can form a mental sentence on the basis of certain rules, then you can also form many others on the basis of the same rules. The rules of combinatorial syntax determine the syntactic or formal structure of complex mental representations. This is the formative (or, formational) aspect of systematicity. But inferential thought processes ( i.e., thinking) seem to be systematic too: the ability to make certain inferences is intrinsically connected to the ability to make certain many others. For instance, you do not find minds that can infer ‘A’ from ‘A&B’ but cannot infer ‘C’ from ‘A&B&C.’ It seems to be a psychological fact that inferential capacities come in clusters that are homogeneous in certain aspects. How is this fact (i.e., the inferential or transformational systematicity) to be explained?
As we have seen, the explanation LOTH offers depends on the exploitation of the notion of logical form or syntactic structure determined by the combinatorial syntax postulated for the representational system. The combinatorial syntax not only gives us a criterion of well-formedness for mental expressions, but it also defines the logical form or syntactic structure for each well-formed expression. The classical solution to inferential systematicity is to make the mental operations on representations sensitive to their form or structure, i.e., to insist on (B2). Since, from a syntactic view point, similarly formed expressions will have similar forms, it is possible to define a single operation which will apply to only certain expressions that have a certain form, say, only to conjunctions, or conditionals. This allows the LOT theorist to give homogeneous explanations of what appear to be homogeneous classes of inferential capacities. This is one of the greatest virtues of LOTH, hence provides an argument for it.
The solution LOTH offers for what I called the problem of thinking, above, is connected to the argument here because the two phenomena are connected in a deep way. Thinking requires that the logico-semantic properties of a particular thought process be somehow causally implicated in the process (say, inferring that John is happy from knowing that if John is at the beach then John is happy and coming to realize that John is indeed at the beach). The systematicity of inferential thought processes then is based on the observation that if the agent is capable of making that particular inference, then she is capable of making many other somehow similarly organized inferences. But the idea of similar organization in this context seems to demand some sort of classification of thoughts independently of their particular content. But what can the basis of such a classification be? The only basis seems to be the logico-syntactic properties of thoughts, their form. Although it feels a little uneasy to talk about syntactic properties of thoughts common-sensically understood, it seems that they are forced upon us by the very attempt to understand their semantic properties: how, for instance, could we explain the semantic content of the thought that if John is at the beach then he is happy without somehow appealing to its being a conditional? This is the point of contact between the two phenomena. Especially when the demands of naturalism are added to this picture, inferring a LOT (= a representational system satisfying B) realized in the brain becomes almost irresistible. Indeed Rey (1995) doesn't resist and claims that, given the above observations, LOTH can be established on the basis of arguments that are not “merely empirical”. I leave it to the reader to evaluate whether mere critical reflection on our concepts of thought and thinking (along with certain mundane empirical observations about them) can be sufficient to establish LOTH.[23]
7. Objections to LOTH
There have been numerous arguments against LOTH. Some of them are directed more specifically against the Representational Theory of Mind (A), some against functionalist materialism (C). Here I will concentrate only on those arguments specifically targeting (B)—the most controversial component of LOTH.
These arguments rely on the explanations offered by LOTH defenders for certain aspects of natural languages. In particular, many LOT theorists advert to LOTH to explain (1) how natural languages are learned, (2) how natural languages are understood, or (3) how the utterances in such languages can be meaningful. For instance, according to Fodor (1975), natural languages are learned by forming and confirming hypotheses about the translation of natural language sentences into Mentalese such as: ‘Snow is white’ is true in English if and only if P, where ‘P’ is a sentence in one's LOT. But to be able to do that, one needs a representational medium in which to form and confirm hypotheses—at least to represent the truth-conditions of natural language sentences. The LOT is such a medium. Again, natural languages are understood because, roughly, such an understanding consists in translating their sentences into one's Mentalese. Similarly, natural language utterances are meaningful in virtue of the meanings of corresponding Mentalese sentences.
The basic complaint is that in each of these cases, either the explanations generate a regress because the same sort of explanations ought to be given for how the LOT is learned, understood or can be meaningful, or else they are gratuitous because if a successful explanation can be given for LOT that does not generate a regress then it could and ought to be given for the natural language phenomena without introducing a LOT (see, e.g., Blackburn 1984). Fodor's response in (1975) is (1) that LOT is not learned, it's innate; (2) that it's understood in a different sense than the sense involved in natural language comprehension; (3) that LOT sentences acquire their meanings not in virtue of another meaningful language but in a completely different way, perhaps by standing in some sort of causal relation to what they represent or by having certain computational profiles (see above, §5.3). For many who have a Wittgensteinian bent, these replies are not likely to be convincing. But here the issues tend to concern RTM rather than (B).
Laurence and Margolis (1997) point out that the regress arguments depend on the assumption that LOTH is introduced only to explain (1)-(3). If it can be shown that there are lots of other empirical phenomena for which the LOTH provides good explanations, then the regress arguments fail because LOTH then would not be gratuitous. In fact, as we have seen above, there are plenty of such phenomena. But still it is important to realize that the sort of explanations proposed for the understanding of one's LOT (computational use/activity of LOT sentences with certain meanings) and how LOT sentences can be meaningful (computational roles and/or nomic relations with the world) cannot be given for (1)-(3): it's unclear, for example, what it would be like to give a computational role and/or nomic relation account for the meanings of natural language utterances. (See Knowles 1998 for a reply to Laurence & Margolis 1997; Margolis & Laurence 1998 counterreplies to Knowles.)
Dennett in his review of Fodor's (1975) has raised the following objection (cf. Fodor 1987: 21–3 for a similar discussion):
In a recent conversation with the designer of a chess-playing program I heard the following criticism of a rival program: “it thinks it should get its queen out early.” This ascribes a propositional attitude to the program in a very useful and predictive way, for as the designer went on to say, one can usefully count on chasing that queen around the board. But for all the many levels of explicit representation to be found in that program, nowhere is anything roughly synonymous with “I should get my queen out early” explicitly tokened. The level of analysis to which the designer's remark belongs describes features of the program that are, in an entirely innocent way, emergent properties of the computational processes that have “engineering reality.” I see no reason to believe that the relation between belief-talk and psychological talk will be any more direct. (Dennett 1981: 107)
The objection, as Fodor (1987: 22) points out, isn't that the program has a dispositional, or potential, belief that it will get its queen out early. Rather, the program actually operates on this belief. There appear to be lots of other examples: e.g., in reasoning we pretty often follow certain inference rules like modus ponens, disjunctive syllogism, etc., without necessarily explicitly representing them.
The standard reply to such objections is to draw a distinction between rules on the basis of which Mentalese data-structures are manipulated, and the data-structures themselves (intuitively, the program/data distinction). LOTH is not committed to every rule's being explicitly represented. In fact, as a point of nomological fact, in a computational device not every rule can be explicitly represented: some have to be hard-wired and, thus, implicit in this sense. In other words, LOTH permits but doesn't require that rules be explicitly represented. On the other hand, data structures have to be explicitly represented: it is these that are manipulated formally by the rules. No causal manipulation is possible without explicit tokening of these structures. According to Fodor, if a propositional attitude is an actual episode in one's reasoning that plays a causal role, then LOTH is committed to explicit representation of its content, which is as per (A2 and B2) causally implicated in the physical process realizing that reasoning. Dispositional propositional attitudes can then be accounted for in terms of an appropriate principle of inferential closure of explicitly represented propositional attitudes (cf. Lycan 1986).
Dennett's chess program certainly involves explicit representations of the chess board, the pieces, etc. and perhaps some of the rules. Which rules are implicit and which are explicit depend on the empirical details of the program. Pointing to the fact that there may be some rules that are emergent out of the implementation of explicit rules and data-structures does not suffice to undermine LOTH.
In any sufficiently complex computational system, there are bound to be many symbol manipulations with no obviously corresponding description at the level of propositional attitudes. For instance, when a multiplication program is run through a standard conventional computer, the steps of the program are translated into the computer's machine language and executed there, but at this level the operations apply to 1's and 0's with no obvious way to map them onto the original numbers to be multiplied or to the multiplication operation. So it seems that at those levels that, according to Dennett, have engineering reality there are plenty of explicit tokenings of symbols with appropriate operations over them that don't correspond to anything like the propositional attitudes of folk psychology. In other words, there is plenty of symbolic activity which it would be wrong to say a person engages in. Rather, they are done by the person's subpersonal computational components as opposed to the person. How to rule out such cases? (cf. Fodor 1987: 23–6 for a similar discussion.)
They are ruled out by an appropriate reading of (A1) and (B1): (A1) says that the person herself must stand in an appropriate computational relation to a Mentalese sentence, which, as per (B1), has a suitable syntax and semantics. Only then will the sentence constitute the person's having a propositional attitude. Not all explicit symbols in one's LOT will satisfy this. In other words, not every computational routine will correspond to a processing appropriately described as storage in, e.g., the “belief-box”. Furthermore, as pointed out by Fodor (1987), LOTH would vindicate the common sense view of propositional attitudes if they turn out to be computational relations to Mentalese sentences. It may not be further required that every explicit representation correspond to a propositional attitude.
There have been many other objections to LOTH in recent years raised especially by connectionists: that LOT systems cannot handle certain cognitive tasks like perceptual pattern recognition, that they are too brittle and not sufficiently damage resistant, that they don't exhibit graceful degradation when physically damaged or as a response to noisy or degraded input, that they are too rigid, deterministic, so are not well-suited for modeling humans' capacity to satisfy multiple soft-constraints so gracefully, that they are not biologically realistic, and so on. (For useful discussions of these and many similar objections, see Rumelhart, McClelland and the PDP Research Group (1986), Fodor and Pylyshyn (1988), Horgan and Tienson (1996), Horgan (1997), McLaughlin and Warfield (1994), Bechtel and Abrahamsen (2002), Marcus (2002).)
8. The Connectionism/Classicism Debate
When Jerry Fodor published his influential book, The Language of Thought, in (1975), he called LOTH “the only game in town.” As we have seen, it was the philosophical articulation of the assumptions that underlay the new developments in “cognitive sciences” after the demise of behaviorism. Fodor argued for the truth of LOTH on the basis of the successes of the best scientific theories we had then. Indeed most of the scientific work in cognitive psychology, psycholinguistics, and AI assumed the framework of LOTH.
In the early 1980's, however, Fodor's claim that LOTH was the only game in town was beginning to be challenged by some who were working on so-called connectionist networks. They claimed that connectionism offered a new and radically different alternative to classicism in modeling cognitive phenomena. The name ‘classicism’ has since then become to be applied to the LOTH framework. On the other hand, many classicists like Fodor thought that connectionism was nothing but a slightly more sophisticated way with which the old and long dead associationism, whose roots could be traced back to early British empiricists, was being revived. In 1988 Fodor and Pylyshyn (F&P) published a long article, “Connectionism and Cognitive Architecture: A Critical Analysis”, in which they launched a formidable attack on connectionism, which largely set the terms for the ensuing debate between connectionists and classicists.
F&P's forceful criticism consists in posing a dilemma for connectionists: They either fail to explain the law-like cognitive regularities like systematicity and productivity in an adequate way or the connectionist models are nothing but mere implementation models of classical architectures; hence, they fail to provide a radically new paradigm as connectionists claim. This conclusion was also meant to be a challenge: Explain the cognitive regularities in question without postulating a LOT architecture.
First, let me present F&P's argument against connectionism in a somewhat reconstructed fashion. It will be helpful to characterize the debate by locating the issues according to the reactions many connectionists had to the premises of the argument.
F&P's Argument against Connectionism in their (1988) article:
Cognition essentially involves representational states and causal operations whose domain and range are these states; consequently, any scientifically adequate account of cognition should acknowledge such states and processes.
Higher cognition (specifically, thought and thinking with propositional content) conceived in this way, has certain empirically interesting properties: in particular, it is a law of nature that cognitive capacities are productive, systematic, and inferentially coherent.
Accordingly, the architecture of any proposed cognitive model is scientifically adequate only if it guarantees that cognitive capacities are productive, systematic, etc. This would amount to explaining, in the scientifically relevant and required sense, how it could be a law that cognition has these properties.
The only way (i.e., necessary condition) for a cognitive architecture to guarantee systematicity (etc.) is for it to involve a representational system for which (B) is true (see above). (Classical architectures necessarily satisfy (B).)
Either the architecture of connectionist models does satisfy (B), or it does not.
If it does, then connectionist models are implementations of the classical LOT architecture and have little new to offer (i.e., they fail to compete with classicism, and thus connectionism does not constitute a radically new way of modeling cognition).
If it does not, then (since connectionism does not then guarantee systematicity, etc., in the required sense) connectionism is empirically false as a theory of the cognitive architecture.
Therefore, connectionism is either true as an implementation theory, or empirically false as a theory of cognitive architecture.
The notion of cognitive architecture assumes special importance in this debate. F&P's characterization of the notion goes as follows:
The architecture of the cognitive system consists of the set of basic operations, resources, functions, principles, etc. (generally the sorts of properties that would be described in a “user's manual” for that architecture if it were available on a computer) whose domain and range are the representational states of the organism. (1988: 10)
Also, note that (B1) and (B2) are meta-architectural properties in that they are themselves conditions upon any specific architecture's being classical. They define classicism per se, but not any particular way of being classical. Classicism as such simply claims that whatever the particular cognitive architecture of the brain might turn out to be (whatever the specific grammar of Mentalese turns out to be), (B) must be true of it. F&P claim that this is the only way an architecture can be said to guarantee the nomological necessity of cognitive regularities like systematicity, etc. This seems to be the relevant and required sense in which a scientific explanation of cognition is required to guarantee the regularities—hence the third premise in their argument.
Connectionist responses have fallen into four classes:
Deny premise(i). The rejection of (i) commits connectionists to what is sometimes called radical or eliminativist connectionism. Premise (i), as F&P point out, draws a general line between eliminativism and representationalism (or, intentional realism). There has been some controversy as to whether connectionism constitutes a serious challenge to the fundamental tenets of folk psychology.[24] Although it may still be too early for assessment,[25] the connectionist research program has been overwhelmingly cognitivist: most connectionists do in fact advance their models as having causally efficacious representational states, and explicitly endorse F&P's first premise. So they seem to accept intentional realism.[26]
Accept the conclusion. This group may be seen as more or less accepting the cogency of the entire argument, and characterizes itself as implementationalist: they hold that connectionist networks will implement a classical architecture or language of thought. According to this group, the appropriate niche for neural networks is closer to neuroscience than to cognitive psychology. They seem to view the importance of the program in terms of its prospects of closing the gap between the neurosciences and high-level cognitive theorizing. In this, many seem content to admit premise (vi). (See Marcus 2001 for a discussion of the virtues of placing connectionist models closer to implementational level.)
Deny premise (ii) or (iv). Some connectionists reject (ii) or (iv),[27] holding that there are no lawlike cognitive regularities such as systematicity (etc.) to be explained, or that such regularities do not require a (B)-like architecture for their explanation. Those who question (ii) often question the empirical evidence for systematicity (etc.) and tend to ignore the challenge put forward by F&P. Those who question (iv) also often question (ii), or they argue that there can be very different sort of explanations for systematicity and the like (e.g. evolutionary explanations, see Braddon-Mitchell and Fitzpatrick 1990), or they question the very notion of explanation involved (e.g. Matthews 1994). There are indeed quite a number of different kinds of arguments in the literature against these premises.[28] For a sampling, see Aydede (1995) and McLaughlin (1993b), who partitions the debate similarly.
Deny premise (vi). The group of connectionists who have taken F&P's challenge most seriously has tended to reject premise (vi) in their argument, while accepting, on the face of it, the previous five premises (sometimes with reservations on the issue of productivity). They think that it is possible for connectionist representations to be syntactically structured in some sense without being classical. Prominent in this group are Smolensky (1990a, 1990b, 1995), van Gelder (1989, 1990, 1991), Chalmers (1990, 1993).[29] Some connectionists whose models give support to this line include Elman (1989), Hinton (1990), Touretzky (1990), Pollack (1990), Barnden and Srinivas (1991), Shastri and Ajjanagadde (1993), Plate (1998), Hummel et al. (2004), Van Der Velde and De Kamps (2006), Barrett et al. (2008), Sanjeevi and Bhattacharyya (2010).
Much of the recent debate between connectionists and classicists has focused on this option. How is it possible to reject premise (vi), which seems true by definition of classicism. The connectionists' answer, roughly put, is that when you devise a representational system whose satisfaction of (B) relies on a non-concatenative realization of structural/syntactic complexity of representations, you have a non-classical system. (See especially Smolensky 1990a and van Gelder 1990.) Interestingly, some classicists like Fodor and McLaughlin (1990) (F&M) seem to agree. F&M stipulate that you have a classical system only if the syntactic complexity of representations is realized concatenatively, or as it is sometimes put, explicitly:
We … stipulate that for a pair of expression types E1, E2, the first is a Classical constituent of the second only if the first is tokened whenever the second is tokened. (F&M 1990: 186)
The issues about how connectionists propose to obtain constituent structure non-concatenatively tend to be complex and technical. But they propose to exploit so called distributed representations in certain novel ways. The essential idea behind most of them is to use vector (and tensor) algebra (involving superimposition, multiplication, etc. of vectors) in composing and decomposing connectionist representations which consist in coding patterns of activity across neuron-like units which can be modeled as vectors. The result of such techniques is the production of representations that have in some interesting sense a complexity whose constituent structure is largely implicit in that the constituents are not tokened explicitly when the representations are tokened, but can be recovered by further operations upon them. The interested reader should consult some of the pioneering work by Elman (1989), Hinton (1990), Smolensky (1989, 1990, 1995), Touretzky (1990), Pollack (1990).
F&M's criticism, more specifically stated, however, is this. Connectionists with such techniques only satisfy (B1) in some “extended sense”, but they are incapable of satisfying (B2), precisely because their way of satisfying (B1) is committed to a non-concatenative realization of syntactic structures.
Some connectionists disagree (e.g., Chalmers 1993, Niklasson and van Gelder 1994—see also Browne 1998 and Browne and Sun 2001 for discussion and overview of models): they claim that you can have structure-sensitive transformations or operations defined over representations whose syntactic structure is non-concatenatively realized. So given the apparent agreement that non-concatenative realization is what makes a system non-classical, connectionists claim that they can and do perfectly satisfy (B) in its entirety with their connectionist models without implementing classical models.
The debate still continues and there is a growing literature built around the many issues raised by it. Aydede (1997a) offers an extensive analysis of the debate between classicists and this group of connectionists with special attention to the conceptual underpinnings of the debate. (See also Roth 2005 who argues that to the extent to which connectionist models can transform representations successfully according to an algorithmic function, to that extent they count as executing program in the sense relevant to classical program execution.) Aydede argues that both parties are wrong in assuming that concatenative realization is relevant to the characterization of LOTH. Part of the argument is that concatenative realization of (B) is just that—a realization. The attentive reader might have noticed that there is nothing in the characterization of (B) that requires concatenative realization. Indeed, when we look at all the major arguments for LOTH focused on the need for (B), none of them requires concatenation or explicit realization of syntactic structure. In fact, it is almost on the border of confusion to necessarily associate LOTH to such an implementational level issue. If anything, this class of connectionist networks, if successful and generalizable across all higher cognition, contributes to our understanding of how radically differently a LOTH architecture could be implemented in neural networks. Indeed, if these models prove to be adequate for explaining the full range of human cognitive capacities, they would show how syntactically structured representations and structure sensitive processes could be implemented in a radically new way. So research programs in this niche are by no means trivial or insignificant. But we need to be clear and careful about what minimally needs to be the case for LOTH to be true, and why.
On the other hand, it is by no means clear that these connectionist models are successful and generalizable (scalable). They all have proved to have serious limitations that seem to be tied to their particular ways of implementing variable binding (syntactic structure) and structure sensitive processing. For critical discussion, see Marcus (2001), Hadley (2009), Browne and Sun (2001). Marcus in particular makes a strong and largely empirical case for why classical symbol systems are needed for explaining human capacities of variable binding and generalizing, and why existing connectionist models aren't up to the job to match human capacities while remaining non-classical. Indeed the trend in the last fifteen years seems to be towards developing hybrid systems combining connectionist and classical symbol processing models—see, for instance, the articles in Wermter and Sun (2000).[30]
Bibliography
Aizawa, K. (1994). “Representations without Rules, Connectionism and the Syntactic Argument.” Synthese 101(3): 465–492.
–––. (1997a). “Explaining Systematicity.” Mind and Language 12(2): 115–136.
–––. (1997b). “Exhibiting versus Explaining Systematicity: A Reply to Hadley and Hayward.” Minds and Machines 7(1): 39–55.
–––. (2003). The Systematicity Arguments, Kluwer Academic Publishers.
Aydede, Murat. (1995). “Connectionism and Language of Thought”, CSLI Technical Report, Stanford, CSLI, 95–195. (This is an early version of Aydede 1997 but contains quite a lot of expository material not contained in 1997.)
–––. (1997a). “Language of Thought: The Connectionist Contribution,” Minds and Machines, Vol. 7, No. 1, pp. 57–101.
–––. (1997b). “Has Fodor Really Changed His Mind on Narrow Content?”, Mind and Language, 12(3–4): 422–458.
–––. (1998). “Fodor On Concepts and Frege Puzzles,” Pacific Philosophical Quarterly, 79(4): 289–294.
–––. (2000). “On the Type/Token Relation of Mental Representations,” Facta Philosophica: International Journal for Contemporary Philosophy, 2(1): 23–49.
–––. (2005). “Computation and Functionalism: Syntactic Theory of Mind Revisited” in Gürol Irzik and G. Güzeldere (eds.), Boston Studies in the History and Philosophy of Science, Dordrecht: Kluwer Academic Publishers.
Aydede, Murat, and Güven Güzeldere (2005). “Cognitive Architecture, Concepts, and Introspection: An Information-Theoretic Solution to the Problem of Phenomenal Consciousness”, Noûs, 39(2): 197–255.
Armstrong, D.M. (1973). Belief, Truth and Knowledge, Cambridge: Cambridge University Press.
–––. (1980). The Nature of Mind, Ithaca, NY: Cornell University Press.
Bader, S. and B. Hitzler (2005). “Dimensions of neural-symbolic integration—a structured survey” in We Will Show Them: Essays in Honour of Dov Gabbay, edited by S. Artemov and H. Barringer and A. S. d'Avila Garcez and L.C. Lamb and J. Woods, King's College Publications.
Barnden, J. and K. Srinivas (1991). “Encoding techniques for complex information structures in connectionist systems,” Connection Science, 3(3): 269–315.
Barrett, L., J Feldman, and L. Mac Dermed (2008). “A (somewhat) new solution to the variable binding problem,” Neural Computation, Vol. 20, pp. 2361–2378.
Barsalou, L. W. (1993). “Flexibility, Structure, and Linguistic Vagary in Concepts: Manifestations of a Compositional System of Perceptual Symbols” in Theories of Memory, edited by A. Collins, S. Gathercole, M. Conway and P. Morris, Hillsdale, NJ: Lawrence Erlbaum Associates.
–––. (1999). “Perceptual Symbol Systems.” Behavioral and Brain Sciences 22(4).
Barsalou, L. W., W. Yeh, B. J. Luka, K. L. Olseth, K. S. Mix, and L.-L. Wu. (1993). “Concepts and Meaning”, Chicago Linguistics Society 29.
Barsalou, L. W., and J. J. Prinz. (1997). “Mundane Creativity in Perceptual Symbol Systems” in Creative Thought: An Investigation of Conceptual Structures and Processes, edited by T. B. Ward, S. M. Smith and J. Vaid, Washington, DC: American Psychological Association.
Barwise, Jon and John Etchemendy (1995). Hyperproof, Stanford, Palo Alto: CSLI Publications.
Barwise, J. and J. Perry (1983). Situations and Attitudes, Cambridge, Massachusetts: MIT Press.
Bechtel, W. and A. Abrahamsen (2002). Connectionism and the Mind: An Introduction to Parallel Processing in Networks, 2nd Edition, Oxford, UK: Basil Blackwell.
Blackburn, S. (1984). Spreading the Word, Oxford, UK: Oxford University Press.
Block, Ned. (1980). “Troubles with Functionalism” in Readings in Philosophy of Psychology, N. Block (ed.), Vol.1, Cambridge, Massachusetts: Harvard University Press, 1980. (Originally appeared in Perception and Cognition: Issues in the Foundations of Psychology, Minnesota Studies in the Philosophy of Science, C.W. Savage (ed.), Minneapolis: The University of Minnesota Press, 1978.)
–––. (ed.) (1981). Imagery. Cambridge, Massachusetts: MIT Press.
–––. (1983a). “Mental Pictures and Cognitive Science,” Philosophical Review 93: 499–542. (Reprinted in Mind and Cognition, W.G. Lycan (ed.), Oxford, UK: Basil Blackwell, 1990.)
–––. (1983b). “The Photographic Fallacy in the Debate about Mental Imagery”, Nous 17: 651–62.
––– (1986). “Advertisement for a Semantics for Psychology” in Studies in the Philosophy of Mind: Midwest Studies in Philosophy, Vol.10, P. French, T. Euhling and H. Wettstein (eds.), Minneapolis: University of Minnesota Press.
Braddon-Mitchell, David and John Fitzpatrick (1990). “Explanation and the Language of Thought,” Synthese 83: 3–29.
Braddon-Mitchell, D. and F. Jackson (2007). Philosophy of Mind and Cognition: An Introduction, Blackwell.
Browne, A. (1998). “Performing a symbolic inference step on distributed representations”, Neurocomputing, 19(1–3): 23–34.
Browne, A., and R. Sun (1999). “Connectionist variable binding”, Expert Systems, 16(3): 189–207.
–––. (2001). “Connectionist inference models”, Neural Networks, 14(10): 1331–1355.
Brentano, Franz (1874/1973). Psychology from an Empirical Standpoint, A. Rancurello, D. Terrell and L. McAlister (trans.), London: Routledge and Kegan Paul.
Butler, Keith (1991). “Towards a Connectionist Cognitive Architecture,” Mind and Language, Vol. 6, No. 3, pp. 252–72.
Chalmers, David J. (1990). “Syntactic Transformations on Distributed Representations,” Connection Science, Vol. 2.
–––. (1993). “Connectionism and Copositionality: Why Fodor and Pylyshyn Were Wrong” in Philosophical Psychology 6: 305–319.
–––. (1996). The Conscious Mind: In Search of a Fundamental Theory, Oxford, UK: Oxford University Press.
Churchland, Patricia Smith (1986). Neurophilosophy: Toward a Unified Science of Mind-Brain, Cambridge, Massachusetts: MIT Press.
–––. (1987). “Epistemology in the Age of Neuroscience,” Journal of Philosophy, Vol. 84, No. 10, pp. 544–553.
Churchland, Patricia S. and Terrence J. Sejnowski (1989). “Neural Representation and Neural Computation” in Neural Connections, Neural Computation, L. Nadel, L.A. Cooper, P. Culicover and R.M. Harnish (eds.), Cambridge, Massachusetts: MIT Press, 1989.
Churchland, Paul M. (1990). A Neurocomputational Perspective: The Nature of Mind and the Structure of Science, Cambridge, Massachusetts: MIT Press.
–––. (1981). “Eliminative Materialism and the Propositional Attitudes,” Journal of Philosophy 78: 67–90.
Churchland, Paul M. and P.S. Churchland (1990). “Could a Machine Think?,” Scientific American, Vol. 262, No. 1, pp. 32–37.
Clark, Andy (1988). “Thoughts, Sentences and Cognitive Science,” Philosophical Psychology, Vol. 1, No. 3, pp. 263–278.
–––. (1989a). “Beyond Eliminativism,” Mind and Language, Vol. 4, No. 4, pp. 251–279.
–––. (1989b). Microcognition: Philosophy, Cognitive Science, and Parallel Distributed Processing, Cambridge, Massachusetts: MIT Press.
–––. (1990). “Connectionism, Competence, and Explanation,” British Journal for Philosophy of Science, 41: 195–222.
–––. (1991). “Systematicity, Structured Representations and Cognitive Architecture: A Reply to Fodor and Pylyshyn” in Connectionism and the Philosophy of Mind, Terence Horgan and John Tienson (eds.), Studies in Cognitive Systems (Volume 9), Dordrecht: Kluwer Academic Publishers, 1991.
–––. (1994). “Language of Thought (2)” in A Companion to the Philosophy of Mind edited by S. Guttenplan, Oxford, UK: Basil Blackwell, 1994.
Cowie, F. (1998). What's Within? Nativism Reconsidered. Oxford, UK, Oxford University Press.
Cummins, Robert. (1986). “Inexplicit Information” in The Representation of Knowledge and Belief, M. Brand and R.M. Harnish (eds.), Tucson, Arizona: Arizona University Press, 1986.
–––. (1989). Meaning and Mental Representation, Cambridge, Massachusetts: MIT Press.
–––. (1996). Representations, Targets, and Attitudes, Cambridge, Massachusetts: MIT Press.
Cummins, Robert and Georg Schwarz (1987). “Radical Connectionism,” The Southern Journal of Philosophy, Vol. XXVI, Supplement.
Davidson, Donald (1984). Inquiries into Truth and Interpretation, Oxford: Clarendon Press.
Davies, Martin (1989). “Connectionism, Modularity, and Tacit Knowledge,” British Journal for the Philosophy of Science 40: 541–555.
–––. (1991). “Concepts, Connectionism, and the Language of Thought,” in Philosophy and Connectionist Theory, W. Ramsey, S.P. Stich and D.E. Rumelhart (eds.), Hillsdale, NJ: Lawrence Erlbaum, 1991.
–––. (1995). “Two Notions of Implicit Rules,” Philosophical Perspectives 9: 153–83.
Dennett, D.C. (1978). “Two Approaches to Mental Images” in Brainstorms: Philosophical Essays on Mind and Psychology, Cambridge, Massachusetts: MIT Press, 1981.
–––. (1981). “Cure for the Common Code” in Brainstorms: Philosophical Essays on Mind and Psychology, Cambridge, Massachusetts: MIT Press, 1981. (Originally appeared in Mind, April 1977.)
–––. (1986). “The Logical Geography of Computational Approaches: A View from the East Pole” in The Representation of Knowledge and Belief, Myles Brand and Robert M. Harnish (eds.), Tucson: The University of Arizona Press, 1986.
–––. (1991a). “Real Patterns,” Journal of Philosophy, Vol. LXXXVIII, No. 1, pp. 27–51.
–––. (1991b). “Mother Nature Versus the Walking Encyclopedia: A Western Drama” in Philosophy and Connectionist Theory, W. Ramsey, S.P. Stich and D.E. Rumelhart (eds.), Lawrence Erlbaum Associates.
Descartes, R. (1637/1970). “Discourse on the Method” in The Philosophical Works of Descartes, Vol.I, E.S. Haldane and G.R.T. Ross (trans.), Cambridge, UK: Cambridge University Press.
Devitt, Michael (1990). “A Narrow Representational Theory of the Mind,” Mind and Cognition, W.G. Lycan (ed.), Oxford, UK: Basil Blackwell, 1990.
–––. (1996). Coming to our Senses: A Naturalistic Program for Semantic Localism, Cambridge, UK: Cambridge University Press.
Devitt, Michael and Sterelny, Kim (1987). Language and Reality: An Introduction to the Philosophy of Language, Cambridge, Massachusetts: MIT Press.
Dretske, Fred (1981). Knowledge and the Flow of Information, Cambridge, Massachusetts: MIT Press.
–––. (1988). Explaining Behavior, Cambridge, Massachusetts: MIT Press.
Elman, Jeffrey L. (1989). “Structured Representations and Connectionist Models”, Proceedings of the Eleventh Annual Meeting of the Cognitive Science Society, Ann Arbor, Michigan, pp.17–23.
Field, Hartry H. (1972). “Tarski's Theory of Truth”, Journal of Philosophy, 69: 347–75.
–––. (1978). “Mental Representation”, Erkenntnis 13, 1, pp.9–61. (Also in Mental Representation: A Reader, S.P. Stich and T.A. Warfield (eds.), Oxford, UK: Basil Blackwell, 1994. References in the text are to this edition.)
Fodor, Jerry A. (1975). The Language of Thought, Cambridge, Massachusetts: Harvard University Press.
–––. (1978). “Propositional Attitudes” in RePresentations: Philosophical Essays on the Foundations of Cognitive Science, J.A. Fodor, Cambridge, Massachusetts: MIT Press, 1981. (Originally appeared in The Monist 64, No.4, 1978.)
–––. (1978a). “Computation and Reduction” in RePresentations: Philosophical Essays on the Foundations of Cognitive Science, J.A. Fodor, Cambridge, MA: MIT Press. (Originally appeared in Minnesota Studies in the Philosophy of Science: Perception and Cognition, Vol. 9, W. Savage (ed.), 1978.)
–––. (1978b). “Tom Swift and His Procedural Grandmother,” Cognition, Vol. 6. (Also in RePresentations: Philosophical Essays on the Foundations of Cognitive Science, J.A. Fodor, Cambridge, Massachusetts: MIT Press, 1981.)
–––. (1980). “Methodological Solipsism Considered as a Research Strategy in Cognitive Psychology”, Behavioral and Brain Sciences 3, 1, 1980. (Also in RePresentations: Philosophical Essays on the Foundations of Cognitive Science, J.A. Fodor, Cambridge, MA: MIT Press, 1981. References in the text are to this edition.)
–––. (1981a). RePresentations: Philosophical Essays on the Foundations of Cognitive Science, Cambridge, Massachusetts: MIT Press.
–––. (1981b), “Introduction: Something on the State of the Art” in RePresentations: Philosophical Essays on the Foundations of Cognitive Science, J.A. Fodor, Cambridge, Massachusetts: MIT Press, 1981.
–––. (1983). The Modularity of Mind, Cambridge, Massachusetts: MIT Press.
–––. (1985). “Fodor's Guide to Mental Representation: The Intelligent Auntie's Vade-Mecum”, Mind 94, 1985, pp.76–100. (Also in A Theory of Content and Other Essays, J.A. Fodor, Cambridge, Massachusetts: MIT Press. References in the text are to this edition.)
–––. (1986). “Banish DisContent” in Language, Mind, and Logic, J. Butterfield (ed.), Cambridge, UK: Cambridge University Press, 1986. (Also in Mind and Cognition, William Lycan (ed.), Oxford, UK: Basil Blackwell, 1990.)
–––. (1987). Psychosemantics: The Problem of Meaning in the Philosophy of Mind, Cambridge, Massachusetts: MIT Press.
–––. (1989). “Substitution Arguments and the Individuation of Belief” in A Theory of Content and Other Essays, J. Fodor, Cambridge, Massachusetts: MIT Press, 1990. (Originally appeared in Method, Reason and Language, G. Boolos (ed.), Cambridge, UK: Cambridge University Press, 1989.)
–––. (1990). A Theory of Content and Other Essays, Cambridge, Massachusetts: MIT Press.
–––. (1991). “Replies” (Ch.15) in Meaning in Mind: Fodor and his Critics, B. Loewer and G. Rey (eds.), Oxford, UK: Basil Blackwell, 1991.
–––. (2001). “Doing without What's Within: Fiona Cowie's Critique of Nativism.” Mind: 110(437) 99–148.
–––. (2008). LOT 2: The Language of Thought Revisited, Oxford: Oxford University Press.
Fodor, Jerry A. and Ernest Lepore (1991). “Why Meaning (Probably) Isn't Conceptual Role?”, Mind and Language, Vol. 6, No. 4, pp. 328–43.
Fodor, Jerry A. and B. McLaughlin (1990). “Connectionism and the Problem of Systematicity: Why Smolensky's Solution Doesn't Work,” Cognition 35: 183–204.
Fodor, Jerry A. and Zenon W. Pylyshyn (1988). “Connectionism and Cognitive Architecture: A Critical Analysis” in S. Pinker and J. Mehler, eds., Connections and Symbols, Cambridge, Massachusetts: MIT Press (A Cognition Special Issue).
Grice, H.P. (1957). “Meaning”, Philosophical Review, 66: 377–88.
Hadley, R. F. (1995). “The ”Explicit-Implicit“ Distinction.” Minds and Machines 5(2): 219–242.
–––. (1997). “Cognition, Systematicity and Nomic Necessity.” Mind and Language 12(2): 137–153.
–––. (1997). “Explaining Systematicity: A Reply to Kenneth Aizawa.” Minds and Machines 7(4): 571–579.
–––. (1999). “Connectionism and Novel Combinations of Skills: Implications for Cognitive Architecture.” Minds and Machines 9(2): 197–221.
–––. (2009). “The problem of rapid variable creation,” Neural Computation, 21: 510–32.
Hadley, R. F. and M. B. Hayward (1997). “Strong Semantic Systematicity from Hebbian Connectionist Learning.” Minds and Machines 7(1): 1–37.
Harman, Gilbert (1973). Thought, Princeton University Press.
Haugeland, John (1981). “The Nature and Plausibility of Cognitivism,” Behavioral and Brain Sciences I, 2: 215–60 (with peer commentary and replies).
–––. (1985). Artificial Intelligence: The Very Idea, Cambridge, Massachusetts: MIT Press.
Hinton, Geoffrey (1990). “Mapping Part-Whole Hierarchies into Connectionist Networks,” Artificial Intelligence, Vol. 46, Nos. 1–2, (Special Issue on Connectionist Symbol Processing).
Horgan, T. E. and J. Tienson (1996). Connectionism and the Philosophy of Psychology, Cambridge, Massachusetts: MIT Press.
Horgan, T. (1997). “Connectionism and the Philosophical Foundations of Cognitive Science.” Metaphilosophy 28(1–2): 1–30.
Hummel, J. E., Holyoak, K. J., Green, C., Doumas, L. A. A., Devnich, D., Kittur, A., & Kalar, D.J. (2004). A Solution to the Binding Problem for Compositional Connectionism. In S.D. Levy & R. Gayler: Compositional Connectionism in Cognitive Science: Papers from the AAAI Fall Symposium (pp. 31–34). Menlo Park, CA: AAAI Press.
Jacob, P. (1997). What Minds Can Do: Intentionality in a Non-Intentional World. Cambridge, UK, Cambridge University Press.
Kirsh, D. (1990). “When Is Information Explicitly Represented?” in Information, Language and Cognition. P. Hanson (ed.), University of British Columbia Press.
Knowles, J. (1998). “The Language of Thought and Natural Language Understanding.” Analysis 58(4): 264–272.
Kosslyn, S.M. (1980). Image and Mind. Cambridge, Massachusetts: Harvard University Press.
–––. (1981). “The Medium and the Message in Mental Imagery: A Theory” in Imagery, N. Block (ed.), Cambridge, Massachusetts: MIT Press, 1981.
–––. (1994). Image and Brain, Cambridge, Massachusetts: MIT Press.
Kulvicki, J. (2004). “Isomorphism in information-carrying systems”, Pacific Philosophical Quarterly 85(4): 380–395.
–––. (2006). On Images: Their Structure and Content, Oxford: Clarendon Press.
Laurence, Stephen and Eric Margolis (1997). “Regress Arguments Against the Language of Thought”, Analysis, Vol. 57, No. 1.
–––. (2002). “Radical Concept Nativism.” Cognition 86: 22–55.
Leeds, S. (2002). “Perception, Transparency, and the Language of Thought.” Noûs 36(1): 104–129.
Lewis, David (1972). “Psychophysical and Theoretical Identifications,” Australasian Journal of Philosophy, 50(3):249–58. (Also in Readings in Philosophy of Psychology, Ned Block (ed.), Vols.1, Cambridge, Massachusetts: Harvard University Press, 1980.)
–––. (1994). “Reduction of Mind” in A Companion to the Philosophy of Mind, edited by Samuel Guttenplan, Oxford: Blackwell, pp. 412–31.
Loar, Brian F. (1982a). Mind and Meaning, Cambridge, UK: Cambridge University Press.
–––. (1982b). “Must Beliefs Be Sentences?” in Proceedings of the Philosophy of Science Association for 1982, Asquith, P. and T. Nickles (eds.), East Lansing, Michigan, 1983.
Lycan, William G. (1981). “Toward a Homuncular Theory of Believing,” Cognition and Brain Theory 4(2): 139–159.
–––. (1986). “Tacit Belief” in Belief: Form, Content, and Function, R. Bogdan (ed.), Oxford, UK: Oxford University Press.
–––. (1993). “A Deductive Argument for the Representational Theory of Thinking,” Mind and Language, Vol. 8, No. 3, pp. 404–22.
–––. (1997). “Consciousness as Internal Monitoring” in The Nature of Consciousness: Philosophical Debates, edited by N. Block, O. Flanagan and G. Güzeldere, Cambridge, Massachusetts: MIT Press.
Marcus, G. F. (1998). “Can connectionism save constructivism?” Cognition 66: 153–182.
–––. (1998). “Rethinking Eliminative Connectionism.” Cognitive Psychology 37: 243–282.
–––. (2001). The Algebraic Mind: Integrating Connectionism and Cognitive Science. Cambridge, MA, MIT Press.
Margolis, Eric (1998). “How to Acquire a Concept?”, Mind and Language.
Margolis, E. and S. Laurence (1999). “Where the Regress Argument Still Goes Wrong: Reply to Knowles.” Analysis 59(4): 321–327.
–––. (2001). “The Poverty of the Stimulus Argument.” British Journal for the Philosophy of Science 52: 217–276.
––– (forthcoming-a). “Learning Matters: The Role of Learning in Concept Acquisition.”
–––. (forthcoming-b). “The Nativist Manifesto.”
Markic, O. (2001). “Is Language of Thought a Conceptual Necessity?” Acta Analytica 16(26): 53–60.
Marr, David (1982). Vision, San Francisco: W. H. Freeman.
Martinez, F. and J. Ezquerro Martinez (1998). “Explicitness with Psychological Ground.” Minds and Machines 8(3): 353–374.
Matthew, Robert J. (1994). “Three-Concept Monte: Explanation, Implementation and Systematicity”, Synthese, Vol. 101, No. 3, pp. 347–63.
McGinn, Colin (1989). Mental Content, Oxford: Blackwell.
–––. (1991). The Problem of Consciousness, Oxford, UK: Basil Blackwell.
McLaughlin, B.P. (1993a). “The Connectionism/Classicism Battle to Win Souls,” Philosophical Studies 71: 163–90.
–––. (1993b). “Systematicity, Conceptual Truth, and Evolution,” in Philosophy and Cognitive Science, C. Hookway and D. Peterson (eds.), Royal Institute of Philosophy, Supplement No. 34.
McLaughlin, B.P. and Ted Warfield (1994). “The Allures of Connectionism Reexamined”, Synthese 101, pp. 365–400
Millikan, Ruth Garrett (1984). Language, Thought, and Other Biological Categories: New Foundations for Realism, Cambridge, Massachusetts: MIT Press.
–––. (1993). White Queen Psychology and Other Essays for Alice, Cambridge, Massachusetts: MIT Press.
Niklasson, L. and T. van Gelder (1994). “On Being Systematically Connectionist,” Mind and Language, 9(3): 288–302
Papineau, D. (1987). Reality and Representation, Oxford, UK: Basil Blackwell.
Perry, John and David Israel (1991). “Fodor and Psychological Explanations” in Meaning in Mind: Fodor and his Critics, B. Loewer and G. Rey (eds.), Oxford, UK: Basil Blackwell, 1991.
Phillips, S. (2002). “Does Classicism Explain Universality?” Minds and Machines 12(3): 423–434.
Piccinini, G. (2008). “Computers,” Pacific Philosophical Quarterly, 89:32 –73.
Pinker, S., and A. Prince (1988). “On language and connectionism: Analysis of a parallel distributed processing model of language acquisition,” Cognition (special issue on Connections and Symbols) 28: 73–193.
Plate, Tony A. (1998). “Structured operations with distributed vector representations” in Keith Holyoak, Dedre Gentner, and Boicho Kokinov, Advances in Analogy Research: Integration of Theory and Data from the Cognitive, Computational, and Neural Sciences. NBU Series in Cognitive Science. New Bugarian University, Sofia.
Pollack, J.B. (1990). “Recursive Distributed Representations,” Artificial Intelligence, Vol.46, Nos.1–2, (Special Issue on Connectionist Symbol Processing).
Prinz, J. (2002). Furnishing the Mind: Concepts and Their Perceptual Basis. Cambridge, MA, MIT Press.
Putnam, Hilary (1988), Representation and Reality, Cambridge, Massachusetts: MIT Press.
Pylyshyn, Z.W. (1978). “Imagery and Artificial Intelligence” in Perception and Cognition. W. Savage (ed.), University of Minnesota Press. (Reprinted in Readings in the Philosophy of Psychology, N. Block (ed.), Cambridge, Massachusetts: MIT Press, 1980.)
Pylyshyn, Z. W. (1984). Computation and Cognition: Toward a Foundation for Cognitive Science, Cambridge, Massachusetts: MIT Press.
Ramsey, F.P. (1931). “General Propositions and Causality” in The Foundations of Mathematics, New York: Harcourt Brace, pp. 237–55.
Ramsey, W., S. Stich and J. Garon (1991). “Connectionism, Eliminativism and the Future of Folk Psychology,” in Philosophy and Connectionist Theory, W. Ramsey, D. Rumelhart and Stephen Stich (eds.), Hillsdale, NJ: Lawrence Erlbaum.
Rescorla, M. (2009a). “Cognitive maps and the language of thought,” The British Journal for the Philosophy of Science, 60 (2): 377–407.
–––. (2009b). “Predication and cartographic representation,” Synthese, 169:175–200.
Rey, Georges (1981). “What are Mental Images?” in Readings in the Philosophy of Psychology, N. Block (ed.), Vol. 2, Cambridge, Massachusetts: Harvard University Press, 1981.
–––. (1991). “An Explanatory Budget for Connectionism and Eliminativism” in Connectionism and the Philosophy of Mind, Terence Horgan and John Tienson (eds.), Studies in Cognitive Systems (Volume 9), Dordrecht: Kluwer Academic Publishers.
–––. (1992). “Sensational Sentences Switched”, Philosophical Studies 67: 73–103.
–––. (1993). “Sensational Sentences” in Consciousness, M. Davies and G. Humphrey (eds.), Oxford, UK: Basil Blackwell, pp. 240–57.
–––. (1995). “A Not ‘Merely Empirical’ Argument for a Language of Thought,” in Philosophical Perspectives 9, J. Tomberlin (ed.), pp. 201–222.
–––. (1997). Contemporary Philosophy of Mind: A Contentiously Classical Approach, Oxford, UK: Basil Blackwell.
Rosenthal, D.M. (1997). “A Theory of Consciousness” in The Nature of Consciousness: Philosophical Debates, edited by N. Block, O. Flanagan and G. Güzeldere, Cambridge, Massachusetts: MIT Press.
Roth, M. (2005). “Program Execution in Connectionist Networks,” Mind & Language, 20(4): 448–467.
Rumelhart, D.E. and J.L. McClelland (1986). “PDP Models and General Issues in Cognitive Science,” in Parallel Distributed Processing, Vol.1, D.E. Rumelhart, J.L. McClelland, and the PDP Research Group, Cambridge, Massachusetts: MIT Press, 1986.
Rumelhart, D.E., J.L. McClelland, and the PDP Research Group (1986). Parallel Distributed Processing, (Vols. 1&2), Cambridge, Massachusetts: MIT Press.
Rupert, R. D. (1999). “On the Relationship between Naturalistic Semantics and Individuation Criteria for Terms in a Language of Thought,” Synthese, 117: 95–131.
–––. (2008). “Frege's puzzle and Frege cases: Defending a quasi-syntactic solution,” Cognitive Systems Research, 9: 76–91.
Sanjeevi, S. and P. Bhattacharyya (2010). “Connectionist predicate logic model with parallel execution of rule chain” in Proceedings of the International Conference and Workshop on Emerging Trends in Technology (ICWET 2010) TCET, Mumbai, India (2010).
Schiffer, Stephen (1981). “Truth and the Theory of Content” in Meaning and Understanding, H. Parret and J. Bouveresse (eds.), Berlin: Walter de Gruyter, 1981.
Searle, John R. (1980). “Minds, Brains, and Programs” Behavioral and Brain Sciences III, 3: 417–24.
–––. (1984). Minds, Brains and Science, Cambridge, Massachusetts: Harvard University Press.
–––. (1990). “Is the Brain a Digital Computer?”, Proceedings and Addresses of the APA, Vol. 64, No. 3, November 1990.
–––. (1992). The Rediscovery of Mind, Cambridge, Massachusetts: MIT Press.
Sehon, S. (1998). “Connectionism and the Causal Theory of Action Explanation.” Philosophical Psychology 11(4): 511–532.
Shastri, L. (2006). “Comparing the neural blackboard and the temporal synchrony-based SHRUTI architecture,” Behavioral and Brain Science, 29: 84–86.
Shastri, L. and A. Ajjanagadde (1993). “From simple associations to systematic reasoning: A connectionist representation of rules, variables and dynamic bindings using temporal synchrony,” Behavioral and Brain Sciences, Vol. 16, pp. 417–94
Shepard, R. and Cooper, L. (1982). Mental Images and their Transformations. Cambridge, Massachusetts: MIT Press.
Smolensky, Paul (1988). “On the Proper Treatment of Connectionism,” Behavioral and Brain Sciences 11: 1–23.
–––. (1990a). “Connectionism, Constituency, and the Language of Thought” in Meaning in Mind: Fodor and His Critics, B. Loewer and G. Rey (eds.), : Oxford, UK: Basil Blackwell, 1991.
–––. (1990b). “Tensor Product Variable Binding and the Representation of Symbolic Structures in Connectionist Systems,” Artificial Intelligence, Vol. 46, Nos. 1–2, (Special Issue on Connectionist Symbol Processing), November 1990.
–––. (1995). “Constituent Structure and Explanation in an Integrated Connectionist/Symbolic Cognitive Architecture” in Connectionism: Debates on Psychological Explanation, C. Macdonald and G. Macdonald (eds.), Oxford, UK: Basil Blackwell, 1995.
Schneider, S. (2009). “The Nature of Symbols in the Language of Thought,” Mind and Language, 24(5): 523–553.
Stalnaker, Robert C. (1984). Inquiry, Cambridge, Massachusetts: MIT Press.
Sterelny, K. (1986). “The Imagery Debate”, Philosophy of Science 53: 560–83. (Reprinted in Mind and Cognition, W. Lycan (ed.), Oxford, UK: Basil Blackwell, 1990.)
–––. (1990). The Representational Theory of Mind, Cambridge, Massachusetts: MIT Press.
Stich, Stephen (1983). From Folk Psychology to Cognitive Science: The Case against Belief, Cambridge, Massachusetts: MIT Press.
Tarski, Alfred (1956). “The Concept of truth in Formalized Languages” in Logic, Semantics and Metamathematics, J.Woodger (trans.), Oxford, UK: Oxford University Press.
Touretzky, D.S. (1990). “BoltzCONS: Dynamic Symbol Structures in a Connectionist Network,” Artificial Intelligence, Vol. 46, Nos. 1–2, (Special Issue on Connectionist Symbol Processing).
Tye, M. (1984). “The Debate about Mental Imagery”, Journal of Philosophy 81: 678–91.
–––. (1991). The Imagery Debate, Cambridge, Massachusetts: MIT Press.
Van Der Velde, F. and Marc De Kamps (2006). “Neural blackboard architectures of combinatorial structures in cognition,” Behavioral and Brain Sciences, Vol. 29 (01), pp. 37–70.
van Gelder, Timothy (1989). “Compositionality and the Explanation of Cognitive Processes”, Proceedings of the Eleventh Annual Meeting of the Cognitive Science Society, Ann Arbor, Michigan, pp. 34–41.
–––. (1990). “Compositionality: A Connectionist Variation on a Classical Theme,” Cognitive Science, Vol. 14.
–––. (1991). “Classical Questions, Radical Answers: Connectionism and the Structure of Mental Representations” in Connectionism and the Philosophy of Mind, Terence Horgan and John Tienson (eds.), Studies in Cognitive Systems (Volume 9), Dordrecht: Kluwer Academic Publishers.
Vinueza, A. (2000). “Sensations and the Language of Thought.” Philosophical Psychology 13(3): 373–392.
Wermter, S. and Ron Sun (eds.) (2000). Hybrid Neural Systems, Heidelberg: Springer.
Academic ToolsAristotle’s logic, especially his theory of the syllogism, has had an unparalleled influence on the history of Western thought. It did not always hold this position: in the Hellenistic period, Stoic logic, and in particular the work of Chrysippus, took pride of place. However, in later antiquity, following the work of Aristotelian Commentators, Aristotle’s logic became dominant, and Aristotelian logic was what was transmitted to the Arabic and the Latin medieval traditions, while the works of Chrysippus have not survived.
This unique historical position has not always contributed to the understanding of Aristotle’s logical works. Kant thought that Aristotle had discovered everything there was to know about logic, and the historian of logic Prantl drew the corollary that any logician after Aristotle who said anything new was confused, stupid, or perverse. During the rise of modern formal logic following Frege and Peirce, adherents of Traditional Logic (seen as the descendant of Aristotelian Logic) and the new mathematical logic tended to see one another as rivals, with incompatible notions of logic. More recent scholarship has often applied the very techniques of mathematical logic to Aristotle’s theories, revealing (in the opinion of many) a number of similarities of approach and interest between Aristotle and modern logicians.
This article is written from the latter perspective. As such, it is about Aristotle’s logic, which is not always the same thing as what has been called “Aristotelian” logic.The economic framework that each society has — its laws, institutions, policies, etc. — results in different distributions of economic benefits and burdens across members of the society. These economic frameworks are the result of human political processes and they constantly change both across societies and within societies over time. The structure of these frameworks is important because the economic distributions resulting from them fundamentally affect people's lives. Arguments about which frameworks and/or resulting distributions are morally preferable constitute the topic of distributive justice. Principles of distributive justice are therefore best thought of as providing moral guidance for the political processes and structures that affect the distribution of economic benefits and burdens in societies.
This entry is structured in the following way. After outlining the scope of the entry and the role of distributive principles, the first relatively simple principle of distributive justice examined is Strict Egalitarianism, which calls for the allocation of equal material goods to all members of society. John Rawls' alternative distributive principle, which he calls the Difference Principle, is examined next. The Difference Principle permits diverging from strict equality so long as the inequalities in question would make the least advantaged in society materially better off than they would be under strict equality. Some have thought that neither strict equality nor Rawls' Difference Principle capture the important moral roles of luck and responsibility in economic life. The “Luck Egalitarianism” literature comprises varying attempts to design distributive principles that are appropriately sensitive to considerations of responsibility and luck in economic life. Desert-based principles similarly emphasize the moral roles of responsibility and luck but are distinct because they approach these factors through claims about what people deserve because of their work.
Advocates of welfare-based principles (of which utilitarianism is the most famous) do not believe the primary distributive concern should be material goods and services. They argue that material goods and services have no intrinsic value but are valuable only in so far as they increase welfare. Hence, they argue, distributive principles should be designed and assessed according to how they affect welfare, either its maximization or distribution. Advocates of libertarian principles, by contrast to each of the principles so far mentioned, generally criticize any distributive ideal that requires the pursuit of economic ‘patterns’, such as maximization or equality of welfare or of material goods. They argue that the pursuit of such patterns conflicts with the more important moral demands of liberty or self-ownership. Finally, feminist critiques of existing distributive principles note that they tend to ignore the particular circumstances of women, so feminists tend to argue for principles which are more sensitive to facts such as that women often have primary responsibility for child-rearing and on average, spend less of their lifetimes than men in the market economy.
2. Strict Egalitarianism
3. The Difference Principle
5. Welfare-Based Principles
6. Desert-Based Principles
7. Libertarian Principles
8. Feminist Principles
Bibliography
Academic Resources
Academic Tools
Related Entries
1. Scope and Role of Distributive Principles
Distributive principles vary in numerous dimensions. They vary in what is considered relevant to distributive justice (income, wealth, opportunities, jobs, welfare, utility, etc.); in the nature of the recipients of the distribution (individual persons, groups of persons, reference classes, etc.); and on what basis the distribution should be made (equality, maximization, according to individual characteristics, according to free transactions, etc.). In this entry, the focus is on principles designed to cover the distribution of benefits and burdens of economic activity among individuals in a society. Although principles of this kind have been the dominant source of Anglo-American debate about distributive justice over the last five decades, there are other important distributive justice questions, some of which are covered by other entries in the encyclopedia. These include questions of distributive justice at the global level rather than just at the national level (see justice: international), distributive justice across generations (see justice: intergenerational) and how the topic of distributive justice can be approached, not as a set of principles but as a virtue (see justice: as a virtue).
Although the numerous distributive principles vary along different dimensions, for simplicity, they are presented here in broad categories. Even though these are common classifications in the literature, it is important to keep in mind they necessarily involve over-simplification, particularly with respect to the criticisms of each of the groups of principles. Some criticisms may not apply equally to every principle in the group. The issue of how we are to understand and respond to criticisms of distributive principles is discussed briefly in the final section on methodology (see Methodology).
Throughout most of history, people were born into, and largely stayed in, a fairly rigid economic position. The distribution of economic benefits and burdens was normally seen as fixed, either by nature or by God. Only when there was a widespread realization that the distribution of economic benefits and burdens could be affected by government did distributive justice become a live topic. Now the topic is unavoidable. Governments continuously make and change laws and policies affecting the distribution of economic benefits and burdens in their societies. Almost all changes, whether they regard tax, industry, education, health, etc. have distributive effects. As a result, every society has a different distribution at any point in time and we are becoming increasingly more adept at measuring that distribution. More importantly, at every point in time now, each society is faced with a choice about whether to stay with current laws, policies, etc. or to modify them. The practical contribution of distributive justice theory is to provide moral guidance for these constant choices.
Partly because many writers on distributive justice tend to advocate their particular principles by describing or considering ideal societies operating under them, some readers may be misled to believe that discussions of distributive justice are merely exercises in ideal theory. This is unfortunate because, in the end, distributive justice theory is a practical enterprise. It is important to acknowledge that there has never been, and never will be, a purely libertarian society or Rawlsian society, or any society whose distribution conforms to one of the proposed principles, so rather than guiding ideal societies, distributive principles provide moral guidance for the choices that each society faces now and every year. So, for instance, advocates of Rawls' Difference Principle are arguing that we should change our institutions to improve the life prospects of the least advantaged in society. Others are arguing for changes to bring economic benefits and burdens more in accordance with what people deserve. Libertarians are arguing that reductions in government intervention in the economy will better respect liberty and/or self-ownership of its citizens. Sometimes a number of the theories will recommend the same changes; other times they will diverge.
Another popular misconception about distributive justice is that it is readily avoidable by the population and/or governments. This reveals a confusion about the nature of the choices always facing each society. To claim that we should not pursue any changes to our economic structures in light of a distributive justice argument is, by its very nature, to take a stand on the distributive justice of (or, if one prefers, the ‘morality’ of) the current distribution and structures in the society compared to any of the possible alternative distributions and structures practically available. At any particular moment the current economic framework is fundamentally affecting the economic and life prospects of everybody in the society. To assert that we should not change the current system is to take a substantive moral stance on that distribution — it is to say that it is morally preferable to any practical alternative proposed. The ‘should’ here has to be a moral should and if it is to be anything other than a bald assertion then the only type of argument that can back it up is one within the broad distributive justice tradition (which includes principles which do not use ‘justice’ per se, such as utilitarianism, but which are moral principles relating to distribution just the same). So societies cannot avoid taking positions about distributive justice.
A related point can be made when people assert that economic structures and policy should be left to economists, or when people assert that economic policy can be pursued without reference to distributive justice. These assertions reveal misconceptions about what distributive justice and economics are, and how they are related. Positive economics, at its best, can tell us about economic causes and effects. Positive economics is very important for distributive justice because it can give us guidance about which changes to pursue in order to better instantiate our moral principles. What it cannot do, in the absence of the principles, is tell us what we should do. This point is easily lost in everyday political discussion. When an economist says ‘The Central Bank should raise interest rates’ the general population often mistakenly believes the recommendation is purely coming from the science of economics. It is not. Moreover the ‘should’ is almost always a moral ‘should’. When economists make such a recommendation, they, sometimes unconsciously, have taken off their social scientific hat. They are employing alongside their positive economic theory, a moral principle. Often the moral evaluation being employed is not that controversial but suppressing that there are always moral arguments at play has had the effect of creating misconceptions about the role of distributive justice arguments in economic decision-making.
For instance, the raising of interest rates is typically thought by economists to have the dual effects of reducing inflation and reducing employment from what they otherwise would be. Other things being equal, most people think that reducing inflation is morally good and reducing employment is morally bad (it makes more people unemployed or underemployed). To get to a recommendation that the Central Bank should reduce interest rates involves not only empirical views about the relative sizes of the inflation and unemployment effects and their long-term impact on growth, etc. but also normative views about the relative moral importance of inflation, employment and growth. For economists, these normative views on economic policies come under the rubric of ‘normative’ economics, while philosophers would typically categorize them under ‘distributive justice’. But the rubrics are not important as basically the same area is covered under different names — the normative evaluation of economic policies/structure/institutions. The evaluations often look different because economists most commonly use utility as their fundamental moral concept while philosophers use a wider variety of moral concepts, but the task in which they are both engaged is the same. What is most important to understand here is that positive economics alone cannot, without the guidance of normative principles, recommend which policies/structures/institutions to pursue. The arguments and principles discussed in what follows aim to supply this kind of normative guidance.
2. Strict Egalitarianism
One of the simplest principles of distributive justice is that of strict, or radical, equality. The principle says that every person should have the same level of material goods and services. The principle is most commonly justified on the grounds that people are morally equal and that equality in material goods and services is the best way to give effect to this moral ideal.
Even with this ostensibly simple principle some of the difficult specification problems of distributive principles can be seen. The two main problems are the construction of appropriate indices for measurement (the index problem), and the specification of time frames. Because there are numerous proposed solutions to these problems, the ‘principle of strict equality’ is not a single principle but a name for a group of closely related principles. This range of possible specifications occurs with all the common principles of distributive justice.
The index problem arises primarily because the goods to be distributed need to be measured if they are going to be distributed according to some pattern (such as equality). The strict equality principle stated above says that there should be ‘the same level of material goods and services’. The problem is how to specify and measure levels. One way of solving the index problem in the strict equality case is to specify that everyone should have the same bundle of material goods and services rather than the same level (so everyone would have 4 oranges, 6 apples, 1 bike, etc.). The main objection to this solution is that it appears likely that there will be many other allocations of material goods and services which will make some people better off without making anybody else worse off. Such allocations are what are called ‘Pareto superior’ allocations (see equality for a more detailed discussion of Pareto efficiency). For instance, someone who prefers apples to oranges will be better off if she swaps some of her oranges for some of the apples belonging to a person who prefers oranges. That way, they are both better off and no one is worse off. Indeed, since most everyone will wish to trade something, requiring identical bundles will make virtually everybody materially worse off than they would be under an alternative allocation. So specifying that everybody must have the same bundle of goods does not seem to be a satisfactory way of solving the index problem. Some index for measuring the value of goods and services is required.
Money is an index for the value of material goods and services. It is an imperfect index whose pitfalls are documented in most economics textbooks. Moreover, once the goods to be allocated are extended beyond material ones to include goods such as opportunities, money must be combined with other indices. (For instance, John Rawls' index of primary goods — see Rawls 1971.) Nevertheless, using money, either in the form of income or wealth or both, as an index for the value of material goods and services is the most common response so far suggested to the index problem and is widely used in the specification and implementation of distributive principles.
The second main specification problem involves time frames. Many distributive principles identify and require that a particular pattern of distribution be achieved or at least aimed at. But they also need to specify when the pattern is required. One version of the principle of strict equality requires that all people should have the same wealth at some initial point, after which people are free to use their wealth in whatever way they choose, with the consequence that future outcomes are bound to be unequal. Principles specifying initial distributions after which the pattern need not be preserved are commonly called ‘starting-gate’ principles. (See Ackerman 1980, 53–59,168–170,180–186; Alstott and Ackerman 1999.)
Because ‘starting-gate’ principles may eventually lead to large inequalities, strict egalitarians do not usually favor them. The most common form of strict equality principle specifies that income (measured in terms of money) should be equal in each time-frame, though even this may lead to significant disparities in wealth if variations in savings are permitted. Hence, strict equality principles are commonly conjoined with some society-wide specification of just saving behavior (see justice: intergenerational). In practice, however, this principle and the starting-gate version might require more similar distributions than it first appears. This is because the structure of the family means the requirement to give people equal starts will often necessitate redistribution to parents, who due to bad luck, bad management, or simply their own choices, have been unsuccessful in accruing or holding onto material goods.
There are a number of direct moral criticisms made of strict equality principles: that they unduly restrict freedom, that they do not give best effect to the moral equality of persons, that they conflict with what people deserve, etc. (see the sections on Libertarian Principles, and Desert-Based Principles, and the entry on equality). But the most common criticism is a welfare-based one related to the Pareto efficiency requirement: that everyone can be materially better off if incomes are not strictly equal (Carens 1981). It is this criticism which partly inspired the Difference Principle.
3. The Difference Principle
The wealth of an economy is not a fixed amount from one period to the next. More wealth can be produced and indeed this has been the overwhelming feature of industrialized countries over the last couple of centuries. The dominant economic view is that wealth is most readily increased in systems where those who are more productive earn greater incomes. This economic view partly inspired the formulation of the Difference Principle.
The most widely discussed theory of distributive justice in the past four decades has been that proposed by John Rawls in A Theory of Justice, (Rawls 1971), and Political Liberalism, (Rawls 1993). Rawls proposes the following two principles of justice:
1. Each person has an equal claim to a fully adequate scheme of equal basic rights and liberties, which scheme is compatible with the same scheme for all; and in this scheme the equal political liberties, and only those liberties, are to be guaranteed their fair value.
2. Social and economic inequalities are to satisfy two conditions: (a) They are to be attached to positions and offices open to all under conditions of fair equality of opportunity; and (b), they are to be to the greatest benefit of the least advantaged members of society. (Rawls 1993, pp. 5–6. The principles are numbered as they were in Rawls' original A Theory of Justice.)
For (2b) Rawls uses an ‘index of primary goods’ to measure the benefits of people for the purposes of the second principle. Where the rules may conflict in practice, Rawls says that Principle (1) has lexical priority over Principle (2), and Principle (2a) has lexical priority over (2b). As a consequence of the priority rules, Rawls' principles do not permit sacrifices to basic liberties in order to generate greater equality of opportunity or a higher level of material goods, even for the worst off. While it is possible to think of Principle (1) as governing the distribution of liberties, it is not commonly considered a principle of distributive justice given that it is not governing the distribution of economic goods per se. Equality of opportunity is discussed in the next section. In this section, the primary focus will be on (2b), known as the Difference Principle.
The main moral motivation for the Difference Principle is similar to that for strict equality: equal respect for persons. Indeed the Difference Principle materially collapses to a form of strict equality under empirical conditions where differences in income have no effect on the work incentive of people. The overwhelming economic opinion though is that in the foreseeable future the possibility of earning greater income will bring forth greater productive effort. This will increase the total wealth of the economy and, under the Difference Principle, the wealth of the least advantaged. Opinion divides on the size of the inequalities which would, as a matter of empirical fact, be allowed by the Difference Principle, and on how much better off the least advantaged would be under the Difference Principle than under a strict equality principle. Rawls' principle however gives fairly clear guidance on what type of arguments will count as justifications for inequality. Rawls is not opposed in principle to a system of strict equality per se; his concern is about the absolute position of the least advantaged group rather than their relative position. If a system of strict equality maximizes the absolute position of the least advantaged in society, then the Difference Principle advocates strict equality. If it is possible to raise the absolute position of the least advantaged further by having some inequalities of income and wealth, then the Difference Principle prescribes inequality up to that point where the absolute position of the least advantaged can no longer be raised.
Because there has been such extensive discussion of the Difference Principle in the last 40 years, there have been numerous criticisms of it from the perspective of all the other theories of distributive justice outlined here. Briefly, the main criticisms are as follows.
Advocates of strict equality argue that inequalities permitted by the Difference Principle are unacceptable even if they do benefit the absolute position of the least advantaged. The problem for these advocates has been to explain convincingly why society should be prevented from materially benefiting the least advantaged when this benefit requires a deviation from strict equality.
For the strict egalitarian the relative position of people is all important and the absolute position is either not important at all or lexically inferior. For Rawls, at least with respect to the social and economic inequalities, the opposite is true. But there have been various plausible explanations given in reply to Rawls' proposed Difference Principle why relative position is a value that should be weighed against the value of the absolute position of the least advantaged rather than subordinated lexically to it. In an early reply to Rawls, Crocker explains the value of paying attention to the relative position as a way of understanding the value of solidarity. His approach fits into a set of views in which being materially equal, or striving towards it, is an important expression of the equality of persons.
Another set of views, in opposition to Rawls' Difference Principle, emphasizes the importance of relative position not as a value in itself but because of its effect on other relations. In particular, if some people are significantly better off materially than others then that can result in them having significant power over others. Rawls' response to this criticism appeals to the priority of his first principle: The inequalities consistent with the Difference Principle are only permitted so long as they do not compromise the fair value of the political liberties. So, for instance, very large wealth differentials may make it practically impossible for poor people to be elected to political office or to have their political views represented. These inequalities of wealth, even if they increase the material position of the least advantaged group, may need to be reduced in order for the first principle to be implemented. However, while this provides a partial reply to Rawls' critics, it does not seem to recognize that it is not just differential political power that can come from significant differences in economic position but also economic power and hence economic freedom. Virtual monopoly employers in regions of developing economies give a stark illustration of this phenomenon. Of course, Rawls can appeal in such cases to the empirical claim that such differentials do not maximize the long-term position of the least advantaged. The empirical question will be whether all such large differentials which result in large differences in economic power also demonstrably have the result of worsening the absolute position of the least advantaged.
The utilitarian objection to the Difference Principle is that it does not maximize utility. In A Theory of Justice, Rawls uses utilitarianism as the main theory for comparison with his own, and hence he offers a number of arguments in response to this utilitarian objection, some of which are outlined in the section on Welfare-Based Principles.
Libertarians object that the Difference Principle involves unacceptable infringements on liberty, property rights, or self-ownership. For instance, the Difference Principle may require redistributive taxation for the benefit of the poor, and libertarians commonly object that such taxation involves the immoral taking of just holdings (see Libertarian Principles).
The Difference Principle is also criticized as a primary distributive principle on the grounds that it mostly ignores claims that people deserve certain economic benefits in light of their actions. Advocates of desert-based principles argue that some may deserve a higher level of material goods because of their hard work or contributions even if their unequal rewards do not also function to improve the position of the least advantaged. Desert theorists as well as libertarians also argue that the explanation of how people come to be in more or less advantaged positions is morally relevant to their fairness, yet the Difference Principle ignores these explanations.
Like desert theorists, advocates of Luck Egalitarian principles argue that the Difference Principle does not fully capture the moral roles they believe luck and responsibility should play in principles of distributive justice. Indeed,‘ luck egalitarianism’ as a distinct approach in the distributive justice literature really developed in critical response to Rawls' theory of distributive justice. The reasons for that response are outlined in the next section.
4. Equality of Opportunity and Luck Egalitarianism
The distribution of material goods and services is not the only economic distribution which is important to people. The distribution of opportunities is also important. As noted in the previous section, John Rawls conjoined his Difference Principle with a principle of equality of opportunity. Endorsement of some form of equality of opportunity is very prevalent among distributive justice theorists and, indeed, among the general population, especially when combined with some form of market distributive mechanism. Equality of opportunity is often contrasted favorably with ‘equality of outcome’ or strict egalitarianism, by those who believe that we can show equal concern, respect, or treatment of people without them having the same material goods and services, so long as they have equal economic opportunities. What is the morally best interpretation of this equality of opportunity principle has been a significant focus of research, particularly among luck egalitarians.
In 1988, Brian Barry gave an interesting reconstruction of the reasoning which led John Rawls to his Equal Opportunity and Difference Principles. Barry's reconstruction and Ronald Dworkin's earlier discussion (which we will come to later), have been seminal in the luck egalitarian literature. A version of this argument is probably the best introduction to some of the relevant moral issues.
‘Formal’ equality of opportunity rules out formal discrimination on grounds such as a person's race, ethnicity, age or gender. What is the underlying concern, shared by most theorists and the general population, with a society lacking formal equality of opportunity? The concern seems to be rooted in the belief that traits such as a persons' gender or race are elements over which people have no control and, hence, a society in which people's race or gender have fundamental effects on their lifetime economic prospects treats people unfairly. In such societies, whether people were born as the favored gender or race, and hence were favored economically, would simply be a matter of luck. Rawls' claim is that structuring a society so that this ‘natural lottery’ has such fundamental effects on people's lives is immoral, when we have the option to structure it another way, with a system of formal equality of opportunity.
The foregoing is relatively uncontroversial, but what made Rawls' (and Barry's) arguments so interesting was their claim that this line of reasoning actually leads to much stronger requirements for social justice. They note that even with formal equality of opportunity, there will remain many factors over which people have no control but which will affect their lifetime economic prospects, such as whether a person's family can afford to purchase good quality educational opportunities or health care. A society therefore will have reasons to adopt a more substantial equality of opportunity principle, with equal opportunities for education, health care, etc. — the same reasons it had for adopting a merely formal equality of opportunity principle.
Following this line of reasoning further (and it certainly has appeared to many that we have no principled reason to stop here) seems to lead to more radical conclusions than those who agreed with formal equality of opportunity would have imagined. A society with a more substantial equality of opportunity principle in place will still not be providing equality of opportunity for all. People are born into more or less nurturing families and social circumstances. People are born into families and neighborhoods which are more or less encouraging of education and the development of economically advantageous talents. There are a whole range of social influences which have fundamental and unequal effects on children's economic prospects and for which they are in no way responsible — the influences children are exposed to are a matter of their luck in the ‘social lottery’. Moreover, the luck of the natural lottery is not just restricted to such characteristics as gender and race. Children are more or less fortunate in the distribution of natural talents as well.
A race where the starting line is arbitrarily staggered, where people's prospects for winning are not largely determined by factors for which they are responsible but rather largely by luck, is not considered a fair race. Similarly, if society is structured so that people's prospects for gaining more economic goods are not largely determined by factors for which they are responsible but rather largely by luck, then the society is open to the charge of being unfair. This is the challenging conclusion with which Barry, following Rawls, presents us.
In response to this challenge, Barry himself explores a number of avenues, including questioning whether economic distribution is really analogous to a race. Rawls, of course, responded to his own challenge by arguing that there is not a lot that can be done (morally) to make the social and natural opportunities more equal, so the fair response is to adopt the Difference Principle. Others, however, have taken this challenge in different directions.
Ronald Dworkin, (Dworkin 1981a, 1981b, 2000) provided one of the most detailed early responses to Rawls' challenge. In retrospect, Dworkin's theory is often identified as one of the earliest in the luck egalitarian literature, though Dworkin himself called his theory Resource Egalitarianism. Dworkin presented his key insight (i.e., what distinguishes him from Rawls) in terms of a distinction between ‘ambitions’ and ‘endowments’. Dworkin uses the term ‘ambitions’ to cover the realm of our choices and what results from our choices, such as the choice to work hard, or to spend money on expensive luxuries. His term ‘endowments’ refers to the results of brute luck, or those things over which we have no control, such as one's genetic inheritance, or unforeseeable bad luck. Dworkin agrees with Rawls that natural inequalities are not distributed according to people's choices, nor are they justified by reference to some other morally relevant fact about people, so people should not end up worse off as a result of bad luck in the natural lottery. However, Dworkin argues the Difference Principle fails to deliver on this ideal, since its formulation in terms of primary goods fails to recognize that those who are very unlucky, such as the severely ill or disabled, may need considerably greater shares of primary goods than others in order to achieve a reasonable life. Dworkin also argued that just economic distributions should be more responsive than the Difference Principle to the consequences of people's choices.
Dworkin proposed that people begin with equal resources but be allowed to end up with unequal economic benefits as a result of their own choices. What constitutes a just material distribution is to be determined by the result of a thought experiment designed to model fair distribution. Suppose that everyone is given the same purchasing power and each uses that purchasing power to bid, in a fair auction, for resources best suited to their life plans. They are then permitted to use those resources as they see fit. Although people may end up with different economic benefits, none of them is given less consideration than another in the sense that if they wanted somebody else's resource bundle they could have bid for it instead.
In Dworkin's proposal we see his attitudes to ‘ambitions’ and ‘endowments’ which have become a central feature of luck egalitarianism (though under a wide variety of alternative names and further subset-distinctions). In terms of sensitivity to ‘ambitions’, Dworkin and many other luck egalitarians argue that provided people have an ‘equal’ starting point (in Dworkin's case, resources) they should live with the consequences of their choices. They argue, for instance, that people who choose to work hard to earn more income should not be required to subsidize those choosing more leisure and hence less income.
With respect to ‘endowments’, Dworkin proposes a hypothetical compensation scheme in which he supposes that, before the hypothetical auction described above, people do not know their own natural endowments. However, they are able to buy insurance against being disadvantaged in the natural distribution of talents and they know that their payments will provide an insurance pool to compensate those people who are unlucky in the ‘natural lottery’.
Dworkin's early proposals were very hypothetical and it was somewhat difficult to see what they meant in practice. Later luck egalitarians have tried to tease out the practical implications of their theories in more detail, though much of the debate still remains at the theoretical level. They agree with Dworkin's recommendation, against Rawls' Difference Principle approach, that those with unequal natural endowments should receive compensation. For instance, people born with handicaps, or ill-health, who have not brought these circumstances upon themselves, can be explicitly compensated so that they are not disadvantaged in their economic prospects. Under Rawls' Difference Principle, though, no such explicit compensation is forthcoming — as Rawls says, the Difference Principle is not the principle of redress (Rawls 1971, 101). Of course, for the subset of people with long-term handicaps or ill-health who are also in the least advantaged group (variously defined by Rawls, but most commonly defined as the lowest socio-economic grouping) the Difference Principle will help. But the help will not be proportionate to their needs arising from their handicaps or ill-health.
Luck egalitarians continue to refine such aspects of their theories as (a) what they believe is the relevant conception of equality of opportunity, (b) how much of a role luck should play in the distribution of economic benefits and (c) what is the best conception of 'luck' (Arneson 1990 and 2001, Fleurbaey 2001, Swift 2008, Sher 2010). Relatedly, they continue to explore what role responsibility should play in the distribution of economic goods (Sen 1985, Cohen 1997, Valentyne 1997, Knight 2011).
Because the luck egalitarian proposals have a similar motivation to the Difference Principle the moral criticisms of them tend to be variations on those leveled against the Difference Principle. However, as noted above, what is practically required of a society operating under the Difference Principle is relatively straightforward. How the theoretical concerns of luck egalitarians are to be practically implemented is often not so clear. For instance, it has seemed impossible to measure differences in people's natural talents — unfortunately, people's talents do not neatly divide into the natural and those for which people can be held responsible. A system of special assistance to the physically and mentally handicapped and to the ill would be a partial implementation of the compensation system, but most natural inequalities would be left untouched by such assistance while the theories commonly require compensation for such inequalities. Exploring how in practical ways the economic systems can be refined to track responsibility while mitigating certain types of pure luck will be an ongoing challenge for luck egalitarians.
5. Welfare-Based Principles
Welfare-based principles are motivated by the idea that what is of primary moral importance is the level of welfare of people. Advocates of welfare-based principles view the concerns of other theories — material equality, the level of primary goods of the least advantaged, resources, desert-claims, or liberty — as derivative concerns. They are only valuable in so far as they affect welfare, so that all distributive questions should be settled entirely by how the distribution affects welfare. However, there are many ways that welfare can be used in answering these distributive questions, so welfare-theorists need to specify what welfare function they believe should be maximized. The welfare functions proposed vary according to what will count as welfare and the weighting system for that welfare. Economists defending some form of welfarism normally state the explicit functional form, while philosophers often avoid this formality, concentrating on developing their theories in answer to two questions: 1) the question of what has intrinsic value, and 2) the question of what actions or policies would maximize the intrinsic value. Moreover, philosophers tend to restrict themselves to a small subset of the available welfare functions. Although there are a number of advocates of alternative welfare functions (such as ‘equality of well-being’), most philosophical activity has concentrated on a variant known as utilitarianism. This theory can be used to illustrate most of the main characteristics of welfare-based principles.
Historically, utilitarians have used the term ‘utility’ rather than ‘welfare’ and utility has been defined variously as pleasure, happiness, or preference-satisfaction. Jeremy Bentham, the historical father of utilitarianism, argued that the experience of pleasure was the only thing with intrinsic value, and all other things had intstrumental value insofar as they contribute to the experience of pleasure or the avoidance of pain. His student John Stuart Mill broadened this theory of intrinsic value to include happiness, or fulfillment. Modern philosophers since Kenneth Arrow, though, tend to argue that intrinsic value consists in preference-satisfaction, i.e. in individuals' having what they want. So, for instance, the principle for distributing economic benefits for preference utilitarians is to distribute them so as to maximize preference-satisfaction. The welfare function for such a principle has a relatively simple theoretical form which requires choosing the distribution which maximizes the arithmetic sum of all satisfied preferences (unsatisfied preferences being negative), weighted for the intensity of those preferences. To accommodate uncertainty with respect to outcomes the function can be modified so that expected utility, rather than utility, is maximized (see consequentialism).
The basic theory of utilitarianism is one of the simplest to state and understand. Much of the work on the theory therefore has been directed towards defending it against moral criticisms, particularly from the point of view of ‘commonsense’ morality. The criticisms and responses have been widely discussed in the literature on utilitarianism as a general moral theory (see consequentialism). Two of the most widely discussed criticisms will be mentioned here.
The first, which was famously articulated by John Rawls (1971), is that utilitarianism fails to take seriously the distinctness of persons. Maximization of preference-satisfaction is often taken as prudent in the case of individuals — people may take on greater burdens, suffering or sacrifice at certain periods of their lives so that their lives are overall better. The complaint against utilitarianism is that it takes this principle, commonly described as prudent for individuals, and uses it on an entity, society, unlike individuals in important ways. While it may be acceptable for a person to choose to suffer at some period in her life (be it a day, or a number of years) so that her overall life is better, it is often argued against utilitarianism that it is immoral to make some people suffer so that there is a net gain for other people. In the individual case, there is a single entity experiencing both the sacrifice and the gain. Also, the individuals, who suffer or make the sacrifices, choose to do so in order to gain some benefit they deem worth their sacrifice. In the case of society as a whole, there is no single experiential entity — some people suffer or are sacrificed so that others may gain. Furthermore, under utilitarianism, there is no requirement for people to consent to the suffering or sacrifice, nor is there necessarily a unified belief in the society that the outcome is worth the cost.
A related criticism of utilitarianism involves the way it treats individual preferences about other peoples' welfare or holdings. For instance, some people may have a preference that the members of some minority racial group have less material benefits. Under utilitarian theories, in their classical form, this preference or interest counts like any other in determining the best distribution. Hence, if racial preferences are widespread and are not outweighed by the minority's contrary preferences (perhaps because the minority is relatively few in number compared to the majority), utilitarianism will recommend an inegalitarian distribution based on race if there is not some other utility-maximizing alternative on offer.
utilitarians have responded to these criticisms in a number of ways. utilitarians may believe that even more welfare in the long run can be achieved by re-educating the majority so that racist preferences weaken or disappear over time, leading to a more harmonious and happier world. However, the utilitarian must supply an account of why racist or sexist preferences should be discouraged if the same level of total long term utility could be achieved by encouraging the less powerful to be content with a lower position. Utilitarians have also argued that the empirical conditions are such that utility maximizing will rarely require racial minorities to sacrifice or suffer for the benefit of others, or to satisfy the prejudices of others. But if their theory on rare occasions does require people sacrifice or suffer in these ways, utilitarians have defended this unintuitive consequence on the grounds that our judgments about what is wrong provide us with ‘rules of thumb’ which are useful at the level of commonsense morality but ultimately mistaken at the level of ‘critical theory’. More recently, some utilitarians have drawn on institutional theory or game theory in defence, or in modification, of utilitarianism (see Hardin 1988, Goodin 1995, Bailey 1997). Noting that the consequences of individual actions are rarely determined in isolation, but rather in conjunction with the actions of many others, these Institutional utilitarians argue that morally intuitive institutions such as constitutional rights, human rights and various property rights would be endorsed by utilitarianism, and would forbid the morally horrible outcomes critics have feared utilitarianism could sanction.
Utilitarian distribution principles, like the other principles described here, have problems with specification and implementation. Most formulations of utilitarianism require interpersonal comparisons of utility. This means, for instance, that we must be able to compare the utility one person gains from eating an apple with that another gains from eating an apple. Furthermore, utilitarianism requires that differences in utility be measured and summed for widely disparate goods (so, for instance, the amount of utility a particular person gains from playing football is measured and compared with the amount of utility another gains from eating a gourmet meal). Some critics have argued that such interpersonal utility comparisons are impossible, even in theory, because even if the already significant challenge of combining all the diverse goods into a single index of ‘utility’ could be met for an individual, there is no conceptually adequate way of calibrating such a measure among individuals (see Elster 1991).
Utilitarians face a greater problem than this theoretical one in determining what material distribution is prescribed by their theory. Those who share similar utilitarian theoretical principles frequently recommend very different material distributions to implement the principle. This problem occurs for other theories, but appears worse for utilitarian and welfare-based distribution principles. Recommendations for distributions or economic structures to implement other distributive principles commonly vary among advocates with similar theoretical principles, but the advocates tend to cluster around particular recommendations. This is not the case for utilitarianism, with adherents dispersed in their recommendations across the full range of possible distributions and economic structures. For instance, many preference utilitarians believe their principle prescribes strongly egalitarian structures with lots of state intervention while other preference utilitarians believe it prescribes a laissez faire style of capitalism.
There is an explanation for why utilitarians are faced with greater difficulties in implementation. Other distributive principles can rule out, relatively quickly, some practical policies on the grounds that they clearly violate the guiding principle, but utilitarians must examine, in great detail, all the policies on offer. For each policy, they must determine the distribution of goods and services yielded by the policy and at least three other factors: the identity of each person in the distribution (if individuals' utility functions differ); the utility of each person from the goods and services distributed to them; the utility of each person from the policy itself. The size of the information requirements make this task impossible. Hence, broad assumptions must be made and each different set of assumptions will yield a different answer, and so the answers range across the full set of policies on offer. Moreover, there is no obvious way to arbitrate between the different sets of assumptions. For instance, suppose three utilitarians agree on the same utilitarian distributive principle. Utilitarian 1, for example, may assert that the population's utility function conforms to function A (e.g. people's marginal utility is linear in the goods and services they consume) and is maximized by Policy 1; Utilitarian 2, however, asserts that half the population's utility function conforms to function A and half to function B (e.g. people's marginal utility is diminishing) and is maximized by Policy 2; Utilitarian 3, furthermore, asserts Utilitarian 2 is correct about the utility functions of the population but claims that Policy 3 will maximize utility. What seems impossible for advocates of utilitarian-distribution principles to answer is how we would arbitrate these claims. If utilitarian principles are to play a role in debates about distributive justice then this is the most important question to answer.
6. Desert-Based Principles
Another complaint against welfarism is that it ignores, and in fact cannot even make sense of, claims that people deserve certain economic benefits in light of their actions (Feinberg, Lamont 1997). The complaint is often motivated by the concern that various forms of welfarism treat people as mere containers for well-being, rather than purposeful beings, responsible for their actions and creative in their environments.
The different desert-based principles of distribution differ primarily according to what they identify as the basis for deserving. While Aristotle proposed virtue, or moral character, to be the best desert-basis for economic distribution, contemporary desert theorists have proposed desert-bases that are more practically implemented in complex modern societies. Most contemporary desert theorists have pursued John Locke's lead in this respect. Locke argued people deserve to have those items produced by their toil and industry, the products (or the value thereof) being a fitting reward for their effort (see Miller 1989). Locke's underlying idea was to guarantee to individuals the fruits of their own labor and abstinence. Most contemporary proposals for desert-bases fit into one of three broad categories:
Contribution: People should be rewarded for their work activity according to the value of their contribution to the social product. (Miller 1976, Miller 1989, Riley 1989)
Effort: People should be rewarded according to the effort they expend in their work activity (Sadurski 1985a,b, Milne 1986).
Compensation: People should be rewarded according to the costs they incur in their work activity (Dick 1975, Lamont 1997).
According to the contemporary desert theorist, people freely apply their abilities and talents, in varying degrees, to socially productive work. People come to deserve varying levels of income by providing goods and services desired by others (Feinberg 1970). Distributive systems are just insofar as they distribute incomes according to the different levels earned or deserved by the individuals in the society for their productive labors, efforts, or contributions.
Contemporary desert-principles all share the value of raising the standard of living — collectively, ‘the social product’. Under each principle, only activity directed at raising the social product will serve as a basis for deserving income. The concept of desert itself does not yield this value of raising the social product; it is a value societies hold independently. Hence, desert principles identifying desert-bases tied to socially productive activity (productivity, compensation, and effort all being examples of such bases) do not do so because the concept of desert requires this. They do so because societies value higher standards of living, and therefore choose the raising of living standards as the primary value relevant to desert-based distribution. This means that the full development of desert-based principles requires specification (and defense) of those activities which will or will not count as socially productive, and hence as deserving of remuneration (Lamont 1994).
It is important to distinguish desert-payments from entitlements. For desert theorists a well-designed institutional structure will make it so that many of the entitlements people have are deserved. But entitlements and just deserts can come apart. As Feinberg notes, a person can be entitled to assume the presidential office without deserving it (Feinberg 1970, 86) and a person who accidentally apprehends a criminal may be entitled to a reward but not deserve it. Conversely, a team may deserve to win the championship prize but not entitled to it or a person may deserve an economic benefit but not be entitled to it. These instances of desert and entitlements coming apart are typical fertile grounds for a desert theorist to argue for institutional reform.
Payments designed to give people incentives are a form of entitlement particularly worth distinguishing from desert-payments as they are commonly confused (Barry 1965, 111–112). Incentive-payments are ‘forward-looking’ in that they are set up to create a situation in the future, while desert-payments are ‘backwards-looking’in that they are justified with reference to work in the present or past. Even though it is possible for the same payment to be both deserved and an incentive, incentives and desert provide distinct rationales for income and should not be conflated (Lamont 1997).
While some have sought to justify current capitalist distributions via desert-based distributive principles, John Stuart Mill and many since have forcefully argued the contrary claim — that the implementation of a productivity principle would involve dramatic changes in modern market economies and would greatly reduce the inequalities characteristic of them. It is important to note, though, that contemporary desert-based principles are rarely complete distributive principles. They usually are only designed to cover distribution among working adults, leaving basic welfare needs to be met by other principles.
The specification and implementation problems for desert-based distribution principles revolve mainly around the desert-bases: it is difficult to identify what is to count as a contribution, an effort or a cost, and it is even more difficult to measure these in a complex modern economy.
The main moral objection to desert-based principles is that they make economic benefits depend on factors over which people have little control. John Rawls has made one of the most widely discussed arguments to this effect (Rawls 1971), and while the strong form of this argument has been clearly refuted (Zaitchik, Sher), it remains a problem for desert-based principles. The problem is most pronounced in the case of productivity-based principles — a person's productivity seems clearly to be influenced by many factors over which the person has little control.
It is interesting to note that under most welfare-based principles, it is also the case that people's level of economic benefits depends on factors beyond their control. But welfarists view this as a virtue of their theory, since they think the only morally relevant characteristic of any distribution is the welfare resulting from it. Whether the distribution ties economic benefits to matters beyond our control is morally irrelevant from the welfarist point of view. (As it happens, welfarists often hold the empirical claim that people have little control over their contributions to society anyway.) However, for people's benefits to depend on factors beyond their control is a more awkward result for desert theorists who emphasize the responsibility of people in choosing to engage in more or less productive activities.
7. Libertarian Principles
Most contemporary versions of the principles discussed so far allow some role for the market as a means of achieving the desired distributive pattern — the Difference Principle uses it as a means of helping the least advantaged; utilitarian principles commonly use it as a means of achieving the distributive pattern maximizing utility; desert-based principles rely on it to distribute goods according to desert, etc. In contrast, advocates of libertarian distributive principles rarely see the market as a means to some desired pattern, since the principle(s) they advocate do not ostensibly propose a ‘pattern’ at all, but instead describe the sorts of acquisitions or exchanges which are just in their own right. The market will be just, not as a means to some pattern, but insofar as the exchanges permitted in the market satisfy the conditions of just acquisition and exchange described by the principles. For libertarians, just outcomes are those arrived at by the separate just actions of individuals; a particular distributive pattern is not required for justice. Robert Nozick has advanced this version of libertarianism (Nozick 1974), and is its best known contemporary advocate.
Nozick proposes a 3-part “Entitlement Theory”.
If the world were wholly just, the following definition would exhaustively cover the subject of justice in holdings:
A person who acquires a holding in accordance with the principle of justice in acquisition is entitled to that holding.
A person who acquires a holding in accordance with the principle of justice in transfer, from someone else entitled to the holding, is entitled to the holding.
No one is entitled to a holding except by (repeated) applications of (a) and (b).
The complete principle of distributive justice would say simply that a distribution is just if everyone is entitled to the holdings they possess under the distribution (Nozick, p.151).
The statement of the Entitlement Theory includes reference to the principles of justice in acquisition and transfer. (For details of these principles see Nozick, pp.149–182.) The principle of justice in transfer is the least controversial and is designed to specify fair contracts while ruling out stealing, fraud, etc. The principle of justice in acquisition is more complicated and more controversial. The principle is meant to govern the gaining of exclusive property rights over the material world. For the justification of these rights, Nozick takes his inspiration from John Locke's idea that everyone ‘owns’ themselves and, by mixing one's labors with the world, self-ownership can generate ownership of some part of the material world. However, of Locke's mixing metaphor, Nozick legitimately asks: ‘...why isn't mixing what I own with what I don't own a way of losing what I own rather than a way of gaining what I don't? If I own a can of tomato juice and spill it in the sea so its molecules... mingle evenly throughout the sea, do I thereby come to own the sea, or have I foolishly dissipated my tomato juice?’ (Nozick 1974, p.174) Nozick concludes that what is significant about mixing our labor with the material world is that in doing so, we tend to increase the value of it, so that self-ownership can lead to ownership of the external world in such cases (Nozick 1974, pp. 149–182).
The obvious objection to this claim is that it is not clear why the first people to acquire some part of the material world should be able to exclude others from it (and, for instance, be the land owners while the later ones become the wage laborers). In response to this objection, Nozick follows Locke in recognizing the need for a qualification on just acquisition. According to the Lockean Proviso, an exclusive acquisition of the external world is just, if, after the acquisition, there is ‘enough and as good left in common for others’. One of the main challenges for libertarians has been to formulate a morally plausible interpretation of this proviso. According to Nozick's weaker version of Locke's Proviso, “a process normally giving rise to a permanent bequeathable property right in a previously unowned thing will not do so if the position of others no longer at liberty to use the thing is thereby worsened” (Nozick, 1974, p. 178). For Nozick's critics, his proviso is unacceptably weak. This is because it fails to consider the position others may have achieved under alternative distributions and thereby instantiates the morally dubious criterion of whoever is first gets the exclusive spoils. For example, one can satisfy Nozick's proviso by ‘acquiring’ a beach and charging $1 admission to those who previously were able to use the beach for free, so long as one compensates them with a benefit they deem equally valuable, such as a clean-up or life-guarding service on the beach. However, the beach-goers would have been even better off had the more efficient organizer among them acquired the beach, charging only 50 cents for the same service, but this alternative is never considered under Nozick's proviso (Cohen, 1995).
Will Kymlicka has given a summary of the steps in Nozick's self-ownership argument:
People own themselves.
The world is initially unowned.
You can acquire absolute rights over a disproportionate share of the world, if you do not worsen the condition of others.
It is relatively easy, without worsening the condition of others, to acquire absolute rights over a disproportionate share of the world. Therefore:
Once private property has been appropriated, a free market in capital and labor is morally required (Kymlicka 1990, p. 112).
The assessment of this argument is quite complex, but the difficulties mentioned above with the proviso call into question claims (3) and (4).
The challenge for libertarians then is to find a plausible reading of (3) which will yield (4). Moreover, Nozick extends the operation of the proviso to apply both to acquisitions and transfers, compounding the problem,(Nozick, 1974, p. 174).
Of course, many existing holdings are the result of acquisitions or transfers which at some point did not satisfy the principles of justice for acquisitions or transfers. Hence, Nozick must supplement those principles with a principle of rectification for past injustice. Although he does not specify this principle he does describe its purpose:
This principle uses historical information about previous situations and injustices done in them... and information about the actual course of events that flowed from these injustices, until the present, and it yields a description (or descriptions) of holdings in the society. The principle of rectification presumably will make use of its best estimate of subjunctive information about what would have occurred... if the injustice had not taken place. If the actual description of holdings turns out not to be one of the descriptions yielded by the principle, then one of the descriptions yielded must be realized. (Nozick 1974, pp. 152–153)
Nozick does not make an attempt to provide a principle of rectification. The absence of such a principle is much worse for a historical theory than for a patterned theory. Past injustices systematically undermine the justice of every subsequent distribution in historical theories. Nozick is clear that his historical theory cannot be used to evaluate the justice of actual societies until such a theory of rectification is given or no considerations of rectification of injustice could apply to justify the distribution in the actual society:
In the absence of [a full treatment of the principle of rectification] applied to a particular society, one cannot use the analysis and theory presented here to condemn any particular scheme of transfer payments, unless it is clear that no considerations of rectification of injustice could apply to justify it. (Nozick 1974, p.231)
Unfortunately for the theory, it would seem that no such treatment will ever be forthcoming because the task is, for all practical purposes, impossible. The numbers of injustices perpetrated throughout history, both within nations and between them, are enormous and the necessary details of the vast majority of injustices are unavailable. Even if the details of the injustices were available, the counterfactual causal chains could not be reliably determined. As Derek Parfit has pointed out, in a different context, even the people who would have been born would have been different (Parfit 1986). As a consequence, it is difficult to see how Nozick's entitlement theory could provide guidance as to what the current distribution of material holdings should be or what distributions or redistributions are legitimate or illegitimate. (Indeed Nozick suggests, for instance, the Difference Principle may be the best implementation of the principle of rectification.) Although Nozick is fairly candid about this consequence, many of his supporters and critics have ignored it and have carried on a vigorous debate as though, contrary to Nozick's own statement, his theory can be used to evaluate the justice of current economic distributions.
Libertarians usually advocate a system in which there are exclusive property rights, with the role of the government restricted to the protection of these property rights. The property rights commonly rule out taxation for purposes other than raising the funds necessary to protect property rights. One of the strongest critiques of any attempt to institute such a system of legally protected strong property rights comes, as we have seen, from Nozick's theory itself — there seems no obvious reason to give strong legal protection to property rights which have arisen through violations of the just principles of acquisition and transfer. But putting this critique to one side for a moment, what other arguments are made in favor of exclusionary property rights?
As already noted, Nozick argues that because people own themselves and hence their talents, they own whatever they can produce with these talents. Moreover, it is possible in a free market to sell the products of exercising one's talents. Any taxation of the income from such selling, according to Nozick, ‘institute[s] (partial) ownership by others of people and their actions and labor’ (Nozick, p. 172). People, according to this argument, have these exclusive rights of ownership. Taxation then, simply involves violating these rights and allowing some people to own (partially) other people. Moreover, it is argued, any system not legally recognizing these rights violates Kant's maxim to treat people always as ends in themselves and never merely as a means. The two main difficulties with this argument have been: (1) to show that self-ownership is only compatible with having such strong exclusive property rights; and (2) that a system of exclusive property rights is the best system for treating people with respect, as ends in themselves.
Nozick candidly accepts that he does not himself give a systematic moral justification of the exclusionary property rights he advocates: ‘This book does not present a precise theory of the moral basis of individual rights.’ (Nozick, p.xiv) But others have tried to provide more systematic justifications of similar rights (Lomasky, Steiner) or to develop, more fully, justifications to which Nozick alludes.
In addition to the arguments from self-ownership, and the requirement to treat people as ends in themselves, the most common other route for trying to justify exclusive property rights has been to argue that they are required for the maximization of freedom and/or liberty or the minimization of violations of these (Hayek 1960). As an empirical claim though, this appears to be false. If we compare countries with less exclusionary property rights (e.g. more taxation) with countries with more exclusionary property regimes, we see no systematic advantage in freedoms/liberties enjoyed by people in the latter countries. (Of course, we do see a difference in distribution of such freedoms/liberties in the latter countries, the richer have more and the poorer less, while in the former they are more evenly distributed.) Now if libertarians restrict what counts as a valuable freedom/liberty (and discount other freedoms/liberties people value), it will follow that exclusionary property rights are required to maximize freedom/liberty or to minimize violations of these. But the challenge for these libertarians is to show why only their favored liberties and freedoms are valuable, and not those which are weakened by a system of exclusive property rights.
8. Feminist Principles
There is no one feminist conception of distributive justice; theorists who name themselves feminists defend positions across the political spectrum. Hence, feminists offer distinctive versions of all the theories considered so far as well as others. One way of thinking about what unifies many feminist theorists is an interest in what difference, if any, the practical experience of gender makes to the subject matter or study of justice; how different feminists answer this question distinguishes them from each other and from those alternative distributive principles that most inspire their thinking.
The distributive principles so far outlined, with the exception of strict egalitarianism, are often described as falling under the broad classification of liberalism — they both inform, and are the product of, the liberal democracies which have emerged over the last two centuries. Lumping them together this way, though clumsy, makes the task of understanding the emergence of feminist critiques (and the subsequent positive theories) much easier.
John Stuart Mill in The Subjection of Women (1869) gives one of the clearest early feminist critiques of the political and distributive structures of the emerging liberal democracies. His writings provide the starting point for many contemporary liberal feminists. Mill argued that the principles associated with the developing liberalism of his time required equal political status for women. The principles Mill explicitly mentions include a rejection of the aristocracy of birth, equal opportunity in education and in the marketplace, equal rights to hold property, a rejection of the man as the legal head of the household, and equal rights to political participation. Feminists who follow Mill believe that a proper recognition of the position of women in society requires that women be given equal and the same rights as men have, and that these primarily protect their liberty and their status as equal persons under the law. Thus, government regulation should not prevent women from competing on equal terms with men in educational, professional, marketplace and political institutions. From the point of view of other feminisms, the liberal feminist position is a conservative one, in the sense that it requires the proper inclusion for women of the rights, protections, and opportunities previously secured for men, rather than a fundamental change to the traditional liberal position. The problem for women, on this view, is not liberalism but the failure of society and the State to properly instantiate liberal principles.
One phrase or motto around which a whole range of feminists have rallied, however, marks a significant break with Mill's liberalism: ‘the personal is political.’ Feminists have offered a variety of interpretations of this motto, many of which take the form of a critique of liberal theories. Mill was crucial in developing the liberal doctrine of limiting the state's intervention in the private lives of citizens. Many contemporary feminists have argued that the resulting liberal theories of justice have fundamentally been unable to accommodate the injustices that have their origins in this ‘protected’ private sphere. This particular feminist critique has also been a primary source of inspiration for the broader multicultural critique of liberalism. The liberal commitments to government neutrality and to a protected personal sphere of liberty, where the government must not interfere, have been primary critical targets.
While issues about neutrality and personal liberty go beyond debates about distributive justice they also have application within these debates. The feminist critics recognize that liberalism correctly identifies the government as one potential source of oppression against individuals, and therefore recommends powerful political protections of individual liberty. They argue, however, that liberal theories of distributive justice are unable to address the oppression which surfaces in the so-called private sphere of government non-interference. Susan Moller Okin, for example, documents the effects of the institution of the nuclear family, arguing that the consequence of this institution is a position of systematic material and political inequality for women. Standard liberal theories, committed to neutrality in the private sphere, seem powerless to address (or sometimes even recognize) striking and lasting inequalities for women, minorities, or historically oppressed racial groups, when these are merely the cumulative effect of individuals' free behavior. Okin and others demonstrate, for example, that women have substantial disadvantages in competing in the market because of childrearing responsibilities which are not equally shared with men. As a consequence, any theory relying on market mechanisms, including most liberal theories, will yield systems which result in women systematically having less income and wealth than men. Thus, feminists have challenged contemporary political theorists to rethink the boundaries of political authority in the name of securing a just outcome for women and other historically oppressed groups.
While the political effects of personal freedom pose a serious challenge to contemporary liberal theories of distributive justice, the feminist critiques are somewhat puzzling because, as Jean Hampton puts it, many feminists appear to complain in the name of liberal values. In other words, their claims about the fundamental flaws of liberalism at the same time leave in tact the various ideals of liberty and equality which inspire the liberal theories of justice. Moreover, the task of defining feasible pathways for modifying the structure of liberal democracies without undermining their virtues and protections has proved more difficult than setting out the criticisms of liberalism. Indeed, despite a legitimate feminist worry about the effects of so-called government neutrality on women's material status, the relative neutrality of liberal democracies compared to non-liberal societies has been one of the significant contributing factors both to the flourishing of feminist theory and to the many significant practical gains women in liberal democracies have made relative to women in other parts of the world. The challenge, being taken up by many, is to navigate both a coherent theoretical and practical path in response to the best feminist critiques available (see the entry on feminist ethics).
9. Methodology and Empirical Beliefs about Distributive Justice
How are we to go about choosing between the different distributive principles on offer, and respond to criticisms of the principles? Unfortunately, few philosophers explicitly discuss the methodology they are using. The most notable exception is John Rawls (1971, 1974) who explicitly brought the method of wide reflective equilibrium to political philosophy. This method has been brilliantly discussed by Norman Daniels over the years and the reader is strongly encouraged to refer to his entry (see reflective equilibrium) to understand how to evaluate, revise and choose between normative principles. While there is no point in reiterating the method here there are some supplementary issues worth noting.
Empirical data on the beliefs of the population about distributive justice was not available when Rawls published A Theory of Justice (Rawls 1971) but much empirical work has since been completed. Swift (1995, 1999) and Miller (1999, chaps. 3–4) have provided surveys of this literature and arguments for why those committed to the method of reflective equilibrium in distributive justice should take the beliefs of the population seriously, though not uncritically. Indeed, some go even further, arguing that the distributive decisions arising through the legitimate application of particular democratic processes might even, at least in part, constitute distributive justice (Walzer 1984). Data on people's beliefs about distributive justice is also useful for addressing the necessary intersection between philosophical and political processes. Such beliefs put constraints on what institutional and policy reforms are practically achievable in any generation — especially when the society is committed to democratic processes.
Two final methodological issues need to be noted. The first concerns the distinctive role counterexamples play in debates about distributive justice. As noted above, the overarching methodological concern of the distributive justice literature must be, in the first instance, the pressing choice of how the benefits and burdens of economic activity should be distributed, rather than the mere uncovering of abstract truth. Principles are to be implemented in real societies with the problems and constraints inherent in such application. Given this, pointing out that the application of any particular principle will have some, perhaps many, immoral results will not by itself constitute a fatal counterexample to any distributive theory. Such counter-evidence to a theory would only be fatal if there were an alternative, or improved, version of the theory, which, if fully implemented, would yield a morally preferable society overall. So, it is at least possible that the best distributive theory, when implemented, might yield a system which still has many injustices and/or negative consequences. This practical aspect partly distinguishes the role of counterexamples in distributive justice theory from many other philosophical areas. Given that distributive justice is about what to do now, not just what to think, alternate distributive theories must, in part, compete as comprehensive systems which take into account the practical constraints we face.
The second and related methodological point is that the evaluation of alternate distributive principles requires us (and their advocates) to consider the application of the distributive principle in the world. If it is uncertain or indeterminate how a particular distributive principle might in practice apply to the ordering of real societies, then this principle is not yet a serious candidate for our consideration. This is also true of principles whose implementation is practically impossible given the institutional/psychological/informational/administrative/technical constraints of a society. Distributive justice is not an area where we can say an idea is good in theory but not in practice. If it is not good in practice, then it is not good in theory either.
Bibliography
Strict Egalitarianism
Carens, Joseph, 1981, Equality, Moral Incentives and the Market, Chicago: Chicago University Press.
Rawls, John, 1971, A Theory of Justice, Harvard, MA: Harvard University Press.
Nielsen, Kai, 1979, “Radical Egalitarian Justice: Justice as Equality,” Social Theory and Practice, 5: 209–226.
The Difference Principle
Crocker, Lawrence, 1977, “Equality, Solidarity, and Rawls' Maximin,” Philosophy and Public Affairs, 6: 262–266
Rawls, John, 1971, A Theory of Justice, Harvard, MA: Harvard University Press.
–––, 1974, “The Independence of Moral Theory,” Proceedings and Addresses of the American Philosophical Association, 47: 5–22, in Collected Papers, 1999, 286–302.
–––, 1993, Political Liberalism, New York: Columbia University Press.
–––, 1999, Collected Papers, Sam Freeman, (ed.), Cambridge: Harvard University Press.
–––, 2001, Justice as Fairness: A Restatement, Cambridge: Harvard University Press.
Wellbank, J. H., 1982, John Rawls and his critics: an annotated bibliography, New York: Garland.
Equality of Opportunity and Luck Egalitarianism
Arneson, Richard, 1990, “Liberalism, Distributive Subjectivism, and Equal Opportunity for Welfare,” Philosophy and Public Affairs, 19: 158–194.
Barry, Brian, 1988, “Equal opportunity and moral arbitrariness,” in Equal Opportunity, Norman E. Bowie (ed.), Boulder and London: Westview Press, 23–44.
Daniels, Norman, 1990, “Equality of What: Welfare, Resources, or Capabilities?,” Philosophy and Phenomenological Research, 50: 273–206.
Dworkin, Ronald, 1981, “What is Equality? Part 1: Equality of Resources,” Philosophy and Public Affairs, 10: 185–246.
Dworkin, Ronald, 1981, “What is Equality? Part 2: Equality of Welfare,” Philosophy and Public Affairs, 10: 283–345.
Dworkin, Ronald, 2000, Sovereign Virtue, Cambridge, MA: Harvard University Press.
Fleurbaey, Marc., 2001, “Egalitarian Opportunities,” Law and Philosophy: An International Journal for Jurisprudence and Legal Philosophy, 20: 499–530.
Knight, C. (ed.) 2011, Responsibility and Distributive Justice , Oxford: Oxford University Press.
Kronman, Anthony T., 1981, “Talent Pooling,” in J. Roland Pennock and John W.Chapman (eds.), Human Rights: Nomos 23, New York: New York University Press, 58–79.
Sen, Amartya, 1982, “Equality of What?,” in A. Sen, Choice, Welfare and Measurement, Cambridge: Cambridge University Press.
Sher, G., 2010, “Real-World Luck Egalitarianism,” Social Philosophy and Policy, 27 (1): 218–232.
Steiner, H. 1997, “Choice and Circumstance,” Ratio: An International Journal of Analytic Philosophy, 10: 296–312.
Swift, A. 2008, “The Value of Philosophy in Nonideal Circumstances,” Social Theory and Practice: An International and Interdisciplinary Journal of Social Philosophy, 34: 363–387.
Vallentyne, Peter, 1997, “Self-Ownership and Equality: Brute Luck, Gifts, Universal Dominance, and Leximin,” Ethics, 107: 321–343.
Welfare-Based Principles
Bailey, James Wood, 1997, Utilitarianism, Institutions, and Justice, New York: Oxford University Press.
Elster, Jon, and John E. Roemer (eds.), 1991, Interpersonal Comparisons of Well-Being, Cambridge: Cambridge University Press.
Gaus, Gerald F., 1998, “Why All Welfare States (Including Laissez-Faire Ones) Are Unreasonable,” Social Philosophy and Policy, 15: 1–33.
Glover, Jonathan (ed.), 1990, Utilitarianism and Its Critics, New York: Macmillan.
Goodin, Robert E., 1995, Utilitarianism as a Public Philosophy, New York: Cambridge University Press.
Hardin, Russell, 1988, Morality within the Limits of Reason, Chicago: University of Chicago Press.
Rescher, Nicholas, 1966, Distributive Justice: A Constructive Critique of the Utilitarian Theory of Distribution, Indianapolis: Bobbs-Merrill.
Schmidtz, David and Robert E. Goodin, 1998, Social Welfare and Individual Responsibility, For and Against, Cambridge: Cambridge University Press.
Sen, Amartya, and Bernard Williams (eds.), 1982, Utilitarianism and Beyond, Cambridge: Cambridge University Press.
Schroth, J. 2008, “Distributive Justice and Welfarism in Utilitarianism,” Inquiry: An Interdisciplinary Journal of Philosophy, 51: 123–146.
Desert-Based Principles
Dick, James, 1975, “How to Justify a Distribution of Earnings,” Philosophy and Public Affairs, 4: 248–72.
Feinberg, Joel, 1970, “Justice and Personal Desert,” Doing and Deserving, Princeton, NJ: Princeton University Press, 55–94.
Lamont, Julian, 1997, “Incentive Income, Deserved Income, and Economic Rents,” Journal of Political Philosophy, 5: 26–46.
Lamont, Julian, 1995, “Problems For Effort-Based Distribution Principles,” Journal of Applied Philosophy, 12: 215–229.
Lamont, Julian, 1994, “The Concept of Desert in Distributive Justice,” The Philosophical Quarterly, 44: 45–64.
Mill, John Stuart, 1848, Principles of Political Economy, W.J. Ashley (ed.), New York: Kelly, 1965. Reprint of the 1909 edition.
Miller, David, 1989, Market, State, and Community, Oxford: Clarendon Press.
Miller, David, 1976, Social Justice, Oxford: Clarendon Press.
Milne, Heather, 1986, “Desert, effort and equality,” Journal of Applied Philosophy, 3: 235–243. .
Pojman, L. and McLeod, O. (eds), 1999, What Do We Deserve?, New York: Oxford University Press.
Riley, Jonathan, 1989, “Justice Under Capitalism,” Markets and Justice, John W. Chapman (ed.), New York: New York University Press, 122–162.
Sadurski, Wojciech, 1985a, Giving Desert Its Due, Dordrecht: D. Reidel.
Sadurski, Wojciech, 1985b, Giving desert its due : social justice and legal theory (Law and Philosophy Library, Volume 2), Dordrecht, Boston: D. Reidel.
Sher, George, Desert, Princeton, NJ: Princeton University Press, 1987.
Zaitchik, Alan, 1977, “On Deserving to Deserve,” Philosophy and Public Affairs, 6: 370–388.
Libertarian Principles
Bogart, J. H., 1985, “Lockean Provisos and State of Nature Theories,” Ethics, 95: 828–836.
Christman, John, 1991, “Self-Ownership, Equality, and the Structure of Property Rights,” Political Theory, 19: 28–46.
Cohen, G. A., 1995, Self-Ownership, Freedom, and Equality, New York: Cambridge University Press.
Hayek, Friedrich A., 1960, The Constitution of Liberty, London, Routledge and Kegan Paul.
Hospers, J. 1971, Libertarianism: a Political Philosophy for Tomorrow, Los Angeles: Nash.
Kymlicka, Will, 1990, Contemporary Political Philosophy, Oxford: Clarendon Press.
Lomasky, Loren E., 1987, Persons, Rights, and the Moral Community, New York: Oxford University Press.
Mack, E. 1995, “The Self-Ownership Proviso: A New and Improved Lockean Proviso,” Social Philosophy and Policy, 12: 186–218.
Narveson, J., 1988, The Libertarian Idea, Philadelphia: Temple University Press.
Nozick, Robert, 1974, Anarchy, State and Utopia, New York: Basic Books.
Otsuka, M. 2003, Libertarianism without Inequality, Oxford: Clarendon Press.
Schmidtz, D. 2005, “History and Pattern,” Social Philosophy and Policy, 22: 148–177.
Steiner, H., 1981, Liberty and Equality, Political Studies, 29: 555–569.
Feminist Principles
Okin, Susan Moller, 1991, Justice, Gender and the Family, New York: Basic Books.
Hampton, Jean, 1997, Political Philosophy, Boulder: Westview Press.
Held, Virginia, 1994, Rights and Goods: justifying social action, New York: Free Press.
Gatens, Moira, 1991, Feminism and Philosophy: Perspectives on Difference and Equality, Indianapolis: Indianan University Press.
MacKinnon, Catherine A., 2001, Sex Equality, New York: Foundation Press.
MacKinnon, Catherine A., 1987, Feminism Unmodified: Discourses of Life and Law, Cambridge, MA: Harvard University Press.
Pateman, Carol, 1988, The Sexual Contract, Stanford: Stanford University Press.
Tong, Rosemary, 1993, Feminine and Feminist Ethics, Belmont, CA: Wadsworth.
Methodology and Empirical Beliefs about Distributive Justice
Daniels, Norman, 1996, Justice and Justification: Reflective Equilibrium in Theory and Practice, New York: Cambridge University Press.
Elster, Jon, 1995, “The Empirical Study of Justice,” in Pluralism, Justice, and Equality, David Miller and Michael Walzer (eds.), New York: Oxford University Press, 81–98. .
Miller, David, 1999, Principles of Social Justice, Cambridge, MA: Harvard University Press.
Swift, Adam, 1999, “Public Opinion and Political Philosophy: The relation between social-scientific and philosophical analyses of distributive justice,” Ethical Theory and Moral Practice: An International Forum, 2: 337–363 .
Swift, Adam, and Gordon Marshall, Carole Burgoyne, and David Routh, 1995, “Distributive justice: Does it matter what the people think?,” in Social Justice and Political Change., D. Mason, J. Kluegel and B. Wegener (eds.), New York: Aldine De Gruyter, 15–47 .
For extensive further references on reflective equilibrium see the entry on reflective equilibrium.
Further Theories and General Reference
Ackerman, Bruce A., 1980, Social Justice and the Liberal State, New Haven: Yale University Press.
Alstott, Anne and Bruce A. Ackerman, 1999, The Stakeholder Society, New Haven: Yale University Press.
Arthur, John and William Shaw (eds.), 1991, Justice and Economic Distribution 2nd Ed., Englewood Cliffs, NJ: Prentice-Hall.
Barry, Brian, 1965, Political Argument, London: Routledge and Keagan Paul.
Barry, Brian, 1989, Theories of Justice (Volume 1), Berkeley: University of California Press.
Cohen, G.A., 1997, “Where the Action Is: On the Site of Distributive Justice,” in Philosophy and Public Affairs, 26: 3–30.
Cohen, G.A., 2000, If You're an Egalitarian, How Come You're so Rich?, Cambridge, MA: Harvard University Press.
Gauthier, David, 1987, Morals by Agreement, Cambridge: Cambridge University Press.
Kymlicka, Will, 1990, Contemporary Political Philosophy, Oxford: Clarendon Press.
Parfit, Derek, 1986, Reasons and Persons, Oxford: Oxford University Press.
Roemer, John E., 1996, Theories of Distributive Justice, Cambridge, MA: Harvard University Press.
Scheffler, Samuel, 2001, Boundaries and Allegiances, Oxford: Oxford University Press.
Schmidtz, D. 2006, Elements of Justice, Cambridge: Cambridge University Press.
Walzer Michael, 1984, Spheres of Justice, New York: Basic Books.
Extended Bibliography
Academic Tools
Other Internet Resources
Current Issues in Distributive Justive
Center For Economic And Social Justice This site promotes a new paradigm of economics and development, the “just third way”. Provides links to numerous organisations, reports, articles and statistical data which support its paradigm.
Centre for Independent Studies (CIS) The CIS offers an Australian perspective on libertarian distributive justice, with its purpose to promote a market economy with high growth, an open society, individual freedom and small government in Australia.
Communist Party of Australia (CPA) Official website of CPA Australia. An alternative approach to current social policy issues within Australia promoting Communist Theory.
Crossroads Community Fund Crossroads was established in 1979 as a response to increasing social problems regarding the distribution of wealth, power and resources in Chicago, USA. This organisation attempts to address the institutional barriers that prevent people from enjoying freedom in their lives and attempts to evaluate the effectiveness of institutional changes to increase freedom.
Index to Economic and Social Development Statistics of the United Nations An index linking to relevant statistics associated with social and economic justice development both globally and in specific regions.
Guild Law Centre for Economic and Social Justice A non-profit law centre which provides advocacy, representation, legal education and technical support to empower communities, worker rights groups and individuals seeking systemic change toward economic and social justice.
Heritage Foundation A research and educational institution in the United States, whose stated purpose is to formulate and promote libertarian public policies based on principles of free enterprise, limited government, individual freedom, and a strong national defence.
Political Research Associates Home Page A non-profit organisation committed to establishing a democratic society based on progressive values and encouraging a pluralistic society. The website enables various activists to voice their opinion about the injustices of American society and supports research projects for developing ideas and informing the general public.
Project for a New American Century Organisation in the USA that promotes conservative policy issues, encouraging an increase in America's defence, and American involvement in international and global issues.
People in Distributive Justice
Marxists Internet Archive A website for Marxist theory, including the history of Marxist thought, writings on Marxism, and a format for questions and debates.
John Rawls Philosophy Books and Online Resources Provides resources and commentaries on Rawls' work.
Further Resources
Archive for the History of Economic Thought A predominately economics site through McMaster University with a large collection of papers, containing a good selection on Mill, Bentham and Hume.
Brown Electronic Article Review Service In Moral And Political Philosophy This site publishes reviews of up to 1000 words on recent articles, papers and reports in moral and political philosophy.
Political Philosophy/Political Theory Site from the University of British Columbia Library to aid students in accessing both primary and secondary sources in political theory.
Utilitarianism Resources Website linked to Carnegie Mellon University which list current material and critiques of applied ethics theory.
[Please contact the author with other suggestions]Scientific inquiry has led to immense explanatory and technological successes, partly as a result of the pervasiveness of scientific theories. Relativity theory, evolutionary theory, and plate tectonics were, and continue to be, wildly successful families of theories within physics, biology, and geology. Other powerful theory clusters inhabit comparatively recent disciplines such as cognitive science, climate science, molecular biology, microeconomics, and Geographic Information Science (GIS). Effective scientific theories magnify understanding, help supply legitimate explanations, and assist in formulating predictions. Moving from their knowledge-producing representational functions to their interventional roles (Hacking 1983), theories are integral to building technologies used within consumer, industrial, and scientific milieus.
This entry explores the structure of scientific theories from the perspective of the Syntactic, Semantic, and Pragmatic Views. Each of these answers questions such as the following in unique ways. What is the best characterization of the composition and function of scientific theory? How is theory linked with world? Which philosophical tools can and should be employed in describing and reconstructing scientific theory? Is an understanding of practice and application necessary for a comprehension of the core structure of a scientific theory? Finally, and most generally, how are these three views ultimately related?
5. Population Genetics
6. Conclusion
Bibliography
Academic Tools
Other Internet Resources
1. Introduction
In philosophy, three families of perspectives on scientific theory are operative: the Syntactic View, the Semantic View, and the Pragmatic View. Savage distills these philosophical perspectives thus:
The syntactic view that a theory is an axiomatized collection of sentences has been challenged by the semantic view that a theory is a collection of nonlinguistic models, and both are challenged by the view that a theory is an amorphous entity consisting perhaps of sentences and models, but just as importantly of exemplars, problems, standards, skills, practices and tendencies. (Savage 1990, vii–viii)
Mormann (2007) characterizes the Syntactic and Semantic Views in similar terms, and is among the first to use the term “Pragmatic View” to capture the third view (137). The three views are baptized via a trichotomy from linguistics deriving from the work of Charles Morris, following Charles S. Peirce. In a classic exposition, the logical positivist Carnap writes:
If in an investigation explicit reference is made to the speaker, or, to put it in more general terms, to the user of a language, then we assign it to the field of pragmatics. (Whether in this case reference to designata is made or not makes no difference for this classification.) If we abstract from the user of the language and analyze only the expressions and their designata, we are in the field of semantics. And if, finally, we abstract from the designata also and analyze only the relations between the expressions, we are in (logical) syntax. The whole science of language, consisting of the three parts mentioned, is called semiotic. (1942, 9; see also Carnap 1939, 3–5, 16)
To summarize, syntax concerns grammar and abstract structures; semantics investigates meaning and representation; and pragmatics explores use. Importantly, while no view is oblivious to the syntax, semantics, or pragmatics of theory, the baptism of each is a product of how one of the three aspects of language is perceived to be dominant: theory as syntactic logical reconstruction (Syntactic View); theory as semantically meaningful mathematical modeling (Semantic View); or theory structure as complex and as closely tied to theory pragmatics, i.e., function and context (Pragmatic View). Each of these philosophical perspectives on scientific theory will be reviewed in this entry. Their relations will be briefly considered in the Conclusion.
It will be helpful to pare each perspective down to its essence. Each endorses a substantive thesis about the structure of scientific theories.
For the Syntactic View, the structure of a scientific theory is its reconstruction in terms of sentences cast in a metamathematical language. Metamathematics is the axiomatic machinery for building clear foundations of mathematics, and includes predicate logic, set theory, and model theory (e.g., Zach 2009; Hacking 2014). A central question of the Syntactic View is: in which logical language should we recast scientific theory?
Some defenders of the Semantic View keep important aspects of this reconstructive agenda, moving the metamathematical apparatus from predicate logic to set theory. Other advocates of the Semantic View insist that the structure of scientific theory is solely mathematical. They argue that we should remain at the mathematical level, rather than move up (or down) a level, into foundations of mathematics. A central question for the Semantic View is: which mathematical models are actually used in science?
Finally, for the Pragmatic View, scientific theory is internally and externally complex. Mathematical components, while often present, are neither necessary nor sufficient for characterizing the core structure of scientific theories. Theory also consists of a rich variety of nonformal components (e.g., analogies and natural kinds). Thus, the Pragmatic View argues, a proper analysis of the grammar (syntax) and meaning (semantics) of theory must pay heed to scientific theory complexity, as well as to the multifarious assumptions, purposes, values, and practices informing theory. A central question the Pragmatic View poses is: which theory components and which modes of theorizing are present in scientific theories found across a variety of disciplines?
In adopting a descriptive perspective on the structure of scientific theories, each view also deploys, at least implicitly, a prescriptive characterization of our central topic. In other words, postulating that scientific theory is X (e.g., X = a set-theoretic structure, as per Suppes 1960, 1962, 1967, 1968, 2002) also implies that what is not X (or could not be recast as X) is not (or could not possibly be) a scientific theory, and would not help us in providing scientific understanding, explanation, prediction, and intervention. For the Syntactic View, what is not (or cannot be) reconstructed axiomatically is not theoretical, while for the Semantic View, what is not (or cannot be) modeled mathematically is not theoretical. In contrast, in part due to its pluralism about what a scientific theory actually (and possibly) is, and because it interprets theory structure as distributed in practices, the Pragmatic View resists the definitional and normative terms set by the other two views. As a result, the Pragmatic View ultimately reforms the very concepts of “theory” and “theory structure.”
This encyclopedia entry will be organized as follows. After presenting this piece’s two sustained examples, immediately below, the three views are reviewed in as many substantive sections. Each section starts with a brief overview before characterizing that perspective’s account of theory structure. Newtonian mechanics is used as a running example within each section. The interpretation of theory structure—viz., how theory “hooks up” with phenomena, experiment, and the world—is also reviewed in each section. In the final section of this entry, we turn to population genetics and an analysis of the Hardy-Weinberg Principle (HWP) to compare and contrast each view. The Conclusion suggests, and remains non-committal about, three kinds of relations among the views: identity, combat, and complementarity. Theory is not a single, static entity that we are seeing from three different perspectives, as we might represent the Earth using three distinct mathematical map projections. Rather, theory itself changes as a consequence of perspective adopted.
Two examples will be used to illustrate differences between the three views: Newtonian mechanics and population genetics. While relativity theory is the preferred theory of the Syntactic View, Newtonian mechanics is more straightforward. Somewhat permissively construed, the theory of Newtonian mechanics employs the basic conceptual machinery of inertial reference frames, centers of mass, Newton’s laws of motion, etc., to describe the dynamics and kinematics of, among other phenomena, point masses acting vis-à-vis gravitational forces (e.g. the solar system) or with respect to forces involved in collisions (e.g., pool balls on a pool table; a closed container filled with gas). Newtonian mechanics is explored in each section.
Population genetics investigates the genetic composition of populations of natural and domesticated species, including the dynamics and causes of changes in gene frequencies in such populations (for overviews, see Lloyd 1994 [1988]; Gould 2002; Pigliucci and Müller 2010; Okasha 2012). Population genetics emerged as a discipline with the early 20th century work of R.A. Fisher, Sewall Wright, and J.B.S. Haldane, who synthesized Darwinian evolutionary theory and Mendelian genetics. One important part of population genetic theory is the Hardy-Weinberg Principle. HWP is a null model mathematically stating that gene frequencies remain unchanged across generations when there is no selection, migration, random genetic drift, or other evolutionary forces acting in a given population. HWP peppers early chapters of many introductory textbooks (e.g., Crow and Kimura 1970; Hartl and Clark 1989; Bergstrom and Dugatkin 2012). We return to HWP in Section 5 and here merely state questions each view might ask about population genetics.
The Syntactic View focuses on questions regarding the highest axiomatic level of population genetics (e.g., Williams 1970, 1973; Van Valen 1976; Lewis 1980; Tuomi 1981, 1992). Examples of such queries are:
What would be the most convenient metamathematical axiomatization of evolutionary processes (e.g., natural selection, drift, migration, speciation, competition)? In which formal language(s) would and could such axiomatizations be articulated (e.g., first-order predicate logic, set theory, and category theory)?
Which single grammars could contain a variety of deep evolutionary principles and concepts, such as HWP, “heritability,” and “competitive exclusion”?
Which formal and methodological tools would permit a smooth flow from the metamathematical axiomatization to the mathematical theory of population genetics?
Investigations of the axiomatized rational reconstruction of theory shed light on the power and promises, and weaknesses and incompleteness, of the highest-level theoretical edifice of population genetics.
Secondly, the Semantic View primarily examines questions regarding the mathematical structure of population genetics (Lewontin 1974, Beatty 1981; López Beltrán 1987; Thompson 1989, 2007; Lloyd 1994 [1988]). Very generally, this exploration involves the following questions:
What is the form and content of the directly presented class of mathematical models of evolutionary theory (e.g., HWP)? How could and should we organize the cluster of mathematical models (sensu Levins 1966) of population genetics?
Which additional models (e.g., diagrammatic, narrative, scale) might be used to enrich our understanding of evolutionary theory?
What are the relations among theoretical mathematical models, data models, and experimental models? How does theory explain and shape data? How do the data constrain and confirm theory?
The main subject of investigation is mathematical structure, rather than metamathematics or even alternative model types or modeling methods.
Finally, the Pragmatic View asks about the internal complexity of population genetic theory, as well as about the development and context of population genetics. In so doing, it inquires into how purposes and values have influenced the theoretical structure of evolutionary theory, selecting and shaping current population genetics from a wide variety of possible alternative theoretical articulations. The following questions about the structure of population genetic theory might be here addressed:
What role did R.A. Fisher’s interest in animal husbandry, and his tenure at Rothamsted Experimental Station, play in shaping his influential methodologies of Analysis of Variance (ANOVA) and experimental design involving randomization, blocking, and factorial designs?
How did the development of computers and computational practices, statistical techniques, and the molecularization of genetics, shape theory and theorizing in population genetics, especially from the 1980s to today?
How might normative context surrounding the concept of “race” impact the way concepts such as “heritability” and “lineage,” or principles such as HWP, are deployed in population genetics?
As when studying an organism, the structure of theory cannot be understood independently of its history and function.
2. The Syntactic View
According to the Syntactic View, which emerged mainly out of work of the Vienna Circle and Logical Empiricism (see Coffa 1991; Friedman 1999; Creath 2014; Uebel 2014), philosophy most generally practiced is, and should be, the study of the logic of natural science, or Wissenschaftslogik (Carnap 1937, 1966; Hempel 1966). Robust and clear logical languages allow us to axiomatically reconstruct theories, which—by the Syntacticists’ definition—are sets of sentences in a given logical domain language (e.g., Campbell 1920, 122; Hempel 1958, 46; cf. Carnap 1967 [1928], §156, "Theses about the Constructional System"). Domain languages include “the language of physics, the language of anthropology” (Carnap 1966, 58).
This view has been variously baptized as the Received View (Putnam 1962; Hempel 1970), the Syntactic Approach (van Fraassen 1970, 1989), the Syntactic View (Wessels 1976), the Standard Conception (Hempel 1970), the Orthodox View (Feigl 1970), the Statement View (Moulines 1976, 2002; Stegmüller 1976), the Axiomatic Approach (van Fraassen 1989), and the Once Received View (Craver 2002). For historical reasons, and because of the linguistic trichotomy discussed above, the “Syntactic View” shall be the name of choice in this entry.
Some conceptual taxonomy is required in order to understand the logical framework of the structure of scientific theories for the Syntactic View. We shall distinguish terms, sentences, and languages (see Table 1).
2.1.1 Terms
Building upwards from the bottom, let us start with the three kinds of terms or vocabularies contained in a scientific language: theoretical, logical, and observational. Examples of theoretical terms are “molecule,” “atom,” “proton,” and protein,” and perhaps even macro-level objects and properties such as “proletariat” and “aggregate demand.” Theoretical terms or concepts can be classificatory (e.g., “cat” or “proton”), comparative (e.g., “warmer”), or quantitative (e.g., “temperature”) (Hempel 1952; Carnap 1966, Chapter 5). Moreover, theoretical terms are “theoretical constructs” introduced “jointly” as a “theoretical system” (Hempel 1952, 32). Logical terms include quantifiers (e.g., ∀,∃) and connectives (e.g., ∧,→). Predicates such as “hard,” “blue,” and “hot,” and relations such as “to the left of” and “smoother than,” are observational terms.
2.1.2 Sentences
Terms can be strung together into three kinds of sentences: theoretical, correspondence, and observational. TS is the set of theoretical sentences that are the axioms, theorems, and laws of the theory. Theoretical sentences include the laws of Newtonian mechanics and of the Kinetic Theory of Gases, all suitably axiomatized (e.g., Carnap 1966; Hempel 1966). Primitive theoretical sentences (e.g., axioms) can be distinguished from derivative theoretical sentences (e.g., theorems; see Reichenbach 1969 [1924]; Hempel 1958; Feigl 1970). CS is the set of correspondence sentences tying theoretical sentences to observable phenomena or “to a ‘piece of reality’” (Reichenbach 1969 [1924], 8; cf. Einstein 1934, 1936 [1936], 351). To simplify, they provide the theoretical syntax with an interpretation and an application, i.e., a semantics. Suitably axiomatized version of the following sentences provide semantics to Boyle’s law, PV=nRT: “V in Boyle’s law is equivalent to the measurable volume xyz of a physical container such as a glass cube that is x, y, and z centimeters in length, width, and height, and in which the gas measured is contained” and “T in Boyle’s law is equivalent to the temperature indicated on a reliable thermometer or other relevant measuring device properly calibrated, attached to the physical system, and read.” Carnap (1987 [1932], 466) presents two examples of observational sentences, OS: “Here (in a laboratory on the surface of the earth) is a pendulum of such and such a kind,” and “the length of the pendulum is 245.3 cm.” Importantly, theoretical sentences can only contain theoretical and logical terms; correspondence sentences involve all three kinds of terms; and observational sentences comprise only logical and observational terms.
2.1.3 Languages
The total domain language of science consists of two languages: the theoretical language, LT, and the observational language, LO (e.g., Hempel 1966, Chapter 6; Carnap 1966, Chapter 23; the index entry for “Language,” of Feigl, Scriven, and Maxwell 1958, 548 has three subheadings: “observation,” “theoretical,” and “ordinary”). The theoretical language includes theoretical vocabulary, while the observational language involves observational terms. Both languages contain logical terms. Finally, the theoretical language includes, and is constrained by, the logical calculus, Calc, of the axiomatic system adopted (e.g., Hempel 1958, 46; Suppe 1977, 50-53). This calculus specifies sentence grammaticality as well as appropriate deductive and non-ampliative inference rules (e.g., modus ponens) pertinent to, especially, theoretical sentences. Calc can itself be written in theoretical sentences.
2.1.4 Theory Structure, in General
Table 1 summarizes the Syntactic View’s account of theory structure:
Table 1
Theory
Observation
Term (or vocabulary)
Theoretical & logical
Theoretical, logical & observational
Observational & logical
The salient divide is between theory and observation. Building on Table 1, there are three different levels of scientific knowledge, according to the Syntactic View:
{TS}= The uninterpreted syntactic system of the scientific theory.
{TS,CS}= The scientific theory structure of a particular domain (e.g., physics, anthropology).
{TS,CS,OS}= All of the science of a particular domain.
Scientific theory is thus taken to be a syntactically formulated set of theoretical sentences (axioms, theorems, and laws) together with their interpretation via correspondence sentences. As we have seen, theoretical sentences and correspondence sentences are cleanly distinct, even if both are included in the structure of a scientific theory.
Open questions remain. Is the observation language a sub-language of the theoretical language, or are they both parts of a fuller language including all the vocabulary? Can the theoretical vocabulary or language be eliminated in favor of a purely observational vocabulary or language? Are there other ways of carving up kinds of languages? First, a “dialectical opposition” between “logic and experience,” “form and content,” “constitutive principles and empirical laws,” and “‘from above’… [and] ‘from below’” pervades the work of the syntacticists (Friedman 1999, 34, 63). Whether syntacticists believe that a synthesis or unification of this general opposition between the theoretical (i.e., logic, form) and the observational (i.e., experience, content) is desirable remains a topic of ongoing discussion. Regarding the second question, Hempel 1958 deflates what he calls “the theoretician’s dilemma”—i.e., the putative reduction without remainder of theoretical concepts and sentences to observational concepts and sentences. Finally, other language divisions are possible, as Carnap 1937 argues (see Friedman 1999, Chapter 7). Returning to the main thread of this section, the distinction toolkit of theoretical and observational terms, sentences, and languages (Table 1) permit the syntacticists to render theoretical structure sharply, thereby aiming at the reconstructive “logic of science” (Wissenschafstlogik) that they so desire.
2.2 A Running Example: Newtonian Mechanics
Reichenbach 1969 [1924] stands as a canonical attempt by a central developer of the Syntactic View of axiomatizing a physical theory, viz., relativity theory (cf. Friedman 1983, 1999; see also Reichenbach 1965 [1920]). For the purposes of this encyclopedia entry, it is preferable to turn to another syntactic axiomatization effort. In axiomatizing Newtonian mechanics, the mid-20th century mathematical logician Hans Hermes spent significant energy defining the concept of mass (Hermes 1938, 1959; Jammer 1961). More precisely, he defines the theoretical concept of “mass ratio” of two particles colliding inelastically in an inertial reference frame S. Here is his full definition of mass ratio (1959, 287):
Mass αxx0≡df∃S,t,y,yo,v,v0(Gxy∧Gx0y0∧CStyy0∧VelSvty∧VelSv0ty0∧α|v|=|v0|)∨(Gxx0∧α=1)
One paraphrase of this definition is, “‘the mass of x is α times that of x0’ is equivalent to ‘there exists a system S, an instant t, momentary mass points y and y0, and initial velocities v and v0, such that y and y0 are genidentical, respectively, with x and x0; the joined mass points move with a velocity of 0 with respect to frame S immediately upon colliding at time t; and y and y0 have determinate velocities v and v0 before the collision in the ratio α, which could also be 1 if x and x0 are themselves genidentical.’” Hermes employs the notion of “genidentical” to describe the relation between two temporal sections of a given particle’s world line (Jammer 1961, 113). Set aside the worry that two distinct particles cannot be genidentical per Hermes’ definition, though they can have identical properties. In short, this definition is syntactically complete and is written in first-order predicate logic, as are the other axioms and definitions in Hermes (1938, 1959). Correspondence rules connecting a postulated mass x with an actual mass were not articulated by Hermes.
The link between theory structure and the world, under the Syntactic View, is contained in the theory itself: CS, the set of correspondence rules. The term “correspondence rules” (Margenau 1950; Nagel 1961, 97–105; Carnap 1966, Chapter 24) has a variety of near-synonyms:
Dictionary (Campbell 1920)
Operational rules (Bridgman 1927)
Coordinative definitions (Reichenbach 1969 [1924], 1938)
Reduction sentences (Carnap 1936/1937; Hempel 1952)
Correspondence postulates (Carnap 1963)
Bridge principles (Hempel 1966; Kitcher 1984)
Reduction functions (Schaffner 1969, 1976)
Bridge laws (Sarkar 1998)
Important differences among these terms cannot be mapped out here. However, in order to better understand correspondence rules, two of their functions will be considered: (i) theory interpretation (Carnap, Hempel) and (ii) theory reduction (Nagel, Schaffner). The dominant perspective on correspondence rules is that they interpret theoretical terms. Unlike “mathematical theories,” the axiomatic system of physics “cannot have… a splendid isolation from the world” (Carnap 1966, 237). Instead, scientific theories require observational interpretation through correspondence rules. Even so, surplus meaning always remains in the theoretical structure (Hempel 1958, 87; Carnap 1966). Second, correspondence rules are seen as necessary for inter-theoretic reduction (van Riel and Van Gulick 2014). For instance, they connect observation terms such as “temperature” in phenomenological thermodynamics (the reduced theory) to theoretical concepts such as “mean kinetic energy” in statistical mechanics (the reducing theory). Correspondence rules unleash the reducing theory’s epistemic power. Notably, Nagel (1961, Chapter 11; 1979) and Schaffner (1969, 1976, 1993) allow for multiple kinds of correspondence rules, between terms of either vocabulary, in the reducing and the reduced theory (cf. Callender 1999; Winther 2009; Dizadji-Bahmani, Frigg, and Hartmann 2010). Correspondence rules are a core part of the structure of scientific theories and serve as glue between theory and observation.
Finally, while they are not part of the theory structure, and although we saw some examples above, observation sentences are worth briefly reviewing. Correspondence rules attach to the content of observational sentences. Observational sentences were analyzed as (i) protocol sentences or Protokollsätze (e.g., Schlick 1934; Carnap 1987 [1932], 1937, cf. 1963; Neurath 1983 [1932]), and as (ii) experimental laws (e.g., Campbell 1920; Nagel 1961; Carnap 1966; cf. Duhem 1954 [1906]). Although constrained by Calc, the grammar of these sentences is determined primarily by the order of nature, as it were. In general, syntacticists do not consider methods of data acquisition, experiment, and measurement to be philosophically interesting. In contrast, the confirmation relation between (collected) data and theory, especially as developed in inductive logic (e.g., Reichenbach 1938, 1978; Carnap 1962 [1950], 1952), as well as questions about the conventionality, grammaticality, foundationalism, atomism, and content of sense-data and synthetic statements, are considered philosophically important (e.g., Carnap 1987 [1932], 1937, 1966; Neurath 1983 [1932]; Reichenbach 1951; Schlick 1925 [1918], 1934; for contemporary commentary, see, e.g., Creath 1987, 2014; Rutte 1991; Friedman 1999).
2.4 Taking Stock: Syntactic View
To summarize, the Syntactic View holds that there are three kinds of terms or vocabularies: logical, theoretical, and observational; three kinds of sentences: TS, CS, and OS; and two languages: LT and LO. Moreover, the structure of scientific theories could be analyzed using the logical tools of metamathematics. The goal is to reconstruct the logic of science, viz. to articulate an axiomatic system.
Interestingly, this perspective has able and active defenders today, who discuss constitutive and axiomatized principles of the historical “relativized a priori” (Friedman 2001, cf. 2013), argue that “the semantic view, if plausible, is syntactic” (Halvorson 2013), and explore “logicism” for, and in, the philosophy of science (Demopulous 2003, 2013; van Benthem 2012). Furthermore, for purposes of the syntactic reconstruction of scientific theories, some continue espousing—or perhaps plea for the resurrection of—predicate logic (e.g., Lutz 2012, 2014), while other contemporary syntacticists (e.g., Halvorson 2012, 2013) endorse more recently developed metamathematical and mathematical equipment, such as category theory, which “turns out to be a kind of universal mathematical language like set theory.” (Awodey 2006, 2; see Eilenberg and MacLane 1945) Classical syntacticists such as Rudolf Carnap (Friedman 1999, 2011; Carus 2007; Koellner ms. in Other Internet Resources) and Joseph Henry Woodger (Nicholson and Gawne 2014) have recently received increasing attention.
3. The Semantic View
An overarching theme of the Semantic View is that analyzing theory structure requires employing mathematical tools rather than predicate logic. After all, defining scientific concepts within a specific formal language makes any axiomatizing effort dependent on the choice, nature, and idiosyncrasies of that narrowly-defined language. For instance, Suppes understands first-order predicate logic, with its “linguistic” rather than “set-theoretical” entities, as “utterly impractical” for the formalization of “theories with more complicated structures like probability theory” (Suppes 1957, 232, 248–9; cf. Suppes 2002). Van Fraassen, another influential defender of the Semantic View, believes that the logical apparatus of the Syntactic View “had moved us mille milles de toute habitation scientifique, isolated in our own abstract dreams” (van Fraassen 1989, 225). Indeed, what would the appropriate logical language for specific mathematical structures be, especially when such structures could be reconstructed in a variety of formal languages? Why should we imprison mathematics and mathematical scientific theory in syntactically defined language(s) when we could, instead, directly investigate the mathematical objects, relations, and functions of scientific theory?
Consistent with the combat strategy (discussed in the Conclusion), here is a list of grievances against the Syntactic View discussed at length in the work of some semanticists.
First-Order Predicate Logic Objection. Theoretical structure is intrinsically and invariably tied to the specific choice of a language, LT, expressed in first-order predicate logic. This places heavy explanatory and representational responsibility on relatively inflexible and limited languages.
Theory Individuation Objection. Since theories are individuated by their linguistic formulations, every change in high-level syntactic formulations will bring forth a distinct theory. This produces a reductio: if T1=p→q and T2=¬p∨q then T1 and T2, though logically equivalent, have different syntactic formulations and would be distinct theories.
Theoretical/Observational Languages Objection. Drawing the theoretical/observational distinction in terms of language is inappropriate, as observability pertains to entities rather than to concepts.
Unintended Models Objection. There is no clear way of distinguishing between intended and unintended models for syntactically characterized theories (e.g., the Löwenheim-Skolem theorem, Bays 2014).
Confused Correspondence Rules Objection. Correspondence rules are a confused medley of direct meaning relationships between terms and world, means of inter-theoretic reduction, causal relationship claims, and manners of theoretical concept testing.
Trivially True yet Non-Useful Objection. Presenting scientific theory in a limited axiomatic system, while clearly syntactically correct, is neither useful nor honest, since scientific theories are mathematical structures.
Practice and History Ignored Objection. Syntactic approaches do not pay sufficient attention to the actual practice and history of scientific theorizing and experimenting.
What, then, does the Semantic View propose to put in the Syntactic View’s place?
Even a minimal description of the Semantic View must acknowledge two distinct strategies of characterizing and comprehending theory structure: the state-space and the set-/model-theoretic approaches.
3.1.1 The State-Space Approach
The state-space approach emphasizes the mathematical models of actual science, and draws a clear line between mathematics and metamathematics. The structure of a scientific theory is identified with the “class,” “family” or “cluster” of mathematical models constituting it, rather than with any metamathematical axioms “yoked to a particular syntax” (van Fraassen 1989, 366). Under this analysis, “the correct tool for philosophy of science is mathematics, not metamathematics”—this is Suppes’ slogan, per van Fraassen (1989, 221; 1980, 65). In particular, a state space or phase space is an N-dimensional space, where each of the relevant variables of a theory correspond to a single dimension and each point in that space represents a possible state of a real system. An actual, real system can take on, and change, states according to different kinds of laws, viz., laws of succession determining possible trajectories through that space (e.g., Newtonian kinematic laws); laws of co-existence specifying the permitted regions of the total space (e.g., Boyle’s law); and laws of interaction combining multiple laws of succession or co-existence, or both (e.g., population genetic models combining laws of succession for selection and genetic drift, Wright 1969; Lloyd 1994 [1988]; Rice 2004; Clatterbuck, Sober, and Lewontin 2013). Different models of a given theory will share some dimensions of their state space while differing in others. Such models will also partially overlap in laws (for further discussion of state spaces, laws, and models pertinent to the Semantic View, see Suppe 1977, 224–8; Lloyd 1994, Chapter 2; Nolte 2010; Weisberg 2013, 26–9).
Historically, the state-space approach emerged from work by Evert Beth, John von Neumann, and Hermann Weyl, and has important parallels with Przełęcki (1969) and Dalla Chiara Scabia and Toraldo di Francia (1973) (on the history of the approach see: Suppe 1977; van Fraassen 1980, 65–67; Lorenzano 2013; advocates of the approach include: Beatty 1981; Giere 1988, 2004; Giere, Bickle, and Mauldin 2006; Lloyd 1983, 1994 [1988], 2013 In Press; Suppe 1977, 1989; Thompson, 1989, 2007; van Fraassen 1980, 1989, 2008; for alternative early analyses of models see, e.g., Braithwaite 1962; Hesse 1966, 1967). Interestingly, van Fraassen (1967, 1970) provides a potential reconstruction of state spaces via an analysis of “semi-interpreted languages.” Weisberg (2013), building on many insights from Giere’s work, presents a broad view of modeling that includes mathematical structures that are “trajectories in state spaces” (29), but also permits concrete objects and computational structures such as algorithms to be deemed models. Lorenzano (2013) calls Giere’s (and, by extension, Weisberg’s and even Godfrey-Smith’s 2006) approach “model-based,” separating it out from the state-space approach. A more fine-grained classification of the state-space approach is desirable, particularly if we wish to understand important lessons stemming from the Pragmatic View of Theories, as we shall see below.
As an example of a state-space analysis of modeling, consider a capsule traveling in outer space. An empirically and dynamically adequate mathematical model of the capsule’s behavior would capture the position of the capsule (i.e., three dimensions of the formal state space), as well as the velocity and acceleration vectors for each of the three standard spatial dimensions (i.e., six more dimensions in the formal state space). If the mass were unknown or permitted to vary, we would have to add one more dimension. Possible and actual trajectories of our capsule, with known mass, within this abstract 9-dimensional state space could be inferred via Newtonian dynamical laws of motion (example in Lewontin 1974, 6–8; consult Suppe 1989, 4). Importantly, under the state-space approach, the interesting philosophical work of characterizing theory structure (e.g., as classes of models), theory meaning (e.g., data models mapped to theoretical models), and theory function (e.g., explaining and predicting) happens at the level of mathematical models.
3.1.2 The Set-/Model-Theoretic Approach
Lurking in the background of the state-space conception is the fact that mathematics actually includes set theory and model theory—i.e., mathematical logic. Indeed, according to some interlocutors, “metamathematics is part of mathematics” (Halvorson 2012, 204). Historically, a set-/model-theoretic approach emerged from Tarski’s work and was extensively articulated by Suppes and his associates (van Fraassen 1980, 67). Set theory is a general language for formalizing mathematical structures as collections—i.e., sets—of abstract objects (which can themselves be relations or functions; see Krivine 2013 [1971]). Model theory investigates the relations between, on the one hand, the formal axioms, theorems, and laws of a particular theory and, on the other hand, the mathematical structures—the models—that provide an interpretation of that theory, or put differently, that make the theory’s axioms, theorems, and laws true (Hodges 1997, Chapter 2; Jones 2005). Interestingly, model theory often uses set theory (e.g., Marker 2002); set theory can, in turn, be extended to link axiomatic theories and semantic models via “set-theoretical predicates” (e.g., Suppes 1957, 2002). Finally, there are certain hybrids of these two branches of mathematical logic, including “partial structures” (e.g., da Costa and French 1990, 2003; Bueno 1997; French and Ladyman 1999, 2003; Vickers 2009; Bueno, French, and Ladyman 2012). Lorenzano (2013) provides a more complex taxonomy of the intellectual landscape of the Semantic View, including a discussion of Structuralism, a kind of set-/model-theoretic perspective. Structuralism involves theses about “theory-nets,” theory-relative theoretical vs. non-theoretical terms, a diversity of intra- and inter-theoretic laws with different degrees of generality, a typology of inter-theoretic relations, and a rich account of correspondence rules in scientific practice (see Moulines 2002; Pereda 2013; Schmidt 2014; Ladyman 2014). On the whole, the set-/model-theoretic approach of the Semantic View insists on the inseparability of metamathematics and mathematics. In preferring to characterize a theory axiomatically in terms of its intension rather than its extension, it shares the Syntactic View’s aims of reconstructive axiomatization (e.g., Sneed 1979; Stegmüller 1979; Frigg and Votsis 2011; Halvorson 2013; Lutz 2012, 2014).
An example will help motivate the relation between theory and model. Two qualifications are required: (i) we return to a more standard set-/model-theoretic illustration below, viz., McKinsey, Sugar, and Suppes’ (1953) axiomatization of particle mechanics, and (ii) this motivational example is not from the heartland of model theory (see Hodges 2013). Following van Fraassen’s intuitive case of “seven-point geometry” (1980, 41–44; 1989, 218–220), also known as “the Fano plane” we see how a particular geometric figure, the model, interprets and makes true a set of axioms and theorems, the theory. In topology and geometry there is rich background theory regarding how to close Euclidean planes and spaces to make finite geometries by, for instance, eliminating parallel lines. Consider the axioms of a projective plane:
For any two points, exactly one line lies on both.
For any two lines, exactly one point lies on both.
There exists a set of four points such that no line has more than two of them.
A figure of a geometric model that makes this theory true is:
This is the smallest geometrical model satisfying the three axioms of the projective plane theory. Indeed, this example fits van Fraassen’s succinct characterization of the theory-model relation:
A model is called a model of a theory exactly if the theory is entirely true if considered with respect to this model alone. (Figuratively: the theory would be true if this model was the whole world.) (1989, 218)
That is, if the entire universe consisted solely of these seven points and seven lines, the projective plane theory would be true. Of course, our universe is bigger. Because Euclidean geometry includes parallel lines, the Fano plane is not a model of Euclidean geometry. Even so, by drawing the plane, we have shown it to be isomorphic to parts of the Euclidean plane. In other words, the Fano plane has been embedded in a Euclidean plane. Below we return to the concepts of embedding and isomorphism, but this example shall suffice for now to indicate how a geometric model can provide a semantics for the axioms of a theory.
In short, for the Semantic View the structure of a scientific theory is its class of mathematical models. According to some advocates of this view, the family of models can itself be axiomatized, with those very models (or other models) serving as axiom truth-makers.
Returning to our running example, consider Suppes’ 1957 model-theoretic articulation of particle mechanics, which builds on his 1953 article with J.C.C. McKinsey and A.C. Sugar. Under this analysis, there is a domain of set-theoretic objects of the form {P,T,s,m,f,g}, where P and T are themselves sets, s and g are binary functions, m is a unary and f a ternary function. P is the set of particles; T is a set of real numbers measuring elapsed times; s(p,t) is the position of particle p at time t; m(p) is the mass of particle p; f(p,q,t) is the force particle q exerts on p at time t; and g(p,t) is the total resultant force (by all other particles) on p at time t. Suppes and his collaborators defined seven axioms—three kinematical and four dynamical—characterizing Newtonian particle mechanics (see also Simon 1954, 1970). Such axioms include Newton’s third law reconstructed in set-theoretic formulation thus (Suppes 1957, 294):
For p,q in P and t in T:f(p,q,t)=−f(q,p,t)
Importantly, the set-theoretic objects are found in more than one of the axioms of the theory, and Newton’s calculus is reconstructed in a novel, set-theoretic form. Set-theoretic predicates such as “is a binary relation” and “is a function” are also involved in axiomatizing particle mechanics (Suppes 1957, 249). Once these axioms are made explicit, their models can be specified and these can, in turn, be applied to actual systems, thereby providing a semantics for the axioms (e.g., as described in Section 3.3.1 below). A particular system satisfying these seven axioms is a particle mechanics system. (For an example of Newtonian mechanics from the state-space approach, recall the space capsule of Section 3.1.1.)
3.3 Interpreting Theory Structure per the Semantic View
How is the theory structure, described in Section 3.1, applied to empirical phenomena? How do we connect theory and data via observation and experimental and measuring techniques? The Semantic View distinguishes theory individuation from both theory-phenomena and theory-world relations. Three types of analysis of theory interpretation are worth investigating: (i) a hierarchy of models (e.g., Suppes; Suppe), (ii) similarity (e.g., Giere; Weisberg), and (iii) isomorphism (e.g., van Fraassen; French and Ladyman).
3.3.1 A Hierarchy of Models
One way of analyzing theory structure interpretation is through a series of models falling under the highest-level axiomatizations. This series has been called “a hierarchy of models,” though it need not be considered a nested hierarchy. These models include models of theory, models of experiment, and models of data (Suppes 1962, 2002). Here is a summary of important parts of the hierarchy (Suppes 1962, Table 1, 259; cf. Giere 2010, Figure 1, 270):
Axioms of Theory. Axioms define set-theoretic predicates, and constitute the core structure of scientific theories, as reviewed in Section 3.1.2.
Models of Theory. “Representation Theorems,” permit us “to discover if an interesting subset of models for the theory may be found such that any model for the theory is isomorphic to some member of this subset” (Suppes 1957, 263). Representation theorem methodology can be extended (i) down the hierarchy, both to models of experiment and models of data, and (ii) from isomorphism to homomorphism (Suppes 2002, p. 57 ff.; Suppe 2000; Cartwright 2008).
Models of Experiment. Criteria of experimental design motivate choices for how to set up and analyze experiments. There are complex mappings between models of experiment thus specified, and (i) models of theory, (ii) theories of measurement, and (iii) models of data.
Models of Data. In building models of data, phenomena are organized with respect to statistical goodness-of-fit tests and parameter estimation, in the context of models of theory. Choices about which parameters to represent must be made.
The temptation to place phenomena at the bottom of the hierarchy must be resisted because phenomena permeate all levels. Indeed, the “class of phenomena” pertinent to a scientific theory is its “intended scope” (Suppe 1977, 223; Weisberg 2013, 40). Furthermore, this temptation raises fundamental questions about scientific representation: “there is the more profound issue of the relationship between the lower most representation in the hierarchy—the data model perhaps—and reality itself, but of course this is hardly something that the semantic approach alone can be expected to address” (French and Ladyman 1999, 113; cf. van Fraassen 2008, 257–258, “The ‘link’ to reality”). Borrowing from David Chalmers, the “hard problem” of philosophy of science remains connecting abstract structures to concrete phenomena, data, and world.
3.3.2 Similarity
The similarity analysis of theory interpretation combines semantic and pragmatic dimensions (Giere 1988, 2004, 2010; Giere, Bickle, and Mauldin 2006; Weisberg 2013). According to Giere, interpretation is mediated by theoretical hypotheses positing representational relations between a model and relevant parts of the world. Such relations may be stated as follows:
S uses X to represent W for purposes P.
Here S is a scientist, research group or community, W is a part of the world, and X is, broadly speaking, any one of a variety of models (Giere 2004, 743, 747, 2010). Model-world similarity judgments are conventional and intentional:
Note that I am not saying that the model itself represents an aspect of the world because it is similar to that aspect. …Anything is similar to anything else in countless respects, but not anything represents anything else. It is not the model that is doing the representing; it is the scientist using the model who is doing the representing. (2004, 747)
Relatedly, Weisberg (2013) draws upon Tversky (1977) to develop a similarity metric for model interpretation (equation 8.10, 148). This metric combines (i) model-target semantics (90–97), and (ii) the pragmatics of “context, conceptualization of the target, and the theoretical goals of the scientist” (149). Giere and Weisberg thus endorse an abundance of adequate mapping relations between a given model and the world. From this diversity, scientists and scientific communities must select particularly useful similarity relationships for contextual modeling purposes. Because of semantic pluralism and irreducible intentionality, this similarity analysis of theory interpretation cannot be accommodated within a hierarchy of models approach, interpreted as a neat model nesting based on pre-given semantic relations among models at different levels.
3.3.3 Isomorphism
The term “isomorphism” is a composite of the Greek words for “equal” and “shape” or “form.” Indeed, in mathematics, isomorphism is a perfect one-to-one, bijective mapping between two structures or sets. Figure (2) literally and figuratively captures the term:
Especially in set theory, category theory, algebra, and topology, there are various kinds of “-morphisms,” viz., of mapping relations between two structures or models. Figure (3) indicates five different kinds of homomorphism, arranged in a Venn diagram.
Although philosophers have focused on isomorphism, other morphisms such as monomorphism (i.e., an injective homomorphism where some elements in the co-domain remain unmapped from the domain) might also be interesting to investigate, especially for embedding data (i.e., the domain) into rich theoretical structures (i.e., the co-domain). To complete the visualization above, an epimorphism is a surjective homomorphism, and an endomorphism is a mapping from a structure to itself, although it need not be a symmetrical—i.e., invertible—mapping, which would be an automorph.
Perhaps the most avid supporter of isomorphism and embedding as the way to understand theory interpretation is van Fraassen. In a nutshell, if we distinguish (i) theoretical models, (ii) “empirical substructures” (van Fraassen 1980, 64, 1989, 227; alternatively: “surface models” 2008, 168), and (iii) “observable phenomena” (1989, 227, 2008, 168), then, van Fraassen argues, theory interpretation is a relation of isomorphism between observable phenomena and empirical substructures, which are themselves isomorphic with one or more theoretical models. Moreover, if a relation of isomorphism holds between X and a richer Y, we say that we have embedded X in Y. For instance, with respect to the seven-point geometry above (Figure 1), van Fraassen contends that isomorphism gives embeddability, and that the relation of isomorphism “is important because it is also the exact relation a phenomenon bears to some model or theory, if that theory is empirically adequate” (1989, 219–20; this kind of statement seems to be simultaneously descriptive and prescriptive about scientific representation, see Section 1.1 above). In The Scientific Image he is even clearer about fleshing out the empirical adequacy of a theory (with its theoretical models) in terms of isomorphism between “appearances” (i.e., “the structures which can be described in experimental and measurement reports,” 1980, 64, italics removed) and empirical substructures. Speaking metaphorically,
the phenomena are, from a theoretical point of view, small, arbitrary, and chaotic—even nasty, brutish, and short…—but can be understood as embeddable in beautifully simple but much larger mathematical models. (2008, 247; see also van Fraassen 1981, 666 and 1989, 230)
Interestingly, and as a defender of an identity strategy (see Conclusion), Friedman also appeals to embedding and subsumption relations between theory and phenomena in his analyses of theory interpretation (Friedman 1981, 1983; see Winther 2009, 136–8). Bueno, da Costa, French, and Ladyman also employ embedding and (partial) isomorphism in the empirical interpretation of partial structures (Bueno 1997; Bueno, French, and Ladyman 2012; da Costa and French 1990, 2003; French and Ladyman 1997, 1999, 2003; Ladyman 2004). Suárez discusses complexities in van Fraassen’s analyses of scientific representation and theory interpretation (Suárez 1999, 2011). On the one hand, representation is structural identity between the theoretical and the empirical. On the other hand, “There is no representation except in the sense that some things are used, made, or taken, to represent some things as thus or so” (van Fraassen 2008, 23, italics removed). The reader interested in learning how van Fraassen simultaneously endorses acontextually structural and contextually pragmatic aspects of representation and interpretation should refer to van Fraassen’s (2008) investigations of maps and “the essential indexical.” [To complement the structure vs. function distinction, see van Fraassen 2008, 309–311 for a structure (“structural relations”) vs. history (“the intellectual processes that lead to those models”) distinction; cf. Ladyman et al. 2011] In all of this, embedding via isomorphism is a clear contender for theory interpretation under the Semantic View.
3.4 Taking Stock: Semantic View
In short, committing to either a state-space or a set-/model-theoretic view on theory structure does not imply any particular perspective on theory interpretation (e.g., hierarchy of models, similarity, embedding). Instead, commitments to the former are logically and actually separable from positions on the latter (e.g., Suppes and Suppe endorse different accounts of theory structure, but share an understanding of theory interpretation in terms of a hierarchy of models). The Semantic View is alive and well as a family of analyses of theory structure, and continues to be developed in interesting ways both in its state-space and set-/model-theoretic approaches.
4. The Pragmatic View
The Pragmatic View recognizes that a number of assumptions about scientific theory seem to be shared by the Syntactic and Semantic Views. Both perspectives agree, very roughly, that theory is (1) explicit, (2) mathematical, (3) abstract, (4) systematic, (5) readily individualizable, (6) distinct from data and experiment, and (7) highly explanatory and predictive (see Flyvbjerg 2001, 38–39; cf. Dreyfus 1986). The Pragmatic View imagines the structure of scientific theories rather differently, arguing for a variety of theses:
Limitations. Idealized theory structure might be too weak to ground the predictive and explanatory work syntacticists and semanticists expect of it (e.g., Cartwright 1983, 1999a, b; Morgan and Morrison 1999; Suárez and Cartwright 2008).
Pluralism. Theory structure is plural and complex both in the sense of internal variegation and of existing in many types. In other words, there is an internal pluralism of theory (and model) components (e.g., mathematical concepts, metaphors, analogies, ontological assumptions, values, natural kinds and classifications, distinctions, and policy views, e.g., Kuhn 1970; Boumans 1999), as well as a broad external pluralism of different types of theory (and models) operative in science (e.g., mechanistic, historical, and mathematical models, e.g., Hacking 2009, Longino 2013; Winther 2012b). Indeed, it may be better to speak of the structures of scientific theories, in the double-plural.
Nonformal aspects. The internal pluralism of theory structure (thesis #2) includes many nonformal aspects deserving attention. That is, many components of theory structure, such as metaphors, analogies, values, and policy views have a non-mathematical and “informal” nature, and they lie implicit or hidden (e.g., Bailer-Jones 2002; Craver 2002; Contessa 2006; Winther 2006a; Morgan 2012). Interestingly, the common understanding of “formal,” which identifies formalization with mathematization, may itself be a conceptual straightjacket; the term could be broadened to include “diagram abstraction” and “principle extraction” (e.g., Griesemer 2013, who explicitly endorses what he also calls a “Pragmatic View of Theories”).
Function. Characterizations of the nature and dynamics of theory structure should pay attention to the user as well as to purposes and values (e.g., Apostel 1960; Minsky 1965; Morrison 2007; Winther 2012a).
Practice. Theory structure is continuous with practice and “the experimental life,” making it difficult to neatly dichotomize theory and practice (e.g., Hacking 1983, 2009; Shapin and Schaffer 1985; Galison 1987, 1988, 1997; Suárez and Cartwright 2008).
These are core commitments of the Pragmatic View.
It is important to note at the outset that the Pragmatic View takes its name from the linguistic trichotomy discussed above, in the Introduction. This perspective need not imply commitment to, or association with, American Pragmatism (e.g. the work of Charles S. Peirce, William James, or John Dewey; cf. Hookway 2013; Richardson 2002). For instance, Hacking (2007a) distinguishes his pragmatic attitudes from the school of Pragmatism. He maps out alternative historical routes of influence, in general and on him, vis-à-vis fallibilism (via Imre Lakatos, Karl Popper; Hacking 2007a, §1), historically conditioned truthfulness (via Bernard Williams; Hacking 2007a, §3), and realism as intervening (via Francis Everitt, Melissa Franklin; Hacking 2007a, §4). To borrow a term from phylogenetics, the Pragmatic View is “polyphyletic.” The components of its analytical framework have multiple, independent origins, some of which circumnavigate American Pragmatism.
With this qualification and the five theses above in mind, let us now turn to the Pragmatic View’s analysis of theory structure and theory interpretation.
We should distinguish two strands of the Pragmatic View: the Pragmatic View of Models and a proper Pragmatic View of Theories.
4.1.1 The Pragmatic View of Models
Nancy Cartwright’s How the Laws of Physics Lie crystallized the Pragmatic View of Models. Under Cartwright’s analysis, models are the appropriate level of investigation for philosophers trying to understand science. She argues for significant limitations of theory (thesis #1), claiming that laws of nature are rarely true, and are epistemically weak. Theory as a collection of laws cannot, therefore, support the many kinds of inferences and explanations that we have come to expect it to license. Cartwright urges us to turn to models and modeling, which are central to scientific practice. Moreover, models “lie”—figuratively and literally—between theory and the world (cf. Derman 2011). That is, “to explain a phenomenon is to find a model that fits it into the basic framework of the theory and that thus allows us to derive analogues for the messy and complicated phenomenological laws which are true of it.” A plurality of models exist, and models “serve a variety of purposes” (Cartwright 1983, 152; cf. Suppes 1978). Cartwright is interested in the practices and purposes of scientific models, and asks us to focus on models rather than theories.
Cartwright’s insights into model pluralism and model practices stand as a significant contribution of “The Stanford School” (cf. Cat 2014), and were further developed by the “models as mediators” group, with participants at LSE, University of Amsterdam, and University of Toronto (Morgan and Morrison 1999; Chang 2011; cf. Martínez 2003). This group insisted on the internal pluralism of model components (thesis #2). According to Morgan and Morrison, building a model involves “fitting together… bits which come from disparate sources,” including “stories” (Morgan and Morrison 1999, 15). Boumans (1999) writes:
model building is like baking a cake without a recipe. The ingredients are theoretical ideas, policy views, mathematisations of the cycle, metaphors and empirical facts. (67)
Mathematical moulding is shaping the ingredients in such a mathematical form that integration is possible… (90)
In an instructive diagram, Boumans suggests that a variety of factors besides theory and data feed into a model: metaphors, analogies, policy views, stylised facts, mathematical techniques, and mathematical concepts (93). The full range of components involved in a model will likely vary according to discipline, and with respect to explanations and interventions sought (e.g., analogies but not policy views will be important in theoretical physics). In short, model building involves a complex variety of internal nonformal aspects, some of which are implicit (theses #2 and #3).
As one example of a nonformal component of model construction and model structure, consider metaphors and analogies (e.g., Bailer-Jones 2002). Geary (2011) states the “simplest equation” of metaphor thus: “X=Y” (8, following Aristotle: “Metaphor consists in giving the thing a name that belongs to something else… ,” Poetics, 1457b). The line between metaphor and analogy in science is blurry. Some interlocutors synonymize them (e.g., Hoffman 1980; Brown 2003), others reduce one to the other (analogy is a form of metaphor, Geary 2011; metaphor is a kind of analogy, Gentner 1982, 2003), and yet others bracket one to focus on the other (e.g., Oppenheimer 1956 sets aside metaphor). One way to distinguish them is to reserve “analogy” for concrete comparisons, with clearly identifiable and demarcated source and target domains, and with specific histories, and use “metaphor” for much broader and indeterminate comparisons, with diffuse trajectories across discourses. Analogies include the “lines of force” of electricity and magnetism (Maxwell and Faraday), the atom as a planetary system (Rutherford and Bohr), the benzene ring as a snake biting its own tail (Kekulé), Darwin’s “natural selection” and “entangled bank,” and behavioral “drives” (Tinbergen) (e.g., Hesse 1966, 1967; Bartha 2010). Examples of metaphor are genetic information, superorganism, and networks (e.g., Keller 1995). More could be said about other informal model components, but this discussion of metaphors and analogies shall suffice to hint at how models do not merely lie between theory and world. Models express a rich internal pluralism (see also de Chadarevian and Hopwood 2004; Morgan 2012).
Model complexity can also be seen in the external plurality of models (thesis #2). Not all models are mathematical, or even ideally recast as mathematical. Non-formalized (i.e., non–state-space, non-set-/model-theoretic) models such as physical, diagrammatic, material, historical, “remnant,” and fictional models are ubiquitous across the sciences (e.g., Frigg and Hartmann 2012; for the biological sciences, see Hull 1975; Beatty 1980; Griesemer 1990, 1991 a, b, 2013; Downes 1992; Richards 1992; Winther 2006a, 2011; Leonelli 2008; Weisberg 2013). Moreover, computer simulations differ in important respects from more standard analytical mathematical models (e.g., Smith 1996; Winsberg 2010; Weisberg 2013). According to some (e.g., Griesemer 2013; Downes 1992; Godfrey-Smith 2006; Thomson-Jones 2012), this diversity belies claims by semanticists that models can always be cast “into set theoretic terms” (Lloyd 2013 In Press), are “always a mathematical structure” (van Fraassen 1970, 327), or that “formalisation of a theory is an abstract representation of the theory expressed in a formal deductive framework… in first-order predicate logic with identity, in set theory, in matrix algebra and indeed, any branch of mathematics...” (Thompson 2007, 485–6). Even so, internal pluralism has been interpreted as supporting a “deflationary semantic view,” which is minimally committed to the perspective that “model construction is an important part of scientific theorizing” (Downes 1992, 151). Given the formal and mathematical framework of the Semantic View (see above), however, the broad plurality of kinds of models seems to properly belong under a Pragmatic View of Models.
4.1.2 The Pragmatic View of Theories
Interestingly, while critiquing the Syntactic and Semantic Views on most matters, the Pragmatic View of Models construed theory, the process of theorizing, and the structure of scientific theories, according to terms set by the two earlier views. For instance, Cartwright tends to conceive of theory as explicit, mathematical, abstract, and so forth (see the first paragraph of Section 4). She always resisted “the traditional syntactic/semantic view of theory” for its “vending machine” view, in which a theory is a deductive and automated machine that upon receiving empirical input “gurgitates” and then “drops out the sought-for representation” (1999a, 184–5). Rather than reform Syntactic and Semantic accounts of theory and theory structure, however, she invites us, as we just saw, to think of science as modeling, “with theory as one small component” (Cartwright, Shomar, and Suárez 1995, 138; Suárez and Cartwright 2008). Many have followed her. Kitcher’s predilection is also to accept the terms of the Syntactic and Semantic Views. For instance, he defines theories as “axiomatic deductive systems” (1993, 93). In a strategy complementary to Cartwright’s modeling turn, Kitcher encourages us to focus on practice, including practices of modeling and even practices of theorizing. In The Advancement of Science, practice is analyzed as a 7-tuple, with the following highly abbreviated components: (i) a language; (ii) questions; (iii) statements (pictures, diagrams); (iv) explanatory patterns; (v) standard examples; (vi) paradigms of experimentation and observation, plus instruments and tools; and (vii) methodology (Kitcher 1993, 74). Scientific practice is also center stage for those singing the praises of “the experimental life” (e.g., Hacking 1983; Shapin and Schaffer 1985; Galison 1987), and those highlighting the cognitive grounds of science (e.g., Giere 1988; Martínez 2014) and science’s social and normative context (e.g., Kitcher 1993, 2001; Longino 1995, 2002; Ziman 2000; cf. Simon 1957). Indeed, the modeling and practice turns in the philosophy of science were reasonable reactions to the power of axiomatic reconstructive and mathematical modeling analyses of the structure of scientific theories.
Yet, a Pragmatic View of Theories is also afoot, one resisting orthodox characterizations of theory often embraced, at least early on, by Pragmatic View philosophers such as Cartwright, Hacking, Kitcher, and Longino. For instance, Craver (2002) accepts both the Syntactic and Semantic Views, which he humorously and not inaccurately calls “the Once Received View” and the “Model Model View.” But he also observes:
While these analyses have advanced our understanding of some formal aspects of theories and their uses, they have neglected or obscured those aspects dependent upon nonformal patterns in theories. Progress can be made in understanding scientific theories by attending to their diverse nonformal patterns and by identifying the axes along which such patterns might differ from one another. (55)
Craver then turns to mechanistic theory as a third theory type (and a third philosophical analysis of theory structure) that highlights nonformal patterns:
Different types of mechanisms can be distinguished on the basis of recurrent patterns in their organization. Mechanisms may be organized in series, in parallel, or in cycles. They may contain branches and joins, and they often include feedback and feedforward subcomponents. (71)
Consistent with theses #2 and #3 of the Pragmatic View, we must recognize the internal pluralism of theories as including nonformal components. Some of these are used to represent organizational and compositional relations of complex systems (Winther 2006a, 2008, 2011; Wimsatt 2007; Walsh 2015 forthcoming). While mechanistic analyses such as Craver’s may not wish to follow every aspect of the Pragmatic View of Theories, there are important and deep resonances between the two.
In a review of da Costa and French (2003), Contessa (2006) writes:
Philosophers of science are increasingly realizing that the differences between the syntactic and the semantic view are less significant than semanticists would have it and that, ultimately, neither is a suitable framework within which to think about scientific theories and models. The crucial divide in philosophy of science, I think, is not the one between advocates of the syntactic view and advocates of the semantic view, but the one between those who think that philosophy of science needs a formal framework or other and those who think otherwise. (376)
Again, we are invited to develop a non-formal framework of science and presumably also of scientific theory. (Halvorson 2012, 203 takes Contessa 2006 to task for advocating “informal philosophy of science.”) Moreover, in asking “what should the content of a given theory be taken to be on a given occasion?”, Vickers (2009) answers:
It seems clear that, in addition to theories being vague objects in the way that ‘heaps’ of sand are, there will be fundamentally different ways to put together theoretical assumptions depending on the particular investigation one is undertaking. For example, sometimes it will be more appropriate to focus on the assumptions which were used by scientists, rather than the ones that were believed to be true. (247, footnote suppressed)
A Pragmatic View of Theories helps make explicit nonformal internal components of theory structure.
Key early defenders of the modeling and practice turns have also recently begun to envision theory in a way distinct from the terms set by the Syntactic and Semantic Views. Suárez and Cartwright (2008) extend and distribute theory by arguing that “What we know ‘theoretically’ is recorded in a vast number of places in a vast number of different ways—not just in words and formulae but in machines, techniques, experiments and applications as well” (79). And while her influence lies primarily in the modeling turn, even in characterizing the “vending machine” view, Cartwright calls for a “reasonable philosophical account of theories” that is “much more textured, and… much more laborious” than that adopted by the Syntactic and Semantic Views (1999a, 185). The theory-data and theory-world axes need to be rethought. Kitcher wishes to transform talk of theories into discussion of “significance graphs” (2001, 78 ff.). These are network diagrams illustrating which (and how) questions are considered significant in the context of particular scientific communities and norms (cf. Brown 2010). Consistently with a Pragmatic View of Theories, Morrison (2007) reconsiders and reforms canonical conceptualizations of “theory.” Finally, Longino (2013) proposes an archaeology of assumptions behind and under different research programs and theories of human behavior such as neurobiological, molecular behavioral genetic, and social-environmental approaches (e.g., Oyama 2000). For instance, two shared or recurring assumptions across programs and theories are:
(1) that the approach in question has methods of measuring both the behavioral outcome that is the object of investigation and the factors whose association with it are the topic of investigation and (2) that the resulting measurements are exportable beyond the confines of the approach within which they are made. (Longino 2013, 117)
A Pragmatic View of Theories expands the notion of theory to include nonformal aspects, which surely must include elements from Boumans’ list above (e.g., metaphors, analogies, policy views), as well as more standard components such as ontological assumptions (e.g., Kuhn 1970; Levins and Lewontin 1985; Winther 2006b), natural kinds (e.g., Hacking 2007b), and conditions of application or scope (e.g., Longino 2013).
In addition to exploring internal theory diversity and in parallel with plurality of modeling, a Pragmatic View of Theories could also explore pluralism of modes of theorizing, and of philosophically analyzing theoretical structure (thesis #2). Craver (2002) provides a start in this direction in that he accepts three kinds of scientific theory and of philosophical analysis of scientific theory. A more synoptic view of the broader pragmatic context in which theories are embedded can be found in the literature on different “styles” of scientific reasoning and theorizing (e.g., Crombie 1994, 1996; Vicedo 1995; Pickstone 2000; Davidson 2001; Hacking 2002, 2009; Winther 2006a, 2011, 2012b; Elwick 2007; Mancosu 2010). While there is no univocal or dominant classification of styles, two lessons are important. First, a rough consensus exists that theoretical investigations of especially historical, mechanistic, and mathematical structures and relations will involve different styles. Second, each style integrates theoretical products and theorizing processes in unique ways, thus inviting an irreducible pragmatic methodological pluralism in our philosophical analysis of the structure of scientific theories. For instance, the structure of theories of mechanisms in molecular biology or neuroscience involves flow charts (e.g., Craver 2002, 2007), and is distinct from the structure of theories of historical processes and patterns as found in systematics and phylogenetics, which involves phylogenetic trees (e.g., Winther 2011; 2012b). As Crombie suggests, we need a “comparative historical anthropology of thinking.” (1996, 71; see Hacking 2009) Mathematical theory hardly remains regnant. It gives way to a pluralism of theory forms and theory processes. Indeed, even mathematical theorizing is a pluralistic motley, as Hacking (2014) argues. Although a “deflationary” Semantic View could account for pluralism of theory forms, the Pragmatic View of Theories, drawing on styles, is required to do justice to the immense variety of theorizing processes, and of philosophical accounts of theory and theory structure.
Finally, outstanding work remains in sorting out the philosophical utility of a variety of proposed units in addition to styles, such as Kuhn’s (1970) paradigms, Lakatos’ (1980) research programmes, Laudan’s (1977) research traditions, and Holton’s (1988) themata. A rational comparative historical anthropology of both theorizing and philosophical analyses of theorizing remains mostly unmapped (cf. Matheson and Dallmann 2014). Such a comparative meta-philosophical analysis should also address Davidson’s (1974) worries about “conceptual schemes” and Popper’s (1996 [1976]) critique of “the myth of the framework” (see Hacking 2002; Godfrey-Smith 2003).
4.2 A Running Example: Newtonian Mechanics
Cartwright has done much to develop a Pragmatic View. Start by considering Newton’s second law:
F=ma
Here F is the resultant force on a mass m, and a is the net acceleration of m; both F and a are vectors. This law is considered a “general” (Cartwright 1999a, 187) law expressed with “abstract quantities” (Cartwright 1999b, 249). Newton’s second law can be complemented with other laws, such as (i) Hooke’s law for an ideal spring:
F=−kx
Here k is the force constant of the spring, and x the distance along the x-axis from the equilibrium position, and (ii) Coulomb’s law modeling the force between two charged particles:
F=K
Here K is Coulomb’s electrical constant, q and q′ are the charges of the two objects, and r the distance between the two objects. The picture Cartwright draws for us is that Newton’s, Hooke’s, and Coulomb’s laws are abstract, leaving out many details. They can be used to derive mathematical models of concrete systems. For instance, by combining (1) and (2), the law of gravitation (a “fundamental” law, Cartwright 1983, 58–59), other source laws, and various simplifying assumptions, we might create a model for the orbit of Mars, treating the Sun and Mars as a 2-body system, ignoring the other planets, asteroids, and Mars’ moons. Indeed, the Solar System is a powerful “nomological machine” (Cartwright 1999a, 50–53), which “is a fixed (enough) arrangement of components, or factors, with stable (enough) capacities that in the right sort of stable (enough) environment will, with repeated operation, give rise to the kind of regular behaviour that we represent in our scientific laws” (Cartwright 1999a, 50). Importantly, most natural systems are complex and irregular, and cannot be neatly characterized as nomological machines. For these cases, abstract laws “run out” (Cartwright 1983) and are rarely smoothly “deidealised” (Suárez 1999). In general, abstract laws predict and explain only within a given domain of application, and only under ideal conditions. More concrete laws or models are not directly deduced from them (e.g., Suárez 1999, Suárez and Cartwright 2008), and they can rarely be combined to form effective “super-laws” (Cartwright 1983, 70–73). In short, the move from (1) and (2) or from (1) and (3) to appropriate phenomenological models, is not fully specified by either abstract law pairing. Indeed, Cartwright developed her notion of “capacities” to discuss how “the principles of physics” “are far better rendered as claims about capacities, capacities that can be assembled and reassembled in different nomological machines, unending in their variety, to give rise to different laws” (1999a, 52). Articulating concrete models requires integrating a mix of mathematical and nonformal components. Laws (1), (2), and (3) remain only one component, among many, of the models useful for, e.g., exploring the behavior of the Solar System, balls on a pool table, or the behavior of charges in electrical fields.
Shifting examples but not philosophical research program, Suárez and Cartwright (2008) explains how analogies such as superconductors as diamagnets (as opposed to ferromagnets) were an integral part of the mathematical model of superconductivity developed by Fritz and Heinz London in the 1930s (63; cf. London and London 1935). Suárez and Cartwright gladly accept that this model “is uncontroversially grounded in classic electromagnetic theory” (64). However, contra Semantic View Structuralists such as Bueno, da Costa, French, and Ladyman, they view nonformal aspects as essential to practices of scientific modeling and theorizing: “The analogy [of diamagnets] helps us to understand how the Londons work with their model… which assumptions they add and which not… a formal reconstruction of the model on its own cannot help us to understand that” (69). In short, the running example of Newtonian mechanics, in conjunction with a glimpse into the use of analogies in mathematical modeling, illustrates the Pragmatic View’s account of theory syntax: theory is constituted by a plurality of formal and informal components.
4.3 Interpreting Theory Structure per the Pragmatic View
As we have explored throughout this section, models and theories have informal internal components, and there are distinct modes of modeling and theorizing. Because of the Pragmatic View’s attention to practice, function, and application, distinguishing structure from interpretation is more difficult here than under the Syntactic and Semantic Views. Any synchronic analysis of the structure of models and theories must respect intentional diachronic processes of interpreting and using, as we shall now see.
Regarding the import of function in models and theories (thesis #4), already the Belgian philosopher of science Apostel defined modeling thus: “Let then R(S,P,M,T) indicate the main variables of the modelling relationship. The subject S takes, in view of the purpose P, the entity M as a model for the prototype T” (1960, 128, see also Apostel 1970). Purposes took center-stage in his article title: “Towards the Formal Study of Models in the Non-Formal Sciences.” MIT Artificial Intelligence trailblazer Minsky also provided a pragmatic analysis:
We use the term “model” in the following sense: To an observer B, an object A∗ is a model of an object A to the extent that B can use A∗ to answer questions that interest him about A. The model relation is inherently ternary. Any attempt to suppress the role of the intentions of the investigator B leads to circular definitions or to ambiguities about “essential features” and the like. (1965, 45)
This account is thoroughly intentionalist and anti-essentialist. That is, mapping relations between model and world are left open and overdetermined. Specifying the relevant relations depends on contextual factors such as questions asked, and the kinds of similarities and isomorphisms deemed to be of interest. The appropriate relations are selected from an infinite (or, at least, near-infinite) variety of possible relations (e.g., Rosenblueth and Wiener 1945; Lowry 1965; Winther 2015 forthcoming).
Regarding practice (thesis #5), in addition to ample work on the experimental life mentioned above, consider a small example. A full understanding of the content and structure of the London brothers’ model of superconductivity requires attention to informal aspects such as analogies. Even London and London (1935) state in the summary of their paper that “the current [“in a supraconductor”] is characterized as a kind of diamagnetic volume current” (88). They too saw the diamagnetic analogy as central to their theoretical practices. Criteria and practices of theory confirmation also differ from the ones typical of the Syntactic and Semantic Views. While predictive and explanatory power as well as empirical adequacy remain important, the Pragmatic View also insists on a variety of other justificatory criteria, including pragmatic virtues (sensu Kuhn 1977; Longino 1995) such as fruitfulness and utility. In a nutshell, the Pragmatic View argues that scientific theory structure is deeply shaped and constrained by functions and practices, and that theory can be interpreted and applied validly according to many different criteria.
4.4 Taking Stock: Pragmatic View
The analytical framework of the Pragmatic View remains under construction. The emphasis is on internal diversity, and on the external pluralism of models and theories, of modeling and theorizing, and of philosophical analyses of scientific theories. The Pragmatic View acknowledges that scientists use and need different kinds of theories for a variety of purposes. There is no one-size-fits-all structure of scientific theories. Notably, although the Pragmatic View does not necessarily endorse the views of the tradition of American Pragmatism, it has important resonances with the latter school’s emphasis on truth and knowledge as processual, purposive, pluralist, and context-dependent, and on the social and cognitive structure of scientific inquiry.
A further qualification in addition to the one above regarding American Pragmatism is in order. The Pragmatic View has important precursors in the historicist or “world view” perspectives of Feyerabend, Hanson, Kuhn, and Toulmin, which were an influential set of critiques of the Syntactic View utterly distinct from the Semantic View. This philosophical tradition focused on themes such as meaning change and incommensurability of terms across world views (e.g., paradigms), scientific change (e.g., revolutionary: Kuhn 1970; evolutionary: Toulmin 1972), the interweaving of context of discovery and context of justification, and scientific rationality (Preston 2012; Bird 2013; Swoyer 2014). The historicists also opposed the idea that theories can secure meaning and empirical support from a theory-neutral and purely observational source, as the Syntactic View had insisted on with its strong distinction between theoretical and observational vocabularies (cf. Galison 1988). Kuhn’s paradigms or, more precisely, “disciplinary matrices” even had an internal anatomy with four components: (i) laws or symbolic generalizations, (ii) ontological assumptions, (iii) values, and (iv) exemplars (Kuhn 1970, postscript; Godfrey-Smith 2003; Hacking 2012). This work was concerned more with theory change than with theory structure and had fewer conceptual resources from sociology of science and history of science than contemporary Pragmatic View work. Moreover, paradigms never quite caught on the way analyses of models and modeling have. Even so, this work did much to convince later scholars, including many of the Pragmatic View, of certain weaknesses in understanding theories as deductive axiomatic structures.
5. Population Genetics
As a final way to contrast the three views, we return to population genetics and, especially, to the Hardy-Weinberg Principle (HWP). Both Woodger (1937, 1959) and Williams (1970, 1973) provide detailed axiomatizations of certain parts of biology, especially genetics, developmental biology, and phylogenetics. For instance, Woodger (1937) constructs an axiomatic system based on ten logical predicates or relations, including P (part of), T (before in time), U (reproduced by cell division or cell fusion), m (male gamete), f (female gamete), and genet (genetic property) (cf. Nicholson and Gawne 2014). Woodger (1959) elaborates these logical predicates or relations to produce a careful reconstruction of Mendelian genetics. Here are two axioms in his system (which are rewritten in contemporary notation, since Woodger used Russell and Whitehead’s Principia Mathematica notation):
(m∧f)=∅ ∀x,y,z,u,v(DLZxyz∧DLZuvz)→(x=u)∧(y=z)
The first axiom should be read thus: “no gamete is both male and female” (1959, 416). In the second axiom, given that DLZxyz is a primitive relation defined as “x is a zygote which develops in the environment y into the life z” (1959, 415), the translation is “every life develops in one and only one environment from one and only one zygote” (416). Woodger claims that “the whole of Mendel’s work can be expressed…” via this axiomatic system. Woodger briefly mentions that if one assumes that the entire system or population is random with respect to gamete fusions, “then the Pearson-Hardy law is derivable” (1959, 427). This was a reference to HWP. In her explorations of various axiomatizations of Darwinian lineages and “subclans,” and the process of the “expansion of the fitter,” Williams (1970, 1973) also carefully defines concepts, and axiomatizes basic biological principles of reproduction, natural selection, fitness, and so forth. However, she does not address HWP. Of interest is the lack of axiomatization of HWP or other mathematical principles of population genetics in Woodger’s and Williams’ work. Were such principles considered secondary or uninteresting by Woodger and Williams? Might Woodger’s and Williams’ respective axiomatic systems simply lack the power and conceptual resources to axiomatically reconstruct a mathematical edifice actually cast in terms of probability theory? Finally, other friends of the Syntactic View, such as the early Michael Ruse, do not provide an axiomatization of HWP (Ruse 1975, 241).
Proponents of the Semantic View claim that their perspective on scientific theory accurately portrays the theoretical structure of population genetics. Thompson (2007) provides both set-theoretical and state-space renditions of Mendelian genetics. The first involves defining a set-theoretic predicate for the system, viz., {P,A,f,g}, where P and A are sets representing, respectively, the total collection of alleles and loci in the population, while f and g are functions assigning an allele to a specific location in, respectively, the diploid cells of an individual or the haploid gametic cells. Axioms in this set-theoretic formalization include “The sets P and A are finite and non empty” (2007, 498). In contrast, the state-space approach of the Semantic View articulates a phase space with each dimension representing allelic (or genotypic) frequencies (e.g., cover and Chapter 3 of Lloyd 1994 [1988]). As an example, “for population genetic theory, a central law of succession is the Hardy-Weinberg law” (Thompson 2007, 499). Mathematically, the diploid version of HWP is written thus:
(p+q)2par=(p2+2pq+q2)off
Here p and q are the frequencies of two distinct alleles at a biallelic locus. The left-hand side represents the allele frequencies in the parental generation and a random mating pattern, while the right-hand side captures genotype frequencies in the offspring generation, as predicted from the parental generation. This is a null theoretical model—actual genotypic and allelic frequencies of the offspring generation often deviate from predicted frequencies (e.g., a lethal homozygote recessive would make the q2off term = 0). Indeed, HWP holds strictly only in abstracted and idealized populations with very specific properties (e.g., infinitely large, individuals reproduce randomly) and only when there are no evolutionary forces operating in the population (e.g., no selection, mutation, migration, or drift) (e.g., Hartl and Clark 1989; Winther et al. 2015 forthcoming). HWP is useful also in the way it interacts with laws of succession for selection, mutation, and so forth (e.g., Okasha 2012). This powerful population genetic principle is central to Semantic View analyses of the mathematical articulation of the theoretical structure of population genetics.
Recall that the Pragmatic View highlights the internal and external pluralism—as well as the purposiveness—of model and theory structure. Consider recent uses of population genetic theory to specify the kinds and amounts of population structure existing in Homo sapiens. In particular, different measures and mathematical modeling methodologies are employed in investigating human genomic diversity (e.g., Jobling et al. 2004; Barbujani et al. 2013; Kaplan and Winther 2013, 2014; Winther 2014). It is possible to distinguish at least two different research projects, each of which has a unique pragmatic content (e.g., aims, values, and methods). Diversity partitioning assesses genetic variation within and among pre-determined groups using Analysis of Variance (also crucial to estimating heritability, Downes 2014). Clustering analysis uses Bayesian modeling techniques to simultaneously produce clusters and assign individuals to these “unsupervised” cluster classifications. The robust result of the first modeling project is that (approximately) 85% of all genetic variance is found within human subpopulations (e.g., Han Chinese or Sami), 10% across subpopulations within a continental region, and only 5% is found across continents (i.e., “Negroid,” “Mongoloid,” and “Caucasoid,” Lewontin 1972 terms). (Recall also that we are all already identical at, on average, 999 out of 1000 nucleotides.) To calculate diversity partitions at these three nested levels, Lewontin (1972) used a Shannon information-theoretic measure closely related to Sewall Wright’s F-statistic:
FST=
Here HT is the total heterozygosity of the population assessed, and S is the heterozygosity of each subpopulation (group) of the relevant population, averaged across all the subpopulations. FST is bounded by 0 and 1, and is a measure of population structure, with higher FST values suggesting more structure, viz., more group differentiation. HWP appears implicitly in both HT and S, which take heterozygosity (2pq) to be equal to the expected proportion of heterozygotes under HWP rather than the actual frequency of heterozygotes. HT is computed by using the grand population average of p and q, whereas calculating S involves averaging across the expected heterozygosities of each subpopulation. If random mating occurs—and thus HWP applies—across the entire population without respecting subpopulation borders, then HT and S will be equal (i.e., p of the total population and of each individual subpopulation will be the same; likewise for q). If, instead, HWP applies only within subpopulations but not across the population as a whole, then S will be smaller than HT, and FST will be positive (i.e., there will be “excess homozygosity” across subpopulations, which is known as the “Wahlund Principle” in population genetics). This is one way among many to deploy the population-genetic principle of HWP. Thus, the Lewontin-style diversity partitioning result that only roughly 5% of the total genetic variance is among races is equivalent to saying that FST across the big three continental populations in Lewontin’s three-level model is 0.05 (e.g., Barbujani et al. 1997). The basic philosophical tendency is to associate the diversity partitioning research project’s (approximately) 85%-10%-5% result with an anti-realist interpretation of biological race.
In contrast, clustering analysis (e.g., Pritchard et al. 2000; Rosenberg et al. 2002; cf. Edwards 2003) can be readily performed even with the small amount of among-continent genetic variance in Homo sapiens. For instance, when the Bayesian modeling computer program STRUCTURE is asked to produce 5 clusters, continental “races” appear—African, Amerindian, Asian, European, and Pacific Islanders. Interestingly, this modeling technique is also intimately linked to HWP: “Our main modeling assumptions are Hardy-Weinberg equilibrium within populations and complete linkage equilibrium between loci within populations” (Pritchard et al. 2000, 946; cf. Winther 2014, 210–212). That is, for a cluster to eventually be robust in the modeling runs, it should meet HWP expectations. Clustering analysis has sometimes been interpreted as a justification for a realist stance towards biological race (see discussions in Hochman 2013; Kaplan and Winther 2013, 2014; Winther and Kaplan 2013; Winther 2014; Edge and Rosenberg 2015 forthcoming; Spencer 2015 forthcoming).
This example of the mathematical modeling of human genomic diversity teaches that basic and simple formal components can be used in different ways to develop and apply theory, both inside and outside of science. In contrast to the Syntactic and Semantic Views, the Pragmatic View foregrounds tensions vis-à-vis ontological assumptions and political consequences regarding the existence (or not) of biological race between diversity partitioning (Lewontin 1972) and clustering analysis (Pritchard et al. 2000) research packages. These ontological ruptures can be identified despite the fact that both research projects assess population structure by examining departures from HWP (i.e., they measure excess homozygosity), and are completely consistent (e.g., Winther 2014; Ludwig 2015; Edge and Rosenberg 2015 forthcoming).
This exploration of how the three views on the structure of scientific theory address population genetics, and in particular HWP, invites a certain meta-pluralism. That is, the Syntactic View carefully breaks down fundamental concepts and principles in genetics and population genetics, articulating definitions and relations among terms. The Semantic View insightfully decomposes and interweaves the complex mathematical edifice of population genetics. The Pragmatic View sheds light on modeling choices and on distinct interpretations and applications of the same theory or model, both within and without science. The three perspectives are hardly mutually exclusive. (N.b., the two running examples concern theory structure in Newtonian mechanics and population genetics, independently considered. While interesting, debates about “evolutionary forces” are beyond the scope of the current entry; see, e.g., Hitchcock and Velasco 2014.)
6. Conclusion
The structure of scientific theories is a rich topic. Theorizing and modeling are core activities across the sciences, whether old (e.g., relativity theory, evolutionary theory) or new (e.g., climate modeling, cognitive science, and systems biology). Furthermore, theory remains essential to developing multipurpose tools such as statistical models and procedures (e.g., Bayesian models for data analysis, agent-based models for simulation, network theory for systems analysis). Given the strength and relevance of theory and theorizing to the natural sciences, and even to the social sciences (e.g., microeconomics, physical, if not cultural, anthropology), philosophical attention to the structure of scientific theories could and should increase. This piece has focused on a comparison of three major perspectives: Syntactic View, Semantic View, and Pragmatic View. In order to handle these complex debates effectively, we have sidestepped certain key philosophical questions, including questions about scientific realism; scientific explanation and prediction; theoretical and ontological reductionism; knowledge-production and epistemic inference; the distinction between science and technology; and the relationship between science and society. Each of these topics bears further philosophical investigation in light of the three perspectives here explored.
A table helps summarize general aspects of the three views’ analyses of the structure of scientific theories:
Syntactic View
Semantic View
Pragmatic View
Theory Structure
Uninterpreted axiomatic system
(i) State-space,
(ii) Model-/set-theoretic
Internal and external pluralism
Theory Interpretation
Correspondence rules
(i) Hierarchy of models,
(ii) Similarity,
(iii) Isomorphism
(i) Structure already inflected by practice, function, and application
(ii) Pragmatic virtues
Is theory interpretation an aspect of theory structure?
Yes
No
Yes, although the distinction is hard to make.
Table 2. General aspects of each view’s analysis of the structure of scientific theories.
The Syntactic, Semantic, and Pragmatic views are often taken to be mutually exclusive and, thus, to be in competition with one another. They indeed make distinct claims about the anatomy of scientific theories. But one can also imagine them to be complementary, focusing on different aspects and questions of the structure of scientific theories and the process of scientific theorizing. For instance, in exploring nonformal and implicit components of theory, the Pragmatic View accepts that scientific theories often include mathematical parts, but tends to be less interested in these components. Moreover, there is overlap in questions—e.g., Syntactic and Semantic Views share an interest in formalizing theory; the Semantic and Pragmatic Views both exhibit concern for scientific practice.
How are these three views ultimately related? A standard philosophical move is to generalize and abstract, understanding a situation from a higher level. One “meta” hypothesis is that a given philosophical analysis of theory structure tends to be associated with a perceived relationship among the three views here discussed. The Syntactic View is inclined to interpret the Semantic View’s formal machinery as continuous with its own generalizing axiomatic strategy, and hence diagnoses many standard Semantic View critiques (Section 3) as missing their mark (the strategy of identity; e.g., Friedman 1982; Worrall 1984; Halvorson 2012, 2013; Lutz 2012; cf. Chakravartty 2001). The Semantic View explicitly contrasts its characterization of theory structure with the “linguistic” or “metamathematical” apparatus of the Syntactic View (the strategy of combat; e.g., Suppe 1977; van Fraassen 1980, 1989; Lloyd 1994 [1988]). Finally, the Pragmatic View, which did not exist as a perspective until relatively recently, imagines theory as pluralistic and can thus ground a holistic philosophical investigation. It envisions a meta-pluralism in which reconstructive axiomatization and mathematical modeling remain important, though not necessary for all theories. This third view endorses a panoply of theoretical structures and theorizing styles, negotiating continuity both between theorizing and “the experimental life,” and among philosophical analyses of the structure of scientific theories (the strategy of complementarity; e.g., Hacking 1983, 2009; Galison 1988, 1997; Craver 2002; Suárez and Cartwright 2008; Winther 2011, 2012a; Griesemer 2013). By design, the ecumenical meta-pluralism sanctioned by the Pragmatic View does not completely offset identity and combat strategies. Moreover, only “partial acceptance” of the respective views may ultimately be possible. Even so, the complementarity strategy might be worth developing further. Compared to identity and combat meta-perspectives, it provides broader—or at least different—insights into the structure of scientific theories. More generally, exploring the relations among these views is itself a rich topic for future philosophical work.
Bibliography
Apostel, L., 1960, “Towards the Formal Study of Models in the Non-Formal Sciences,” Synthese, 12 (23): 125–161.
–––, 1970, “The Justification of Formalisation,” Quality and Quantity, 4 (1): 3–38.
Awodey, S., 2006, Category Theory, Oxford: Oxford University Press.
Bailer-Jones, D.M., 2002, “Models, Metaphors and Analogies,” in Blackwell Guide to the Philosophy of Science, P.K. Machamer and M. Silberstein (eds.), Oxford: Blackwell, pp. 108–127.
Barbujani, G., S. Ghirotto, and F. Tassi, 2013, “Nine Things to Remember about Human Genome Diversity, ” Tissue Antigens, 82 (3): 155–164.
Barbujani, G.A., Magagni, E. Minch, and L.L. Cavalli-Sforza, 1997, “An Apportionment of Human DNA Diversity,” Proceedings of the National Academy of Sciences, 94 (9): 4516–4519.
Bartha, P.F.A., 2010, By Parallel Reasoning: The Construction and Evaluation of Analogical Arguments, New York: Oxford University Press
Bays, T., 2014, “Skolem’s Paradox”, The Stanford Encyclopedia of Philosophy (Spring 2014 Edition), E. N. Zalta (ed.), URL = <http://plato.stanford.edu/archives/spr2014/entries/paradox-skolem/>.
Beatty, J., 1981, “What’s Wrong with the Received View of Evolutionary Theory?” PSA: Proceedings of the Biennial Meeting of the Philosophy of Science Association 1980, (2): 397–426.
Bergstrom, C. and L. Dugatkin, 2012, Evolution, New York: Norton.
Bird, A., 2013, “Thomas Kuhn”, The Stanford Encyclopedia of Philosophy (Fall 2013 Edition), E. N. Zalta (ed.), URL = <http://plato.stanford.edu/archives/fall2013/entries/thomas-kuhn/>.
Boumans, M., 1999, “Built-In Justification,” in Models as Mediators: Perspectives on Natural and Social Science, M.S. Morgan and M. Morrison (eds.), Cambridge: Cambridge University Press, pp. 66–96.
Braithwaite, R., 1962, “Models in the Empirical Sciences,” in Logic, Methodology and Philosophy of Science: Proceedings of the 1960 International Congress, E. Nagel, P. Suppes, and A. Tarski (eds.), Stanford, CA: Stanford University Press, pp. 224–231.
Bridgman, P.W., 1927, The Logic of Modern Physics, New York: Macmillan.
Bueno, O., 1997, “Empirical Adequacy: A Partial Structures Approach,” Studies in History and Philosophy of Science (Part A), 28 (4): 585–610.
Bueno, O., S. French, and J. Ladyman, 2012, “Models and Structures: Phenomenological and Partial,” Studies in History and Philosophy of Science (Part B), 43 (1): 43–46.
Brown, T., 2003, Making Truth: Metaphor in Science, Urbana: University of Illinois Press.
Brown, M.J., 2010, “Genuine Problems and the Significance of Science,” Contemporary Pragmatism, 7 (2): 131–153.
Callender, C., 1999, “Reducing Thermodynamics to Statistical Mechanics: The Case of Entropy,” The Journal of Philosophy, 96 (7): 348–373.
Campbell, N.R., 1920, Physics: The Elements, Cambridge: Cambridge University Press.
Carnap, R., 1967 [1928], The Logical Structure of the World, translated by R.A. George, Berkeley, CA: University of California Press. Original: Der logische Aufbau der Welt, Leipzig: Felix Meiner.
–––, 1932, “Über Protokollsätze”, Erkenntnis, 3: 215–228; transl. by R. Creath and R. Nollan, “On Protocol Sentences,” Noûs, 21 (4) (1987): 457–470.
–––, 1936/1937, “Testability and Meaning,” Philosophy of Science, 1936, 3 (4): 419–471; 1937, 4 (1): 1–40.
–––, 1937, The Logical Syntax of Language, London: Kegan Paul, Trench, & Trübner.
–––, 1939, Foundations of Logic and Mathematics (International Encyclopedia of Unified Science, Volume 1, Number 3), Chicago: University of Chicago Press.
–––, 1942, Introduction to Semantics, Cambridge, MA: Harvard University Press.
–––, 1952, The Continuum of Inductive Methods, Chicago: University of Chicago Press.
–––, 1962 [1950], Logical Foundations of Probability, Chicago: University of Chicago Press, 2nd edition.
–––, 1963, “Philosopher Replies,” in The Philosophy of Rudolf Carnap (Library of Living Philosophers, Volume 11), P. Schilpp (ed.), La Salle: Open Court, pp. 889–999.
–––, 1966, Philosophical Foundations of Science, New York: Basic Books; repr. as An Introduction to the Philosophy of Science, 1972; repr. New York: Dover, 1996.
Cartwright, N., 1983, How the Laws of Physics Lie, New York: Oxford University Press.
–––, 1989, Nature’s Capacities and Their Measurement, New York: Oxford University Press.
–––, 1999a, The Dappled World: A Study of the Boundaries of Science, Cambridge: Cambridge University Press.
–––, 1999b, “Models and the Limits of Theories: Quantum Hamiltonians and the BCS Model of Superconductivity,” in Models as Mediators: Perspectives on Natural and Social Science, M. Morgan and M. Morrison (eds.), (Perspectives on Natural and Social Sciences), Cambridge: Cambridge University Press, pp. 241–281.
–––, 2008, “In Praise of the Representation Theorem,” in Representation, Evidence, and Justification: Themes from Suppes, W.K. Essler and M. Frauchiger (eds.), Ontos Verlag, pp. 83–90.
Cartwright, N., T. Shomar, and M. Suárez, 1995, “The Tool Box of Science: Tools for the Building of Models with a Superconductivity Example,” in Theories and Models in Scientific Processes (Poznan Studies in the Philosophy of the Sciences and the Humanities, Volume 44), W. Herfel, W. Krajewski, I. Niiniluoto, and R. Wojcicki (eds.), Amsterdam: Rodopi, pp. 137–149.
Carus, A.W., 2007, Carnap and Twentieth-Century Thought: Explication as Enlightenment, Cambridge: Cambridge University Press.
Cat, J., 2014, “The Unity of Science”, The Stanford Encyclopedia of Philosophy (Winter 2014 Edition), E. N. Zalta (ed.), URL = <http://plato.stanford.edu/archives/win2014/entries/scientific-unity/>.
Chakravartty, A., 2001, “The Semantic or Model-Theoretic View of Theories and Scientific Realism,” Synthese, 127 (3): 325–345.
Chang, H., 2011, “The Philosophical Grammar of Scientific Practice” in International Studies in the Philosophy of Science, 25 (3): 205–221.
Clatterbuck, H., E. Sober, and R. Lewontin, 2013, “Selection Never Dominates Drift (Nor Vice Versa),” Biology & Philosophy, 28 (4): 577–592.
Coffa, A. J., 1991, The Semantic Tradition From Kant to Carnap: To the Vienna Station, Cambridge: Cambridge University Press.
Contessa, G., 2006, “Scientific Models, Partial Structures and the New Received View of Theories,” Studies in History and Philosophy of Science (Part A), 37 (2): 370–377.
Craver, C.F., 2002, “Structures of Scientific Theories,” in Blackwell Guide to the Philosophy of Science, P.K. Machamer and M. Silberstein (eds.), Oxford: Blackwell, pp. 55–79.
–––, 2007, Explaining the Brain: Mechanisms and the Mosaic Unity of Neuroscience. New York: Oxford University Press.
Creath, R., 1987, “The Initial Reception of Carnap’s Doctrine of Analyticity,” Noûs, 21 (4): 477–499.
–––, 2014, “Logical Empiricism”, The Stanford Encyclopedia of Philosophy (Spring 2014 Edition), E. N. Zalta (ed.), URL = <http://plato.stanford.edu/archives/spr2014/entries/logical-empiricism/>.
Crombie, A.C., 1994, Styles of Scientific Thinking in the European Tradition (Volumes 1–3), London: Duckworth.
–––, 1996, “Commitments and Styles of European Scientific Thinking,” Theoria, 11 (25): 65–76.
Crow J. and M. Kimura, 1970, An Introduction to Population Genetics Theory, Edina, MN: Burgess International Group Incorporated.
da Costa, N.C.A. and S. French, 1990, “The Model-Theoretic Approach in the Philosophy of Science,” Philosophy of Science, 57 (2): 248–65.
–––, 2003. Science and Partial Truth: A Unitary Approach to Models and Scientific Reasoning, Oxford: Oxford University Press.
Dalla Chiara Scabia, M.L. and G. Toraldo di Francia, 1973, “A Logical Analysis of Physical Theories,” La Rivista del Nuovo Cimento, 3 (1): 1–20.
Davidson, A., 2001, The emergence of sexuality: Historical epistemology and the formation of concepts, Cambridge, MA: Harvard University Press.
Davidson, D., 1974, “On the Very Idea of a Conceptual Scheme,” Proceedings and Addresses of the American Philosophical Association, 47: 5–20.
de Chadarevian, S. and N. Hopwood, 2004, Models: The Third Dimension of Science, Stanford, CA: Stanford University Press.
Demopoulos, W., 2003, “On the Rational Reconstruction of our Theoretical Knowledge,” The British Journal for the Philosophy of Science, 54 (3): 371–403.
–––, 2013, Logicism and Its Philosophical Legacy, Cambridge: Cambridge University Press.
Derman, E., 2011, Models Behaving Badly: Why Confusing Illusion with Reality Can Lead to Disaster, on Wall Street and in Life, New York: Free Press.
Dizadji-Bahmani, F., R. Frigg, and S. Hartmann, 2010, “Who’s Afraid of Nagelian Reduction?,” Erkenntnis, 73 (3): 393–412.
Downes, S., 1992, “The Importance of Models in Theorizing: A Deflationary Semantic View,” PSA: Proceedings of the Biennial Meeting of the Philosophy of Science Association 1992, (1): 142–153.
–––, “Heritability,” The Stanford Encyclopedia of Philosophy (Spring 2014 Edition), E. N. Zalta (ed.), URL = <http://plato.stanford.edu/archives/spr2014/entries/heredity/>.
Dreyfus, H., 1986, “Why Studies of Human Capacities Modeled on Ideal Natural Science Can Never Achieve their Goal,” in Rationality, Relativism, and the Human Sciences, J. Margolis, M. Krausz, and R. Burian (eds.), Dordrecht: Martinus Nijhoff, pp. 3–22.
Duhem, P., 1906, La théorie physique: Son objet et sa structure, Paris: Chevalier et Rivière; transl. by P.W. Wiener, The Aim and Structure of Physical Theory, Princeton, NJ: Princeton University Press (1954).
Edge, M.D. and N. Rosenberg, 2015 forthcoming, “Implications of the Apportionment of Human Genetic Diversity for the Apportionment of Human Phenotypic Diversity,” Studies in History and Philosophy of Biological and Biomedical Sciences.
Edwards, A.W.F., 2003, “Human Genetic Diversity: Lewontin‘s Fallacy” BioEssays, 25 (8): 798–801.
Eilenberg, S. and S. MacLane, 1945, “General Theory of Natural Equivalences,” Transactions of the American Mathematical Society, 58 (2): 231–294.
Einstein, A., 1934, “On the Method of Theoretical Physics,” Philosophy of Science, 1 (2): 163–169.
–––, 1936, “Physik und Realität,” Journal of The Franklin Institute, 221 (3): 313–347; transl. by J. Piccard, “Physics and Reality,” Journal of the Franklin Institute, 221 (3) (1936): 349–382.
Elwick, J., 2007, Styles of Reasoning in British Life Sciences: Shared Assumptions, 1820–1858, London: Pickering & Chatto.
Feigl, H., 1970, “The ‘Orthodox’ View of Theories: Remarks in Defense as Well as Critique,” in Analyses of Theories and Methods of Physics and Psychology (Minnesota Studies in the Philosophy of Science, Volume 4), M. Radner and S. Winokur (eds.), Minneapolis: University of Minnesota Press, pp. 3–16.
Feigl, H., M. Scriven, and G. Maxwell (eds.), 1958, Minnesota Studies in the Philosophy of Science (Volume 2), Minneapolis: University of Minnesota Press.
Flyvbjerg, B., 2001, Making Social Science Matter: Why Social Inquiry Fails and How it Can Succeed Again, Cambridge: Cambridge University Press.
French, S. and J. Ladyman, 1997, “Superconductivity and Structures: Revisiting the London Account,” Studies in History and Philosophy of Modern Physics, 28 (3): 363–393.
–––, 1999, “Reinflating the Semantic Approach,” International Studies in the Philosophy of Science, 13 (2): 103–121.
–––, 2003. “Remodelling Structural Realism: Quantum Physics and the Metaphysics of Structure,” Synthese, 136 (1): 31–56.
Friedman, M., 1981, “Theoretical Explanation,” in Reduction, Time, and Reality: Studies in the Philosophy of the Natural Sciences, R. Healey (ed.), New York: Cambridge University Press, pp. 1–16.
–––, 1982, “The Scientific Image, by B. van Fraassen,” The Journal of Philosophy, 79 (5): 274–283.
–––, 1983, Foundations of Space-Time Theories: Relativistic Physics and Philosophy of Science, Princeton: Princeton University Press.
–––, 1999, Reconsidering Logical Positivism. New York: Cambridge University Press.
–––, 2001, Dynamics of Reason, Stanford, CA: CSLI Publications.
–––, 2011, “Carnap on Theoretical Terms: Structuralism without Metaphysics,” Synthese, 180 (2): 249–263.
–––, 2013, Kant’s Construction of Nature: A Reading of the Metaphysical Foundations of Natural Science, Cambridge: Cambridge University Press.
Frigg, R. and S. Hartmann, 2012, “Models in Science”, The Stanford Encyclopedia of Philosophy (Fall 2012 Edition), E. N. Zalta (ed.), URL = <http://plato.stanford.edu/archives/fall2012/entries/models-science/>.
Frigg, R. and I. Votsis, 2011, “Everything You Always Wanted to Know about Structural Realism but Were Afraid to Ask,” European Journal for Philosophy of Science, 1 (2): 227–276.
Galison, P., 1987, How Experiments End, Chicago: University of Chicago Press.
–––, 1988, “History, Philosophy, and the Central Metaphor,” Science in Context, 2 (1): 197–212.
–––, 1997, Image and Logic: A Material Culture of Microphysics, Chicago: University of Chicago Press.
Geary, J., 2011, I Is an Other: The Secret Life of Metaphor and How It Shapes the Way We See The World, New York: Harper Perennial.
Gentner, D., 1982, “Are Scientific Analogies Metaphors?” in Metaphor: Problems and Perspectives, D. Miall (ed.), Brighton: Harvester Press, pp. 106–132.
–––, 2003, “Analogical Reasoning, Psychology of,” in Encyclopedia of Cognitive Science, L. Nadel (ed.), London: Nature Publishing Group, pp. 106–112.
Giere, R., 1988, Explaining Science: A Cognitive Approach, Chicago: University of Chicago Press.
–––, 2004, “How Models Are Used to Represent Reality,” Philosophy of Science, 71 (5): 742–752.
–––, 2010, “An Agent-based Conception of Models and Scientific Representation,” Synthese, 172 (2): 269–281.
Giere, R., B. Bickle, and R. Mauldin, 2006, Understanding Scientific Reasoning, Belmont, CA: Thomson/Wadsworth, 5th edition.
Godfrey-Smith, P., 2003, Theory and Reality: An Introduction to the Philosophy of Science, Chicago: University of Chicago Press.
–––, 2006, “The Strategy of Model-Based Science,” Biology and Philosophy, 21 (5): 725–740.
Gould, S.J., 2002, The Structure of Evolutionary Theory. Cambridge, MA: Harvard University Press.
Griesemer, J., 1990, “Modeling in the Museum: On the Role of Remnant Models in the Work of Joseph Grinnell,” Biology and Philosophy, 5 (1): 3–36.
–––, 1991a, “Material Models in Biology,” PSA: Proceedings of the Biennial Meeting of the Philosophy of Science Association 1990, (2): 79–94.
–––, 1991b, “Must Scientific Diagrams Be Eliminable? The Case of Path Analysis,” Biology and Philosophy, 6 (2): 155–180.
–––, 2013, “Formalization and the Meaning of Theory in the Inexact Biological Sciences,” Biological Theory, 7 (4): 298–310.
Hacking, I., 1983, Representing and Intervening: Introductory Topics in the Philosophy of Natural Science, Cambridge: Cambridge University Press.
–––, 2002, Historical Ontology, Cambridge, MA: Harvard University Press.
–––, 2007a, “On Not Being a Pragmatist: Eight Reasons and a Cause,” in New Pragmatists, C. Misak (ed.), New York: Oxford University Press, pp. 32–49.
–––, 2007b, “Natural Kinds: Rosy Dawn, Scholastic Twilight,” Royal Institute of Philosophy Supplements, 61: 203–240.
–––, 2009, Scientific Reason, Taipei: National Taiwan University Press.
–––, 2012, “Introduction, ” in T.S. Kuhn, The Structure of Scientific Revolutions, 50th Anniversary ed. (4th ed.), Chicago: University of Chicago Press, pp. vii–xxxvii.
–––, 2014, Why Is There Philosophy of Mathematics At All?, Cambridge: Cambridge University Press.
Halvorson, H., 2012, “What Scientific Theories Could Not Be,” Philosophy of Science, 79 (2): 183–206.
–––, 2013, “The Semantic View, if Plausible, is Syntactic,” Philosophy of Science, 80 (3): 475–478.
Hartl, D. and A. Clark, 1989, Principles of Population Genetics, Sunderland, MA: Sinauer Associates.
Hempel, C., 1952, Fundamentals of Concept Formation in Empirical Science, Chicago: University of Chicago Press.
–––, 1958, “The Theoretician’s Dilemma,” in Minnesota Studies in the Philosophy of Science (Volume 2), H. Feigl, M. Scriven, and G. Maxwell (eds.), Minneapolis: University of Minnesota Press, pp. 37–98.
–––, 1966, Philosophy of Natural Science, Englewood Cliffs, N.J.: Prentice-Hall.
–––, 1970, “On the ‘Standard Conception’ of Scientific Theories,” in Minnesota Studies in the Philosophy of Science (Volume 4), M. Radner and S. Winokur (eds.), Minneapolis: University of Minnesota Press, pp. 142–163.
Hermes, H. 1938, Eine Axiomatisierung der allgemeinen Mechanik (Forschungen zur Logik und zur Grundlegung der exacten Wissenschaften, Heft 3), Leipzig: S. Hirzel.
–––, 1959, “Zur Axiomatisierung der Mechanik,” in The Axiomatic Method with Special Reference to Geometry and Physics: Proceedings of an International Symposium Held at the University of California, Berkeley, December 26, 1957–January 4, 1958, L. Henkin, P. Suppes, and A. Tarski (eds.), Amsterdam: North Holland, pp. 282–290.
Hesse, M., 1966, Models and Analogies in Science, Notre Dame: University of Notre Dame Press.
–––, 1967, “Models and Analogy in Science,” in The Encyclopedia of Philosophy (Volume 5), P. Edwards (ed.), New York: Macmillan, pp. 354–359.
Hitchcock, C. and J.D. Velasco, 2014, “Newtonian and Evolutionary Forces,” Ergo, 1 (2): 39–77.
Hochman, A., 2013, “Against the New Racial Naturalism,” The Journal of Philosophy 110 (6): 331–351.
Hodges, W., 1997, A Shorter Model Theory, New York: Cambridge University Press.
–––, 2013, “Model Theory”, The Stanford Encyclopedia of Philosophy (Fall 2013 Edition), E. N. Zalta (ed.), URL = <http://plato.stanford.edu/archives/fall2013/entries/model-theory/>.
Hoffman, R., 1980, “Metaphor in Science,” in Cognition and Figurative Language, R. Honeck (ed.), Hillsdale: Lawrence Erlbaum Associates, pp. 393–423.
Holton, G., 1988, Thematic Origins of Scientific Thought: Kepler to Einstein, Cambridge, MA: Harvard University Press, 2nd edition.
Hookway, C., 2013, “Pragmatism”, The Stanford Encyclopedia of Philosophy (Winter 2013 Edition), E. N. Zalta (ed.), URL = <http://plato.stanford.edu/archives/win2013/entries/pragmatism/>.
Hull, D., 1975, “Central Subjects and Historical Narratives,” History & Theory, 14 (3): 253–274.
Jammer, M., 1961, Concepts of Mass in Classical and Modern Physics, Cambridge, MA: Harvard University Press; reprinted unabridged by Dover in 1997.
Jobling, M.A., M. Hurles, C. Tyler-Smith, 2004, Human Evolutionary Genetics. Origins, Peoples and Diseases, New York: Garland Science.
Jones, M., 2005, “Idealization and Abstraction: A Framework,” in Idealization XII: Correcting the Model – Idealization and Abstraction in the Sciences (Poznan Studies in the Philosophy of the Sciences and the Humanities, Volume 86), M. Jones and N. Cartwright (eds.), Amsterdam: Rodopi, pp. 173–217. (Same individual as Thomson-Jones 2012.)
Kaplan, J.M. and R.G. Winther, 2013, “Prisoners of Abstraction? The Theory and Measure of Genetic Variation, and the Very Concept of ‘Race’,” Biological Theory, 7 (4): 401–412.
–––, 2014, “Realism, Antirealism, and Conventionalism about Race,” Philosophy of Science, 81 (5): 1039-1052.
Keller, E.F., 1995, Reconfiguring Life: Metaphors of Twentieth-Century Biology, New York: Columbia University Press.
Kitcher P., 1984, “1953 and All That. A Tale of Two Sciences,” Philosophical Review, 93 (3): 335–373.
–––, 1993, The Advancement of Science: Science Without Legend, Objectivity Without Illusion, New York: Oxford University Press.
–––, 2001, Science, Truth, and Democracy, New York: Oxford University Press.
Krivine, J., 2013 [1971], Introduction to Axiomatic Set Theory (Synthese Library, Volume 34), Dordrecht: D. Reidel.
Kuhn, T.S., 1970, The Structure of Scientific Revolutions, Chicago: University of Chicago Press, 2nd edition.
–––, 1977, “Objectivity, Value Judgment, and Theory Choice,” in The Essential Tension: Selected Studies in Scientific Tradition and Change, T.S. Kuhn (ed.), Chicago: University of Chicago Press, pp. 320–339.
Ladyman, J., 2014, “Structural Realism”, The Stanford Encyclopedia of Philosophy (Spring 2014 Edition), E. N. Zalta (ed.), URL = <http://plato.stanford.edu/archives/spr2014/entries/structural-realism/>.
Ladyman, J., O. Bueno, M. Suárez, and B. van Fraassen, 2011, “Scientific Representation: A Long Journey from Pragmatics to Pragmatics,” Metascience, 20 (3): 417–442.
Lakatos, I., 1980, The Methodology of Scientific Research Programmes (Philosophical Papers: Volume 1), Cambridge: Cambridge University Press.
Laudan, L., 1977, Progress and Its Problems: Towards a Theory of Scientific Growth, Berkeley, CA: University of California Press.
Leonelli, S., 2008, “Performing Abstraction: Two Ways of Modelling Arabidopsis thaliana,” Biology and Philosophy, 23 (4): 509–528.
Levins, R., 1966, “The Strategy of Model Building in Population Biology,” American Scientist, 54 (4): 421–431.
Levins, R. and R. Lewontin, 1985, The Dialectical Biologist, Cambridge, MA: Harvard University Press.
Lewis, R.W., 1980, “Evolution: A System of Theories,” Perspectives in Biology and Medicine, 23 (4): 551–572.
Lewontin, R.C., 1972, “Apportionment of Human Diversity,” Evolutionary Biology, 6: 381–398.
–––, 1974, The Genetic Basis of Evolutionary Change, New York: Columbia University Press.
Lloyd, E., 1983, “The Nature of Darwin’s Support for the Theory of Natural Selection,” Philosophy of Science, 50 (1): 112–129.
–––, 1994 [1988], The Structure and Confirmation of Evolutionary Theory, Princeton: Princeton University Press.
–––, 2013 In Press, “Structure of Evolutionary Theory,” in International Encyclopedia of Social and Behavioral Sciences, W. Durham (ed.), 2nd edition, Amsterdam: Elsevier.
London, F. and H. London, 1935, “The Electromagnetic Equations of the Supraconductor,” Proceedings of the Royal Society of London. Series A, Mathematical and Physical Sciences, 149 (866): 71–88.
Longino, H.E., 1995, “Gender, Politics, and the Theoretical Virtues,” Synthese 104 (3): 383–397.
–––, 2002, The Fate of Knowledge, Princeton: Princeton University Press.
–––, 2013, Studying Human Behavior: How Scientists Investigate Aggression & Sexuality, Chicago: University of Chicago Press.
López Beltrán, C., 1987, “La Explicación Evolucionista y el Uso de Modelos,” Masters Thesis, Posgrado en Filosofía de la Ciencia, Universidad Autónoma Metropolitana (Iztapalapa).
Lorenzano, P., 2013, “The Semantic Conception and the Structuralist View of Theories: A Critique of Suppe’s Criticisms,” Studies in History and Philosophy of Science (Part A), 44: 600–607.
Lowry, I., 1965, “A Short Course in Model Design,” Journal of the American Institute of Planners, 31 (2): 158–166.
Ludwig, D., 2015. “Against the New Metaphysics of Race,” Philosophy of Science 82: 1–21.
Lutz, S., 2012, “On a Straw Man in the Philosophy of Science: A Defense of the Received View,” HOPOS: The Journal of the International Society for the History of Philosophy of Science, 2 (1): 77–120.
–––, 2014, “What’s Right with a Syntactic Approach to Theories and Models?” Erkenntnis, 79 (8 supplement): 1475–1492.
Mancosu, P., 2010, “Mathematical Style”, The Stanford Encyclopedia of Philosophy (Spring 2010 Edition), E. N. Zalta (ed.), URL = <http://plato.stanford.edu/archives/spr2010/entries/mathematical-style/>.
Margenau, H., 1950, The Nature of Physical Reality: A Philosophy of Modern Physics, New York: McGraw-Hill.
Marker, D., 2002, Model Theory: An Introduction, New York: Springer.
Martínez, S., 2003, Geografía de las prácticas científicas: Racionalidad, heurística y normatividad, Mexico City: UNAM Press.
–––, 2014, “Technological Scaffolds for Culture and Cognition,” in Developing Scaffolds in Evolution, Culture and Cognition, L. Caporael, J. Griesemer, and W. Wimsatt (eds.), Cambridge, MA: MIT Press, pp. 249–264.
Matheson, C. and J. Dallmann, 2014, “Historicist Theories of Scientific Rationality”, The Stanford Encyclopedia of Philosophy (Fall 2014 Edition), E. N. Zalta (ed.), forthcoming URL = <http://plato.stanford.edu/archives/fall2014/entries/rationality-historicist/>.
McKinsey, J.C.C., A.C. Sugar, and P. Suppes, 1953, “Axiomatic Foundations of Classical Particle Mechanics,” Journal of Rational Mechanics and Analysis, 2 (2): 253–272.
Minsky, M., 1965, “Matter, Mind, and Models,” in Proceedings of the International Federation for Information Processing Congress (Volume 1), W. Kalenich (ed.), Washington D.C.: Spartan Books, pp. 45–49.
Morgan, M., 2012, The World in the Model: How Economists Work and Think, New York: Cambridge University Press.
Morgan, M.S. and M. Morrison (eds.), 1999, Models as Mediators: Perspectives on Natural and Social Science, Cambridge: Cambridge University Press.
Mormann, T., 2007, ‘The Structure of Scientiﬁc Theories in Logical Empiricism,” The Cambridge Companion to Logical Empiricism, in A. Richardson and T. Uebel (eds.), Cambridge: Cambridge University Press, pp. 136–162.
Morrison, M., 2007, “Where Have All the Theories Gone?,” Philosophy of Science, 74 (2): 195–228.
Moulines, C., 1976, “Approximate Application of Empirical Theories: A General Explication,” Erkenntnis, 10 (2): 201–227.
–––, 2002, “Introduction: Structuralism as a Program for Modelling Theoretical Science,” Synthese, 130 (1): 1–11.
Nagel, E., 1961, The Structure of Science: Problems in the Logic of Scientific Explanation, New York: Harcourt, Brace & World.
–––, 1979, “Issues in the Logic of Reductive Explanations,” in Teleology Revisited and Other Essays in the Philosophy and History of Science, New York: Columbia University Press, pp. 95–117.
Neurath, O., 1932, “Protokollsätze”, Erkenntnis, 3: 204–214; “Protocol Statements,” in Philosophical Papers 1913-1946, R.S. Cohen and M. Neurath (eds.), Dordrecht: Reidel (1983), pp. 91–99.
Nicholson, D. and R. Gawne, 2014, “Rethinking Woodger’s Legacy in the Philosophy of Biology,” Journal of the History of Biology, 47 (2): 243–292.
Nolte, D.D., 2010, “The Tangled Tale of Phase Space,” Physics Today, April: 33–38.
Okasha, S., 2012, “Population Genetics”, The Stanford Encyclopedia of Philosophy (Fall 2012 Edition), E. N. Zalta (ed.), URL = <http://plato.stanford.edu/archives/fall2012/entries/population-genetics/>.
Oppenheimer, J.R., 1956, “Analogy in Science,” American Psychologist, 11 (3): 127–135.
Oyama, S., 2000, The Ontogeny of Information: Developmental Systems and Evolution, 2nd ed., Durham: Duke University Press.
Pereda, C., 2013, “Ulises Moulines y la concepción estructural de las teorías científicas,” in La filosofía en México en el siglo XX: Apuntes de un participante, C. Pereda, Mexico City: CONACULTA (Consejo Nacional para la Cultura y las Artes), pp. 200–212.
Pickstone, J.V., 2000, Ways of Knowing: A New History of Science, Technology and Medicine, Chicago: University of Chicago Press.
Pigliucci, M. and G.B. Müller, 2010, Evolution: The Extended Synthesis, Cambridge, MA: MIT Press.
Popper, K., 1996 [1976], “The Myth of the Framework,” In The Myth of the Framework: In Defence of Science and Rationality, M. A. Notturno (ed), Abingdon: Routledge, pp. 33–64.
Pritchard J.K., M. Stephens, and P. Donnelly, 2000, “Inference of Population Structure Using Multilocus Genotype Data,” Genetics, 155 (2): 945–959.
Preston, J., 2012, “Paul Feyerabend”, The Stanford Encyclopedia of Philosophy (Winter 2012 Edition), E. N. Zalta (ed.), URL = <http://plato.stanford.edu/archives/win2012/entries/feyerabend/>.
Przełęcki, M., 1969, The Logic of Empirical Theories, London: Routledge & Kegan Paul.
Putnam, H., 1962, “What Theories Are Not,” in Logic, Methodology, and Philosophy of Science: Proceedings of the 1960 International Congress, E. Nagel, P. Suppes, and A. Tarski (eds.), Stanford, CA: Stanford University Press, pp. 240–251.
Reichenbach, H., 1938, Experience and Prediction: An Analysis of the Foundations and the Structure of Knowledge, Chicago: University of Chicago Press.
–––, 1965 [1920], The Theory of Relativity and A Priori Knowledge, with an introduction by M. Reichenbach, Berkeley: University of California Press. Original: Relativitätstheorie und Erkenntnis apriori, Berlin: Springer.
–––, 1969 [1924], The Axiomatization of the Theory of Relativity, with an introduction by W.C. Salmon. Berkeley-Los Angeles: University of California Press. Original: Axiomatik der relativistischen Raum-Zeit-Lehre, Braunschweig: F. Vieweg & Sohn.
–––, 1978, Selected Writings, 1909–1953: With a Selection of Biographical and Autobiographical Sketches (Volumes 1–2), Dordrecht: Reidel.
Rice, S., 2004, Evolutionary Theory: Mathematical and Conceptual Foundations, Sunderland, MA: Sinauer Associates.
Richards, R., 1992, “The Structure of Narrative Explanation in History and Biology,” in History and Evolution, M. Nitecki and D. Nitecki (eds.), Albany: SUNY Press, pp. 19–53.
Richardson, A., 2002, “Engineering Philosophy of Science: American Pragmatism and Logical Empiricism in the 1930s,” Philosophy of Science, 69 (S3): S36–S47.
Rosenberg N.A., J.K. Pritchard, J.L. Weber, H.M. Cann, K.K. Kidd, L.A. Zhivotovsky, and M.A. Feldman, 2002, “Genetic Structure of Human Populations,” Science, 298 (5602): 2381–2385.
Rosenblueth, A. and N. Wiener, 1945, “The Role of Models in Science,” Philosophy of Science, 12 (4): 316–321.
Ruse, M., 1975, “Charles Darwin’s Theory of Evolution: An Analysis,” Journal of the History of Biology, 8 (2): 219–241.
Rutte, H., 1991, “Neurath contra Schlick. On the Discussion of Truth in the Vienna Circle,” in Rediscovering the Forgotten Vienna Circle: Austrian studies on Otto Neurath and the Vienna Circle, T. Uebel (ed.), Dordrecht: Kluwer, pp. 169–174.
Sarkar, S., 1998, Genetics and Reductionism, Cambridge: Cambridge University Press.
Savage, C.W., 1990, “Preface,” in Scientific Theories. Minnesota Studies in the Philosophy of Science. Volume 14, C.W. Savage (ed.), Minneapolis: University of Minnesota Press, pp. vii–ix.
Schaffner K., 1969, “Correspondence Rules,” Philosophy of Science, 36 (3): 280–290.
–––, 1976, “Reductionism in Biology: Prospects and Problems,” in PSA: Proceedings of the Biennial Meeting of the Philosophy of Science Association 1974: 613–632.
–––, 1993, Discovery and Explanation in Biology and Medicine, Chicago: University of Chicago Press.
Schlick, M., 1925 [1918], General Theory of Knowledge, LaSalle, IL: Open Court.
–––, 1934, “Über das Fundament der Erkenntnis,” Erkenntnis, 4 (1): 79–99.
Schmidt, H.-J., 2014, “Structuralism in Physics”, The Stanford Encyclopedia of Philosophy (Spring 2014 Edition), E. N. Zalta (ed.), URL = <http://plato.stanford.edu/archives/spr2014/entries/physics-structuralism/>.
Shapin, S. and S. Schaffer, 1985, Leviathan and the Air-Pump: Hobbes, Boyle, and the Experimental Life, Princeton: Princeton University Press.
Simon, H., 1954, “The Axiomatization of Classical Mechanics,” Philosophy of Science, 21 (4): 340–343.
–––, 1957, Models of Man, New York: Wiley.
–––, 1970, “The Axiomatization of Physical Theories,” Philosophy of Science, 37 (1): 16–26.
Smith, B.C., 1996, On the Origin of Objects, Cambridge, MA: MIT Press.
Sneed, J., 1979, The Logical Structure of Mathematical Physics, Dordrecht: D. Reidel, 2nd edition.
Spencer, Q., 2015 forthcoming, “Philosophy of Race Meets Population Genetics,” Studies in History and Philosophy of Biological and Biomedical Sciences.
Stegmüller, W., 1976, The Structure and Dynamics of Theories, New York: Springer.
–––, 1979, “The Structuralist View: Survey, Recent Developments and Answers to Some Criticisms”, in The Logic and Epistemology of Scientific Change, I. Niiniluoto and R. Tuomela (eds.), Amsterdam: North Holland.
Suárez, M., 1999, “The Role of Models in the Application of Scientific Theories; Epistemological Implications,” in Models as Mediators. Perspectives on Natural and Social Science, M.S. Morgan and M. Morrison (eds.), Cambridge: Cambridge University Press, pp. 168–196.
–––, 2011, Comment on van Fraassen Scientific Representation: Paradoxes of Perspective, in Ladyman, J., O. Bueno, M. Suárez, and B. van Fraassen, “Scientific Representation: A Long Journey from Pragmatics to Pragmatics,” Metascience, 20 (3): 428–433.
Suárez, M. and N. Cartwright, 2008, “Theories: Tools versus Models,” Studies in History and Philosophy of Modern Physics, 39 (1): 62–81.
Suppe, F., 1977, The Structure of Scientific Theories, Urbana, IL: University of Illinois Press.
–––, 1989, The Semantic Conception of Theories and Scientific Realism, Chicago: University of Illinois Press.
–––, 2000, “Understanding Scientific Theories: An Assessment of Developments,” PSA: Proceedings of the Biennial Meeting of the Philosophy of Science Association 1998, (2): S102–S115.
Suppes, P., 1957, Introduction to Logic, Princeton: D. Van Nostrand Co.
–––, 1960, “A Comparison of the Meaning and Uses of Models in Mathematics and the Empirical Sciences,” Synthese, 12 (2-3): 287–301.
–––, 1962, “Models of Data,” in Logic, Methodology, and Philosophy of Science: Proceedings of the 1960 International Congress, E. Nagel, P. Suppes, and A. Tarski (eds.), Stanford, CA: Stanford University Press, pp. 252–261.
–––, 1967, “What is a Scientific Theory?,” In Philosophy of Science Today, S. Morgenbesser (ed.), New York: Basic Books, pp. 55–67.
–––, 1968, “The Desirability of Formalization in Science,” The Journal of Philosophy, 65 (20): 651–664.
–––, 1978, “The Plurality of Science,” PSA: Proceedings of the Biennial Meeting of the Philosophy of Science Association 1978, (2): 3–16.
–––, 2002, Representation and Invariance of Scientific Structures, Stanford, CA: CSLI Publications.
Swoyer, C., 2014, “Relativism”, The Stanford Encyclopedia of Philosophy (Winter 2014 Edition), E. N. Zalta (ed.), URL = <http://plato.stanford.edu/archives/win2014/entries/relativism/>.
Thompson, P., 1989, The Structure of Biological Theories, Albany: SUNY Press.
–––, 2007, “Formalisations of Evolutionary Biology,” in Philosophy of Biology, M. Matthen and C. Stephens (eds.), Elsevier, Amsterdam, pp. 485–523
Thomson-Jones, M., 2012, “Modelling without Mathematics,” Philosophy of Science, 79 (5): 761–772. (Same individual as Jones 2005.)
Toulmin, S., 1972, Human Understanding: The Collective Use and Evolution of Concepts, Princeton: Princeton University Press.
Tuomi, J., 1981, “Structure and Dynamics of Darwinian Evolutionary Theory,” Systematic Zoology, 30 (1): 22–31.
–––, 1992, “Evolutionary Synthesis: A Search for the Strategy,” Philosophy of Science, 59 (3): 429–438.
Tversky, A., 1977, “Features of Similarity,” Psychological Review, 84 (4): 327–352.
Uebel, T., 2014, “Vienna Circle”, The Stanford Encyclopedia of Philosophy (Spring 2014 Edition), E. N. Zalta (ed.), URL = <http://plato.stanford.edu/archives/spr2014/entries/vienna-circle/>.
van Benthem J., 2012, “The Logic of Empirical Theories Revisited,” Synthese, 186 (3): 775–792.
van Fraassen, B., 1967, “Meaning Relations among Predicates,” Noûs, 1 (2): 161–179.
–––, 1970, “On the Extension of Beth’s Semantics of Physical Theories,” Philosophy of Science, 37 (3): 325–339.
–––, 1980, The Scientific Image, Oxford: Oxford University Press.
–––, 1981, “Theory Construction and Experiment: An Empiricist View,” PSA: Proceedings of the Biennial Meeting of the Philosophy of Science Association 1980, (2): 663–678.
–––, 1989, Laws and Symmetry, New York: Oxford University Press.
–––, 2008, Scientific Representation: Paradoxes of Perspective, New York: Oxford University Press.
van Riel, R. and R. Van Gulick, 2014, “Scientific Reduction”, The Stanford Encyclopedia of Philosophy (Summer 2014 Edition), E. N. Zalta (ed.), URL = <http://plato.stanford.edu/archives/sum2014/entries/scientific-reduction/>.
Van Valen, L., 1976, “Domains, Deduction, the Predictive Method, and Darwin,” Evolutionary Theory, 1: 231–245.
Vicedo, M., 1995, “Scientific Styles: Toward Some Common Ground in the History, Philosophy, and Sociology of Science,” Perspectives on Science, 3: 231–254.
Vickers, P., 2009, “Can Partial Structures Accommodate Inconsistent Science?” Principia, 13 (2): 233–250.
Walsh, D., 2015 forthcoming, Organisms, Agency, and Evolution, Cambridge: Cambridge University Press.
Weisberg, M., 2013, Simulation and Similarity: Using Models to Understand the World, New York: Oxford University Press.
Wessels, L., 1976, “Laws and Meaning Postulates in van Fraassen’s View of Theories,” in PSA: Proceedings of the Biennial Meeting of the Philosophy of Science Association 1974: 215–234.
Williams, M., 1970, “Deducing the Consequences of Selection: A Mathematical Model,” Journal of Theoretical Biology, 48: 343–385.
–––, 1973, “The Logical Status of Natural Selection and other Evolutionary Controversies: Resolution by Axiomatization,” in M. Bunge (ed.), The Methodological Unity of Science, Dordrecht: D. Reidel, pp. 84–102.
Wimsatt, W.C., 2007, Re-Engineering Philosophy for Limited Beings: Piecewise Approximations to Reality, Cambridge, MA: Harvard University Press.
Winsberg, E., 2010, Science in the Age of Computer Simulation, Chicago: University of Chicago Press.
Winther, R.G., 2006a, “Parts and Theories in Compositional Biology,” Biology and Philosophy, 21 (4): 471–499.
–––, 2006b, “Fisherian and Wrightian Perspectives in Evolutionary Genetics and Model-Mediated Imposition of Theoretical Assumptions,” Journal of Theoretical Biology, 240 (2): 218–232.
–––, 2008, “Systemic Darwinism,” Proceedings of the National Academy of Sciences, 105 (33): 11833–11838.
–––, 2009, “Schaffner’s Model of Theory Reduction: Critique and Reconstruction,” Philosophy of Science, 76 (2): 119–142.
–––, 2011, “Part-Whole Science,” Synthese, 178 (3): 397–427.
–––, 2012a, “Mathematical Modeling in Biology: Philosophy and Pragmatics,” Frontiers in Plant Evolution and Development, 3: 102, doi: 10.3389/fpls.2012.00102, [available online]
–––, 2012b, “Interweaving Categories: Styles, Paradigms, and Models,” Studies in History and Philosophy of Science (Part A), 43 (4): 628–639.
–––, 2014, “The Genetic Reification of ‘Race’? A Story of Two Mathematical Methods,” Critical Philosophy of Race, 2 (2): 204–223.
–––, forthcoming, “Mapping Kinds in GIS and Cartography,” in Natural Kinds After the Practice-Turn, C. Kendig (ed.), London: Pickering & Chatto. <preprint available online>
Winther, R.G., R. Giordano, M.D. Edge, and R. Nielsen, 2015 forthcoming, “The Mind, the Lab, and the Field: Three Kinds of Populations in Scientific Practice,” Studies in History and Philosophy of Biological and Biomedical Sciences.
Winther, R.G. and J.M. Kaplan, 2013, “Ontologies and Politics of Biogenomic ‘Race’,” Theoria. A Journal of Social and Political Theory (South Africa), 60 (3): 54–80.
Woodger J.H., 1937, The Axiomatic Method in Biology, Cambridge: Cambridge University Press.
–––, 1959, “Studies in the Foundations of Genetics,” in The Axiomatic Method with Special Reference to Geometry and Physics: Proceedings of an International Symposium Held at the University of California, Berkeley, December 26, 1957–January 4, 1958, L. Henkin, P. Suppes, and A. Tarski (eds.), Amsterdam: North Holland, pp. 408–428.
Worrall, J., 1984, “An Unreal Image,” The British Journal for the Philosophy of Science, 35 (1): 65–80.
Wright, S., 1969, Evolution and the Genetics of Populations: A Treatise in Four Volumes, Volume 2, The Theory of Gene Frequencies, Chicago: University of Chicago Press.
Zach, R., 2009, “Hilbert’s Program”, The Stanford Encyclopedia of Philosophy (Spring 2009 Edition), E. N. Zalta (ed.), URL = <http://plato.stanford.edu/archives/spr2009/entries/hilbert-program/>.
Ziman, J., 2000, Real Science: What It Is, and What It Means, Cambridge: Cambridge University Press.
Academic Tools
Other Internet Resources
Koellner, P., ms., “Carnap on the Foundations of Logic and Mathematics,” unpublished.
Definitions of Fact, Theory, and Law in Scientific Work, National Center for Science Education (NCSE).Category theory has come to occupy a central position in contemporary mathematics and theoretical computer science, and is also applied to mathematical physics. Roughly, it is a general mathematical theory of structures and of systems of structures. As category theory is still evolving, its functions are correspondingly developing, expanding and multiplying. At minimum, it is a powerful language, or conceptual framework, allowing us to see the universal components of a family of structures of a given kind, and how structures of different kinds are interrelated. Category theory is both an interesting object of philosophical study, and a potentially powerful formal tool for philosophical investigations of concepts such as space, system, and even truth. It can be applied to the study of logical systems in which case category theory is called “categorical doctrines” at the syntactic, proof-theoretic, and semantic levels. Category theory is an alternative to set theory as a foundation for mathematics. As such, it raises many issues about mathematical ontology and epistemology. Category theory thus affords philosophers and logicians much to use and reflect upon.
2. Brief Historical Sketch
3. Philosophical Significance
Bibliography
Academic Tools
Other Internet Resources
Related Entries
1. General Definitions, Examples and Applications
1.1 Definitions
Categories are algebraic structures with many complementary natures, e.g., geometric, logical, computational, combinatorial, just as groups are many-faceted algebraic structures. Eilenberg & Mac Lane (1945) introduced categories in a purely auxiliary fashion, as preparation for what they called functors and natural transformations. The very definition of a category evolved over time, according to the author's chosen goals and metamathematical framework. Eilenberg & Mac Lane at first gave a purely abstract definition of a category, along the lines of the axiomatic definition of a group. Others, starting with Grothendieck (1957) and Freyd (1964), elected for reasons of practicality to define categories in set-theoretic terms.
An alternative approach, that of Lawvere (1963, 1966), begins by characterizing the category of categories, and then stipulates that a category is an object of that universe. This approach, under active development by various mathematicians, logicians and mathematical physicists, lead to what are now called “higher-dimensional categories” (Baez 1997, Baez & Dolan 1998a, Batanin 1998, Leinster 2002, Hermida et al. 2000, 2001, 2002). The very definition of a category is not without philosophical importance, since one of the objections to category theory as a foundational framework is the claim that since categories are defined as sets, category theory cannot provide a philosophically enlightening foundation for mathematics. We will briefly go over some of these definitions, starting with Eilenberg's & Mac Lane's (1945) algebraic definition. However, before going any further, the following definition will be required.
Definition: A mapping e will be called an identity if and only if the existence of any product eα or βe implies that eα = α and βe = β
Definition (Eilenberg & MacLane 1945): A category C is an aggregate Ob of abstract elements, called the objects of C, and abstract elements Map, called mappings of the category. The mappings are subject to the following five axioms:
(C1) Given three mappings α1, α2 and α3, the triple product α3(α2α1) is defined if and only if (α3α2)α1 is defined. When either is defined, the associative law
α3(α2α1) = (α3α2)α1
holds. This triple product is written α3α2α1.
(C2) The triple product α3α2α1 is defined whenever both products α3α2 and α2α1 are defined.
(C3) For each mapping α, there is at least one identity e1 such that αe1 is defined, and at least one identity e2 such that e2α is defined.
(C4) The mapping eX corresponding to each object X is an identity.
(C5) For each identity e there is a unique object X of C such that eX = e.
As Eilenberg & Mac Lane promptly remark, objects play a secondary role and could be entirely omitted from the definition. Doing so, however, would make the manipulation of the applications less convenient. It is practically suitable,and perhaps psychologically more simple to think in terms of mappings and objects. The term “aggregate” is used by Eilenberg & Mac Lane themselves, presumably so as to remain neutral with respect to the background set theory one wants to adopt.
Eilenberg & Mac Lane defined categories in 1945 for reasons of rigor. As they note:
It should be observed first that the whole concept of a category is essentially an auxiliary one; our basic concepts are essentially those of a functor and of natural transformation (…). The idea of a category is required only by the precept that every function should have a definite class as domain and a definite class as range, for the categories are provided as the domains and ranges of functors. Thus one could drop the category concept altogether and adopt an even more intuitive standpoint, in which a functor such as “Hom” is not defined over the category of “all” groups, but for each particular pair of groups which may be given. The standpoint would suffice for applications, inasmuch as none of our developments will involve elaborate constructions on the categories themselves. (1945, chap. 1, par. 6, p. 247)
Things changed in the following ten years, when categories started to be used in homology theory and homological algebra. Mac Lane, Buchsbaum, Grothendieck and Heller were considering categories in which the collections of morphisms between two fixed objects have an additional structure. More specifically, given any two objects X and Y of a category C, the set Hom(X, Y) of morphisms from X to Y form an abelian group. Furthermore, for reasons related to the ways homology and cohomology theories are linked, the definition of a category had to satisfy an additional formal property (which we will leave aside for the moment): it had to be self-dual. These requirements lead to the following definition.
Definition: A category C can be described as a set Ob, whose members are the objects of C, satisfying the following three conditions:
Morphism : For every pair X, Y of objects, there is a set Hom(X, Y), called the morphisms from X to Y in C. If f is a morphism from X to Y, we write f : X → Y.
Identity : For every object X, there exists a morphism idX in Hom(X, X), called the identity on X.
Composition : For every triple X, Y and Z of objects, there exists a partial binary operation from Hom(X, Y) × Hom(Y, Z) to Hom(X, Z), called the composition of morphisms in C. If f : X → Y and g : Y → Z, the composition of f and g is notated (g ○ f ) : X → Z.
Identity, morphisms, and composition satisfy two axioms:
Associativity : If f : X → Y, g : Y → Z and h : Z → W, then h ○ (g ○ f) = (h ○ g) ○ f.
Identity : If f : X → Y, then (idY ○ f) = f and (f ○ idX) = f.
This is the definition one finds in most textbooks of category theory. As such it explicitly relies on a set theoretical background and language. An alternative, suggested by Lawvere in the early sixties, is to develop an adequate language and background framework for a category of categories. We will not present the formal framework here, for it would take us too far from our main concern, but the basic idea is to define what are called weak n-categories (and weak ω-categories), and what had been called categories would then be called weak 1-categories (and sets would be weak 0-categories). (See, for instance, Baez 1997, Makkai 1998, Leinster 2004, Baez & May 2010, Simpson 2011.)
Also in the sixties, Lambek proposed to look at categories as deductive systems. This begins with the notion of a graph, consisting of two classes Arrows and Objects, and two mappings between them, s : Arrows → Objects and t : Arrows → Objects, namely the source and the target mappings. The arrows are usually called the “oriented edges” and the objects “nodes” or “vertices”. Following this, a deductive system is a graph with a specified arrow:
(R1) idX : X → X,
and a binary operation on arrows:
(R2) Given f : X → Y and g : Y → Z, the composition of f and g is (g ○ f) : X → Z.
Of course, the objects of a deductive system are normally thought of as formulas, the arrows are thought of as proofs or deductions, and operations on arrows are thought of as rules of inference. A category is then defined thus:
Definition (Lambek): A category is a deductive system in which the following equations hold between proofs: for all f : X → Y, g : Y → Z and h: Z → W,
(E1) f ○ idX = f, idY ○ f = f, h ○ (g ○ f) = (h ○ g) ○ f.
Thus, by imposing an adequate equivalence relation upon proofs, any deductive system can be turned into a category. It is therefore legitimate to think of a category as an algebraic encoding of a deductive system. This phenomenon is already well-known to logicians, but probably not to its fullest extent. An example of such an algebraic encoding is the Lindenbaum-Tarski algebra, a Boolean algebra corresponding to classical propositional logic. Since a Boolean algebra is a poset, it is also a category. (Notice also that Boolean algebras with appropriate homomorphisms between them form another useful category in logic.) Thus far we have merely a change of vocabulary. Things become more interesting when first-order and higher-order logics are considered. The Lindenbaum-Tarski algebra for these systems, when properly carried out, yields categories, sometimes called “conceptual categories” or “syntactic categories” (Mac Lane & Moerdijk 1992, Makkai & Reyes 1977, Pitts 2000).
1.2 Examples
Almost every known example of a mathematical structure with the appropriate structure-preserving map yields a category.
The category Set with objects sets and morphisms the usual functions. There are variants here: one can consider partial functions instead, or injective functions or again surjective functions. In each case, the category thus constructed is different
The category Top with objects topological spaces and morphisms continuous functions. Again, one could restrict morphisms to open continuous functions and obtain a different category.
The category hoTop with objects topological spaces and morphisms equivalence classes of homotopic functions. This category is not only important in mathematical practice, it is at the core of algebraic topology, but it is also a fundamental example of a category in which morphisms are not structure preserving functions.
The category Vec with objects vector spaces and morphisms linear maps.
The category Diff with objects differential manifolds and morphisms smooth maps.
The categories Pord and PoSet with objects preorders and posets, respectively, and morphisms monotone functions.
The categories Lat and Bool with objects lattices and Boolean algebras, respectively, and morphisms structure preserving homomorphisms, i.e., (⊤, ⊥, ∧, ∨) homomorphisms.
The category Heyt with objects Heyting algebras and (⊤, ⊥, ∧, ∨, →) homomorphisms.
The category Mon with objects monoids and morphisms monoid homomorphisms.
The category AbGrp with objects abelian groups and morphisms group homomorphisms, i.e. (1, ×, ?) homomorphisms
The category Grp with objects groups and morphisms group homomorphisms, i.e. (1, ×, ?) homomorphisms
The category Rings with objects rings (with unit) and morphisms ring homomorphisms, i.e. (0, 1, +, ×) homomorphisms.
The category Fields with objects fields and morphisms fields homomorphisms, i.e. (0, 1, +, ×) homomorphisms.
Any deductive system T with objects formulae and morphisms proofs.
These examples nicely illustrates how category theory treats the notion of structure in a uniform manner. Note that a category is characterized by its morphisms, and not by its objects. Thus the category of topological spaces with open maps differs from the category of topological spaces with continuous maps — or, more to the point, the categorical properties of the latter differ from those of the former.
We should underline again the fact that not all categories are made of structured sets with structure-preserving maps. Thus any preordered set is a category. For given two elements p, q of a preordered set, there is a morphism f : p → q if and only if p ≤ q. Hence a preordered set is a category in which there is at most one morphism between any two objects. Any monoid (and thus any group) can be seen as a category: in this case the category has only one object, and its morphisms are the elements of the monoid. Composition of morphisms corresponds to multiplication of monoid elements. That the monoid axioms correspond to the category axioms is easily verified.
Hence the notion of category generalizes those of preorder and monoid. We should also point out that a groupoid has a very simple definition in a categorical context: it is a category in which every morphism is an isomorphism, that is for any morphism f : X → Y, there is a morphism g : Y → X such that f ○ g = idX and g ○ f = idY.
1.3 Fundamental Concepts of the Theory
Category theory unifies mathematical structures in two different ways. First, as we have seen, almost every set theoretically defined mathematical structure with the appropriate notion of homomorphism yields a category. This is a unification provided within a set theoretical environment. Second, and perhaps even more important, once a type of structure has been defined, it is imperative to determine how new structures can be constructed out of the given one. For instance, given two sets A and B, set theory allows us to construct their Cartesian product A × B. It is also imperative to determine how given structures can be decomposed into more elementary substructures. For example, given a finite Abelian group, how can it be decomposed into a product of certain of its subgroups? In both cases, it is necessary to know how structures of a certain kind may combine. The nature of these combinations might appear to be considerably different when looked at from a purely set theoretical perspective.
Category theory reveals that many of these constructions are in fact certain objects in a category having a “universal property”. Indeed, from a categorical point of view, a Cartesian product in set theory, a direct product of groups (Abelian or otherwise), a product of topological spaces, and a conjunction of propositions in a deductive system are all instances of a categorical product characterized by a universal property. Formally, a product of two objects X and Y in a category C is an object Z of C together with two morphisms, called the projections, p : Z → X and q : Z → Y such that—and this is the universal property—for all objects W with morphisms f : W → X and g : W → Y, there is a unique morphism h : W → Z such that p ○ h = f and q ○ h = g.
Note that we have defined a product for X and Y and not the product for X and Y. Indeed, products and other objects with a universal property are defined only up to a (unique) isomorphism. Thus in category theory, the nature of the elements constituting a certain construction is irrelevant. What matters is the way an object is related to the other objects of the category, that is, the morphisms going in and the morphisms going out, or, put differently, how certain structures can be mapped into a given object and how a given object can map its structure into other structures of the same kind.
Category theory reveals how different kinds of structures are related to one another. For instance, in algebraic topology, topological spaces are related to groups (and modules, rings, etc.) in various ways (such as homology, cohomology, homotopy, K-theory). As noted above, groups with group homomorphisms constitute a category. Eilenberg & Mac Lane invented category theory precisely in order to clarify and compare these connections. What matters are the morphisms between categories, given by functors. Informally, functors are structure-preserving maps between categories. Given two categories C and D, a functor F from C to D sends objects of C to objects of D, and morphisms of C to morphisms of D, in such a way that composition of morphisms in C is preserved, i.e., F(g ○ f) = F(g) ○ F(f), and identity morphisms are preserved, i.e., F(idX) = idFX. It immediately follows that a functor preserves commutativity of diagrams between categories. Homology, cohomology, homotopy, K-theory are all example of functors.
A more direct example is provided by the power set operation, which yields two functors on the category of sets, depending on how one defines its action on functions. Thus given a set X, ℘(X) is the usual set of subsets of X, and given a function f : X → Y, ℘(f) : ℘(X) → ℘(Y) takes a subset A of X and maps it to B = f(A), the image of f restricted to A in X. It is easily verified that this defines a functor from the category of sets into itself.
In general, there are many functors between two given categories, and the question of how they are connected suggests itself. For instance, given a category C, there is always the identity functor from C to C which sends every object/morphism of C to itself. In particular, there is the identity functor over the category of sets.
Now, the identity functor is related in a natural manner to the power set functor described above. Indeed, given a set X and its power set ℘(X), there is a function hX which takes an element x of X and sends it to the singleton set {x}, a subset of X, i.e., an element of ℘(X). This function in fact belongs to a family of functions indexed by the objects of the category of sets {hY : Y → ℘(X) | Y in Ob(Set)}. Moreover, it satisfies the following commutativity condition: given any function f : X → Y, the identity functor yields the same function Id(f) : Id(X) → Id(Y). The commutativity condition thus becomes: hY ○ Id(f) = ℘(f) ○ hX. Thus the family of functions h(-) relates the two functors in a natural manner. Such families of morphisms are called natural transformations between functors. Similarly, natural transformations between models of a theory yield the usual homomorphisms of structures in the traditional set theoretical framework.
The above notions, while important, are not fundamental to category theory. The latter heading arguably include the notions of limit/colimit; in turn, these are special cases of what is certainly the cornerstone of category theory, the concept of adjoint functors, first defined by Daniel Kan in 1956 and published in 1958.
Adjoint functors can be thought of as being conceptual inverses. This is probably best illustrated by an example. Let U : Grp → Set be the forgetful functor, that is, the functor that sends to each group G its underlying set of elements U(G), and to a group homomorphism f : G → H the underlying set function U(f) : U(G) → U(H). In other words, U forgets about the group structure and forgets the fact that morphisms are group homomorphisms. The categories Grp and Set are certainly not isomorphic, as categories, to one another. (A simple argument runs as follows: the category Grp has a zero object, whereas Set does not.) Thus, we certainly cannot find an inverse, in the usual algebraic sense, to the functor U. But there are many non-isomorphic ways to define a group structure on a given set X, and one might hope that among these constructions at least one is functorial and systematically related to the functor U. What is the conceptual inverse to the operation of forgetting all the group theoretical structure and obtaining a set? It is to construct a group from a set solely on the basis of the concept of group and nothing else, i.e., with no extraneous relation or data. Such a group is constructed “freely”; that is, with no restriction whatsoever except those imposed by the axioms of the theory. In other words, all that is remembered in the process of constructing a group from a given set is the fact that the resulting construction has to be a group. Such a construction exists; it is functorial and it yields what are called free groups. In other words, there is a functor F : Set → Grp, which to any set X assigns the free group F(X) on X, and to each function f : X → Y, the group homomorphism F(f) : F(X) → F(Y), defined in the obvious manner. The situation can be described thusly: we have two conceptual contexts, a group theoretical context and a set theoretical context, and two functors moving systematically from one context to the other in opposite directions. One of these functors is elementary, namely the forgetful functor U. It is apparently trivial and uninformative. The other functor is mathematically significant and important. The surprising fact is that F is related to U by a simple rule and, in some sense, it arises from U. One of the striking features of adjoint situations is precisely the fact that fundamental mathematical and logical constructions arise out of given and often elementary functors.
The fact that U and F are conceptual inverses expresses itself formally as follows: applying F first and then U does not yield the original set X, but there is a fundamental relationship between X and UF(X). Indeed, there is a function η : X → UF(X), called the unit of the adjunction, that simply sends each element of X to itself in UF(X) and this function satisfies the following universal property: given any function g : X → U(G), there is a unique group homomorphism h : F(X) → G such that U(h) ○ η = g. In other words, UF(X) is the best possible solution to the problem of inserting elements of X into a group (what is called “insertion of generators” in the mathematical jargon). Composing U and F in the opposite order, we get a morphism ξ : FU(G) → G, called the counit of the adjunction, satisfying the following universal property: for any group homomorphism g : F(X) → G, there is a unique function h : X → U(G) such that ξ ○ F(h) = g ○ FU(G) constitutes the best possible solution to the problem of finding a representation of G as a quotient of a free group. If U and F were simple algebraic inverses to one another, we would have the following identity: UF = ISet and FU = IGrp, where ISet denotes the identity functor on Set and IGrp the identity functor on Grp. As we have indicated, these identities certainly do not hold in this case. However, some identities do hold: they are best expressed with the help of the commutative diagrams:
where the diagonal arrows denote the appropriate identity natural transformations.
This is but one case of a very common situation: every free construction can be described as arising from an appropriate forgetful functor between two adequately chosen categories. The number of mathematical constructions that can be described as adjoints is simply stunning. Although the details of each one of these constructions vary considerably, the fact that they can all be described using the same language illustrates the profound unity of mathematical concepts and mathematical thinking. Before we give more examples, a formal and abstract definition of adjoint functors is in order.
Definition: Let F : C → D and G : D → C be functors going in opposite directions. F is a left adjoint to G (G a right adjoint to F), denoted by F ⊣ G, if there exists natural transformations η : IC → GF and ξ : FG → ID, such that the composites
and
are the identity natural transformations. (For different but equivalent definitions, see Mac Lane 1971 or 1998, chap. IV.)
Here are some of the important facts regarding adjoint functors. Firstly, adjoints are unique up to isomorphism; that is any two left adjoints F and F' of a functor G are naturally isomorphic. Secondly, the notion of adjointness is formally equivalent to the notion of a universal morphism (or construction) and to that of representable functor. (See, for instance Mac Lane 1998, chap. IV.) Each and every one of these notions exhibit an aspect of a given situation. Thirdly, a left adjoint preserves all the colimits which exist in its domain, and, dually, a right adjoint preserves all the limits which exist in its domain.
We now give some examples of adjoint situations to illustrate the pervasiveness of the notion.
Instead of having a forgetful functor going into the category of sets, in some cases only a part of the structure is forgotten. Here are two standard examples:
There is an obvious forgetful functor U : AbGrp → AbMon from the category of abelian groups to the category of abelian monoids: U forgets about the inverse operation. The functor U has a left adjoint F: AbMon → AbGrp which, given an abelian monoid M, assigns to it the best possible abelian group F(M) such that M can be embedded in F(M) as a submonoid. For instance, if M is ℕ, then F(ℕ) “is” ℤ, that is, it is isomorphic to ℤ.
Similarly, there is an obvious forgetful functor U : Haus → Top from the category of Hausdorff topological spaces to the category of topological spaces which forgets the Hausdorff condition. Again, there is a functor F : Top → Haus such that F ⊣ U. Given a topological space X, F(X) yields the best Hausdorff space constructed from X: it is the quotient of X by the closure of the diagonal ΔX ⊆ X × X, which is an equivalence relation. In contrast with the previous example where we had an embedding, this time we get a quotient of the original structure.
Consider now the category of compact Hausdorff spaces kHaus and the forgetful functor U : kHaus → Top, which forgets the compactness property and the separation property. The left adjoint to this U is the Stone-Cech compactification.
There is a forgetful functor U : ModR → AbGrp from a category of R-modules to the category of abelian groups, where R is a commutative ring with unit. The functor U forgets the action of R on a group G. The functor U has both a left and a right adjoint. The left adjoint is R ⊗ − : AbGrp → ModR which sends an abelian group G to the tensor product R ⊗ G and the right adjoint is given by the functor Hom(R, −) : AbGrp → ModR which assigns to any group G the modules of linear mappings Hom(R, G).
The case where the categories C and D are posets deserves special attention here. Adjoint functors in this context are usually called Galois connections. Let C be a poset. Consider the diagonal functor Δ : C → C × C, with Δ(X) = ⟨X, X⟩ and for f : X → Y, Δ(f) = ⟨f, f⟩ : ⟨X, X⟩ → ⟨Y, Y⟩. In this case, the left-adjoint to Δ is the coproduct, or the sup, and the right-adjoint to Δ is the product, or the inf. The adjoint situation can be described in the following special form:
where the vertical double arrow can be interpreted as rules of inference going in both directions.
Implication can also be introduced. Consider a functor with a parameter: (− ∧ X) : C → C. It can easily be verified that when C is a poset, the function (− ∧ X) is order preserving and therefore a functor. A right adjoint to (− ∧ X) is a functor that yields the largest element of C such that its infimum with X is smaller than Z. This element is sometimes called the relative pseudocomplement of X or, more commonly, the implication. It is denoted by X ⇒ Z or by X ⊃ Z. The adjunction can be presented as follows:
The negation operator ¬X can be introduced from the last adjunction. Indeed, let Z be the bottom element ⊥ of the lattice. Then, since Y ∧ X ≤ ⊥ is always true, it follows that Y ≤ X ⇒ ⊥ is also always true. But since X ⇒ ⊥ ≤ X is always the case, we get at the numerator that X ⇒ ⊥ ∧ X = ⊥. Hence, X ⇒ ⊥ is the largest element disjoint from X. We can therefore put ¬X =def X ⇒ ⊥.
Limits, colimits, and all the fundamental constructions of category theory can be described as adjoints. Thus, products and coproducts are adjoints, as are equalizers, coequalizers, pullbacks and pushouts, etc. This is one of the reasons adjointness is central to category theory itself: because all the fundamental operations of category theory arise from adjoint situations.
An equivalence of categories is a special case of adjointness. Indeed, if in the above triangular identities the arrows η : IC → GF and ξ : FG → ID are natural isomorphisms, then the functors F and G constitute an equivalence of categories. In practice, it is the notion of equivalence of categories that matters and not the notion of isomorphism of categories.
It is easy to prove certain facts about these operations directly from the adjunctions. Consider, for instance, implication. Let Z = X. Then we get at the numerator that Y ∧ X ≤ X, which is always true in a poset (as is easily verified). Hence, Y ≤ X ⇒ X is also true for all Y and this is only possible if X ⇒ X = ⊤, the top element of the lattice. Not only can logical operations be described as adjoints, but they naturally arise as adjoints to basic operations. In fact, adjoints can be used to define various structures, distributive lattices, Heyting algebras, Boolean algebras, etc. (See Wood, 2004.) It should be clear from the simple foregoing example how the formalism of adjointness can be used to give syntactic presentations of various logical theories. Furthermore, and this is a key element, the standard universal and existential quantifiers can be shown to be arising as adjoints to the operation of substitution. Thus, quantifiers are on a par with the other logical operations, in sharp contrast with the other algebraic approaches to logic. (See, for instance Awodey 1996 or Mac Lane & Moerdijk 1992.) More generally, Lawvere showed how syntax and semantics are related by adjoint functors. (See Lawvere 1969b.)
Dualities play an important role in mathematics and they can be described with the help of equivalences between categories. In other words, many important mathematical theorems can be translated as statements about the existence of adjoint functors, sometimes satisfying additional properties. This is sometimes taken as expressing the conceptual content of the theorem. Consider the following fundamental case: let C be the category whose objects are the locally compact abelian groups and the morphisms are the continuous group homomorphisms. Then, the Pontryagin duality theorem amounts to the claim that the category C is equivalent to the category C°, that is, to the opposite category. Of course, the precise statement requires that we describe the functors F : C → C° and G : C° → C and prove that they constitute an equivalence of categories.
Another well known and important duality was discovered by Stone in the thirties and now bears his name. In one direction, an arbitrary Boolean algebra yields a topological space, and in the other direction, from a (compact Hausdorff and totally disconnected) topological space, one obtains a Boolean algebra. Moreover, this correspondence is functorial: any Boolean homomorphism is sent to a continuous map of topological spaces, and, conversely, any continuous map between the spaces is sent to a Boolean homomorphism. In other words, there is an equivalence of categories between the category of Boolean algebras and the dual of the category of Boolean spaces (also called Stone spaces). (See Johnstone 1982 for an excellent introduction and more developments.) The connection between a category of algebraic structures and the opposite of a category of topological structures established by Stone's theorem constitutes but one example of a general phenomenon that did attract and still attracts a great deal of attention from category theorists. Categorical study of duality theorems is still a very active and significant field, and is largely inspired by Stone's result. (For recent applications in logic, see, for instance Makkai 1987, Taylor 2000, 2002a, 2002b, Caramello 2011.)
2. Brief Historical Sketch
It is difficult to do justice to the short but intricate history of the field. In particular it is not possible to mention all those who have contributed to its rapid development. With this word of caution out of the way, we will look at some of the main historical threads.
Categories, functors, natural transformations, limits and colimits appeared almost out of nowhere in a paper by Eilenberg & Mac Lane (1945) entitled “General Theory of Natural Equivalences.” We say “almost,” because their earlier paper (1942) contains specific functors and natural transformations at work, limited to groups. A desire to clarify and abstract their 1942 results led Eilenberg & Mac Lane to devise category theory. The central notion at the time, as their title indicates, was that of natural transformation. In order to give a general definition of the latter, they defined functor, borrowing the term from Carnap, and in order to define functor, they borrowed the word ‘category’ from the philosophy of Aristotle, Kant, and C. S. Peirce, but redefining it mathematically.
After their 1945 paper, it was not clear that the concepts of category theory would amount to more than a convenient language; this indeed was the status quo for about fifteen years. Category theory was employed in this manner by Eilenberg & Steenrod (1952), in an influential book on the foundations of algebraic topology, and by Cartan & Eilenberg (1956), in a ground breaking book on homological algebra. (Curiously, although Eilenberg & Steenrod defined categories, Cartan & Eilenberg simply assumed them!) These books allowed new generations of mathematicians to learn algebraic topology and homological algebra directly in the categorical language, and to master the method of diagrams. Indeed, without the method of diagram chasing, many results in these two books seem inconceivable, or at the very least would have required a considerably more intricate presentation.
The situation changed radically with Grothendieck's (1957) landmark paper entitled “Sur quelques points d'algèbre homologique”, in which the author employed categories intrinsically to define and construct more general theories which he (Grothendieck 1957) then applied to specific fields, e.g., to algebraic geometry. Kan (1958) showed that adjoint functors subsume the important concepts of limits and colimits and could capture fundamental concepts in other areas (in his case, homotopy theory).
At this point, category theory became more than a convenient language, by virtue of two developments.
Employing the axiomatic method and the language of categories, Grothendieck (1957) defined in an abstract fashion types of categories, e.g., additive and Abelian categories, showed how to perform various constructions in these categories, and proved various results about them. In a nutshell, Grothendieck showed how to develop part of homological algebra in an abstract setting of this sort. From then on, a specific category of structures, e.g., a category of sheaves over a topological space X, could be seen as a token of an abstract category of a certain type, e.g., an Abelian category. One could therefore immediately see how the methods of, e.g., homological algebra could be applied to, for instance, algebraic geometry. Furthermore, it made sense to look for other types of abstract categories, ones that would encapsulate the fundamental and formal aspects of various mathematical fields in the same way that Abelian categories encapsulated fundamental aspects of homological algebra.
Thanks in large part to the efforts of Freyd and Lawvere, category theorists gradually came to see the pervasiveness of the concept of adjoint functors. Not only does the existence of adjoints to given functors permit definitions of abstract categories (and presumably those which are defined by such means have a privileged status) but as we mentioned earlier, many important theorems and even theories in various fields can be seen as equivalent to the existence of specific functors between particular categories. By the early 1970's, the concept of adjoint functors was seen as central to category theory.
With these developments, category theory became an autonomous field of research, and pure category theory could be developed. And indeed, it did grow rapidly as a discipline, but also in its applications, mainly in its source contexts, namely algebraic topology and homological algebra, but also in algebraic geometry and, after the appearance of Lawvere's Ph. D thesis, in universal algebra. This thesis also constitutes a landmark in this history of the field, for in it Lawvere proposed the category of categories as a foundation for category theory, set theory and, thus, the whole of mathematics, as well as using categories for the study of the logical aspects of mathematics.
Over the course of the 1960's, Lawvere outlined the basic framework for an entirely original approach to logic and the foundations of mathematics. He achieved the following:
Axiomatized the category of sets (Lawvere 1964) and of categories (Lawvere 1966);
Gave a categorical description of theories that was independent of syntactical choices and sketched how completeness theorems for logical systems could be obtained by categorical methods (Lawvere 1967);
Characterized Cartesian closed categories and showed their connections to logical systems and various logical paradoxes (Lawvere 1969);
Showed that the quantifiers and the comprehension schemes could be captured as adjoint functors to given elementary operations (Lawvere 1966, 1969, 1970, 1971);
Argued that adjoint functors should generally play a major foundational role through the notion of “categorical doctrines” (Lawvere 1969).
Meanwhile, Lambek (1968, 1969, 1972) described categories in terms of deductive systems and employed categorical methods for proof-theoretical purposes.
All this work culminated in another notion, thanks to Grothendieck and his school: that of a topos. Even though toposes appeared in the 1960's, in the context of algebraic geometry, again from the mind of Grothendieck, it was certainly Lawvere and Tierney's (1972) elementary axiomatization of a topos which gave impetus to its attaining foundational status. Very roughly, an elementary topos is a category possessing a logical structure sufficiently rich to develop most of “ordinary mathematics”, that is, most of what is taught to mathematics undergraduates. As such, an elementary topos can be thought of as a categorical theory of sets. But it is also a generalized topological space, thus providing a direct connection between logic and geometry. (For more on the history of categorical logic, see Marquis & Reyes 2012, Bell 2005.)
The 1970s saw the development and application of the topos concept in many different directions. The very first applications outside algebraic geometry were in set theory, where various independence results were recast in terms of topos (Tierney 1972, Bunge 1974, but also Blass & Scedrov 1989, Blass & Scedrov 1992, Freyd 1980, Mac Lane & Moerdijk 1992, Scedrov 1984). Connections with intuitionistic and, more generally constructive mathematics were noted early on, and toposes are still used to investigate models of various aspects of intuitionism and constructivism (Lambek & Scott 1986, Mac Lane & Moerdijk 1992, Van der Hoeven & Moerdijk 1984a, 1984b, 1984c, Moerdijk 1984, Moerdijk 1995a, Moerdijk 1998, Moerdijk & Palmgren 1997, Moerdijk & Palmgren 2002), Palmgren 2012. For more on the history of topos theory, see McLarty (1992).
More recently, topos theory has been employed to investigate various forms of constructive mathematics or set theory (Joyal & Moerdijk 1995, Taylor 1996, Awodey 2008), recursiveness, and models of higher-order type theories generally. The introduction of the so-called “effective topos” and the search for axioms for synthetic domain theory are worth mentioning (Hyland 1982, Hyland 1988, 1991, Hyland et al. 1990, McLarty 1992, Jacobs 1999, Van Oosten 2008, Van Oosten 2002 and the references therein). Lawvere's early motivation was to provide a new foundation for differential geometry, a lively research area which is now called “synthetic differential geometry” (Lawvere 2000, 2002, Kock 2006, Bell 1988, 1995, 1998, 2001, Moerdijk & Reyes 1991). This is only the tip of the iceberg; toposes could prove to be for the 21st century what Lie groups were to the 20th century.
From the 1980s to the present, category theory has found new applications. In theoretical computer science, category theory is now firmly rooted, and contributes, among other things, to the development of new logical systems and to the semantics of programming. (Pitts 2000, Plotkin 2000, Scott 2000, and the references therein). Its applications to mathematics are becoming more diverse, even touching on theoretical physics, which employs higher-dimensional category theory — which is to category theory what higher-dimensional geometry is to plane geometry — to study the so-called “quantum groups” and quantum field theory (Majid 1995, Baez & Dolan 2001 and other publications by these authors).
3. Philosophical Significance
Category theory challenges philosophers in two ways, which are not necessarily mutually exclusive. On the one hand, it is certainly the task of philosophy to clarify the general epistemological and ontological status of categories and categorical methods, both in the practice of mathematics and in the foundational landscape. On the other hand, philosophers and philosophical logicians can employ category theory and categorical logic to explore philosophical and logical problems. I now discuss these challenges, briefly, in turn.
Category theory is now a common tool in the mathematician's toolbox; that much is clear. It is also clear that category theory organizes and unifies much of mathematics. (See for instance Mac Lane 1971, 1998 or Pedicchio & Tholen 2004.) No one will deny these simple facts.
Doing mathematics in a categorical framework is almost always radically different from doing it in a set-theoretical framework (the exception being working with the internal language of a Boolean topos; whenever the topos is not Boolean, then the main difference lies in the fact that the logic is intuitionistic). Hence, as is often the case when a different conceptual framework is adopted, many basic issues regarding the nature of the objects studied, the nature of the knowledge involved, and the nature of the methods used have to be reevaluated. We will take up these three aspects in turn.
Two facets of the nature of mathematical objects within a categorical framework have to be emphasized. First, objects are always given in a category. An object exists in and depends upon an ambient category. Furthermore, an object is characterized by the morphisms going in it and/or the morphisms coming out of it. Second, objects are always characterized up to isomorphism (in the best cases, up to a unique isomorphism). There is no such thing, for instance, as the natural numbers. However, it can be argued that there is such a thing as the concept of natural numbers. Indeed, the concept of natural numbers can be given unambiguously, via the Dedekind-Peano-Lawvere axioms, but what this concept refers to in specific cases depends on the context in which it is interpreted, e.g., the category of sets or a topos of sheaves over a topological space. It is hard to resist the temptation to think that category theory embodies a form of structuralism, that it describes mathematical objects as structures since the latter, presumably, are always characterized up to isomorphism. Thus, the key here has to do with the kind of criterion of identity at work within a categorical framework and how it resembles any criterion given for objects which are thought of as forms in general. One of the standard objections presented against this view is that if objects are thought of as structures and only as abstract structures, meaning here that they are separated from any specific or concrete representation, then it is impossible to locate them within the mathematical universe. (See Hellman 2003 for a standard formulation of the objection, McLarty 1993, Awodey 2004, Landry & Marquis 2005, Shapiro 2005, Landry 2011, Linnebo & Pettigrew 2011, McLarty 2011 for relevant material on the issue.)
A slightly different way to make sense of the situation is to think of mathematical objects as types for which there are tokens given in different contexts. This is strikingly different from the situation one finds in set theory, in which mathematical objects are defined uniquely and their reference is given directly. Although one can make room for types within set theory via equivalence classes or isomorphism types in general, the basic criterion of identity within that framework is given by the axiom of extensionality and thus, ultimately, reference is made to specific sets. Furthermore, it can be argued that the relation between a type and its token is not represented adequately by the membership relation. A token does not belong to a type, it is not an element of a type, but rather it is an instance of it. In a categorical framework, one always refers to a token of a type, and what the theory characterizes directly is the type, not the tokens. In this framework, one does not have to locate a type, but tokens of it are, at least in mathematics, epistemologically required. This is simply the reflection of the interaction between the abstract and the concrete in the epistemological sense (and not the ontological sense of these latter expressions.) (See Ellerman 1988, Marquis 2000, Marquis 2006, Marquis 2013.)
The history of category theory offers a rich source of information to explore and take into account for an historically sensitive epistemology of mathematics. It is hard to imagine, for instance, how algebraic geometry and algebraic topology could have become what they are now without categorical tools. (See, for instance, Carter 2008, Corfield 2003, Krömer 2007, Marquis 2009, McLarty 1994, McLarty 2006.) Category theory has lead to reconceptualizations of various areas of mathematics based on purely abstract foundations. Moreover, when developed in a categorical framework, traditional boundaries between disciplines are shattered and reconfigured; to mention but one important example, topos theory provides a direct bridge between algebraic geometry and logic, to the point where certain results in algebraic geometry are directly translated into logic and vice versa. Certain concepts that were geometrical in origin are more clearly seen as logical (for example, the notion of coherent topos). Algebraic topology also lurks in the background. On a different but important front, it can be argued that the distinction between mathematics and metamathematics cannot be articulated in the way it has been. All these issues have to be reconsidered and reevaluated.
Moving closer to mathematical practice, category theory allowed for the development of methods that have changed and continue to change the face of mathematics. It could be argued that category theory represents the culmination of one of deepest and most powerful tendencies in twentieth century mathematical thought: the search for the most general and abstract ingredients in a given situation. Category theory is, in this sense, the legitimate heir of the Dedekind-Hilbert-Noether-Bourbaki tradition, with its emphasis on the axiomatic method and algebraic structures. When used to characterize a specific mathematical domain, category theory reveals the frame upon which that area is built, the overall structure presiding to its stability, strength and coherence. The structure of this specific area, in a sense, might not need to rest on anything, that is, on some solid soil, for it might very well be just one part of a larger network that is without any Archimedean point, as if floating in space. To use a well-known metaphor: from a categorical point of view, Neurath's ship has become a spaceship.
Still, it remains to be seen whether category theory should be “on the same plane,” so to speak, as set theory, whether it should be taken as a serious alternative to set theory as a foundation for mathematics, or whether it is foundational in a different sense altogether. (That this very question applies even more forcefully to topos theory will not detain us.)
Lawvere from early on promoted the idea that a category of categories could be used as a foundational framework. (See Lawvere 1964, 1966.) This proposal now rests in part on the development of higher-dimensional categories, also called weak n-categories. (See, for instance Makkai 1998.) The advent of topos theory in the seventies brought new possibilities. Mac Lane has suggested that certain toposes be considered as a genuine foundation for mathematics. (See Mac Lane 1986.) Lambek proposed the so-called free topos as the best possible framework, in the sense that mathematicians with different philosophical outlooks might nonetheless agree to adopt it. (See Couture & Lambek 1991, 1992, Lambek 1994.) He has recently argued that there is no topos that can thoroughly satisfy a classical mathematician. (See Lambek 2004.) (For more on the various foundational views among category theorists, see Landry & Marquis 2005.)
Arguments have been advanced for and against category theory as a foundational framework. (Blass 1984 surveys the relationships between category theory and set theory. Feferman 1977, Bell 1981, and Hellman 2003 argue against category theory. See Marquis 1995 for a quick overview and proposal and McLarty 2004 and Awodey 2004 for replies to Hellman 2003.) This matter is further complicated by the fact that the foundations of category theory itself have yet to be clarified. For there may be many different ways to think of a universe of higher-dimensional categories as a foundations for mathematics. An adequate language for such a universe still has to be presented together with definite axioms for mathematics. (See Makkai 1998 for a short description of such a language. A different approach based on homotopy theory but with closed connections with higher-dimensional categories has been proposed by Voevodsky et al. and is being vigorously pursued. See the book Homotopy Type Theory, by Awodey et al. 2013.)
It is an established fact that category theory is employed to study logic and philosophy. Indeed, categorical logic, the study of logic by categorical means, has been under way for about 30 years now and still vigorous. Some of the philosophically relevant results obtained in categorical logic are:
The hierarchy of categorical doctrines: regular categories, coherent categories, Heyting categories and Boolean categories; all these correspond to well-defined logical systems, together with deductive systems and completeness theorems; they suggest that logical notions, including quantifiers, arise naturally in a specific order and are not haphazardly organized;
Joyal's generalization of Kripke-Beth semantics for intuitionistic logic to sheaf semantics (Lambek & Scott 1986, Mac Lane & Moerdijk 1992);
Coherent and geometric logic, so-called, whose practical and conceptual significance has yet to be explored (Makkai & Reyes 1977, Mac Lane & Moerdiejk 1992, Johnstone 2002, Caramello 2011b, 2012a);
The notions of generic model and classifying topos of a theory (Makkai & Reyes 1977, Boileau & Joyal 1981, Bell 1988, Mac Lane & Moerdijk 1992, Johnstone 2002, Caramello 2012b);
The notion of strong conceptual completeness and the associated theorems (Makkai & Reyes 1977, Butz & Moerdijk 1999, Makkai 1981, Pitts 1989, Johnstone 2002);
Geometric proofs of the independence of the continuum hypothesis and other strong axioms of set theory (Tierney 1972, Bunge 1974, Freyd 1980, 1987, Blass & Scedrov 1983, 1989, 1992, Mac Lane & Moerdijk 1992);
Models and development of constructive mathematics (see bibliography below);
Synthetic differential geometry, an alternative to standard and non-standard analysis (Kock 1981, Bell 1998, 2001, 2006);
The construction of the so-called effective topos, in which every function on the natural numbers is recursive (McLarty 1992, Hyland 1982, 1991, Van Oosten 2002, Van Oosten 2008);
Categorical models of linear logic, modal logic, fuzzy sets, and general higher-order type theories (Reyes 1991, Reyes & Zawadoski 1993, Reyes & Zolfaghari 1991, 1996, Makkai & Reyes 1995, Ghilardi & Zawadowski 2002, Rodabaugh & Klement 2003, Jacobs 1999, Taylor 1999, Johnstone 2002, Blute & Scott 2004, Awodey & Warren 2009, Awodey et. al. 2013);
A graphical syntax called “sketches” (Barr & Wells 1985, 1999, Makkai 1997a, 1997b, 1997c, Johnstone 2002).
Quantum logic, the foundations of quantum physics and quantum field theory (Abramsky & Duncan 2006, Heunen et. al. 2009, Baez & Stay 2010, Baez & Lauda 2011, Coecke 2011, Isham 2011, Döring 2011).
Categorical tools in logic offer considerable flexibility, as is illustrated by the fact that almost all the surprising results of constructive and intuitionistic mathematics can be modeled in a proper categorical setting. At the same time, the standard set-theoretic notions, e.g. Tarski's semantics, have found natural generalizations in categories. Thus, categorical logic has roots in logic as it was developed in the twentieth century, while at the same time providing a powerful and novel framework with numerous links to other parts of mathematics.
Category theory also bears on more general philosophical questions. From the foregoing disussion, it should be obvious that category theory and categorical logic ought to have an impact on almost all issues arising in philosophy of logic: from the nature of identity criteria to the question of alternative logics, category theory always sheds a new light on these topics. Similar remarks can be made when we turn to ontology, in particular formal ontology: the part/whole relation, boundaries of systems, ideas of space, etc. Ellerman (1988) has bravely attempted to show that category theory constitutes a theory of universals, one having properties radically different from set theory, which is also seen as a theory of universals. Moving from ontology to cognitive science, MacNamara & Reyes (1994) have tried to employ categorical logic to provide a different logic of reference. In particular, they have attempted to clarify the relationships between count nouns and mass terms. Other researchers are using category theory to study complex systems, cognitive neural networks, and analogies. (See, for instance, Ehresmann & Vanbremeersch 1987, 2007, Healy 2000, Healy & Caudell 2006, Arzi-Gonczarowski 1999, Brown & Porter 2006.) Finally, philosophers of science have turned to category theory to shed a new light on issues related to structuralism in science. (See, for instance, Brading & Landry 2006, Bain 2013, Lam & Wüthrich forthcoming.)
Category theory offers thus many philosophical challenges, challenges which will hopefully be taken up in years to come.
Bibliography
Readers may find the following useful:
Programmatic Reading Guide
The citations in this guide and in the text above can all be found in the list below.
Abramsky, S. & Duncan, R., 2006, “A Categorical Quantum Logic”, Mathematical Structures in Computer Science, 16 (3): 469–489.
Adamek, J. et al., 1990, Abstract and Concrete Categories: The Joy of Cats, New York: Wiley.
Adamek, J. et al., 1994, Locally Presentable and Accessible Categories, Cambridge: Cambridge University Press.
Arzi-Gonczaworski, Z., 1999, “Perceive This as That — Analogies, Artificial Perception, and Category Theory”, Annals of Mathematics and Artificial Intelligence, 26 (1): 215–252.
Awodey, S., 1996, “Structure in Mathematics and Logic: A Categorical Perspective”, Philosophia Mathematica, 3: 209–237.
–––, 2004, “An Answer to Hellman's Question: Does Category Theory Provide a Framework for Mathematical Structuralism”, Philosophia Mathematica, 12: 54–64.
–––, 2006, Category Theory, Oxford: Clarendon Press.
–––, 2007, “Relating First-Order Set Theories and Elementary Toposes”, The Bulletin of Symbolic, 13 (3): 340–358.
–––, 2008, “A Brief Introduction to Algebraic Set Theory”, The Bulletin of Symbolic, 14 (3): 281–298.
Awodey, S., et al., 2013, Homotopy Type Theory: Univalent Foundations of Mathematics, The Univalent Foundations Program.
Awodey, S. & Butz, C., 2000, “Topological Completeness for Higher Order Logic”, Journal of Symbolic Logic, 65 (3): 1168–1182.
Awodey, S. & Reck, E. R., 2002, “Completeness and Categoricity I. Nineteen-Century Axiomatics to Twentieth-Century Metalogic”, History and Philosophy of Logic, 23 (1): 1–30.
–––, 2002, “Completeness and Categoricity II. Twentieth-Century Metalogic to Twenty-first-Century Semantics”, History and Philosophy of Logic, 23 (2): 77–94.
Awodey, S. & Warren, M., 2009, “Homotopy theoretic Models of Identity Types”, Mathematical Proceedings of the Cambridge Philosophical Society, 146 (1): 45–55.
Baez, J., 1997, “An Introduction to n-Categories”, Category Theory and Computer Science, Lecture Notes in Computer Science (Volume 1290), Berlin: Springer-Verlag, 1–33.
Baez, J. & Dolan, J., 1998a, “Higher-Dimensional Algebra III. n-Categories and the Algebra of Opetopes”, Advances in Mathematics, 135: 145–206.
–––, 1998b, “Categorification”, Higher Category Theory (Contemporary Mathematics, Volume 230), Ezra Getzler and Mikhail Kapranov (eds.), Providence: AMS, 1–36.
–––, 2001, “From Finite Sets to Feynman Diagrams”, Mathematics Unlimited – 2001 and Beyond, Berlin: Springer, 29–50.
Baez, J. & Lauda, A.D., 2011, “A Pre-history of n-Categorical Physics”, Deep Beauty: Understanding the Quantum World Through Mathematical Innovation, H. Halvorson, ed., Cambridge: Cambridge University Press, 13–128.
Baez, J. & May, P. J., 2010, Towards Higher Category Theory, Berlin: Springer.
Baez, J. & Stay, M., 2010, “Physics, Topology, Logic and Computation: a Rosetta Stone”, New Structures for Physics (Lecture Notes in Physics 813), B. Coecke (ed.), New York, Springer: 95–172.
Baianu, I. C., 1987, “Computer Models and Automata Theory in Biology and Medecine”, in Witten, Matthew, Eds. Mathematical Modelling, Vol. 7, 1986, chapter 11, Pergamon Press, Ltd., 1513–1577.
Bain, J., 2013, “Category-theoretic Structure and Radical Ontic Structural Realism”, Synthese, 190: 1621–1635.
Barr, M. & Wells, C., 1985, Toposes, Triples and Theories, New York: Springer-Verlag.
–––, 1999, Category Theory for Computing Science, Montreal: CRM.
Batanin, M., 1998, “Monoidal Globular Categories as a Natural Environment for the Theory of Weak n-Categories”, Advances in Mathematics, 136: 39–103.
Bell, J. L., 1981, “Category Theory and the Foundations of Mathematics”, British Journal for the Philosophy of Science, 32: 349–358.
–––, 1982, “Categories, Toposes and Sets”, Synthese, 51 (3): 293–337.
–––, 1986, “From Absolute to Local Mathematics”, Synthese, 69 (3): 409–426.
–––, 1988, “Infinitesimals”, Synthese, 75 (3): 285–315.
–––, 1988, Toposes and Local Set Theories: An Introduction, Oxford: Oxford University Press.
–––, 1995, “Infinitesimals and the Continuum”, Mathematical Intelligencer, 17 (2): 55–57.
–––, 1998, A Primer of Infinitesimal Analysis, Cambridge: Cambridge University Press.
–––, 2001, “The Continuum in Smooth Infinitesimal Analysis”, Reuniting the Antipodes — Constructive and Nonstandard Views on the Continuum (Synthese Library, Volume 306), Dordrecht: Kluwer, 19–24.
–––, 2005, “The Development of Categorical Logic”, in Handbook of Philosophical Logic (Volume 12), 2nd ed., D.M. Gabbay, F. Guenthner (eds.), Dordrecht: Springer, pp. 279–362.
Birkoff, G. & Mac Lane, S., 1999, Algebra, 3rd ed., Providence: AMS.
Blass, A., 1984, “The Interaction Between Category Theory and Set Theory”, in Mathematical Applications of Category Theory (Volume 30), Providence: AMS, 5–29.
Blass, A. & Scedrov, A., 1983, “Classifying Topoi and Finite Forcing”, Journal of Pure and Applied Algebra, 28: 111–140.
–––, 1989, Freyd's Model for the Independence of the Axiom of Choice, Providence: AMS.
–––, 1992, “Complete Topoi Representing Models of Set Theory”, Annals of Pure and Applied Logic , 57 (1): 1–26.
Blute, R. & Scott, P., 2004, “Category Theory for Linear Logicians”, in Linear Logic in Computer Science, T. Ehrhard, P. Ruet, J-Y. Girard, P. Scott, eds., Cambridge: Cambridge University Press, 1–52.
Boileau, A. & Joyal, A., 1981, “La logique des topos”, Journal of Symbolic Logic, 46 (1): 6–16.
Borceux, F., 1994, Handbook of Categorical Algebra, 3 volumes, Cambridge: Cambridge University Press.
Brading, K. & Landry, E., 2006, “Scientific Structuralism: Presentation and Representation”, Philosophy of Science, 73: 571–581.
Brown, R. & Porter, T., 2006, “Category Theory: an abstract setting for analogy and comparison”, What is Category Theory?, G. Sica, ed., Monza: Polimetrica: 257–274.
Bunge, M., 1974, “Topos Theory and Souslin's Hypothesis”, Journal of Pure and Applied Algebra, 4: 159–187.
–––, 1984, “Toposes in Logic and Logic in Toposes”, Topoi, 3 (1): 13–22.
Caramello, O., 2011, “A Characterization Theorem for Geometric Logic”, Annals of Pure and Applied Logic,162, 4: 318–321.
–––, 2012a, “Universal Models and Definability”, Mathematical Proceedings of the Cambridge Philosophical Society, 152 (2): 279–302.
–––, 2012b, “Syntactic Characterizations of Properties of Classifying Toposes”, Theory and Applications of Categories, 26 (6): 176–193.
Carter, J., 2008, “Categories for the working mathematician: making the impossible possible”, Synthese, 162 (1): 1–13.
Cheng, E. & Lauda, A., 2004, Higher-Dimensional Categories: an illustrated guide book, available at: http://cheng.staff.shef.ac.uk/guidebook/index.html
Cockett, J. R. B. & Seely, R. A. G., 2001, “Finite Sum-product Logic”, Theory and Applications of Categories (electronic), 8: 63–99.
Coecke, B., 2011, “A Universe of Processes and Some of its Guises”, Deep Beauty: Understanding the Quantum World through Mathematical Innovation, Cambridge: Cambridge University Press: 129–186.
Couture, J. & Lambek, J., 1991, “Philosophical Reflections on the Foundations of Mathematics”, Erkenntnis, 34 (2): 187–209.
http://arxiv.org/abs/1103.3493, 1992, “Erratum:”Philosophical Reflections on the Foundations of Mathematics“”, Erkenntnis, 36 (1): 134.
Crole, R. L., 1994, Categories for Types, Cambridge: Cambridge University Press.
Dieudonné, J. & Grothendieck, A., 1960 [1971], Éléments de Géométrie Algébrique, Berlin: Springer-Verlag.
Döring, A., 2011, “The Physical Interpretation of Daseinisation”, Deep Beauty: Understanding the Quantum World through Mathematical Innovation, Cambridge: Cambridge University Press: 207-238.
Ehresmann, A. & Vanbremeersch, J.-P., 2007, Memory Evolutive Systems: Hierarchy, Emergence, Cognition, Amsterdam: Elsevier
–––, 1987, “Hierarchical Evolutive Systems: a Mathematical Model for Complex Systems”, Bulletin of Mathematical Biology, 49 (1): 13–50.
Eilenberg, S. & Cartan, H., 1956, Homological Algebra, Princeton: Princeton University Press.
Eilenberg, S. & Mac Lane, S., 1942, “Group Extensions and Homology”, Annals of Mathematics, 43: 757–831.
–––, 1945, “General Theory of Natural Equivalences”, Transactions of the American Mathematical Society, 58: 231–294.
Eilenberg, S. & Steenrod, N., 1952, Foundations of Algebraic Topology, Princeton: Princeton University Press.
Ellerman, D., 1988, “Category Theory and Concrete Universals”, Erkenntnis, 28: 409–429.
Feferman, S., 1977, “Categorical Foundations and Foundations of Category Theory”, Logic, Foundations of Mathematics and Computability, R. Butts (ed.), Reidel, 149–169.
–––, 2004, “Typical Ambiguity: trying to have your cake and eat it too”, One Hundred Years of Russell's Paradox, G. Link (ed.), Berlin: De Gruyter, 135–151.
Freyd, P., 1964, Abelian Categories. An Introduction to the Theory of Functors, New York: Harper & Row.
–––, 1965, “The Theories of Functors and Models”. Theories of Models, Amsterdam: North Holland, 107–120.
–––, 1972, “Aspects of Topoi”, Bulletin of the Australian Mathematical Society, 7: 1–76.
–––, 1980, “The Axiom of Choice”, Journal of Pure and Applied Algebra, 19: 103–125.
–––, 1987, “Choice and Well-Ordering”, Annals of Pure and Applied Logic, 35 (2): 149–166.
–––, 1990, Categories, Allegories, Amsterdam: North Holland.
–––, 2002, “Cartesian Logic”, Theoretical Computer Science, 278 (1–2): 3–21.
Freyd, P., Friedman, H. & Scedrov, A., 1987, “Lindembaum Algebras of Intuitionistic Theories and Free Categories”, Annals of Pure and Applied Logic, 35 (2): 167–172.
Galli, A. & Reyes, G. & Sagastume, M., 2000, “Completeness Theorems via the Double Dual Functor”, Studia Logical, 64 (1): 61–81.
Ghilardi, S., 1989, “Presheaf Semantics and Independence Results for some Non-classical first-order logics”, Archive for Mathematical Logic, 29 (2): 125–136.
Ghilardi, S. & Zawadowski, M., 2002, Sheaves, Games & Model Completions: A Categorical Approach to Nonclassical Porpositional Logics, Dordrecht: Kluwer.
Goldblatt, R., 1979, Topoi: The Categorical Analysis of Logic, Studies in logic and the foundations of mathematics, Amsterdam: Elsevier.
Grothendieck, A., 1957, “Sur Quelques Points d'algèbre homologique”, Tohoku Mathematics Journal, 9: 119–221.
Grothendieck, A. et al., Séminaire de Géométrie Algébrique, Vol. 1–7, Berlin: Springer-Verlag.
Hatcher, W. S., 1982, The Logical Foundations of Mathematics, Oxford: Pergamon Press.
Healy, M. J., 2000, “Category Theory Applied to Neural Modeling and Graphical Representations”, Proceedings of the IEEE-INNS-ENNS International Joint Conference on Neural Networks: IJCNN200, Como, vol. 3, M. Gori, S-I. Amari, C. L. Giles, V. Piuri, eds., IEEE Computer Science Press, 35–40.
Healy, M. J., & Caudell, T. P., 2006, “Ontologies and Worlds in Category Theory: Implications for Neural Systems”,Axiomathes, 16 (1–2): 165–214.
Hellman, G., 2003, “Does Category Theory Provide a Framework for Mathematical Structuralism?”, Philosophia Mathematica, 11 (2): 129–157.
–––, 2006, “Mathematical Pluralism: the case of smooth infinitesimal analysis”, Journal of Philosophical Logic, 35 (6): 621–651.
Hermida, C. & Makkai, M. & Power, J., 2000, “On Weak Higher-dimensional Categories I”, Journal of Pure and Applied Algebra, 154 (1–3): 221–246.
–––, 2001, “On Weak Higher-dimensional Categories 2”, Journal of Pure and Applied Algebra, 157 (2–3): 247–277.
–––, 2002, “On Weak Higher-dimensional Categories 3”, Journal of Pure and Applied Algebra, 166 (1–2): 83–104.
Heunen, C. & Landsmann, N. & Spitters, B., 2009, “A Topos for Algebraic Quantum Theory”, Communications in Mathematical Physics, 291 (1): 63–110.
Hyland, J. M. E., 1982, “The Effective Topos”, Studies in Logic and the Foundations of Mathematics (Volume 110), Amsterdam: North Holland, 165–216.
–––, 1988, “A Small Complete Category”, Annals of Pure and Applied Logic, 40 (2): 135–165.
–––, 1991, “First Steps in Synthetic Domain Theory”, Category Theory (Como 1990) (Lecture Notes in Mathematics, Volume 1488), Berlin: Springer, 131–156.
–––, 2002, “Proof Theory in the Abstract”, Annals of Pure and Applied Logic, 114 (1–3): 43–78.
Hyland, J. M. E. & Robinson, E. P. & Rosolini, G., 1990, “The Discrete Objects in the Effective Topos”, Proceedings of the London Mathematical Society (3), 60 (1): 1–36.
Isham, C.J., 2011, “Topos Methods in the Foundations of Physics”, Deep Beauty: Understanding the Quantum World through Mathematical Innovation, Cambridge: Cambridge University Press: 187–206.
Jacobs, B., 1999, Categorical Logic and Type Theory, Amsterdam: North Holland.
Johnstone, P. T., 1977, Topos Theory, New York: Academic Press.
–––, 1979a, “Conditions Related to De Morgan's Law”, Applications of Sheaves (Lecture Notes in Mathematics, Volume 753), Berlin: Springer, 479–491.
–––, 1979b, “Another Condition Equivalent to De Morgan's Law”, Communications in Algebra, 7 (12): 1309–1312.
–––, 1981, “Tychonoff's Theorem without the Axiom of Choice”, Fundamenta Mathematicae, 113 (1): 21–35.
–––, 1982, Stone Spaces, Cambridge:Cambridge University Press.
–––, 1985, “How General is a Generalized Space?”, Aspects of Topology, Cambridge: Cambridge University Press, 77–111.
–––, 2001, “Elements of the History of Locale Theory”, Handbook of the History of General Topology, Vol. 3, Dordrecht: Kluwer, 835–851.
–––, 2002a, Sketches of an Elephant: a Topos Theory Compendium. Vol. 1 (Oxford Logic Guides, Volume 43), Oxford: Oxford University Press.
Joyal, A. & Moerdijk, I., 1995, Algebraic Set Theory, Cambridge: Cambridge University Press.
Kan, D. M., 1958, “Adjoint Functors”, Transactions of the American Mathematical Society, 87: 294–329.
Kock, A., 2006, Synthetic Differential Geometry (London Mathematical Society Lecture Note Series, Volume 51), Cambridge: Cambridge University Press, 2nd ed.
Krömer, R., 2007, Tool and Objects: A History and Philosophy of Category Theory, Basel: Birkhäuser.
La Palme Reyes, M., John Macnamara, Gonzalo E. Reyes, and Houman Zolfaghari, 1994, “The non-Boolean Logic of Natural Language Negation”, Philosophia Mathematica, 2 (1): 45–68.
–––, 1999, “Count Nouns, Mass Nouns, and their Transformations: a Unified Category-theoretic Semantics”, Language, Logic and Concepts, Cambridge: MIT Press, 427–452.
Lambek, J., 1968, “Deductive Systems and Categories I. Syntactic Calculus and Residuated Categories”, Mathematical Systems Theory, 2: 287–318.
–––, 1969, “Deductive Systems and Categories II. Standard Constructions and Closed Categories”, Category Theory, Homology Theory and their Applications I, Berlin: Springer, 76–122.
–––, 1972, “Deductive Systems and Categories III. Cartesian Closed Categories, Intuitionâ‰ istic Propositional Calculus, and Combinatory Logic”, Toposes, Algebraic Geometry and Logic (Lecture Notes in Mathematics, Volume 274), Berlin: Springer, 57–82.
–––, 1982, “The Influence of Heraclitus on Modern Mathematics”, Scientific Philosophy Today, J. Agassi and R.S. Cohen, eds., Dordrecht, Reidel, 111–122.
–––, 1986, “Cartesian Closed Categories and Typed lambda calculi”, Combinators and Functional Programming Languages (Lecture Notes in Computer Science, Volume 242), Berlin: Springer, 136–175.
–––, 1989a, “On Some Connections Between Logic and Category Theory”, Studia Logica, 48 (3): 269–278.
–––, 1989b, “On the Sheaf of Possible Worlds”, Categorical Topology and its relation to Analysis, Algebra and Combinatorics, Teaneck: World Scientific Publishing, 36–53.
–––, 1993, “Logic without Structural Rules”, Substructural Logics (Studies in Logic and Computation, Volume 2), Oxford: Oxford University Press, 179–206.
–––, 1994a, “Some Aspects of Categorical Logic”, Logic, Methodology and Philosophy of Science IX (Studies in Logic and the Foundations of Mathematics, Volume 134), Amsterdam: North Holland, 69–89.
–––, 1994b, “Are the Traditional Philosophies of Mathematics Really Incompatible?”, Mathematical Intelligencer, 16 (1): 56–62.
–––, 1994c, “What is a Deductive System?”, What is a Logical System? (Studies in Logic and Computation, Volume 4), Oxford: Oxford University Press, 141–159.
–––, 2004, “What is the world of Mathematics? Provinces of Logic Determined”, Annals of Pure and Applied Logic, 126: 1–3, 149–158.
Lambek, J. & Scott, P.J., 1981, “Intuitionistic Type Theory and Foundations”, Journal of Philosophical Logic, 10 (1): 101–115.
–––, 1983, “New Proofs of Some Intuitionistic Principles”, Zeitschrift für Mathematische Logik und Grundlagen der Mathematik, 29 (6): 493–504.
–––, 1986, Introduction to Higher Order Categorical Logic, Cambridge: Cambridge University Press.
Lam, V. & Wütrich, C., forthcoming, “No Categorical Support for Radical Ontic Structural Realism”, British Journal for the Philosophy of Science.
Landry, E., 1999, “Category Theory: the Language of Mathematics”, Philosophy of Science, 66 (3) (Supplement): S14–S27.
–––, 2001, “Logicism, Structuralism and Objectivity”, Topoi, 20 (1): 79–95.
–––, 2007, “Shared Structure need not be Shared Set-structure”, Synthese, 158 (1): 1–17.
–––, 2011, “How to be a Structuralist all the way down”, Synthese, 179: 435–454.
Landry, E. & Marquis, J.-P., 2005, “Categories in Context: Historical, Foundational and philosophical”, Philosophia Mathematica, 13: 1–43.
Lawvere, F. W., 1963, “Functorial Semantics of Algebraic Theories”, Proceedings of the National Academy of Sciences U.S.A., 50: 869–872.
–––, 1964, “An Elementary Theory of the Category of Sets”, Proceedings of the National Academy of Sciences U.S.A., 52: 1506–1511.
–––, 1965, “Algebraic Theories, Algebraic Categories, and Algebraic Functors”, Theory of Models, Amsterdam: North Holland, 413–418.
–––, 1966, “The Category of Categories as a Foundation for Mathematics”, Proceedings of the Conference on Categorical Algebra, La Jolla, New York: Springer-Verlag, 1–21.
–––, 1969a, “Diagonal Arguments and Cartesian Closed Categories”, Category Theory, Homology Theory, and their Applications II, Berlin: Springer, 134–145.
–––, 1969b, “Adjointness in Foundations”, Dialectica, 23: 281–295.
–––, 1970, “Equality in Hyper doctrines and Comprehension Schema as an Adjoint Functor”, Applications of Categorical Algebra, Providence: AMS, 1–14.
–––, 1971, “Quantifiers and Sheaves”, Actes du Congrès International des Mathématiciens, Tome 1, Paris: Gauthier-Villars, 329–334.
–––, 1972, “Introduction”, Toposes, Algebraic Geometry and Logic, Lecture Notes in Mathematics, 274, Springer-Verlag, 1–12.
–––, 1975, “Continuously Variable Sets: Algebraic Geometry = Geometric Logic”, Proceedings of the Logic Colloquium Bristol 1973, Amsterdam: North Holland, 135–153.
–––, 1976, “Variable Quantities and Variable Structures in Topoi”, Algebra, Topology, and Category Theory, New York: Academic Press, 101–131.
–––, 1992, “Categories of Space and of Quantity”, The Space of Mathematics, Foundations of Communication and Cognition, Berlin: De Gruyter, 14–30.
–––, 1994a, “Cohesive Toposes and Cantor's lauter Ensein ”, Philosophia Mathematica, 2 (1): 5–15.
–––, 1994b, “Tools for the Advancement of Objective Logic: Closed Categories and Toposes”, The Logical Foundations of Cognition (Vancouver Studies in Cognitive Science, Volume 4), Oxford: Oxford University Press, 43–56.
–––, 2000, “Comments on the Development of Topos Theory”, Development of Mathematics 1950–2000, Basel: Birkhäuser, 715–734.
–––, 2002, “Categorical Algebra for Continuum Micro Physics”, Journal of Pure and Applied Algebra, 175 (1–3): 267–287.
–––, 2003, “Foundations and Applications: Axiomatization and Education. New Programs and Open Problems in the Foundation of Mathematics”, Bulletin of Symbolic Logic, 9 (2): 213–224.
Lawvere, F. W. & Rosebrugh, R., 2003, Sets for Mathematics, Cambridge: Cambridge University Press.
Lawvere, F. W. & Schanuel, S., 1997, Conceptual Mathematics: A First Introduction to Categories, Cambridge: Cambridge University Press.
Leinster, T., 2002, “A Survey of Definitions of n-categories”, Theory and Applications of Categories, (electronic), 10: 1–70.
–––, 2004, Higher Operads, Higher Categories, London Mathematical Society Lecture Note Series, 298, Cambridge: Cambridge University Press.
Linnebo, O. & Pettigrew, R., 2011, “Category Theory as an Autonomous Foundation”, Philosophia Mathematica, 19 (3): 227–254.
Lurie, J., 2009, Higher Topos Theory, Princeton: Princeton University Press.
Mac Lane, S., 1950, “Dualities for Groups”, Bulletin of the American Mathematical Society, 56: 485–516.
–––, 1969, “Foundations for Categories and Sets”, Category Theory, Homology Theory and their Applications II, Berlin: Springer, 146–164.
–––, 1969, “One Universe as a Foundation for Category Theory”, Reports of the Midwest Category Seminar III, Berlin: Springer, 192–200.
–––, 1971, “Categorical algebra and Set-Theoretic Foundations”, Axiomatic Set Theory, Providence: AMS, 231–240.
–––, 1975, “Sets, Topoi, and Internal Logic in Categories”, Studies in Logic and the Foundations of Mathematics (Volumes 80), Amsterdam: North Holland, 119–134.
–––, 1981, “Mathematical Models: a Sketch for the Philosophy of Mathematics”, American Mathematical Monthly, 88 (7): 462–472.
–––, 1986, Mathematics, Form and Function, New York: Springer.
–––, 1988, “Concepts and Categories in Perspective”, A nCentury of Mathematics in America, Part I, Providence: AMS, 323–365.
–––, 1989, “The Development of Mathematical Ideas by Collision: the Case of Categories and Topos Theory”, Categorical Topology and its Relation to Analysis, Algebra and Combinatorics, Teaneck: World Scientific, 1–9.
–––, 1996, “Structure in Mathematics. Mathematical Structuralism”, Philosophia Mathematica, 4 (2): 174–183.
–––, 1997, “Categorical Foundations of the Protean Character of Mathematics”, Philosophy of Mathematics Today, Dordrecht: Kluwer, 117–122.
–––, 1998, Categories for the Working Mathematician, 2nd edition, New York: Springer-Verlag.
Mac Lane, S. & Moerdijk, I., 1992, Sheaves in Geometry and Logic, New York: Springer-Verlag.
MacNamara, J. & Reyes, G., (eds.), 1994, The Logical Foundation of Cognition, Oxford: Oxford University Press.
Majid, S., 1995, Foundations of Quantum Group Theory, Cambridge: Cambridge University Press.
Makkai, M., 1987, “Stone Duality for First-Order Logic”, Advances in Mathematics, 65 (2): 97–170.
–––, 1988, “Strong Conceptual Completeness for First Order Logic”, Annals of Pure and Applied Logic, 40: 167–215.
–––, 1997a, “Generalized Sketches as a Framework for Completeness Theorems I”, Journal of Pure and Applied Algebra, 115 (1): 49–79.
–––, 1997b, “Generalized Sketches as a Framework for Completeness Theorems II”, Journal of Pure and Applied Algebra, 115 (2): 179–212.
–––, 1997c, “Generalized Sketches as a Framework for Completeness Theorems III”, Journal of Pure and Applied Algebra, 115 (3): 241–274.
–––, 1998, “Towards a Categorical Foundation of Mathematics”, Lecture Notes in Logic (Volume 11), Berlin: Springer, 153–190.
–––, 1999, “On Structuralism in Mathematics”, Language, Logic and Concepts, Cambridge: MIT Press, 43–66.
Makkai, M. & Paré, R., 1989, Accessible Categories: the Foundations of Categorical Model Theory, Contemporary Mathematics 104, Providence: AMS.
Makkai, M. & Reyes, G., 1977, First-Order Categorical Logic, Springer Lecture Notes in Mathematics 611, New York: Springer.
–––, 1995, “Completeness Results for Intuitionistic and Modal Logic in a Categorical Setting”, Annals of Pure and Applied Logic, 72 (1): 25–101.
Marquis, J.-P., 1993, “Russell's Logicism and Categorical Logicisms”, Russell and Analytic Philosophy, A. D. Irvine & G. A. Wedekind, (eds.), Toronto, University of Toronto Press, 293–324.
–––, 1995, “Category Theory and the Foundations of Mathematics: Philosophical Excavations”, Synthese, 103: 421–447.
–––, 2000, “Three Kinds of Universals in Mathematics?”, in Logical Consequence: Rival Approaches and New Studies in Exact Philosophy: Logic, Mathematics and Science, Vol. II, B. Brown & J. Woods (eds.), Oxford: Hermes, 191–212.
–––, 2006, “Categories, Sets and the Nature of Mathematical Entities”, in The Age of Alternative Logics. Assessing philosophy of logic and mathematics today, J. van Benthem, G. Heinzmann, Ph. Nabonnand, M. Rebuschi, H. Visser (eds.), Springer, 181–192.
–––, 2009, From a Geometrical Point of View: A Study in the History and Philosophy of Category Theory, Berlin: Springer.
–––, 2013, “Mathematical Forms and Forms of Mathematics: leaving the shores of extensional mathematics”, Synthese, 190 (12): 2141–2164.
Marquis, J.-P. & Reyes, G., 2012, “The History of Categorical Logic: 1963–1977”, Handbook of the History of Logic, Vol. 6, D. Gabbay & J. Woods, eds., Amsterdam: Elsevier, 689-800.
McLarty, C., 1986, “Left Exact Logic”, Journal of Pure and Applied Algebra, 41 (1): 63–66.
–––, 1990, “Uses and Abuses of the History of Topos Theory”, British Journal for the Philosophy of Science, 41: 351–375.
–––, 1991, “Axiomatizing a Category of Categories”, Journal of Symbolic Logic, 56 (4): 1243–1260.
–––, 1992, Elementary Categories, Elementary Toposes, Oxford: Oxford University Press.
–––, 1993, “Numbers Can be Just What They Have to”, Noûs, 27: 487–498.
–––, 1994, “Category Theory in Real Time”, Philosophia Mathematica, 2 (1): 36–44.
–––, 2004, “Exploring Categorical Structuralism”, Philosophia Mathematica, 12: 37–53.
–––, 2005, “Learning from Questions on Categorical Foundations”, Philosophia Mathematica, 13 (1): 44–60.
–––, 2006, “Emmy Noether's set-theoretic topology: from Dedekind to the rise of functors”, The Architecture of Modern Mathematics, J.J. Gray & J. Ferreiros, Oxford: Oxford University Press, 187–208.
–––, 2011, “Recent Debate over Categorical Foundations”, in Foundational Theories of Classical and Constructive Mathematics, G. Sommaruga, ed., New York: Springer: 145–154.
Moerdijk, I., 1984, “Heine-Borel does not imply the Fan Theorem”, Journal of Symbolic Logic, 49 (2): 514–519.
–––, 1995a, “A Model for Intuitionistic Non-standard Arithmetic”, Annals of Pure and Applied Logic, 73 (1): 37–51.
–––, 1998, “Sets, Topoi and Intuitionism”, Philosophia Mathematica, 6 (2): 169–177.
Moerdijk, I. & Palmgren, E., 1997, “Minimal Models of Heyting Arithmetic”, Journal of Symbolic Logic, 62 (4): 1448–1460.
–––, 2002, “Type Theories, Toposes and Constructive Set Theory: Predicative Aspects of AST”, Annals of Pure and Applied Logic, 114 (1–3): 155–201.
Moerdijk, I. & Reyes, G., 1991, Models for Smooth Infinitesimal Analysis, New York: Springer-Verlag.
Palmgren, E., 2012, “Constructivist and Structuralist Foundations: Bishop's and Lawvere's Theories of Sets”, Annals of Pure and Applied Logic, 63: 1384–1399.
Pareigis, B., 1970, Categories and Functors, New York: Academic Press.
Pedicchio, M. C. & Tholen, W., 2004, Categorical Foundations, Cambridge: Cambridge University Press.
Peirce, B., 1991, Basic Category Theory for Computer Scientists, Cambridge: MIT Press.
Pitts, A. M., 1987, “Interpolation and Conceptual Completeness for Pretoposes via Category Theory”, Mathematical Logic and Theoretical Computer Science (Lecture Notes in Pure and Applied Mathematics, Volume 106), New York: Dekker, 301–327.
–––, 1989, “Conceptual Completeness for First-order Intuitionistic Logic: an Application of Categorical Logic”, Annals of Pure and Applied Logic, 41 (1): 33–81.
–––, 1992, “On an Interpretation of Second-order Quantification in First-order Propositional Intuitionistic Logic”, Journal of Symbolic Logic, 57 (1): 33–52.
–––, 2000, “Categorical Logic”, Handbook of Logic in Computer Science, Vol.5, Oxford: Oxford Unversity Press, 39–128.
Pitts, A. M. & Taylor, P., 1989, “A Note of Russell's Paradox in Locally Cartesian Closed Categories”, Studia Logica, 48 (3): 377–387.
Plotkin, B., 2000, “Algebra, Categories and Databases”, Handbook of Algebra, Vol. 2, Amsterdam: Elsevier, 79–148.
Porter, T., 2004, “Interpreted Systems and Kripke Models for Multiagent Systems from a Categorical Perspective”, Theoretical Computer Science, 323 (1–3): 235–266.
Reyes, G., 1991, “A Topos-theoretic Approach to Reference and Modality”, Notre Dame Journal of Formal Logic, 32 (3): 359–391.
–––, 1974, “From Sheaves to Logic”, in Studies in Algebraic Logic, A. Daigneault, ed., Providence: AMS.
Reyes, G. & Zawadowski, M., 1993, “Formal Systems for Modal Operators on Locales”, Studia Logica, 52 (4): 595–613.
Reyes, G. & Zolfaghari, H., 1991, “Topos-theoretic Approaches to Modality”, Category Theory (Como 1990) (Lecture Notes in Mathematics, Volume 1488), Berlin: Springer, 359–378.
–––, 1996, “Bi-Heyting Algebras, Toposes and Modalities”, Journal of Philosophical Logic, 25 (1): 25–43.
Rodabaugh, S. E. & Klement, E. P., eds., Topological and Algebraic Structures in Fuzzy Sets: A Handbook of Recent Developments in the Mathematics of Fuzzy Sets (Trends in Logic, Volume 20), Dordrecht: Kluwer.
Scedrov, A., 1984, Forcing and Classifying Topoi, Providence: AMS.
Scott, P.J., 2000, “Some Aspects of Categories in Computer Science”, Handbook of Algebra, Vol. 2, Amsterdam: North Holland, 3–77.
Seely, R. A. G., 1984, “Locally Cartesian Closed Categories and Type Theory”, Mathematical Proceedings of the Cambridge Mathematical Society, 95 (1): 33–48.
Shapiro, S., 2005, “Categories, Structures and the Frege-Hilbert Controversy: the Status of Metamathematics”, Philosophia Mathematica, 13 (1): 61–77.
Sica, G., ed., 2006, What is Category Theory?, Firenze: Polimetrica.
Simpson, C., 2011, Homotopy Theory of Higher Categories, Cambridge: Cambridge University Press.
Taylor, P., 1996, “Intuitionistic sets and Ordinals”, Journal of Symbolic Logic, 61: 705–744.
–––, 1999, Practical Foundations of Mathematics, Cambridge: Cambridge University Press.
Tierney, M., 1972, “Sheaf Theory and the Continuum Hypothesis”, Toposes, Algebraic Geometry and Logic, F.W. Lawvere (ed.), Springer Lecture Notes in Mathematics 274, 13–42.
Van Oosten, J., 2002, “Realizability: a Historical Essay”, Mathematical Structures in Computer Science, 12 (3): 239–263.
–––, 2008, Realizability: an Introduction to its Categorical Side (Studies in Logic and the Foundations of Mathematics, Volume 152), Amsterdam: Elsevier.
Van der Hoeven, G. & Moerdijk, I., 1984a, “Sheaf Models for Choice Sequences”, Annals of Pure and Applied Logic, 27 (1): 63–107.
–––, 1984b, “On Choice Sequences determined by Spreads”, Journal of Symbolic Logic, 49 (3): 908–916.
–––, 1984c, “Constructing Choice Sequences for Lawless Sequences of Neighbourhood Functions”, Models and Sets (Lecture Notes in Mathematics, Volume 1103), Berlin: Springer, 207–234.
Wood, R.J., 2004, “ Ordered Sets via Adjunctions”, Categorical Foundations, M. C. Pedicchio & W. Tholen, eds., Cambridge: Cambridge University Press.
Yanofski, N., 2003, “A Universal Approach to Self-Referential Paradoxes, Incompleteness and Fixed Points”, The Bulletin of Symbolic Logic, 9 (3): 362–386.
Academic Tools
Other Internet Resources
Caramello, O., 2011, “A Topos-Theoretic Approach to Stone-Type Dualities,” at arXiv.org.
Web page of McGill's “Centre de recherches en théorie des catégories”
The category theory mailing list (with many links and useful information)
The n-category Cafe, A blog on higher-dimensional categories, physics and philosophyImpartiality
Impartiality is sometimes treated by philosophers as if it were equivalent to moral impartiality. Or, at the very least, the former word is often used, without the qualifying adjective ‘moral’, even when it is the particularly moral concept that is intended. This is misleading, since impartiality in its broadest sense is best understood as a formal notion, while moral impartiality in particular is a substantive concept — and one concerning which there is considerable dispute. This entry will be predominantly concerned with moral impartiality — the sort of impartiality, that is, that commonly features in normative moral and political theories. However, we will begin by addressing the broader, formal concept, and we will end with a brief discussion of issues raised by epistemic, rather than moral, impartiality.
It is all too easy to assume that the word impartiality must denote a positive, unitary concept — presumably a concept closely linked with, if not identical to, morality. This, however, is simply not the case. Rather, there are various sorts of behavior that may be described as ‘impartial,’ and some of these obviously have little or nothing to do with morality. A person who chooses an accountant on the basis of her friends' recommendations may be entirely impartial between the various candidates (members of the pool of local accountants) with respect to their gender, their age, or where they went to school. Yet if her choice is motivated solely by rational self-interested considerations then it is clear that the impartiality she manifests is in no way a form of moral impartiality. To take a more extreme case, consider an insane serial killer who chooses his victims on the basis of their resemblance to that some celebrity. The killer may be impartial with respect to his victims' occupations, religious beliefs, and so forth, but it would be absurd to regard this as a form of moral impartiality (despite the fact that, in certain contexts, morality does require impartiality with respect to such considerations.)
It is also worth noting that some types of impartiality may in themselves be immoral or morally questionable. Suppose that I decide to pass along a treasured family heirloom to one of my two sons, Bill and Phil. Flipping a coin would constitute one type of impartial procedure for choosing between the two. But suppose that I have already promised the heirloom to Phil, on several occasions. In this case it would be quite wrong to allow a coin toss to determine whether he gets it. Deciding by means of a coin toss would be an impartial procedure, but it would be the wrong sort of impartiality here, for it would ignore the moral obligation created by my previous promises.
The word ‘impartiality’, then, picks out a broad concept that need not have anything to do with morality. (Indeed the final species of impartiality discussed below, epistemic impartiality, is not essentially a moral concept at all.) In this broad sense, impartiality is probably best characterized in a negative rather than positive manner: an impartial choice is simply one in which a certain sort of consideration (i.e. some property of the individuals being chosen between) has no influence. An analysis along these lines has been proposed by Bernard Gert. Gert's analysis holds that “A is impartial in respect R with regard to group G if and only if A's actions in respect R are not influenced at all by which member(s) of G benefit or are harmed by these actions” (Gert 1995, p.104). Thus, for Gert, impartiality is a property of a set of decisions made by a particular agent, directed toward a particular group.
Gert's analysis captures the important fact that one cannot simply ask of a given agent whether or not she is impartial. Rather, we must also specify with regard to whom she is impartial, and in what respect. Gert's analysis, then, permits and indeed requires that we make fairly fine-grained distinctions between various sorts of impartiality. This is necessary, since one and the same agent might manifest various sorts of partiality and impartiality towards various groups of persons. Consider, for instance, a university professor who is also a mother of five children, and who is currently acting as a member of a hiring committee. Such an agent might be impartial between her children with respect to the care they receive (while preferring her own children over others in this respect), and also impartial between the various job candidates; but it is clear that these two uses of the word ‘impartial’ denote very different practices. In particular, the idea of merit applies in one case but not the other: to be impartial between job candidates is presumably to select between them on the basis of merit, whereas to be impartial between one's children is not to think of merit at all, but rather to provide equal protection and care to all.
Many attempts to characterize impartiality fail to respect the distinction between the broadest, most formalistic sense of the notion, and a more specifically moral impartiality. To say, for instance, that an impartial choice is one that is free of bias or prejudice is to presuppose that we are dealing with a certain sort of impartiality, that which is required or recommended by morality, or at least worthy of moral approbation. ‘Bias’ and ‘prejudice’ are loaded terms, suggesting not only that some consideration is being excluded, but also that the exclusion is appropriate and warranted. Similarly, the idea that impartiality requires that we give equal and/or adequate consideration to the interests of all concerned parties goes well beyond the requirements of the merely formal notion. (In the coin toss case, it is quite clear that Phil's claims to the heirloom are not being given equal or adequate consideration.) As a characterization of moral impartiality, however, this suggestion is considerably more promising.
It is characteristic of modern moral thought to see impartiality as a requirement of, if not a fundamental component of, morality. However, the precise nature of this connection remains disputed. As Brad Hooker has pointed out, there are at least three levels at which assessments of moral impartiality may be made. First, one may ask whether moral rules are being impartially applied. Second, impartial benevolence may be used as a direct guide to practical decisions. And third, the content of first-order moral rules may be assessed from an impartial standpoint. (Hooker 2010).
We will begin with the second interpretation: the idea that to act morally is to act from the standpoint of impartial benevolence. This idea has exerted considerable influence, and many writers have simply assumed that to assert the importance of impartiality in the context of morality just is to accept the idea of acting from such a perspective. It is generally agreed that some sort of close connection obtains between morality and impartiality. Indeed, the phrases ‘moral point of view’ and ‘impartial (or ‘impersonal’) point of view’ are sometimes used interchangeably to refer to the imagined impersonal perspective from which, it is supposed, moral judgments are to be made (Baier 1958, chapter 8; Harsanyi 1982; Scheffler 1982, 1985; Smith 1976 [1759]; Wolf 1992; see also Blum 1980, Chapter 3). As noted above, however, the word ‘impartial’ is a general term with many particular species; it follows from this that the phrase ‘impartial point of view’ is itself ambiguous. At most, it might be that the moral point of view constitutes one sort of impartial point of view.
It is not clear, however, that the demands of impartial benevolence are sufficient to exhaust those of morality. Treating a person appropriately and respectfully may well require certain sorts of emotional and/or cognitive responses: sensitivity to her needs and values, empathy for her suffering, and the like. But if these responses are pictured as the results of positive traits or attributes (and not simply as, say, the result of a lack of bias or prejudice), then it is not clear that merely being impartial between persons is sufficient to guarantee that one will possess and display the necessary sensitivities. Indeed, characterizations of impartial agents which proceed in negative terms (that is, by defining various preferences, emotions or bits of information that she does not possess or that do not move her) often risk picturing the impartial agent as impersonal and even indifferent (Henberg 1978; Brandt 1954).
A second problem for the claim that the moral point of view is identical with (some version of) the impartial point of view — or indeed, for any view which identifies morality and impartiality in the direct sense — is that it seems plausible to regard some forms of moral partiality as morally admirable, and perhaps even morally required (Blum 1980; Cottingham 1983, 1986, 1996; Jeske & Fumerton 1997; Jollimore 2001; Kapur 1991; Kekes 1981; MacIntyre 1984; Oldenquist 1982). Loyalty to one's family, community or country, for instance, is commonly regarded as a virtue. Yet such an attitude is a clear and indeed paradigmatic example of partiality, requiring that an agent feel and act differently toward one set of persons than she does toward humanity in general. Similarly, certain specific moral duties arising from certain particular relationships seem to involve partiality in an irreducible manner. Parents, for example, are thought to be morally obliged to take special care of their own children; to regard one's child as merely one among millions would be regarded as highly eccentric if not monstrous. Of course, some moral duties do require that an agent be impartial in performing them. But on common sense moral views at least, impartiality seems mostly to be required in the context of specific roles — such as when a person is acting as a judge, an umpire, a journalist, or a representative of some public institution; or, perhaps, when we are evaluating and selecting first-order moral rules. (Baron 1991; Blum 1980; Cottingham 1983). The idea that impartiality is a pervasive and universal moral requirement that should be directly manifested in our thoughts and practices during daily life seems to contradict our ordinary moral intuitions.
Whether there exists such a thing as morally admirable partiality is the main issue that separates the so-called partialists from the impartialists. Partialists, in general, tend to claim that morally admirable partiality does exist, that it cannot be reduced to any form of impartiality at a more fundamental level, and that these facts pose a serious problem for those who claim that morality and (some form of) impartiality are identical, or even closely related. Impartialists, by contrast, either deny the existence of morally admirable partiality altogether, or hold that any apparent cases are in fact ultimately reducible to impartial standards (see section 6). Thus impartialists hold that — contrary, perhaps, to appearances — impartiality is, indeed, a pervasive and universal requirement of morality.
Rather than being put in terms of an impartial point of view, the relation between morality and impartiality is sometimes made out in terms of an impartial agent or observer — a person who makes moral judgments without being influenced by the sort of contaminating biases or prejudices that tend to arise from the occupation of some particular point of view. (Smith 1976 [1759]; Hume 1978 [1740]; Firth 1952; Brandt 1954; Hare 1989.) (We should note that this idea is not always clearly distinguished from the conception based on the impartial point of view; Smith 1976 [1759], for instance, seems to advance them both at once, in claiming that the ideal observer simply is the observer who occupies the impartial point of view.)
The observer may also be defined as ‘ideal’ in various other ways. It is generally stipulated that she is in possession of all the nonmoral facts that are relevant to the judgments she has to make (Firth 1952). It is also fairly common to assume that she is an ideal reasoner, and thus immune to logical fallacy or mistaken inference, etc. (Indeed, Hare goes so far as to state that his ‘archangel’ possesses “superhuman powers of thought, superhuman knowledge and no human weaknesses” (Hare 1989, p. 44).) The ‘ideal observer theory’ of morality, in its most straightforward form, states that moral judgments simply are the judgments an ideal observer of this sort will make.
What must be pointed out about such a conception of morality, for our purposes, is that any advantage it has over the conception of morality as an impartial point of view presumably arises from the fact that the ideal observer is not completely defined in terms of impartiality. (If she were, the two conceptions would simply coincide.) Yet many ideal observer theorists seem to accept a characterization of the ideal observer which concentrates on her impartiality and impersonality. Firth, for example, suggests that the ideal observer is both ‘distinterested,’ in the strong sense of being ‘entirely lacking in particular interests,’ and ‘dispassionate,’ in that she is ‘incapable of experiencing any emotions at all.’ (Firth, 1952) Defined in this way, however, the ideal observer sounds not only impersonal but deeply indifferent; and the idea that the moral judgments of a person who had neither emotional responses nor particular interests could be trusted, let alone that they might be considered definitive of morality, strikes some critics as highly implausible (Brandt 1979).
Suppose, then, that the ideal observer theorist decides that the definition of the ideal observer must include more than the bare idea of impartiality — that in addition the observer must be, say, compassionate (and thus not indifferent); and that she must possess a considerable facility for proper moral judgments — practical wisdom, in the Aristotelian sense. Such a theorist will now face a different problem: the more we build into the definition of our ideal observer, the less useful it becomes as a heuristic device. Stipulating that the ideal observer is very wise, for example, is not very helpful if we ourselves are not wise, and so have no idea what an ideally wise observer would choose. Indeed, ideal observer analyses that go too far in this direction seem to become circular — the ‘ideal’ observer is ideal because she always makes proper judgments, those being defined as just those judgments the ideal observer would make (Broad 1959, p. 263). A circularity of this sort seems to be present in John Stuart Mill's claim:
Impartiality, in short, as an obligation of justice, may be said to mean, being exclusively influenced by the considerations which it is supposed ought to influence the particular case in hand; and resisting the solicitation of any motives which prompt to conduct different from what those considerations would dictate. (Mill 1861/1992, p. 154; see also Firth 1952, p. 336)
The ideal observer, then, to be useful, must be given some independent definition, and not simply defined as ‘an agent who always gets it right.’ The challenge, of course, is to find such a definition. Here, as with the conception of morality as defined by an impartial point of view, the phenomenon of morally admirable partiality proves a particularly difficult issue. Should we define the ideal observer as being loyal to her country, or as being above loyalty? If the former, can she serve as an adequate moral example to people who do not share her allegiances? If the latter, how can she serve as an adequate example to anyone? The persistent problem that faces the ideal observer approach to moral impartiality seems to be that any process of idealization of the sort required to make such a conception work seems likely to result in an individual so removed from the concrete lives and concerns of actual human moral agents, that her moral judgments will turn out to be in large part irrelevant to the question of how such agents ought to live (see Walker 1991).
The moral importance of the impartial point of view is that from it, every moral agent counts equally: no one, including the person occupying that point of view, is considered to be intrinsically more significant than anyone else, or to have more powerful claims to attention simply by virtue of who they are. Similarly, one of the primary virtues of the ideal observer seems to be that she also regards persons in this way. Whatever these conceptions may get wrong, then, one thing they seem to get right is the idea that there is a close and important connection between moral impartiality and equality (see especially Nagel 1991, Chapter 7).
Some clarification, however, is required. To say that from the impartial point of view, no one is seen as intrinsically more significant than anyone else, is not to say that there is no reason whatsoever for which a person might count as more significant than others, or for which a person might legitimately demand disproportionate moral attention in some circumstances. Many moral theorists, after all, will suppose that from the impartial point of view, properly conceived, some individuals will count as more significant, at least in certain ways. William Godwin (Godwin 1793) provides an influential, and rather infamous, example. Fenelon, the archbishop of Cambrai, Godwin writes, may be supposed to be more significant than a mere chambermaid, and it follows — at least according to Godwin — that in the case of a fire, the archbishop ought to be rescued first. The reason, however, is not simply that the archbishop happens to be himself — that is, his greater significance is not supposed to be intrinsic; rather, the claim is grounded on the fact that the archbishop makes greater contributions to society:
We are not connected with one or two percipient beings, but with a society, a nation, and in some sense with the whole family of mankind. Of consequence that life ought to be preferred which will be most conducive to the general good. In saving the life of Fenelon, suppose at the moment when he was conceiving the project of his immortal Telemachus, I should be promoting the benefit of thousands who have been cured by the perusal of it of some error, vice and consequent unhappiness. Nay, my benefit would extend further than this, for every individual thus cured has become a better member of society and has contributed in his turn to the happiness, the information and improvement of mankind. (Godwin 1793, 41–42)
The claim that the archbishop is more significant, then, is grounded on what are essentially universal properties: if the chambermaid also had it in her to write Telemachus, her claim to be rescued would be just as great. Fenelon's claim to priority is not based on his intrinsic significance. In Godwin's mind, the fact that one individual has a greater claim to rescue than the other is not only not in conflict with impartiality, but indeed is implied by impartiality, for it is based on the (alleged) fact that an impartial judgment of their worth attributes more to one than to the other.
Thus, viewing persons from an impartial point of view need not imply that we view them equally, in every sense of the word; and it certainly does not imply that everyone must receive equal treatment. (In Godwin's Archbishop Fenelon, if we assume that only one person can be saved, the only way to give the archbishop and the chambermaid equal treatment would be to let them both perish in the flames.) What impartiality seems to require is not that everyone receive equal treatment, but rather that everyone be treated as an equal (Dworkin 1977, p. 227). While the distinction between equal treatment and treatment as equals is difficult to make out with precision, the main idea is fairly clear: treatment as equals requires that persons are not treated equally, but rather treated in accordance with what rights they possess, what legitimate claims they put forward, and, in general, with what they deserve. Thus, to inflict a one year jail sentence on all accused persons, regardless of whether they are guilty or innocent, is to provide equal treatment to members of that group; but it is not to treat them as equals.
Whether or not moral impartiality obliges us to see the archbishop as having a greater claim to be rescued is, of course, controversial. Moreover, Godwin asserts two even more controversial claims in connection with the Archbishop Fenelon example. The first is that the chambermaid herself ought to have perceived the greater significance of the archbishop, and so should have sacrificed her own life for his, were that necessary. The second is that any other person — even the child or husband of the chambermaid — ought to have been willing to make the same sacrifice:
Supposing the chambermaid had been my wife, my mother or my benefactor. That would not alter the truth of the proposition. The life of Fenelon would still be more valuable than that of the chambermaid; and justice — pure, unadulterated justice — would still have preferred that which was most valuable. Justice would have taught me to save the life of Fenelon at the expense of the other. What magic is there, in the pronoun ‘my’ to overturn the decisions of everlasting truth? My wife or my mother may be a fool or a prostitute, malicious, lying or dishonest. If they be, what consequence is it that they are mine? (Godwin 1793, pp. 41–42)
Whether this extreme position really is required, either by moral impartiality or by the demand that we treat people as equals, is a matter of great dispute, not only between partialists and impartialists but within the impartialist camp itself. If nothing else, Godwin's position is quite clearly incompatible with the apparent existence of morally admirable partiality. ((Williams 1981) holds that even to consider sacrificing one's wife for the sake of impersonal justice constitutes a kind of moral error in its own right.) Moreover, despite the fact that the ultimate evaluation is made on the grounds of perfectly general properties, it is not entirely clear that the objects of the evaluation really are being treated as equals, in the relevant sense — the fact that the chambermaid's life is to be sacrificed for the overall good at least suggests that her standing as a moral being is not really being taken into account, and that the suggested understanding of moral impartiality is therefore deficient.
Indeed, John Taurek (1977) has famously argued that the various goods of individual persons cannot be added up to a total ‘overall’ good in any meaningful sense, and that the traditional consequentialist conception of right action as maximizing the overall good is incoherent; indeed, Taurek claims, such decision-making actually fail to show equal respect for all persons concerned. (Taurek's denial that one can aggregate various individual goods can be regarded as a strong version of the Rawlsian claim that morality must respect a ‘distinction between persons.’) Suppose a lifeguard must choose between saving one drowning person or saving five; whomever she chooses not to save will drown, and she cannot save both groups. Most consequentialists (and many others) would take it as obvious that, at least in the absence of very special circumstances (the solitary drowner's being the potential author of Telemachus, for instance) the five should be saved rather than the one. But to assume this, Taurek argues, would be to fail to show the one the same respect one shows the five: after all, this response leaves the single victim no chance at all of being rescued. Taurek's controversial suggestion is that the lifeguard would show equal respect by flipping a coin, as this would every person involved an equal chance (fifty percent) of being rescued. Not surprisingly, Taurek's (in)famous argument has engendered a substantial amount of discussion and criticism (see for instance Kamm 1993 Chapters 5 & 6, Kavka 1979, Otsuka 2000, Parfit 1978.)
Consequentialist moral theories hold that moral evaluations and justifications must ultimately be grounded in the value of the consequences of the actions, rules, policies, strategies, character traits, etc. that are being evaluated (Hooker 1994). That is, the ultimate question to be asked of any action, rule, or character trait under evaluation is, “Does it [the action, rule, or trait in question] promote the good?” For the purposes of this entry, three important assumptions will be made regarding consequentialist theories. First, consequentialist theories will be assumed to hold that the overall values of sets of consequences can be determined, and thus ranked, independently of the identity of any particular agent (thus, we can speak of the ‘best’ consequences without having to ask, ‘best relative to whom?’) Second, such theories will be assumed to hold that the impersonal good (i.e. the overall value of some particular state of affairs) is largely if not entirely composed of the interests of individual persons, and that the interests of each person count for just as much as those of every other person. Finally, it will be assumed that we are dealing with act consequentialist theories — theories, that is, which hold that the consequentialist standard is to be applied directly to the actions of agents, and that what is required is that every action (or overall pattern of action) maximize the impersonal good. Such a theory, then, requires that every agent always choose an action that will bring about consequences at least as good as those that would be brought about by any other available action.
We should in so characterizing consequentialism I am defining it as operating on the second level identified by Brad Hooker in (Hooker, 2010): the level, that is, of direct action. One might instead adhere to a theory according to which first-order moral rules should be chosen in accordance with their tendency to promote the overall good, impartially conceived. Such theories typically go by the name ‘rule consequentialism’, though there has been some debate as to whether they constitute genuinely consequentialist theories at all (Howard-Snyder 1993). For the purposes of understanding impartiality, at any rate, it is most useful to group rule consequentialist theories not with act consequentialist theories but with deontological theories, which are more similar in terms of their underlying normative structure.
As we are understanding it, then, consequentialism seems to place each agent under a pervasive obligation to be strictly impartial between all persons, by requiring her always to exclude from her practical deliberations (almost) all considerations that do not bear directly on the ways in which people's interests might be advanced or injured by her actions.
The consequentialist standard, then, is strictly impartial in a very direct manner and in a very rigorous sense. A consequentialist agent is not permitted to prefer herself, nor any of her loved ones, in choosing a distribution of benefits and burdens. She may not accept a pleasure for herself if doing so involves passing up the opportunity to bring about a slightly larger pleasure for a stranger. Nor is she permitted to feed her own children if she could do more good by feeding hungrier strangers instead. She must sacrifice the life of a spouse, parent or child if, by doing so, she would save more lives, or even save the life of one other person whose contribution to the overall good would be greater than that of the person sacrificed. (Recall Godwin's Archbishop Fenelon case, discussed in section 2.3.) It is for reasons such as this that consequentialist impartiality is accused of being too demanding. By refusing to allow the agent's personal concerns to play a special role in her practical deliberations, it is claimed, consequentialism threatens her integrity and alienates her from herself and others (Kapur 1991, Scheffler 1982, Stocker 1976, Williams 1973, 1981). As Brian Barry has written, the effect of consequentialist impartiality “is, in effect, to extend to the whole of conduct the requirements of impartiality that on the common-sense view are restricted to judges and bureaucrats acting in their official capacities.” (Barry 1995, p. 23) The kind of impartiality that features in consequentialist theories, then, seems to be much more pervasive, and much more severe, than that recommended by common sense morality.
The fact that consequentialist impartiality turns out to have such strict and demanding implications is, for the consequentialist, a double-edged sword. On the one hand, there is no doubt that consequentialism is a deeply impartial moral theory; on the plausible and popular assumption that a moral theory must be deeply impartial, consequentialism meets this criterion with flying colors. And consequentialists have typically been adept at exploiting this fact with powerful rhetoric (Godwin's famous query, ‘what magic is there in the pronoun ‘my’?’ being a noteworthy example.) On the other hand, the impartial demands of consequentialism are so strict and so extreme that some critics have found them unacceptable: consequentialism, they claim, simply demands too much and must therefore be rejected (Scheffler 1982, Slote 1985, Williams 1981).
Essentially, this worry is a version of what we referred to above as the problem of morally admirable partiality. The common-sense view is that it is permissible for an agent to be partial toward herself; that is, to treat her own projects and concerns as if they had special significance (Scheffler 1982). (From her point of view of course, they do have special significance.) This sort of self-concern, then, constitutes a form of partiality which seems, from the vantage point of common sense, to be morally endorsed. Similarly, certain sorts of partiality directed toward other people — friends, family members, and the like — are also forbidden by consequentialist impartiality, but regarded as justifiable, and in many cases admirable, from the standpoint of common sense (Blum 1980, Cottingham 1983, Kekes 1981, Slote 1985).
Defenders of consequentialism generally respond in one of three ways. First, a consequentialist might argue that any genuinely impartial moral theory will make extreme demands of agents. Second, they might argue that the view that consequentialism is excessively demanding depends on a false theory of practical reasoning, which accords too much significance to morality. Third, they might argue that in fact, the demands of consequentialism are not as extreme as have been supposed.
The first strategy faces a severe difficulty: namely, it at least seems to be the case that certain non-consequentialist moral theories — in particular, deontological theories — also incorporate impartial elements in a fundamental manner, and yet make demands on the moral agent which are considerably less extreme than those of consequentialism. Thus, while some consequentialists (e.g. Brink 1989) have argued that the truth of consequentialism can be logically derived more or less directly from the requirement that morality be impartial, this seems to be a mistake (Scheffler 1992, pp. 105–109). Of course, it is open to the consequentialist either to deny that deontological moral theories are genuinely impartial (Kagan 1989; Scheffler 1982, 1985), or to argue that, properly understood, any plausible ethical theory will be seen to make demands comparable to those made by consequentialism (Brink 1989, Ashford 2000). Both of these strategies, however, face difficulties; as we will see in section 4, there is in fact a very strong case in favor of viewing at least some deontological theories as genuinely and fundamentally impartial — a case which nevertheless does not prohibit us from viewing such theories as less demanding than their consequentialist rivals.
The second strategy is to argue that those who object to consequentialism on the grounds that it is too demanding are placing too much importance on the role of morality in practical reasoning (Brink 1989; Wolf 1982, 1992). If moral considerations dominated practical reasoning — if, that is, they were the only or at any rate by far the most significant considerations in determining our actions — then consequentialism would be untenable, on account of its demanding too much. A proper perspective on practical reasoning, however, reveals that moral demands constitute only one set of demands among many. When put in their proper place then in the larger scheme of practical reasons and requirements, the extreme demands of consequentialist morality will no longer seem threatening. To borrow a pair of phrases from David Brink, what appear to be ‘moral worries’ about the tendency of consequentialism to make excessive moral demands, might really be ‘worries about morality’ — worries, that is, about whether or not we have reason to act as morality requires. Whether the view of morality presupposed by this strategy is true, however, is questionable; at the very least, it does not seem to be the case that the majority of those who have defended consequentialism as a normative theory of ethics have intended it to be viewed as a theory that could be frequently or easily overridden (Jollimore 2001, Chapter 3; see also Peter Railton (1984), Richard Miller (1992, Chapter 10).
The third strategy is perhaps the best known and most frequently employed. It is argued that, given a reasonable and accurate view of human nature and the abilities of agents, it will be seen that what consequentialism requires is not a radically different sort of life from the one most of us currently live; rather, consequentialism will require (in most cases, at least) only reasonable, and relatively minor, adjustments in our current lifestyles. In particular, it is argued that consequentialism permits the agent both to give preference to her own projects and concerns, and to favor particular other individuals (friends, family members, etc.), and that all this is consistent with the agent's having as her overriding project the maximizing of the good. The locus classicus of this argument is found in Mill's Utilitarianism:
The objectors to utilitarianism cannot always be charged with representing it in a discreditable light. On the contrary, those among them who entertain anything like a just idea of its disinterested character, sometimes find fault with its standard as being too high for humanity. They say it is exacting too much to require that people shall always act from the inducement of promoting the general interests of society. But this is to mistake the very meaning of a standard of morals, and to confound the rule of action with the motive of it […] The great majority of good actions are intended, not for the benefit of the world, but for that of individuals, of which the good of the world is made up; and the thoughts of the most virtuous man need not on these occasions travel beyond the particular persons concerned, except so far as is necessary to assure himself that in benefiting them he is not violating the rights — that is, the legitimate and authorized expectations — of any one else. The multiplication of happiness is, according to the utilitarian ethics, the object of virtue: the occasions on which any person (except one in a thousand) has it in his power to do this on an extended scale, in other words, to be a public benefactor, are but exceptional; and on these occasions alone is he called on to consider public utility; in every other case, private utility, the interest or happiness of some few persons, is all he has to attend to. (Mill 1992 [1861], pp. 64–66.)
Similarly, Godwin (1968 [1801]) argues that
True wisdom will recommend to us individual attachments […] since it is the object of virtue to produce happiness; and since the man who lives in the midst of domestic relations will have many opportunities of conferring pleasure, minute in the detail, yet not trivial in the amount. (Quoted in Cannold, et al., 1995)
(This position, it will be noted, appears to be in some amount of tension with the more extreme consequentialist position attributed to Godwin in section 2.3).
More recent versions of this argument follow Mill's basic strategy. Peter Railton (1984) argues that a ‘sophisticated’ consequentialist will develop patterns of decision-making that do not, except on rare occasions, refer explicitly to consequentialist aims and goals, and that both the psychology and the outward behavior of such an individual will be similar to that of the typical non-consequentialist. Similarly, Frank Jackson (1991) argues that the most efficient strategy for a dedicated consequentialist is to concentrate on small groups of particular persons, rather than trying to promote the well being of humanity at large, and that this will involve the formation of close personal relationships with other individuals. Others who have deployed versions of this argument include Bales (1971), Brink (1989), and Pettit & Brennan (1986).
The evaluation of this consequentialist strategy is a difficult issue. Consequentialists are surely correct to point out that obsessive consequentialist strategizing is likely, at a certain point, to turn counter-productive, and that a consequentialist agent is therefore well-advised to develop more moderate approaches. On the other hand, Mill and many other consequentialists seem to underestimate the amount of good that a dedicated consequentialist agent might be able to contribute, and thus, to underestimate the amount of good that she will be required to contribute. Moreover, our powers to influence the lives of strangers have increased considerably since Mill's day. As Susan Wolf writes, “[T]his argument is simply unconvincing in light of the empirical circumstances of our world. The gain in happiness that would accrue to oneself and one's neighbors by a more well-rounded, richer life than that of the moral saint would be pathetically small in comparison to the amount by which one could increase the general happiness if one devoted oneself explicitly to the care of the sick, the downtrodden, the starving, and the homeless” (Wolf 1982, p. 428; see also Singer 1972). Moreover, while a theory such as Railton's sophisticated consequentialism can acknowledge that a sophisticated consequentialist agent might sometimes knowingly bring about less than maximally good consequences, such a theory must nonetheless continue to insist that each particular act of doing so is indeed morally wrong — an insistence which seems contrary to our moral intuitions (Jollimore 2001). It is not clear, then, that an appeal to the limits of human powers can succeed in converting what is, after all, a fundamentally radical moral theory, into a comfortably conservative one.
In addition to claiming that consequentialist impartiality is too demanding, many critics have also argued that it is too permissive. Since consequentialism makes the permissibility of an action entirely dependent on the value of that action's consequences, it follows that there is no type of action that can be prohibited on consequentialist grounds (except, of course, for that ‘type’ which is defined explicitly in terms of sub-optimal consequences.) Thus instances of torture, premeditated murder, rape, and other violations of fundamental human rights are at least potentially justifiable on a consequentialist basis; no such action can be ruled out, morally speaking, until the comparative value of the state of affairs it will bring about has been determined.
The effect of this complaint, like the previous one, is not to deny the claim that consequentialism is a deeply impartial moral theory, but rather to suggest that it incorporates the wrong sort of impartiality. Suppose, to take an example common in the literature, that consequentialism recommends that an man be convicted of, and punished for, a crime he did not commit, in order to prevent the public from rioting (McCloskey 1963). Such an action would, according to common intuitions, constitute a gross violation of justice; and it seems a weak reply to point out that the recommendation was arrived at through an impartial calculation — a calculation that took the interests of every individual (including the framed man) into equal account. For while the claim is, strictly speaking, true, there is nevertheless a clear and compelling case in favor of concluding that the framed man was not treated impartially, in the sense that ought to matter here. We expect a judicial system to allocate punishments in accordance with degree of guilt, not in accordance with the expected value to society of the consequences in each case; and the fact that both methods constitute forms of impartial decision-making does not imply that they are equally morally acceptable.
Again, the classic response to this objection dates back to Mill's Utilitarianism (1992 [1861]). If institutions of justice are to be given a general justification, Mill argues, this justification must find its ultimate grounding in utility to society; for what else could explain why justice is valued at all, other than the fact that it serves and protects our interests? But since a justice system will only succeed in this role if it is governed by common principles of justice — principles including, for instance, that only the guilty should be punished, and that the punishment ought to be proportional to the crime — it follows that such principles are not opposed to consequentialism at all. Rather, at the deepest justificatory level, consequentialism and the demands of justice coincide.
The claim that such a coincidence generally obtains is probably easy to establish. The challenge for Mill, and for other consequentialists, arises in those particular cases in which the coincidence fails. Assuming that the possibility of such cases does not move one to simply abandon consequentialism in favor of some more justice-friendly conception (such as the rule consequentialism Mill himself sometimes seems to find attractive), there are two general defense strategies for consequentialists to employ. The first strategy argues that there are good consequentialist reasons for being the sort of agent who respects the dictates of justice even in cases in which the coincidence between the demands of justice and those of consequentialism fails (Pettit 1997; cf. Railton 1986). The second strategy admits that there are cases in which unjust actions can be given a consequentialist justification, but holds that when so much as it stake, justice must give way to consequentialism's demands (Smart 1973; Kagan 1989; Pettit 1997). Whether either approach is sufficient, given the apparent depth and force of our common intuitions about the requirements of justice, is a matter of ongoing debate.
In section 3.2 we noted that while consequentialist impartiality is one possible interpretation of the demand that morality be impartial, it is not by any means the only available interpretation; nor is it clearly the most plausible. The considerations related to justice discussed in section 3.3 may help us to appreciate this. For consider once more the position of the framed innocent, whose fundamental interests have been sacrificed for the sake of the greater good. Such a person may well complain that he has not been treated impartially, in the appropriate sense; for, while it is true that his interests were counted in determining the nature of the overall good, it is nevertheless also true that ultimately, he became the victim of a form of abuse that was both harsh and undeserved. The framed innocent might also back up his complaint by making the plausible claim that, had he been in a position to choose, he would never have consented to a moral system that allowed anyone to be accorded such treatment. Thus, while there is a sense in which his interests were counted equally, there is another and very important sense in which his interests — and perhaps more importantly, his claims and rights — do not seem to have received full or adequate consideration at all.
Deontologists insist that consequentialism errs by failing to accord proper significance to the moral agent as an individual; in John Rawls' words, consequentialism “does not take seriously the distinction between persons” (Rawls 1971, section 5). (Rawls has utilitarianism in particular as his target, but the point applies more widely.) Similarly, Samuel Scheffler has suggested that “for human beings as creatures with values, the normative force of certain forms of partiality is nearly unavoidable. If that is right, then for morality to reject partiality in a general or systematic way would be for it to set itself against our nature as valuing creatures. And that, I believe, would make morality an incoherent enterprise” (Scheffler 2010). (It should be noted that Scheffler's ultimate conclusion, that “morality itself actually incorporates reasons of partiality” in the sense that “such reasons bear directly on the rightness or wrongness of actions” would rule out not only straightforwardly act consequentialist theories but many though not all types of deontological theory as well.)
Thus, the fact that consequentialist impartiality makes extraordinary and, to many, unreasonable demands on the individual (section 3.2) might be taken to indicate that consequentialism fails to take individuals seriously as agents. At the same time, the fact that consequentialist impartiality permits the individual to be used as a mere means when doing so promotes the greater good (section 3.3)might indicate that consequentialism fails to take individuals seriously as patients. The conception of impartiality that tends to be favored by deontologists avoids such implications by refusing to view impartial action simply as a matter of maximizing interests (or some other version of the impersonally determined good.) Indeed, deontologists take the right rather than the good to be fundamental to ethics, and tend to see moral action in terms of acting in accordance with principles that are rationally acceptable to all.
Exactly what these principles are, and exactly what method should be used to determine them, are matters of some disagreement among deontological theorists. But there does seem to be a general consensus among deontologists that moral impartiality does not require that an agent be strictly neutral between her own good and the good of other people in ordinary decision-making contexts. Rather, an agent is permitted on deontological views to give special attention to her own projects and interests. An important distinction can be drawn here between first-order and second-order impartiality (Barry 1995; see also Hooker 2010). First-order impartiality is that displayed by an agent in ordinary choice situations — choosing how to spend one's day, who to spend time with, and so forth. Second-order impartiality, by contrast, operates only in a certain, special sort of context: contexts in which the rules, principles and institutions which govern first-order behavior are evaluated and selected. Thus a moral rule granting individuals complete freedom of association, and thus allowing them to display first-order partiality by spending time with whomever they please regardless of whether doing so promotes the greater social good in any particular case, might be given a second-order impartialist justification by demonstrating that such a rule would promote the impersonal good, or that it would be selected by a group of impartial persons who were choosing the moral rules that were to govern society.
The fact that deontological theories generally permit (some degree of) first-order partiality — that is, that agents are permitted to pay special attention to their own interests, projects, and loved ones — should not, then, be taken to imply either that the agent's interests are objectively more valuable than those of other persons, or that the agent is justified in viewing them as such. Rather, the deontologist will claim, it reflects the fact that it is morally legitimate (perhaps, again, because justifiable in second-order impartialist terms) for an agent to regard her own goals and interests as especially important to her. Thus, deontological moral systems tend to incorporate an irreducible element of agent-relativity of a sort that consequentialist theories cannot embody (Nagel 1986; McNaughton & Rawling 1992, 1993, 1998; Jollimore 2001).
The incorporation of agent-relativity of this sort into deontological theories allows such theories to escape the most straightforward versions of the claim that they demand too much of moral agents. Nevertheless, various versions of that objection have been leveled against deontological theories. It has been claimed, for instance, that Kantianism, by insisting that only actions performed out of the motive of duty have moral worth, delegitimizes or even forbids the type of motives which typically (and perhaps necessarily) operate in the context of close personal relationships (Stocker 1976; Williams; 1981). Typically, Kantians have responded by distancing themselves from the view that only actions motivated by duty have value, and acknowledging instead that a commitment to duty need only function as a limiting condition, rather than as the primary source of motivation in all cases (Baron 1995). The Kantian account of moral value, of course, is not essential to deontological theories; and those theories which eschew it may well be able to avoid the demandingness objection altogether.
On many deontological views, particularly Kantian ones, the significance of moral impartiality is seen as arising from the fact that a core role is given to the concept of universalizability (Gert 1998; Hare 1981; Kant 1964 [1785]; Kohlberg 1979). The requirement that moral judgments be universalizable is, roughly, the requirement that such judgments be independent of any particular point of view. Thus, an agent who judges that A ought morally to do X in situation S ought to be willing to endorse the same judgment whether she herself happens to be A, or some other individual involved in the situation (someone who, perhaps, will be directly affected by A's actions), or an entirely neutral observer. Her particular identity is completely irrelevant in the determination of the correctness or appropriateness of the judgment.
Universalizability, thus formulated, does imply at least one sort of impartiality: an agent whose judgments are universalizable will be morally consistent, in the sense that she will judge her own actions by the same standards she applies to others. Such an agent will not make an exception of herself by allowing herself to break a rule she regards as binding for others, or to perform any other action which she would not accept if performed by another agent. Impartiality of this sort, however, does not necessarily imply any sort of impartiality with respect to other individuals' interests, rights, or claims. On a minimally demanding interpretation of the universalizability requirement, the judgments made by a person whose conception of the good was intrinsically racist — that is, a person who held that the well-being of members of some one particular race mattered more (or less), objectively speaking, than the well-being of members of other races — could very well turn out to be universalizable, so long as the racist held that his judgments were objectively correct, and so ought to be assented to by all individuals — including those individuals who would be disadvantaged by the general adoption of those views (cf. Gewirth 1978, p. 164; Gert 1998, Chapter 6; Wiggins 1978; Williams 1985, p. 115).
However, the conclusion that the racist's judgments are universalizable presupposes a very minimal account of what universalizability requires. On this account, it requires only that an agent be sincerely committed to the objectivity of his judgments, in the sense that he views them (from his current perspective) as correct from all perspectives, and thus as calling for everyone's assent (whether or not that assent is actually given.) There are two ways of making the universalizability requirement more demanding. The first is to appeal to certain counterfactual claims about what the agent would endorse if he actually did occupy various perspectives. On this view, a particular judgment by A is universalizable if and only if A endorses that judgment from his current perspective, and would endorse the same judgment from any other perspective. Given this understanding of universalizability, it is much less likely — indeed, extraordinarily unlikely — that racist views will turn out to be universalizable; for it is not generally true of individuals that they would endorse the view “The well-being of members of race R matters less than the well-being of members of other races” if they themselves were members of race R. However, such a view may well require too much, for there are few if any moral judgments or principles that would be endorsed from every perspective any given agent might occupy.
A different approach to universalizability eschews the appeal to psychological facts altogether, and holds that whether or not a particular judgment is universalizable is a logical fact rather than a psychological one. Kant's categorical imperative test, for example, holds that universalizability is the distinguishing feature of correct moral judgments, and that a judgment is universalizable if and only if it can, without contradiction, be willed as a universal practical law (Kant 1964 [1785]). Since the test hinges on whether the willing of a judgment as a universal law results in a contradiction, it follows that whether or not a judgment is universalizable in this way is a matter of practical reason, and does not depend on which particular individual's will happens to be involved.
The types of impartiality implied by both of these more demanding versions of the universalizability requirement are likely to be considerably more substantial than the formal consistency required by the minimal version. Kant, for instance, seems to hold that universalizability implies a certain level of altruism or charity, in the form of the imperfect duties we owe towards other individuals. There are problems, however, with Kant's argument for this. In particular, it is not clear just how the universal willing of a maxim such as “When others are in need of help, I always ignore their needs” give rise to any sort of contradiction. It is true, of course, that, were we actually in a position to choose the universal maxims on which all rational persons would act, this would be a poor choice, for we might someday be in need of assistance from another. But to say that the willing of this maxim as a universal law would be imprudent is not to say that doing so is contradictory. Moreover, as David Wiggins (1978) points out, certain other actions that seem as if they ought to be morally permissible — the act, for instance, of releasing a debtor from his debt out of generosity — have maxims that seem to fail the universalizability test so conceived. These examples may point to a general problem with the attempt to derive impartiality from universalizability: whereas the latter, at least on a Kantian interpretation, is a formal property of moral judgments, moral impartiality, as we have seen, is a substantive rather than a formal concept. (See Herman 1993 and Korsgaard 1996 for attempts to respond to these problems.)
It should be mentioned that some moral theorists have attempted to derive various versions of consequentialist impartiality more or less directly from the universalizability requirement (Hare 1981, Pettit 2000; see also Harsanyi 1982). However, the claim that a conception of impartiality that is not only substantive but also extraordinarily demanding can be derived from a requirement which, as just pointed out, is essentially a formal one, continues to strike a majority of moral philosophers as dubious.
The requirement that moral judgements be universalizable seems to reflect two fundamental moral insights: first, that morality is objective, and not simply a matter of personal opinion or expression of interest and desire; and second, that from the standpoint of morality, each person matters just as much as, and no more than, any other person. The contractualist approach to moral theorizing provides one method of giving expression to these fundamental ideas about morality.
Contractualism borrows from the social contract tradition the idea that morality may be viewed as the result of an agreement between those who are to be bound by its dictates. Two variants of this approach can be distinguished. The former, sometimes referred to as contractarianism, identifies the participants in the bargaining process with actual individuals, and thus is broadly historical. The latter approach, by contrast, appeals to what agents would choose under various, quite possibly unrealizable conditions, and is thus hypothetical rather than historical. It is the latter approach that will concern us here.
The hypothetical contractualist model, then, regards moral principles as the result of a bargaining process among a group of agents, subject to certain restrictions that are specified so as to guarantee that the chosen principles will meet the demands of second-order impartiality. The most famous example of this approach is John Rawls' ‘veil of ignorance’, as described in (Rawls 1971). According to Rawls, the principles of a just society are those that would be chosen by self-interested rational agents in the ‘original position’ — a position in which agents possess broad knowledge about human history and the nature of the world they live in, but are denied specific information regarding their own particular identities or prospects in the society in question, the nature of that society, and, crucially, the nature of their own particular conception of the good. Since nobody knows who they will be or what social position they will occupy, there is no opportunity for anyone in an advantaged position to take advantage of that position in order to force a less privileged party to concede to an otherwise unacceptable outcome. It is this fact that allows Rawls to claim that principles chosen under the veil of ignorance are guaranteed to be impartially acceptable to all — and thus, guaranteed not to be unjust.
It should be noted that Rawls does not intend that morality in its entirely be derived from the original position. Rather, the function of the original position is limited to the choice of the most general principles of social justice in a well-ordered society (Rawls 1971, section 2; 2001, section 12). Nevertheless, Rawls' mechanism is intended to draw the broad outlines of what many see as the most important part of morality: its public or political aspect. By viewing political morality as the result of an agreement between contractors limited by the strictures of the veil of ignorance, Rawls intends to develop a political philosophy that reflects his commitment to the idea of liberal neutrality: the idea, that is, that each person has a private right to her own conception of the good, and that particular conceptions of the good therefore ought not to be legislatively instituted, nor legislated against.
An especially difficult task attending a project of this sort is that of determining what shape this political morality will take — that is, determining which principles would be chosen by agents in the original position. On Rawls' account, the contractors settle on principles that guaranteed as much liberty as possible for all and, within the limits set by this guarantee, a roughly egalitarian distribution of goods in which inequalities are allowed only if they are to the benefit of the worst off (Rawls 1971, section 11; 2001, Part II). The claim that such principles would recognize all persons as equals — and thus, their claim to reflect the demands of moral impartiality — is supported by several considerations, of which three are perhaps most significant: first, that all persons are guaranteed equal (and substantial) civil liberties; second, that the resulting allocation of resources is broadly egalitarian, and in particular, ensures, so far as is possible, that the fundamental needs of all persons are met; and third, that since the only inequalities that are permitted are those that would benefit the least advantaged, it can presumably be assumed that the least advantaged would give their assent to the existence of such inequalities (they would not, even if they could, veto the system.)
In Rawls' scheme, the function of the veil of ignorance is necessary to prevent rational self-interested persons from using their knowledge of their own positions to win unfair advantages over others. (Whether such an approach can provide genuine impartiality between competing conceptions of the good is a difficult question that will be further considered in section 5.) An alternative approach abandons both the veil of ignorance and the assumption that the bargaining parties are primarily self-interested. This is the strategy favored by T.M. Scanlon, whose contractors are motivated not by self-interest but by ‘the desire for reasonable agreement’ (Scanlon 1982, p. 115 n. 10; see also Scanlon 1978, 1998; Barry 1995). On the resulting account of moral permissibility, “an act is wrong if its performance under the circumstances would be disallowed by any system of rules for the general regulation of behavior which no one could reasonably reject as a basis for informed, unforced general agreement.” (Scanlon, 1982, p. 110) The requirement of impartiality is captured here by the basic fact that the question is whether everyone who is to live under the selected rules can reasonably accept them. As in Rawls' theory, however, the principles of second-order impartiality accepted at the contract level allow for considerable first-order partiality at the level of agent-choice.
Harsanyi (1977) argues that a version of utilitarianism can be defended on the basis of an ‘equiprobability model,’ according to which an agent ought to choose between social systems “under the assumption that, in either system, he would have the same probability of occupying any one of the available social positions” (Harsanyi 1982, p. 45; cf. Hare 1981). Gert (1998) argues for a list of moral rules which “all impartial rational persons would favor including […] as part of the moral system” (p. 158). Gauthier (1986) defends a contemporary version of contractarianism.
Traditional conceptions of impartiality such as those we have been discussing face a variety of objections. Many of these objections focus on the claim that such conceptions take insufficient account of the nature of the moral agent and of the pragmatics of the situations in which impartial decisions are actually made. Along these lines, some objectors claim that traditional conceptions set the bar too high, demanding superhuman abilities or cognitive efforts from moral agents. Others, meanwhile, concentrate on the fact that the traditional conceptions tend to identify impartiality with an unemotional, dispassionate disposition, or to otherwise characterize it in impersonal or otherwise negative terms — in terms, that is, of what the moral agent lacks, rather than what she possesses. Two other types of objection are particularly troubling for liberal theorists. The first argues that, by restricting impartiality within the bounds of individual societies, liberal theory tends to fall short of the level of impartiality actually demanded by morality. The second objection here questions whether the liberal conception of impartiality can remain genuinely neutral between competing conceptions of the good. We shall examine these objections in turn.
The first charge — that impartiality, as conceived by traditional ethical theories, makes extraordinary and unreasonable cognitive demands on moral agents — must be distinguished from the objection to consequentialist impartiality considered earlier, which claimed that the sacrifices demanded by consequentialist impartiality were unreasonable and excessive. The objection now being considered is not that impartiality asks the agent to give up too much, but rather that the cognitive feats demanded by these moral theories will exceed the capacity of the typical moral agent. Indeed, one popular version of this objection alleges that an agent will require an unreasonable amount of knowledge or cognitive ability simply to be able to identify what the demands of impartiality are (Friedman 1989; Walker 1991). Given the conception of the impartial point of view as a ‘God's eye’ point of view, for example (Baier 1958), it seems questionable whether it is ever reasonable to expect a human moral agent to be able to occupy such a perspective. God, quite obviously, possesses far more knowledge than does any human being; moreover, God's point of view is both objective and impersonal in ways that an individual human's perspective cannot be. (As Margaret Urban Walker points out, it is often said that human beings have to live with their decisions, but it sounds very odd to say that of God (Walker 1991, p. 765).) Similar remarks apply to the conception of the impartial point of view as ‘the point of view of the universe’ (Sidgwick 1907), to Hare's conception of the ideal moral agent as a so-called ‘archangel’ (Hare, 1981), and, Walker claims, to Firth's conception of the ideal impartial observer (Firth, 1952.) Similarly, Marilyn Friedman points out that even if a person did manage to occupy such a point of view for a period of time — supposing such a thing to be possible — there would be no way to confirm that she had successfully done so: standard conceptions of impartiality, she claims, prescribe “methods of normative thinking [which] represent psychological and epistemic feats, the achievement of which we have no independent way to confirm” (Friedman 1991, p. 645).
The second objection finds fault with the traditional tendency to define impartiality in negative or abstract terms — in terms, that is, of which elements must be absent from the psychology of the agent, or which we must pretend are absent in the process of idealization. M.C. Henberg, for instance, claims that most if not all procedural accounts of impartiality confuse it with distinterest or impersonality, and thus, ultimately, with indifference. (It should be noted that many impartialists are quite explicit about the link between morality, impartiality, and the lack of emotion; Baier (1958), for instance, writes that “the moral point of view [is] that of an independent, unbiased, impartial, objective, dispassionate, disinterested observer” (p. 201; see also Firth 1952).) Similarly, Richard Brandt argues that it is a mistake to define moral impartiality with reference to an ideal observer who is defined as (among other things) distinterested; for after all, “it is not clear that a purely disinterested being would support a moral system at all” (Brandt 1979, p. 227). While Brandt's complaint is particularly directed at the ideal observer theory of (Firth 1952), this objection seems to apply much more broadly; it is obvious, for instance, that Rawls's veil of ignorance is designed precisely to prevent the contractors from acting in an interested manner.
The problem is not only that impersonal persons of this sort are likely to suffer from massive indifference, but also that there is alleged to be a conceptual difficulty with the very idea of conceiving impartiality in such terms. An abstract or impersonal evaluator, it is argued, could not possibly make reliable judgments about substantive moral matters (whether or not he was motivated to), since he would be unable to appreciate the particular concerns of the contesting parties. Both of these difficulties — the motivational and the cognitive — are well expressed by Iris Marion Young, who rejects altogether the idea that morality is primarily a matter of impartiality:
The ideal of impartiality is an idealist fiction. It is impossible to adopt an unsituated point of view, and if a point of view is situated, it cannot stand apart from and understand all points of view. It is impossible to reason about substantive moral issues without understanding their substance, which always presupposes some particular social and historical context; and one has no motive for making moral judgments and resolving moral dilemmas unless the outcome matters, unless one has a particular and passionate interest in the outcome […] when class, race, ethnicity, gender, sexuality, and age define different social locations, one subject cannot fully empathize with another in a different social location, adopt her point of view; if that were possible then the social locations would not be different. (Young 1990, pp. 104–5; cf. Benhabib 1987, p. 90)
As noted above, liberal theorists often tend to conceptualize impartiality using the model of a social contract. If society is pictured as the result of a hypothetical agreement between persons, each of whom is equally empowered to revoke the agreement, then it stands to reason that the resulting set of rules must in some sense be acceptable to all, and must embody, in some deep way, the ideal of equal respect. Some have complained, however, that this approach risks leaving those not party to the contract out in the cold. But surely it is plausible to think that a society, in order to be just, must not only treat (and avoid treating) its own citizens in certain ways, but must also respect certain rules regarding its behavior towards members of other societies. As Charles Jones (1999) writes, “Unlike Rawls … I see no reason to restrict our moral focus to the basic structure of any particular nation-state; on the contrary, if one's concern is with the justifiability of the institutions which determine people's life chances, there are compelling grounds for taking a wider view.”
Amartya Sen (2002) draws a distinction between ‘open’ and ‘closed’ impartiality, which “turns on whether or not the exercise of impartial assessment is confined … to a fixed group.” Since the contractors behind the veil of ignorance are aware that they are part of a certain society (and do not see themselves in any sense as representing the world as a whole), the veil of ignorance represents an impartial system only in the closed sense. Therefore, Sen complains that “As a device of structured political analysis, the procedure is not geared to addressing the need to overcome group prejudices.” By contrast, open impartiality, which Sen finds recommended in the works of Adam Smith (see Smith 1759), demands “that the viewpoints of others, whether or not belonging to some group of which one is specifically a member, receive adequate attention.”
There are various responses open to Rawlsian theorists. Rawls himself suggests that we imagine a second veil of ignorance behind which representatives of various societies can meet in order to set fair and impartial ground rules for international relations. Much like justice within states, Rawls writes, “Justice between states is determined by the principles that would be chosen in the original position so interpreted. These principles are political principles, for they govern public policies toward other nations.” (Rawls 1971) Such a position, of course, will not satisfy everyone, and some critics worry that reiterating the veil of ignorance on the international level will simply reiterate its more problematic elements in a wider scale. Nonetheless, it is important to keep in mind that the objection, here, is not to impartiality itself, but to a particular version of it. Indeed, what critics such as Sen and Jones are really claiming, of course, is that the framework Rawls provides is not impartial enough.
If genuine impartiality is an illusion, as Young alleges, then impartialists may be suspected in smuggling in their own substantive moral positions and biases under the guise of neutrality. Rawls' use of the veil of ignorance, for example, has been criticized by Thomas Nagel and others on the basis that, by requiring that agents lack knowledge of their conceptions of the good (a necessary stipulation of the bargainers are to achieve a consensus), the veil of ignorance excludes from the original position information that is morally relevant, and indeed may put some of the bargainers at a disadvantage. “The original position,” Nagel writes, “seems to presuppose not just a neutral theory of the good, but a liberal, individualistic conception according to which the best that can be wished for someone is the unimpeded pursuit of his own path, provided it does not interfere with the rights of others” (Nagel 1973; see also Teitelman 1972; Schwartz 1973; Sandel 1982; Benhabib 1987). Such a conception, it is held, clearly does favor some conceptions of the good over others: in particular, atomic, individualistic conceptions focusing on personal fulfillment (constituted, perhaps, through the acquisition of consumer goods) are privileged over more communal or social ideals that focus on solidarity and mutual interaction between persons (Sandel 1982; cf. O'Neill 1997, Chapter 1).
Feminist critics have paid particular attention to the ways in which liberal conceptions of neutrality and impartiality presuppose and reinforce traditional male-dominated, individualistic approaches to moral theory, and in doing so reinforce the social status quo (Gilligan 1982; Noddings 1984; Benhabib 1987; Young 1990). As Benhabib has pointed out, “Universalistic moral theories in the Western tradition from Hobbes to Rawls are substitutionalist, in the sense that the universalism they defend is defined surreptitiously by identifying the experiences of a specific group of subjects as the paradigmatic case of the human as such. These subjects are invariably white, male adults who are propertied or at least professional.” (Benhabib 1987, p. 81) As a result, the dominant social positions of such parties tend to be protected and even enhanced in the social and political theories resulting from such allegedly neutral liberal theories.
The problem of neutrality is a pressing one for liberals: given the importance to their view of the thought that an impartial government must be neutral between various moral conceptions (it must, that is, respect what Rawls calls ‘the fact of pluralism’), it is essential to show that liberal impartialism does not simply represent another such moral conception (or ‘sectarian view’) in its own right. Liberal impartialism, then, must turn out to be a framework that can be agreed to by all relevant parties, even as they continue to disagree regarding particular substantive moral issues.
How is the liberal to establish this? Nagel (1987) endorses what he calls ‘epistemological restraint,’ which holds that it can be reasonable for an individual to hold certain beliefs yet simultaneously unreasonable to attempt to decide matters of public policy on the basis of such beliefs. Such beliefs, which tend to be moral or religious in nature, are said to be viewed differently from the inside (from which standpoint they have perfect authority) than from the outside (from which standpoint they are regarded as questionable). The difficulty, as Barry (1995) and Raz (1990) have pointed out, is to explain why doubts visible from the outside would not infect the internal point of view, thus weakening these beliefs' internal authority as well. (It should be noted that Nagel himself has expressed doubts about this argument in Nagel 1991.)
Rawls's view appears to be similar to Nagel's (and thus, subject to the same difficulty). According to Rawls, to endorse a view of justice is not to claim that it is true; moreover, the acceptability of liberal impartialism is not to be derived from its truth; rather, such a view will be accepted (it is to be hoped) because, in societies of the relevant sort, it will form a common element (an ‘overlapping consensus’) in the various competing conceptions of the good that occupy the public sphere (Rawls 1993). (Again, the criticisms contained in Raz 1990 are especially trenchant.)
While both Nagel and Rawls explicitly reject the idea that liberal impartialism is to be justified on the basis of skepticism toward various conceptions of the good, Barry (1995) explicitly endorses this form of justification. (Barry emphasizes that the relevant form of skepticism does not involve eschewing one's moral and religious beliefs, but rather rejecting the claim to be certain of the truth of those beliefs.) This approach has been criticized on the basis that such skepticism itself constitutes a sectarian view, and therefore is not neutral (Larmore 1987, Mendus 2002) However, as Barry points out, the decisive issue is not whether some people would reject skepticism, but whether it can reasonably be rejected — and given Barry's definition of skepticism, its claim to resist being so rejected seems considerably stronger than the claims of the various conceptions of the good themselves, which must indeed be excluded from the public sphere.
Although many people continue to speak of a ‘partialist vs. impartialist debate,’ it should by now be clear that neither ‘partialism’ nor ‘impartialism’ unambiguously denote any single moral position; at best, they designate two poles of a continuum, one of which attributes no moral significance to the demands of (any sort of) impartiality, the other of which sees morality as exhausted by (some version of) impartiality. While a somewhat general distinction can be usefully maintained, it is misleading to think of the partialist-impartialist debate as a dispute between two clearly defined, and clearly opposed, camps (Deigh 1991; Barry 1995, pp. 191–5). Maximillian de Gaynesford goes so far as to argue that “debates about partialism and impartialism thrive on tacit assumptions about the way each relates to the first person. These assumptions rest on mistakes and confusions …” (de Gaynesford 2010).
Thus, any general claim beginning with the words ‘partialists (or impartialists) think that…’ is bound to be both misleading and contentious. In particular, there is good reason to be wary of objections to impartialism which claim that all impartialists endorse extreme moral demands, or that they require that practical reasoning be completely expunged of every vestige of the partial. It is true, of course, that at least some impartialists, such as Godwin, have endorsed such claims. But many do not. Deontologists, as we have seen, hold impartiality to be a deep and significant element of morality, but they also tend to allow for a considerable degree of first-order partiality. And even many consequentialists are prepared to admit the legitimacy of partial reasoning in some contexts, if only on an instrumental basis. It is useful, then, to draw a distinction between two sorts of impartialist moral theory. Impartialist theories which require all agents to display first-order impartiality at all times (Godwin's, for example) might be referred to as strict impartialist theories. Impartialist theories which allow for some first-order partiality, but which nevertheless insist that all such behavior be justified in second-order impartialist terms, might be referred to as fundamentally impartialist moral theories. The class of fundamentally impartial theories will include not only contractualist, Kantian, and rule consequentialist theories, but also certain act consequentialist theories (e.g. Railton 1986) which allow the practice of first-order partiality as a means of promoting the impersonal good. Such theories allow for partiality that is permissible, justifiable, and perhaps even admirable in moral terms. At the same time, however, they insist that all such partiality is ultimately reducible — that is, justifiable in impartialist terms at some deeper level.
Within the partialist camp, a strict partialist might be defined as holding that no sort of impartiality plays any moral role whatsoever — a logically possible, but uncommon, position. A moderate partialist, by contrast, would admit that impartiality of some sort plays a moral role, but deny that this role encompasses, or grounds, all of morality; in particular, such a figure would be committed to the existence, in some contexts at least, of irreducible morally admirable partiality. A virtue theorist, for instance, might make a significant place for impartiality by selecting it as one of the virtues; but a virtue of this sort would presumably have to compete with other deeply partialist virtues such as loyalty, which would override impartiality in at least some contexts.
To the extent that a deep issue between partialists and impartialists can be identified, it is presumably the question of whether (irreducible) morally admirable partiality does indeed exist; and it is along this line of dispute that the debate seems likeliest to continue. (Whether this debate is identical to the so-called ‘justice-care’ debate, as contended in Cannold, et al (1995), is questionable, though it is undeniable that there are important parallels.) However, this way of classifying the disputants, and of characterizing the issue itself, is meant to be suggestive rather than definitive. The fact remains that there are many types of partialist theories, and many types of impartialist ones, and that continuing to speak of the ‘partialist-impartialist debate’ in loose and imprecise terms is more likely to obscure than to illuminate.
Commonsense morality agrees with most deontological theories that personal relationships involve various forms of morally admirable partiality. Until now most philosophers who have examined this phenomenon have focused on practical obligations: the ways in which we are obligated to treat our friends and relatives better than we treat people whom we do not know and to whom we are not significantly related. Disagreements regarding the extent and nature of such practical obligations have dominated the partialist-impartialist debate.
Recently, however, a number of philosophers have focused their attention on a second sort of obligation we seem to have to friends and relatives. In addition to treating them differently, commonsense thought seems to hold that we ought to adopt different patterns of belief formation and evaluation with respect to them—patterns of belief formation and evaluation that make it more likely that we will think highly of them and regard them in a positive light. Thus, it has been suggested that friendship and similar relationships involve epistemic partiality: there are forms of epistemic bias which are recommended and possibly required by such relationships. As Simon Keller has written, “when good friends form beliefs about each other, they sometimes respond to considerations that have to do with the needs and interests of their friends, not with aiming at the truth, and that this is part of what makes them good friends” (Keller 2004, p. 333).
Similarly, Sarah Stroud has argued that when it is a friend's behavior that is in question, rather than that of a stranger, “we tend to devote more energy to defeating or minimizing the impact of unfavorable data than we otherwise would. … [A]t the end of the day we are simply less likely to conclude that our friend acted disreputably, or that he is a bad person, than we would in the case of a nonfriend” (Stroud 2006, pp. 505–6).
As both Keller and Stroud point out, these are not simply descriptions of typical friendship behavior; rather, they seem to be generally accepted as requirements of friendship. If so—and if it really is true that epistemic partiality makes us less likely to form true beliefs (but see Jollimore 2011 for a challenge to this claim)—then we seem to face a difficult choice: we must either accept that forming true beliefs is not the only goal with respect to which epistemic standards should be evaluated, or else accept that the requirements of friendship and other forms of love can conflict with the requirements of epistemic rationality: being an ideal epistemic agent, that is, is not always compatible with being an ideal friend.
Archard, David, 1995. “Moral Partiality,” Midwest Studies in Philosophy, XX: 129–141.
Ashford, Elizabeth, 2000. “Utilitarianism, Integrity, and Partiality,” The Journal of Philosophy, XCVII(8): 421–39.
Baier, Kurt, 1958. The Moral Point of View: A Rational Basis of Ethics, Ithaca: Cornell University Press.
Bales, R. Eugene, 1971. “Act-Utilitarianism: Account of Right-Making Characteristics or Decision-Making Procedure?” American Philosophical Quarterly, 8(3): 257–65.
Baron, Marcia, 1991. “Impartiality and Friendship,” Ethics 101: 836–57.
Baron, Marcia, 1995. Kantian Ethics Almost Without Apology, Ithaca: Cornell University Press.
Baron, Marcia, Philip Pettit, and Michael Slote, 1997. Three Methods of Ethics, Oxford: Blackwell.
Barry, Brian, 1989. Theories of Justice, Berkeley: University of California Press.
Barry, Brian, 1995. Justice as Impartiality, Oxford: Oxford University Press.
Benhabib, Seyla, 1987. “The Generalized and the Concrete Other: The Kohlberg-Gilligan Controversy and Feminist Theory,” in Benhabib and Cornell 1987, pp. 77–95.
Benhabib, Seyla, and Drucilla Cornell (eds.), 1987. Feminism as Critique, Cambridge: The Polity Press.
Blum, Lawrence, 1980. Friendship, Altruism, and Morality, London: Routledge and Kegan Paul.
Brandt, Richard, 1954. “The Definition of an ‘Ideal Observer’ in Ethics,” Philosophy and Phenomenological Research, 15: 407–13.
Brandt, Richard, 1979. A Theory of the Good and the Right, Oxford: Oxford University Press.
Brink, David O., 1989. Moral Realism and the Foundations of Ethics, Cambridge: Cambridge University Press.
Brink, David O., 2001. “Impartiality and Associative Duties,” Utilitas, 13: 2.
Broad, C.D., 1959. Five Types of Ethical Theory, Paterson, NJ: Littlefield, Adams & Co.
Cannold, Leslie, Peter Singer, Helga Kuhse, and Lori Gruen, 1995. “What is the Justice-Care Debate Really, About?” Midwest Studies in Philosophy, XX: 357–75.
Cottingham, John, 1983. “Ethics and Impartiality,” Philosophical Studies, 43: 83–99.
Cottingham, John, 1986. “Partiality, Favoritism, and Morality,” Philosophical Quarterly, 36: 357–73.
Cottingham, John, 1996. “Partiality and the Virtues,” in Roger Crisp, ed., How Should One Live? Essays on the Virtues, Oxford: Clarendon Press, 1996.
Cottingham, John, 1996. “Morality, Virtues, and Consequences,” in D. Oderberg and L. Laing, ed., Human Lives, London: Macmillan.
Cottingham, John, 2010. “Impartiality and Ethical Formation,” in Feltham and Cottingham 2010, pp. 65–83.
Darwall, Stephen L, 1983. Impartial Reason, Ithaca: Cornell University Press.
Darwall, Stephen L., 2010. “Responsibility within Relations,” in Feltham and Cottingham 2010, pp. 150–168.
Deigh, John, 1991. “Impartiality: A Closing Note,” Ethics 101: 858–864.
Double, Richard, 1999. “Morality, Impartiality, and What We Can Ask of Persons,” American Philosophical Quarterly, 36(2) (April): 149–158.
Dworkin, Gerald, 1974. “Non-neutral Principles,” Journal of Philosophy, 71(14): 491–506.
Dworkin, Ronald, 1977. Taking Rights Seriously, Cambridge, MA: Harvard University Press.
Estlund, David, 2010. “I Will If You Will: Leveraged Enhancements and Distributive Justice,” in Feltham and Cottingham 2010, pp. 223–241.
Feltham, Brian, and John Cottingham, 2010. Partiality and Impartiality: Morality, Special Relationships, and the Wider World, New York: Oxford University Press.
Firth, Roderick, 1952. “Ethical Absolutism and the Ideal Observer,” Philosophy and Phenomenological Research, 12(3): 317–345.
Flanagan, Owen, and Jonathan Alder, 1983. “Impartiality and Particularity,” Social Research L, 3: 576–596.
Frankfurt, Harry, 1997. “Equality and Respect,” Social Research, 64: 3–15. Reprinted in Necessity, Volition, and Love, Cambridge: Cambridge University Press, 1999, pp. 146–55.
Friedman, Marilyn, 1989.“The Impracticality of Impartiality,” Journal of Philosophy, 86: 645–56.
Gaus, Gerald F., 2010, “The Demands of Impartiality and the Evolution of Morality,” in Feltham and Cottingham 2010, pp. 42–64.
Gauthier, David, 1986. Morals by Agreement, Oxford: Oxford University Press.
de Gaynesford, Maximillian, 2010. “The Bishop, the Valet, the Wife, and the Ass: What Difference Does it Make if Something is Mine?” in Feltham and Cottingham 2010, pp. 84–97.
Gert, Bernard, 1998. Morality: Its Nature and Justification, Oxford: Oxford University Press.
Gert, Bernard, 1995. “Moral Impartiality,” Midwest Studies in Philosophy, XX: 102–127.
Gewirth, Alan, 1978. Reason and Morality, Chicago: University of Chicago Press.
Gilligan, Carol, 1982. In a Different Voice: Psychological Theory and Women's Development, Cambridge, MA: Harvard University Press.
Godwin, William, 1926 [1793]. Enquiry Concerning Political Justice and its Influence on General Virtue and Happiness, ed. Raymond Preston. New York: Alfred A Knopf.
Godwin, William, 1968 [1801]. Thoughts Occasioned by the Perusal of Dr. Parr's Spital Sermon, In Uncollected Writings (1785–1822) by William Godwin, ed. J. Marken and B. Pollin, Gainesville, FL: Scholars' Facsimiles & Reprints.
Hare, R.M., 1981. Moral Thinking, Oxford: Oxford University Press.
Harsanyi, John C., 1977. Rational Behavior and Bargaining Equilibrium in Games and Social Situations, Cambridge: Cambridge University Press.
Harsanyi, John C., 1982. “Morality and the Theory of Rational Behavior,” in Sen and Williams, 1982, pp. 39–62.
Henberg, M.C., 1978. “Impartiality,” Canadian Journal of Philosophy, 8(4): 715–724.
Herman, Barbara, 1993. The Practice of Moral Judgment, Cambridge, MA: Harvard University Press.
Hooker, Brad, 1994. “Is Rule-Consequentialism a Rubber Duck?” Analysis, 54.2: pp. 92–97.
Hooker, Brad, 2010. “When is Impartiality Morally Appropriate?” in Feltham and Cottingham 2010, pp. 26–41.
Howard-Snyder, Frances, 1993. “Rule Consequentialism Is a Rubber Duck,” American Philosophical Quarterly, 30: 271–78.
Hume, David, 1978 [1740]. A Treatise of Human Nature, Second edition, ed. L.A. Selby-Bigge & P.H. Nidditch, Oxford University Press.
Jeske, Diane, and Richard Fumerton, 1997. “Relatives and Relativism,” Philosophical Studies, 87: 143–57.
Jollimore, Troy A., 2000. “Friendship Without Partiality?” Ratio, 13(1): 69–82.
Jollimore, Troy A., 2001. Friendship and Agent-Relative Morality, New York: Garland Publishing.
Jollimore, Troy A., 2011. Love's Vision, Princeton: Princeton University Press.
Jones, Charles, 1999. Global Justice: Defending Cosmopolitanism, Oxford: Oxford University Press.
Kagan, Shelley, 1989. The Limits of Morality, Oxford: Clarendon Press.
Kamm, F.M., 1993. Morality, Mortality, Volume I: Death and Whom to Save From It, Oxford: Oxford University Press.
Kamm, F.M., 1996. Morality, Mortality, Volume II: Rights, Duties, and Status, Oxford: Oxford University Press.
Kant, Immanuel, 1964 [1785]. Groundwork of the Metaphysics of Morals, Translated by H.J. Paton, New York: Harper and Row.
Kapur, Neera Badwhar, 1991. “Why It Is Wrong to be Always Guided by the Best: Consequentialism and Friendship,” Ethics, 101: 483–504.
Kavka, Gregory, 1979. “The Numbers Should Count,” Philosophical Studies, 36: 285–294.
Kekes, John, 1981. “Morality and Impartiality,” American Philosophical Quarterly, 18: 295–303.
Keller, Simon, 2004. “Friendship and Belief,” Philosophical Papers, 33(3): 329–351.
Kohlberg, Lawrence, 1979. “Justice as Reversibility,” in P. Laslett and J. Fishkin, ed., Philosophy, Politics and Society, Series 5, Oxford: Blackwell.
Kolodny, Niko, 2010 (1). “Which Relationships Justify Partiality? General Considerations and Problem Cases,” in Feltham and Cottingham 2010, pp. 169–193.
Kolodny, Niko, 2010 (2). “Which Relationships Justify Partiality? The Case of Parents and Children,” Philosophy & Public Affairs, 38: 37–75.
Korsgaard, Christine, 1996. Creating the Kingdom of Ends, Cambridge: Cambridge University Press.
Larmore, Charles E., 1987. Patterns of Moral Complexity, Cambridge: Cambridge University Press.
Locke, Don, 1981. “The Principle of Equal Interests,” Philosophical Review, 90: 531–59.
MacIntyre, Alasdair, 1984. “Is Patriotism a Virtue?” University of Kansas: The Lindley Lecture Series.
MacIntyre, Alasdair, 1988. Whose Justice? Which Rationality?, Notre Dame, IN: University of Notre Dame Press.
McCloskey, H.J., 1963. “A Note on Utilitarian Punishment,” Mind, 72(288): 599.
McNaughton, David, and Piers Rawling, 1992. “Honoring and Promoting Values,” Ethics, 102: 835–43.
McNaughton, David, and Piers Rawling, 1993. “Deontology and Agency,” The Monist, 76: 81–100.
McNaughton, David, and Piers Rawling, 1998. “On Defending Deontology,” Ratio, 11(1): 37–54.
Mendus, Susan, 2002. Impartiality in Moral and Political Philosophy, Oxford: Oxford University Press.
Mill, J.S., 1992 [1861]. Utilitarianism, In On Liberty and Utilitarianism, Knopf: Everyman's Library, Volume 81.
Miller, Richard W., 1992. Moral Differences, Princeton: Princeton University Press.
Monro, D.H., 1950. “Archbishop Fenelon versus My Mother,” Australasian Journal of Philosophy, 28(3): 154–173.
Nagel, Thomas, 1973. “Rawls on Justice,” Philosophical Review, 82(2): 220–234. Reprinted in Norman Daniels, ed., Reading Rawls, Oxford: Blackwell, 1975.
Nagel, Thomas, 1986. The View from Nowhere, New York: Oxford University Press.
Nagel, Thomas, 1987. “Moral Conflict and Political Legitimacy,” Philosophy and Public Affairs, 16(3): 215–240.
Nagel, Thomas, 1991. Equality and Partiality, New York: Oxford University Press.
Nielsen, Kai, 1994. “Justice as a Kind of Impartiality,” Laval Theologique et Philosophique, 50(3) (October): 511–529.
Noddings, Nel, 1984. Caring: A Feminine Approach to Ethics and Moral Education, Berkeley: University of California Press.
Oldenquist, Andrew, 1982. “Loyalties,” Journal of Philosophy, 79(4): 173–193.
Okin, Susan Moller, 1989a. Justice, Gender and the Family, New York: Basic Books.
Okin, Susan Moller, 1989b. “Reason and Feeling in Thinking About Justice,” Ethics, 99: 229–49.
O'Neill, Shane, 1997. Impartiality in Context, Albany: State University of New York Press.
Otsuka, Michael. 2000. “Scanlon and the Claims of the Many Versus the One,” Analysis, 60(3): 288–93.
Parfit, Derek. 1978. “Innumerate Ethics,” Philosophy and Public Affairs, 7(4): 285–301.
Pettit, Philip, 1997. “The Consequentialist Perspective,” in Baron, Pettit, and Slote (1997), pp. 92–174.
Pettit, Philip, 2000. “Non-consequentialism and Universalizability,” The Philosophical Quarterly, 50(199): 175–90.
Pettit, Philip, and Geoffrey Brennan, 1986. “Restrictive Consequentialism,” Australasian Journal of Philosophy, 64(4): 438–55.
Piper, Adrian, 1990. “Higher-Order Discrimination,” in Flanagan and Rorty, ed., Identity, Character and Morality: Essays in Moral Psychology, Cambridge, MA: The MIT Press, 1990.
Piper, Adrian, 1991. “Impartiality, Compassion, and Modal Imagination,” Ethics, 101 (1991).
Powers, Madison, 1993. “Contractualist Impartiality and Personal Commitments,” American Philosophical Quarterly, 30(1): 63–71.
Railton, Peter, 1984. “Alienation, Consequentialism, and the Demands of Morality,” Philosophy and Public Affairs, 13: 134–71.
Rawls, John, 1971. A Theory of Justice, Cambridge, MA: Harvard University Press.
Rawls, John, 1993. Political Liberalism, New York: Columbia University Press.
Rawls, John, 1999. The Law of Peoples, Cambridge, MA: Harvard University Press.
Rawls, John, 2001. Justice as Fairness: A Restatement, Cambridge, MA: Belknap/ Harvard University Press.
Raz, Joseph, 1990. “Facing Diversity: The Case of Epistemic Abstinence,” Philosophy and Public Affairs, 19(1): 3–46.
Ridge, Michael, 2010. “Fairness and Non-Compliance,” in Feltham and Cottingham 2010, pp. 194–222.
Sandel, Michael, 1982. Liberalism and the Limits of Justice, Cambridge: Cambridge University Press.
Scanlon, T.M., 1978. “Rights, Goals, and Fairness,” in Stuart Hampshire, ed., Public and Private Morality, Cambridge: Cambridge University Press.
Scanlon, T.M., 1982. “Contractualism and Utilitarianism,” in Sen and Williams, 1982, pp. 103–128.
Scanlon, T.M., 1998. What We Owe to Each Other, Cambridge, MA: Belknap/Harvard University Press.
Scheffler, Samuel, 1982. The Rejection of Consequentialism, Oxford: Oxford University Press.
Scheffler, Samuel, 1985. “Agent-Centred Restrictions, Rationality, and the Virtues,” Mind, 94: 409–19.
Scheffler, Samuel, 1986. “Morality's Demands and Their Limits,” The Journal of Philosophy, 83: 531–37.
Scheffler, Samuel, 1992. Human Morality, Oxford: Oxford University Press.
Scheffler, Samuel, 2010. “Morality and Reasonable Partiality,” in Feltham and Cottingham 2010, pp. 98–130.
Schwartz, Adina, 1973. “Moral Neutrality and Primary Goods,” Ethics, 83: 294–307.
Sen, Amartya, and Bernard Williams (eds.), 1982. Utilitarianism and Beyond, Cambridge: Cambridge University Press.
Sen, Amartya. 2002. “Open and Closed Impartiality,” The Journal of Philosophy, XCIX(9) (September): 445–469.
Sidgwick, Henry, 1907. The Methods of Ethics, Seventh Edition. London: Macmillan.
Singer, Peter, 1972. “Famine, Affluence, and Morality,” Philosophy and Public Affairs, 1: 229–43.
Singer, Peter, Leslie Cannold, and Helga Kuhse, 1995. “William Godwin and the Defense of Impartialist Ethics,” Utilitas, 7 (1): 67–86.
Slote, Michael, 1985. Common Sense Morality and Consequentialism, Boston: Routledge and Kegan Paul.
Smart, J.J.C., 1973. “An Outline of a System of Utilitarian Ethics,” in Smart and Williams 1973, pp. 1–74.
Smart, J.J.C., and Bernard Williams. 1973. Utilitarianism: For and Against, Cambridge: Cambridge University Press.
Smith, Adam, 1976 [1759]. Theory of the Moral Sentiments, Oxford: Oxford University Press.
Stocker, Michael, 1976. “The Schizophrenia of Modern Ethical Theories,” The Journal of Philosophy, 73: 453–66.
Stroud, Sarah, 2006. “Epistemic Partiality in Friendship,” Ethics, 116(3): 498–524.
Stroud, Sarah, 2010. “Permissible Projects, Partiality, and Plural Agency,” in Feltham and Cottingham 2010, pp. 131–149.
Taurek, John, 1977. “Should the Numbers Count?” Philosophy and Public Affairs, 6: 293–316.
Teitelman, Michael, 1972. “The Limits of Individualism,” Journal of Philosophy, 69: 545–56.
Walker, Margaret Urban, 1991. “Partial Consideration,” Ethics, 101: 758–74.
Wiggins, David, 1978. “Universalizability, Impartiality, Truth,” in Needs Values, Truth, Oxford: Oxford University Press.
Williams, Bernard, 1973. “A Critique of Utilitarianism,” in Smart and Williams 1973, pp. 75–150.
Williams, Bernard, 1985. Ethics and the Limits of Philosophy, Cambridge, MA: Harvard University Press.
Wissenburg, Marcel, 1999. Imperfection and Impartiality: A Liberal Theory of Social Justice, London: Taylor and Francis.
Wolf, Susan, 1982. “Moral Saints,” Journal of Philosophy, 89: 419–39.
Wolf, Susan, 1992. “Morality and Partiality,” Philosophical Perspectives, 6: 243–259.
Young, Iris Marion, 1987. “Impartiality and the Civic Public: Some Implications of Feminist Critiques of Moral and Political Theory,” in Benhabib and Cornell, 1987, pp. 56–76.
Young, Iris Marion, 1990. Justice and the Politics of Difference, Princeton: Princeton University Press.
Open access to the SEP is made possible by a world-wide funding initiative.
Please Read How You Can Help Keep the Encyclopedia Free
The SEP would like to congratulate the National Endowment for the Humanities on its 50th anniversary and express our indebtedness for the five generous grants it awarded our project from 1997 to 2007. Readers who have benefited from the SEP are encouraged to examine the NEH’s anniversary page and, if inspired to do so, send a testimonial to neh50@neh.gov.Through conscience and its related notion, synderesis, human beings discern what is right and wrong. While there are many medieval views about the nature of conscience, most views regard human beings as capable of knowing in general what ought to be done and applying this knowledge through conscience to particular decisions about action. The ability to act on the determinations of conscience is, moreover, tied to the development of the moral virtues, which in turn refines the functions of conscience.
1. Background
2. Bonaventure
3. Aquinas
4. Scotus and Ockham
Bibliography
Academic Tools
Other Internet Resources
Related Entries
1. Background
There are significant discussions of conscience among the Stoics if not before. (Using a broad definition of conscience as a form of moral self-awareness, Richard Sorabji claims that the notion of conscience can be found in the Fifth Century BCE playwrights as well as in the writings of Plato and Aristotle. See chapters one and two of his Moral Conscience Throughout the Ages.) Seneca the Younger discusses conscience in his Epistulae Morales (43, 97, 105) and attributes several qualities to it. St. Paul discusses conscience in various letters (I Corinthians; Romans; Hebrews; Timothy). Whatever the influence of Seneca and St. Paul might be on subsequent discussions of conscience and synderesis, late medieval discussions of conscience derive from Peter Lombard's presentation of the concepts of conscience and synderesis in his Sentences. Lombard cites a passage from St. Jerome, interpreting Ezekiel's vision of four living creatures coming out of a cloud. Each creature was shaped like a man, but each had four faces: the front face was human; the right was that of a lion; the left was that of an ox; and the back was that of an eagle (Ezekiel 1.4–14). Jerome identifies the human face as representing the rational part of man, the lion as the emotional, the ox as the appetitive, and the eagle as that “which the Greeks call synteresis: that spark of conscience which was not even extinguished in the breast of Cain after he was turned out of paradise, and by which we discern that we sin, when we are overcome by pleasures or frenzy and meanwhile are misled by an imitation of reason.” Jerome's comment that synteresis (alternatively, synderesis) is never extinguished in human beings and his remarks elsewhere to the effect that wicked people do cease to have any conscience led Lombard and subsequent thinkers to distinguish synderesis from conscience. While it is unclear that Jerome meant to distinguish the two, the distinction plays a major role in late medieval discussions of conscience.
In these discussions, constant reference was made to certain works by Plato and Aristotle. Neither Plato nor Aristotle explicitly mention conscience, however. It is their discussions of the virtues, practical wisdom, and weakness of will that form the critical backdrop to medieval discussions of conscience. These discussions were heavily influenced by Augustine's modification of these classical authors. For example, Augustine championed Plato's notion of the unity of the virtues, but he argued that love of God provided the unity to them. Moreover, he claimed that what pagan authors regarded as virtues were in fact vices unless they were developed for the love of God.
Two distinct views about the relationship between conscience and synderesis emerged in the late Middle Ages. The first view, a voluntaristic one, can be identified with Franciscan thinkers like Bonaventure. The second, most clearly expounded by Aquinas, is an intellectualistic view. Both seem to derive from Philip the Chancellor's treatise on conscience. In his treatise, Philip chiefly discusses synderesis, and at times he describes it as an unerring intellectual dispositional potentiality that provides general truths to conscience for specific application. At other times, he describes synderesis as the desire for the good, and it is equated with emotional reactions when one follows evil instead of good. This latter description fits well with Bonaventure's views on synderesis and conscience.
2. Bonaventure
Bonaventure discusses both in his Commentary on the Sentences, Book II, distinction 39. He places conscience squarely within the rational faculty, specifying that it is part of practical reason since it is connected to the performance of actions. It is thus also connected to the will as well as the emotions. On the other hand, he places synderesis in the affective part of human beings, for he regards synderesis as that which stimulates us to the good.
Conscience is divided into two general parts by Bonaventure. The first part seems to be a power for discovering the truth of very general practical principles like “obey God,” “honor your parents,” and “do not harm your neighbors.” This part of conscience is innate and unerring; it cannot be lost to any person, no matter how morally corrupt that person may become. The second part of conscience involves the application of the very general principles to situations that may be either general or particular. This second part is also innate, but it can be mistaken since the very general principles of the first part may be misapplied through ignorance or faulty reasoning. The misapplication explains, to a certain extent, how conscience, oriented to good, can be involved in the performance of evil actions. The distinction between the two parts of conscience also opens up the possibility for developing, through experience, practical principles of behavior not directly entailed by the content of the synderesis. By generalizing on activities performed in accordance with the principles of the synderesis, one can formulate new general principles not contained in the synderesis that can guide behavior in a number of contexts. Conscience thus appears to be a dynamic faculty for Bonaventure.
Bonaventure calls synderesis the “spark of conscience,” and he sees it as resting in the affective part of human beings. It is the spark because, as the general drive to do good, synderesis provides the movement that conscience needs to operate. In general, Bonaventure regards conscience and synderesis as interpenetrating one another. The formation of ethical rules by conscience is seen by him as an implementation of a human being's desire for good (the synderesis). He also sees the following of these principles as another aspect of the desire for good. Because we naturally have a desire for the good, we also desire the means to that goal. The principles of conscience are such means, and so we are naturally disposed to carry out the principles of conscience. Similarly, the emotional reaction to doing evil (guilt or remorse) is a reaction to the frustration of the desire for good caused when one fails to adhere to what the conscience has determined will lead to good. Bonaventure, while placing synderesis and conscience in different parts of a human being, does not isolate them. On the contrary, he views conscience as driven by synderesis and at the same time directing synderesis.
3. Aquinas
Thomas Aquinas, the principal advocate of the intellectualistic view of the relationship of conscience and synderesis, explicitly defines ‘conscience’ as the “application of knowledge to activity” (Summa Theologiae, I-II, I) The knowledge he has in mind here comes from the synderesis, which he regards as the natural disposition of the human mind by which we apprehend without inquiry the basic principles of behavior. For Aquinas, then, the conscience applies the first principles of the synderesis to particular situations. The principles of synderesis are rather general in form. Examples are “Do good and avoid evil” and “Obey God.” To be helpful in human activity, conscience requires principles that contain much more content. One can call these “secondary principles” and Aquinas discusses them in several places and suggests that they are derived from experience and instruction through the virtue of prudence. Thus, the function of conscience for Aquinas is to apply the general principles of synderesis and the more content-laden secondary principles developed from prudence to particular circumstances. Prudence is involved in the application to particular circumstances, according to Aquinas, because it is connected to the correct perception of individual circumstances. And this aspect of prudence connects both conscience and prudence to the problem of weakness of will.
In Aquinas's presentation of Aristotle's discussion of weakness of will in his Commentary on the Nicomachean Ethics, the fourth position offered in Book 7, Chapter 3 of the Nicomachean Ethics is emphasized. According to this position, the incontinent man knows the appropriate general principles of behavior concerning what should be done, e.g., one should not fornicate. If the incontinent man sees a particular action as falling under this general principle, e.g., a man sees that having intercourse with an unmarried woman is a case of fornication, he will not perform the action. However, the incontinent man also holds the general rule that pleasures should be enjoyed. If the incontinent man, driven by his particular desire for a particular unmarried woman, sees the proposed sexual liaison as a case of pleasure, he subsumes it under the general rule about pursuing pleasure and pursues the relationship. The desire he has, as it were, blinds him to the general principle about fornication he still possesses, but only habitually. The actual knowledge he possesses is that the proposed liaison is a case of pleasure to be pursued. He thus has (habitually) the knowledge that he should avoid fornication, but he fornicates nonetheless because he actually sees the fornication as an act of pleasure to be pursued. As a general comment on Aristotle's analysis, Aquinas remarks: “It is not the knowledge of the universal but only the evaluation of the sensible, which is not so excellent, that is dragged about by passion.” (Commentary on the Nicomachean Ethics, Book 7, lecture 3, paragraph 1352) The point Aquinas is making is that the incontinent man possesses the knowledge of what he should do, but he is driven by the passion he has for a particular; this passion leads him to act contrary to what the knows (habitually) should not be done. The incontinent man so fails because he has failed to cultivate the appropriate virtues that would enable him to size up the situation correctly (synesis) and deliberate well about it (eubulia). This analysis of weakness of will falls in line with Aquinas's general view of the will as a passive potency that always follows the judgments of the intellect. While this view of the will is modified by such disciples of Aquinas as Giles of Rome, perhaps under the impetus of the Condemnations of 1277, Aquinas's linking of conscience with prudence and the virtues in general through his concern with weakness of will is innovative and undoubtedly connected with his interest in the Nicomachean Ethics. Duns Scotus and William of Ockham follow his lead in linking conscience with issues surrounding development of the virtues.
4. Scotus and Ockham
Scotus offers very little explicit discussion of either conscience or synderesis. Yet, from his discussion of issues chiefly concerned with development of the virtues, it is apparent that his view of conscience and synderesis seems to draw from both Bonaventure and Aquinas. Following Aquinas, Scotus thinks that both synderesis and conscience are to be placed in the intellectual order. In agreement with Bonaventure, Scotus gives conscience much more of a dynamic role in the human personality than a mechanical application of general principles. Scotus's close linking of conscience and the development of the virtues allows him to combine the two sources.
According to the virtue tradition, in order to perform a virtuous action, one must have the right dictates associated with the relevant virtue. Yet, one must perform appropriate virtuous actions to develop the habit of the virtue and to know the relevant right dictates. The obvious circularity seems vicious enough to undermine any attempt to cultivate virtues. Scotus regards conscience as offering a way into the circle. Whenever a person formulates what is to be done in some circumstance, this is an exercise of conscience, which has determined proper action from the principles of synderesis. On the basis of the dictates of conscience, a person can perform an action that will provide the basis for the development of the relevant virtues. For the performance of these acts from conscience leads to the type of habit that Scotus thinks of as a virtue. Ideally, the moral virtues are unified since a perfect, virtuous person should possess all virtues. In fact, Scotus's perfect, virtuous person seems very similar to Aristotle's man of practical wisdom. This is the person who has, through long experience, developed the moral virtues and is able to deliberate so well about all moral situations that in Aristotle's view to be moral is to do what a man of practical wisdom would do. Scotus's perfect, virtuous person, like the man of practical wisdom, is skilled at determining what should be done in given circumstances; he takes delight in acting in accord with his virtues, and he possesses all of the moral virtues by developing them through experience.
Ockham's discussion of conscience, prudence, and the virtues indicates that he follows Scotus's turn towards discussing conscience in relation to the virtues. He agrees with Scotus that conscience can provide the entry into the seeming circularity of performing virtuous actions in order to develop intentions that seem to be required for performing the virtuous actions in the first place. Nevertheless, he criticizes Scotus for failing to make a number of necessary distinctions about degrees of virtues and the relationship of conscience to prudence. He never mentions synderesis in his writings and emphasizes the fact that only internal acts have moral worth. According to him, external acts are morally significant only by extrinsic denomination from internal acts. Particularly in these last two claims, Ockham exercised considerable influence on Reformation thinkers like Luther and Calvin in their discussions of conscience. In fact, the topics of conscience and synderesis were discussed in German universities with great attention both before and after the Reformation. Some of the thinkers involved in these discussions (Usingen and Peyligk) adhered in various ways to the views of Bonaventure, Aquinas, Scotus, and Ockham while others (Bernhardi and Melanchthon) blended and transformed the various views found among these thinkers. Many of these discussions related conscience to issues about practical reasoning. Interestingly, discussions of conscience and synderesis appeared in works on natural philosophy. After Luther, the linking of conscience with practical knowledge found in the writings of Aquinas, Scotus, and Ockham gives way, under the influence of Joseph Butler and Immanuel Kant, to conceiving of conscience as a faculty.
Bibliography
Baylor, Michael G., 1977, Action and Person: Conscience in Late Scholasticism and the Young Luther, Studies in Medieval and Reformation Thought, Volume XX, Leiden: E. J. Brill.
D'Arcy, Eric, 1961, Conscience and Its Right to Freedom, New York and London: Sheed and Ward.
Davies, Brian, 1992, The Thought of Thomas Aquinas, Oxford: Clarendon Press.
Dolan, Joseph V., 1971, “Conscience in the Catholic Theological Tradition,” in William C. Bier (ed.), Conscience: Its Freedom and Limitations, New York: Fordham University Press.
Eardley, P. S., 2003, “Thomas Aquinas and Giles of Rome on the Will,” Review of Metaphysics, 56 (4): 835–862.
Forschner, Maximilian, 2004, “Stoische Oikeiosislehre und mittelalterliche Theorie des Gewissens,” in J. Szaif and M. Lutz-Bachmann (eds.), Was ist das fur den Menschen Gute?/What Is Good for a Human Being?, Berlin and New York: Walter de Gruyter.
Holopainen, Taina M., 1991, William Ockham's Theory of the Foundations of Ethics, Helsinki: Luther-Agricola-Society.
Iozzio, Mary Jo, 2006, “Odon Lottin, OSB (1880–1965) and the renewal of Agent-Centered Moral Thought,” Modern Schoolman, 84 (1): 1–16.
Karkkainen, Pekka, 2012, “Synderesis in Late Medieval Philosophy and the Wittenberg Reforms,” British Journal for the History of Philosophy, 20 (5): 881–901.
Kent, Bonnie, 1989, “Transitory Vice: Thomas Aquinas on Incontinence,” The Journal of the History of Philosophy, 27 (2): 199–223.
Kent, Bonnie, 1995, Virtues of the Will. The Transformation of Ethics in the Late Thirteenth Century, Washington, D.C.: Catholic University of America Press.
Kreis, Douglas, 2002, “Origen, Plato, and Conscience (Synderesis) in Jerome's Ezekiel Commentary.” Traditio, 57: 67–83.
Langston, Douglas C., 2001, Conscience and Other Virtues. From Bonaventure to MacIntyre, University Park: Pennsylvania State University Press.
–––, 1993, “The Spark of Conscience: Bonaventure's View of Conscience and Synderesis,”Franciscan Studies, 53: 79–95.
–––, 2008, “The Aristotelian Background to Scotus's Rejection of the Necessary Connection of Prudence and the Moral Virtues,” Franciscan Studies, 66: 317–336.
Lottin, O., 1957 [1948], Psychologie et morale aux XIIe et XIIIe siecles, Volumes I (second edition) and II, Gembloux: J. Duculot.
Nelson, Dan, 1988, The Priority of Prudence, College Park: Penn State Press.
Potts Timothy C., 1980, Conscience in Medieval Philosophy, Cambridge: Cambridge University Press.
–––, 1982, “Conscience,” in N. Kretzmann, A. Kenny, and J. Pinborg (eds.),. The Cambridge History of Later Medieval Philosophy, Cambridge: Cambridge University Press.
Saarinen, Risto, 1994, Weakness of the Will in Medieval Thought From Augustine to Buridan, Leiden: E. J. Brill.
Sorabji, Richard, 2014, Moral Conscience Throughout The Ages: Fifth Century BCE to the Present, Chicago: University of Chicago Press.
Zachman, Randall C., 1993, The Assurance of Faith. Conscience in the Theology of Martin Luther and John Calvin, Minneapolis: Augusburg Fortress Press.
Academic ToolsStudy of the social dimensions of scientific knowledge encompasses the effects of scientific research on human life and social relations, the effects of social relations and values on scientific research, and the social aspects of inquiry itself. Several factors have combined to make these questions salient to contemporary philosophy of science. These factors include the emergence of social movements, like environmentalism and feminism, critical of mainstream science; concerns about the social effects of science-based technologies; epistemological questions made salient by big science; new trends in the history of science, especially the move away from internalist historiography; anti-normative approaches in the sociology of science; turns in philosophy to naturalism and pragmatism. This entry reviews the historical background to current research in this area and features of contemporary science that invite philosophical attention. The philosophical work can roughly be classified into two camps. One acknowledges that scientific inquiry is in fact carried out in social settings and asks whether and how standard epistemology must be supplemented to address this feature. The other treats sociality as a fundamental aspect of knowledge and asks how standard epistemology must be modified from this broadly social perspective. Concerns in the supplementing approach include such matters as trust and answerability raised by multiple authorship, the division of cognitive labor, the reliability of peer review, the challenges of privately funded science, as well as concerns arising from the role of scientific research in society. The reformist approach highlights the challenge to normative philosophy from social, cultural, and feminist studies of science while seeking to develop philosophical models of the social character of scientific knowledge, and treats the questions of the division of cognitive labor, expertise and authority, the interactions of science and society, etc., from the perspective of philosophical models of the irreducibly social character of scientific knowledge.
1. Historical Background
2. Big Science, Trust, and Authority
3. Science in Society
4. Social, Cultural, and Feminist Studies of Science
5. Models of the Social Character of Knowledge
6. Social Direction of Science
7. Conclusion
Academic Tools
Other Internet Resources
Related Entries
1. Historical Background
Philosophers who study the social character of scientific knowledge can trace their lineage at least as far as John Stuart Mill. Mill, Charles Sanders Peirce, and Karl Popper all took some type of critical interaction among persons as central to the validation of knowledge claims.
Mill's arguments occur in his well-known political essay On Liberty, (Mill 1859) rather than in the context of his logical and methodological writings, but he makes it clear that they are to apply to any kind of knowledge or truth claim. Mill argues from the fallibility of human knowers to the necessity of unobstructed opportunity for and practice of the critical discussion of ideas. Only such critical discussion can assure us of the justifiability of the (true) beliefs we do have and can help us avoid falsity or the partiality of belief or opinion framed in the context of just one point of view. Critical interaction maintains the freshness of our reasons and is instrumental in the improvement of both the content and the reasons of our beliefs. The achievement of knowledge, then, is a social or collective, not an individual, matter.
Peirce's contribution to the social epistemology of science is commonly taken to be his consensual theory of truth: “The opinion which is fated to be ultimately agreed to by all who investigate is what we mean by truth, and the object represented is the real.” (Peirce 1878, 133) While often read as meaning that the truth is whatever the community of inquirers converges on in the long run, the notion is interpretable as meaning more precisely either that truth (and “the real”) depends on the agreement of the community of inquirers or that it is an effect of the real that it will in the end produce agreement among inquirers. Whatever the correct reading of this particular statement, Peirce elsewhere makes it clear that, in his view, truth is both attainable and beyond the reach of any individual. “We individually cannot hope to attain the ultimate philosophy which we pursue; we can only seek it for the community of philosophers.” (Peirce 1868, 40). Peirce puts great stock in instigating doubt and critical interaction as means to knowledge. Thus, whether his theory of truth is consensualist or realist, his view of the practices by which we attain it grants a central place to dialogue and social interaction.
Popper is often treated as a precursor of social epistemology because of his emphasis on the importance of criticism in the development of scientific knowledge. Two concepts of criticism are found in his works (Popper 1963, 1972) and these can be described as logical and practical senses of falsification. The logical sense of falsification is just the structure of a modus tollens argument, in which a hypothesis is falsified by the demonstration that one of its logical consequences is false. This is one notion of criticism, but it is a matter of formal relations between statements. The practical sense of falsification refers to the efforts of scientists to demonstrate the inadequacies of one another's theories by demonstrating observational shortcomings or conceptual inconsistencies. This is a social activity. For Popper the methodology of science is falsificationist in both its logical and practical senses, and science progresses through the demonstration by falsification of the untenability of theories and hypotheses. Popper's logical falsificationism is part of an effort to demarcate genuine science from pseudo science, and has lost its plausibility as a description of scientific methodology as the demarcation project has come under challenge from naturalist and historicist approaches in philosophy of science. While criticism does play an important role in some current approaches in social epistemology, Popper's own views are more closely approximated by evolutionary epistemology, especially that version that treats cognitive progress as the effect of selection against incorrect theories and hypotheses. In contrast to Mill's views, for Popper the function of criticism is to eliminate false theories rather than to improve them.
The work of Mill, Peirce, and Popper is a resource for philosophers presently exploring the social dimensions of scientific knowledge. However, the current debates are framed in the context of developments in both philosophy of science and in history and social studies of science following the collapse of the logical empiricist consensus. The philosophers of the Vienna Circle are conventionally associated with an uncritical form of positivism and with the logical empiricism that replaced American pragmatism in the 1940s and 1950s. According to some recent scholars, however, they saw natural science as a potent force for progressive social change. (Cartwright, Cat, and Chang 1996; Giere and Richardson, eds., 1996; Uebel 2005) With its grounding in observation and public forms of verification, science for them constituted a superior alternative to what they saw as metaphysical obscurantism, an obscurantism that led not only to bad thinking but to bad politics. While one development of this point of view leads to scientism, the view that any meaningful question can be answered by the methods of science; another development leads to inquiry into what social conditions promote the growth of scientific knowledge. Logical empiricism, the version of Vienna Circle philosophy that developed in the United States, focused on logical, internal aspects of scientific knowledge and discouraged philosophical inquiry into the social dimensions of science. These came into prominence again after the publication of Thomas Kuhn's Structure of Scientific Revolutions (Kuhn 1962). A new generation of sociologists of science, among them Barry Barnes, Steven Shapin, and Harry Collins, took Kuhn's emphasis on the role of non-evidential community factors in scientific change even further than he had and argued that scientific judgment was determined by social factors, such as professional interests and political ideologies (Barnes 1977, Shapin 1982, Collins 1983). This family of positions provoked a counter-response among philosophers. These responses are marked by an effort to acknowledge some social dimensions to scientific knowledge while at the same time maintaining its epistemological legitimacy, which they take to be undermined by the new sociology. At the same time, features of the organization of scientific inquiry compel philosophers to consider their implications for the normative analysis of scientific practices.
2. Big Science, Trust, and Authority
The second half of the twentieth century saw the emergence of what has come to be known as Big Science: the organization of large numbers of scientists bringing different bodies of expertise to a common research project. The original model was the Manhattan Project, undertaken during the Second World War to develop an atomic weapon in the United States. Theoretical and experimental physicists located at various sites across the country, though principally at Los Alamos, New Mexico, worked on sub-problems of the project under the overall direction of J. Robert Oppenheimer. While academic and military research have since been to some degree separated, much experimental research in physics, especially high energy particle physics, continues to be pursued by large teams of researchers. Research in other areas of science as well, for example the work comprehended under the umbrella of the Human Genome Project, has taken on some of the properties of Big Science, requiring multiple forms of expertise. In addition to the emergence of Big Science, the transition from small scale university or even amateur science to institutionalized research with major economic impacts supported by national funding bodies and connected across international borders has seemed to call for new ethical and epistemological thinking. Moreover, the consequent dependence of research on central funding bodies and increasingly, private foundations or commercial entities, prompts questions about the degree of independence of contemporary scientific knowledge from its social and economic context.
John Hardwig (1985) articulated one philosophical dilemma posed by large teams of researchers. Each member or subgroup participating in such a project is required because each has a crucial bit of expertise not possessed by any other member or subgroup. This may be knowledge of a part of the instrumentation, the ability to perform a certain kind of calculation, the ability to make a certain kind of measurement or observation. The other members are not in a position to evaluate the results of other members' work, and hence, all must take one anothers' results on trust. The consequence is an experimental result, (for example, the measurement of a property such as the decay rate or spin of a given particle) the evidence for which is not fully understood by any single participant in the experiment. This leads Hardwig to ask two questions, one about the evidential status of testimony, and one about the nature of the knowing subject in these cases. With respect to the latter, Hardwig says that either the group as a whole, but no single member, knows or it is possible to know vicariously. Neither of these is palatable to him. Talking about the group or the community knowing smacks of superorganisms and transcendent entities and Hardwig shrinks from that solution. Vicarious knowledge, knowing without oneself possessing the evidence for the truth of what one knows, requires, according to Hardwig, too much of a departure from our ordinary concepts of knowledge.
The first question is, as Hardwig notes, part of a more general discussion about the epistemic value of testimony. Much of what passes for common knowledge is acquired from others. We depend on experts to tell us what is wrong or right with our appliances, our cars, our bodies. Indeed, much of what we later come to know depends on what we previously learned as children from our parents and teachers. We acquire knowledge of the world through the institutions of education, journalism, and scientific inquiry. Philosophers disagree about the status of beliefs acquired in this way. Here is the question: If A knows that p on the basis of evidence e, B has reason to think A trustworthy and B believes p on the basis of A's testimony that p, does B also know that p? Some philosophers, as Locke and Hume seem to have, argue that only what one has observed oneself could count as a good reason for belief, and that the testimony of another is, therefore, never sufficient warrant for belief. Thus, B does not know simply on the basis of A's testimony. While this result is consistent with traditional philosophical empiricism and rationalism, which emphasized the individual's sense experience or rational apprehension as foundations of knowledge, it does have the consequence that we do not know most of what we think we know.
A number of philosophers have recently offered alternative analyses focusing on one or another element in the problem. Some argue that testimony by a qualified expert is itself evidential, (Schmitt 1988), others that the expert's evidence constitutes good reason for, but is not itself evidential for the recipient of testimony (Hardwig 1985, 1988), others that what is transmitted in testimony is knowledge and not just propositional content and thus the question of the kind of reason a recipient of testimony has is not to the point (Welbourne 1981).
However this dispute is resolved, questions of trust and authority arise in a particularly pointed way in the sciences, and Hardwig's dilemma for the physics experiment is also a specific version of a more general phenomenon. A popular conception of science, fed partly by Popper's falsificationism, is that it is epistemically reliable because the results of experiments and observational studies are checked by independent repetition. In practice, however, only some results are so checked and many are simply accepted on trust. Not only must positive results be accepted on trust, but claims of failure to replicate as well as other critiques must be also. Thus, just as in the non-scientific world information is accepted on trust, so in science, knowledge grows by depending on the testimony of others. What are the implications of accepting this fact for our conceptions of the reliability of scientific knowledge?
David Hull, in his (1988) argues that because the overall structure of reward and punishment in the sciences is a powerful incentive not to cheat, further epistemological analysis of the sciences is unnecessary. The structure itself guarantees the veridicality of research reports. But some celebrated recent episodes, such as the purported production of “cold fusion” were characterized by the failure of replication attempts to produce the same phenomenon. And, while the advocates of cold fusion were convinced that their experiments had produced the phenomenon, there have also been cases of outright fraud. Thus, even if the structure of reward and punishment is an incentive not to cheat, it does not guarantee the veridicality of every research report.
The reward individual scientists seek is credit. That is, they seek recognition, to have their work cited as important and as necessary to further scientific progress. The scientific community seeks true theories or adequate models. Credit, or recognition, accrues to individuals to the extent they are perceived as having contributed to that community goal. There is a strong incentive to cheat, to try to obtain credit without necessarily having done the work.
Both Alvin Goldman (Goldman, 1995, 1999) and Philip Kitcher (1993) have treated the potential for premature, or otherwise (improperly) interested reporting of results to corrupt the sciences as a question to be answered by means of decision theoretic models. The decision theoretic approach to problems of trust and authority treats both credit and truth as utilities. The challenge then is to devise formulas that show that actions designed to maximize credit also maximize truth. Kitcher, in particular, develops formulas intended to show that even in situations peopled by non-epistemically motivated individuals (that is, individuals motivated more by a desire for credit than by a desire for truth), the reward structure of the community can be organized in such a way as to maximize truth and foster scientific progress. One consequence of this approach is to treat scientific fraud and value or interest infused science as the same problem. One advantage is that it incorporates the motivation to cheat into the solution to the problem of cheating. But one may wonder how effective this solution really is. Increasingly, we learn of problematic behavior in science based industries, such as the pharmaceutical industry. Results are withheld or distorted, authorship is manipulated. Hot areas, such as stem cell research or cloning have been subjected to fraudulent research. Thus, even if the structure of reward and punishment is an in principle incentive not to cheat, it does not guarantee the reliability of every research report.
Community issues have been addressed under the banners of research ethics and of peer review. One might think that the only ethical requirements on scientists are to protect their research subjects from harm and, as professional scientists, to seek truth above any other goals. This presupposes that seeking truth is a sufficient guide to scientific decision-making. Heather Douglas, in her critical study of the ideal of value-freedom (Douglas 2009), rejects this notion. Douglas draws on her earlier study of inductive risk (Douglas 2000) to press the point that countless methodological decisions required in the course of carrying out a single piece of research are underdetermined by the factual elements of the situation and must be guided by an assessment of the consequences of being wrong. Science is not value-free, but can be protected from the deleterious effects of values if scientists take steps to mitigate the influence of inappropriate values. One step is to distinguish between direct and indirect roles of values; another is the articulation of guidelines for individual scientists. Values play a direct role when they provide direct motivation to accept or reject a theory; they play an indirect role when they play a role in evaluating the consequences of accepting or rejecting a claim, thus influencing what will count as sufficient evidence to accept or reject. The responsibility of scientists is to make sure that values do not play a direct role in their work and to be transparent about the indirect roles of values. A number of writers have taken issue with the tenability of Douglas’s distinction between direct and indirect. Steel and Whyte (2012) examine testing guidelines developed by pharmaceutical companies to point out that the very same decision may be motivated by values playing a direct role or playing an indirect role. If the point is to prohibit practices such as withholding negative results, then it shouldn’t matter whether the practice is motivated by values functioning directly or indirectly. Elliott (2011) questions whether only harmful consequences should be considered. If science is to be useful to policy makers, then questions of relative social benefit should also be permitted to play a role. Finally the cognitive activities demanded by Douglas’s ethical prescriptions for scientists seem beyond the capacities of individual scientists. This point will be pursued below.
Torsten Wilholt (2013) argues that the research situation is more complicated than the epistemic vs. nonepistemic tradeoff implied by the decision theoretic approach. He argues that the reliance called for in science extends beyond the veridicality of reported results to the values guiding the investigators relied upon. Most research involves both results expressed statistically (which requires choice of significance threshold and balancing chances of Type I vs. Type II error) and multiple steps each requiring methodological decisions. These decisions, Wilholt argues, represent trade-offs among the reliability of positive results, the reliability of negative results, and the power of the investigation. In making these tradeoffs, the investigator is per force guided by an evaluation of the consequences of the various possible outcomes of the study. Wilholt references arguments about inductive risk offered originally by Richard Rudner and elaborated by Heather Douglas and discussed below. He extends those to propose that, in relying on another’s results I am relying not only on his or her competence and truthfulness, but on her or his making methodological decisions informed by the same valuations of outcomes as I have. This attitude is more than epistemic reliance, but a deeper attitude: one of trust that we are guided by the same values in a shared enterprise. For Wilholt, then, scientific inquiry engages ethical norms as well as epistemic norms. Formal or mechanical solutions such as those suggested by the application of decision theoretic models are not sufficient, if the community must be held together by shared ethical values.
Peer review and replication are methods the scientific community, indeed the research world in general, employs to assure consumers of scientific research that the work is credible. Peer review both of research proposals and of research reports submitted for publication screens for quality, which includes methodological competence and appropriateness as well as for originality and significance, while replication is intended to probe the robustness of results when reported experiments are carried out in different laboratories and with slight changes to experimental conditions. Scholars of peer review have noted various forms of bias entering into the peer review process. In a review of the literature, Lee, Sugimoto, Zhang, and Cronin (2013) report documented bias along gender, language, nationality, prestige, and content as well as such problems as lack of inter-reviewer reliability consistency, confirmation bias, and reviewer conservatism. Lee (2012) argues that a Kuhnian perspective on values in science interprets lack of inter-reviewer consistency as variation in interpretation, applicability, and weight assigned to shared values by different members of the scientific community. Lee and colleagues (2013) argue that journal editors must take much more action than is currently taken to require that researchers make their raw data and other relevant trial information available to enable peer reviewers to conduct their work adequately.
One issue that has yet to be addressed by philosophers is the gap between the ideal of replication resulting in confirmation, modification, or retraction and the reality. This ideal lies behind the assumptions of efficacy of structures of reward and sanction. Only if researchers believe that their research reports will be probed by efforts at replication will the threat of sanctions against faulty or fraudulent research be realistic. John Ioannidis and collaborators (Tatsioni, Bonitsis, and Ioannidis 2007; Young, N.S. Ioannidis, and Al-Ubaydli 2008) have shown how infrequently attempts to replicate are actually made and, even more strikingly, how contradicted results persist in the literature. This is an issue that goes beyond individuals and beyond large research collaborators to the scientific community in general. It underscores Wilholt’s contention that the scientific community must be held together by bonds of trust, but much more empirical and philosophical work is needed to address how to proceed when such trust is not justified.
Winsberg, Huebner, and Kukla (2013) draw attention to a different kind of supra-empirical, ethical issue raised by the contemporary situation of multiple authorship. What they call “radically collaborative research” involves investigators with different forms of expertise, as in Hardwig’s example, and as is now common across many fields, collaborating to generate an experimental result. For Winsberg, Huebner, and Kukla, the question is not merely reliability, but accountability. Who can speak for the integrity of the research when it has been conducted by researchers with a variety not just of interests, but of methodological standards, most opaque one to another? Winsberg, Huebner, and Kukla argue that a model of the social collaboration is needed as much as a model of the data or of the instruments. They argue further that the laissez-faire Wisdom of Crowds model (according to which local differences in methodological standards will cancel each other out), while perhaps adequate if the question is one of reliability, is not adequate for addressing these issues of accountability. They do not themselves, however, offer an alternative model.
3. Science in Society
Work on the role of science in society encompasses both general models of the public authority of science and analysis of particular research programs that have a bearing on public life. In their early work, Steve Fuller and Joseph Rouse were both concerned with political dimensions of cognitive authority. Rouse in his (1987) integrated analytic and continental philosophy of science and technology sought to develop what might be called a critical pragmatism. This perspective facilitated an analysis of the transformative impact of science on human life and social relations. Rouse emphasized the increased power over individual lives that developments in science made possible. This can only be said to have increased with the development of information technology. Fuller (1988) partially accepted the empirical sociologists' claim that traditional normative accounts of scientific knowledge fail to get a purchase on actual scientific practices, but took this as a challenge to relocate the normative concerns of philosophers. These should include the distribution and circulation of knowledge claims. The task of social epistemology of science, according to Fuller, should be regulation of the production of knowledge by regulating the rhetorical, technological, and administrative means of its communication. While there has not been much uptake of Fuller's proposals as articulated, Lee's work mentioned above begins to make detailed recommendations that take into account the current structures of funding and communication.
One key area of socially relevant interdisciplinary science is risk assessment, which involves both research on the effects of various substances or practices and the evaluation of those effects once identified. The idea is to gain an understanding of both positive effects and of negative effects and a method of evaluating these. This involves integrating the work of specialists in the kind of substance whose risks are under assessment (geneticists, chemists, physicists), biomedical specialists, epidemiologists, statisticians, and so on. In these cases, we are dealing not only with the problems of trust and authority among specialists from different disciplines, but also with the effects of introducing new technologies or new substances into the world. The risks studied are generally of harm to human health or to the environment. Interest in applying philosophical analysis to risk assessment originated in response to debates about the development and expansion of nuclear power-generating technologies. In addition, the application of cost-benefit analysis and attempts to understand decision-making under conditions of uncertainty became topics of interest as extensions of formal modeling techniques (Giere 1991). These discussions intersect with debates about the scope of rational decision theory and have expanded to include other technologies as well as applications of scientific research in agriculture and in the myriad forms of biological engineering. Essays on the relation between science and social values in risk research collected in the volume edited by Deborah Mayo and Rachelle Hollander (1991) attempt to steer a course between uncritical reliance on cost-benefit models and their absolute rejection. Coming from a slightly different angle, the precautionary principle represents an approach shifting the burden of proof in regulatory decisions from demonstration of harm to demonstration of safety of substances and practices. Carl Cranor (2004) explores versions of the principle and defends its use in certain decision contexts. Shrader-Frechette (2002) has advocated models of ethically weighted cost-benefit analysis and greater public involvement in risk assessment. Philosophers of science have also worked to make visible the ways in which values play a role in the research assessing the effects of technoscientifically produced substances and practices themselves, as distinct from the challenges of assigning values to identified risks and benefits. In addition to Douglas’s elaboration of inductive risk (Douglas 2000, Lacey (2005) delineates the values informing conventional agriculture and agroecology. In light of the potential impacts of technological developments on communities, Shrader-Frechette (1994, 2002) has argued for including members of the public in deliberations about health effects of and reasonable exposure limits on environmental pollutants, especially radioactive materials.
In addition to risk assessment, philosophers have begun thinking about a variety of research programs and methods that affect human wellbeing. Cartwright (2012), elaborated in Cartwright and Hardie (2012), is primarily a critical analysis of the reliance on randomized control trials to support policy decisions in economic development, medicine, and education. These fail to take account of variations in contexts of application that will affect the outcome. Cartwright's focus on a particular methodological approach is an extension of philosophers' traditional engagement in areas of controversy in which philosophical analysis might make a difference. Philip Kitcher's (1985) which took on sociobiology and Elliott Sober and David Sloan Wilson's (1998), an extensive argument for group level selection, are examples that focus on content and methodology of extensions of evolutionary theory.
Climate change research has provoked several quite different kinds of analysis. As a complex interdisciplinary field, its evidential structure leaves it vulnerable to challenge. Opponents of limits to carbon pollutants have exploited those vulnerabilities to sow public doubts about the reality and/or causes of climate change (Oreskes and Conway 2011). Parker 2006, Lloyd 2010, Parker 2010, Winsberg 2012 have, respectively, investigated strategies for reconciling apparent inconsistencies among climate models, the differences between model-based projections and strictly inductive projections, methods for assessing and communicating the uncertainties inherent in climate models. Philosophers have also considered how to interpret the (American) public’s susceptibility to the climate change deniers. Philip Kitcher (2012) interprets it as lack of information amid a plethora of misinformation and proposes methods for more effective communication of reputable science to the public. Anderson (2011), on the contrary, contends that members of the public are perfectly able to evaluate the reliability of contradictory assessments by following citation trails, etc., whether on the internet or in hard copies of journals. Her view is that the reluctance to accept the reality of climate change is a reluctance to abandon familiar ways of life, which is what averting climate-caused disaster requires all to do. Finally, there is an ethical and political question once the inevitability of climate change is accepted: how should the burdens of taking action be distributed? The industrialized West is responsible for most of the carbon pollution up to the end of the 20th century, but developing nations trying to industrialize have contributed an increasing share, and will continue to do so, in the 21st century. Who bears the burden? And if the effects will only be felt by generations in the future, why should present generations take actions whose harms will be felt now and whose benefits lie in the future and will not be experienced by those bearing the costs? Broome (2008) explores the intergenerational issues, while Raina (forthcoming) explores the global dimensions.
Two additional areas of ongoing scientific controversy are the biological reality (or not) of race and the biology of gender differences. Developments in genetics, and documented racial differences in health, have thrown doubt on earlier anti-realist views of race, such as those articulated by Stephen J. Gould (1981) and Richard Lewontin (Lewontin, Rose, and Kamin 1984). Spencer (2012, 2014) argues for a sophisticated form of biological racial realism. Gannett (2003) argues that biological populations are not independent objects that can provide data relevant to racial realism, while Kaplan and Winther (2013) argue that no claims about race can be read from biological theory or data. The reality and basis of observed gender differences were the subject of much debate in the late 20th century(See Fausto-Sterling 1992). These issues have crystallized in the early 21st century in debates about the brain and cognition drawing the attention of philosophers of biology and cognitive scientists. Rebecca Jordan-Young (2010), Cordelia Fine (2010), and Bluhn, Jacobson and Maibom, eds. (2012) all explore, with an aim of debunking, claims of gendered brains.
3. Social, Cultural, and Feminist Studies of Science
Kuhn's critique of logical empiricism included a strong naturalism. Scientific rationality was to be understood by studying actual episodes in the history of science, not by formal analyses developed from a priori concepts of knowledge and reason (Kuhn 1962, 1977). Sociologists and sociologically inclined historians of science took this as a mandate for the examination of the full spectrum of scientists' practices without any prior prejudice as to which were epistemically legitimate and which not. That very distinction came under suspicion from the new social scholars, often labeled “social constructivists.” They urged that understanding the production of scientific knowledge required looking at all the factors causally relevant to the acceptance of a scientific idea, not just at those the researcher thinks should be relevant.
A wide range of approaches in social and cultural studies of science has come under the umbrella label of “social constructivism.” Both terms in the label are understood differently in different programs of research. While constructivists agree in holding that those factors treated as evidential, or as rationally justifying acceptance, should not be privileged at the expense of other causally relevant factors, they differ in their view of which factors are causal or worth examination. Macro-analytic approaches, such as those associated with the so-called Strong Programme in the Sociology of Scientific Knowledge, treat social relations as an external, independent factor and scientific judgment and content as a dependent outcome. Micro-analyses or laboratory studies, on the other hand, abjure the implied separation of social context and scientific practice and focus on the social relations within scientific research programs and communities and on those that bind research-productive and research-receptive communities together.
Researchers also differ in the degree to which they treat the social and the cognitive dimensions of inquiry as independent or interactive. The researchers associated with the macro-analytic Strong Programme in the Sociology of Scientific Knowledge (Barry Barnes, David Bloor, Harry Collins, Donald MacKenzie, Andrew Pickering, Steve Shapin) were particularly interested in the role of large scale social phenomena, whether widely held social/political ideologies or group professional interests, on the settlement of scientific controversies. Some landmark studies in this genre include Andrew Pickering's (1984) study of competing professional interests in the interpretation of high energy particle physics experiments, and Steven Shapin and Simon Shaffer's (1985) study of the controversy between Robert Boyle and Thomas Hobbes about the epistemological relevance of experiments with vacuum pumps.
The micro-sociological or laboratory studies approach features ethnographic study of particular research groups, tracing the myriad activities and interactions that eventuate in the production and acceptance of a scientific fact or datum. Karin Knorr Cetina's (1981) reports her year-long study of a plant science laboratory at UC Berkeley. Bruno Latour and Steven Woolgar's (1986) study of Roger Guillemin's neuroendocrinology laboratory at the Salk Institute is another classic in this genre. These scholars argued in subsequent work that their form of study showed that philosophical analyses of rationality, of evidence, of truth and knowledge, were irrelevant to understanding scientific knowledge. Sharon Traweek's (1988) comparative study of the cultures of Japanese and North American high energy physics communities pointed to the parallels between cosmology and social organization but abstained from making extravagant or provocative epistemological claims. The efforts of philosophers of science to articulate norms of scientific reasoning and judgment were, in the view of both macro- and micro-oriented scholars, misdirected, because actual scientists relied on quite different kinds of considerations in the practice of science.
Until recently, apart from a few anomalous figures like Caroline Herschel, Barbara McClintock, and Marie Curie, the sciences were a male preserve. Feminist scholars have asked what bearing the masculinity of the scientific profession has had on the content of science and on conceptions of scientific knowledge and practice. Drawing both on work by feminist scientists that exposed and critiqued gender biased science and on theories of gender, feminist historians and philosophers of science have offered a variety of models of scientific knowledge and reasoning intended to accommodate the criticism of accepted science and the concomitant proposal and advocacy of alternatives. Evelyn Keller (1985) proposed a psycho-dynamic model of knowledge and objectivity, arguing that a certain psychological profile, facilitated by typical patterns of masculine psychological development, associated knowledge and objectivity with domination. The association of knowledge and control continues to be a topic of concern for feminist thinkers as it is also for environmentally concerned critics of the sciences. In this connection, see especially Lacey's (2005) study of the controversy concerning transgenic crops. Other feminists turned to Marxist models of social relations and developed versions of standpoint theory, which holds that the beliefs held by a group reflect the social interests of that group. As a consequence, the scientific theories accepted in a context marked by divisions of power such as gender will reflect the interests of those in power. Alternative theoretical perspectives can be expected from those systematically excluded from power. (Harding 1986; Rose 1983; Haraway 1978).
Still other feminists have argued that some standard philosophical approaches to the sciences can be used to express feminist concerns. Nelson (1990) adopts Quine's holism and naturalism to analyze debates in recent biology. Elizabeth Potter (2001) adapts Mary Hesse's network theory of scientific inference to analyse gendered aspects of 17th century physics. Helen Longino (1990) develops a contextual empiricism to analyze research in human evolution and in neuroendocrinology. In addition to the direct role played by gender bias, scholars have attended to the ways shared values in the context of reception can confer an a priori implausibility on certain ideas. Keller (1983) argued that this was the fate of Barbara McClintock's unorthodox proposals of genetic transposition. Stephen Kellert (1993) makes a similar suggestion regarding the resistance to so-called chaos theory.
What the feminist and empirical sociological analyses have in common is the view that the social organization of the scientific community has a bearing on the knowledge produced by that community. There are deep differences, however, in their views as to what features of that social organization are deemed relevant and how they are expressed in the theories and models accepted by a given community. The gender relations focused on by feminists went unrecognized by sociologists pursuing macro- or microsociological research programs. The feminist scientists and scholars further differ from the scholars in empirical social and cultural studies of science in their call for alternative theories and approaches in the sciences. These calls imply that philosophical concerns with truth and justification are not only legitimate but useful tools in advancing feminist transformative goals for the sciences. As can be seen in their varying treatments of objectivity, however, philosophical concepts are often reworked in order to be made applicable to the content or episodes of interest (See Anderson 2004, Haraway 1988, Harding 1993, Keller 1985, Longino 1990, Nelson 1990, Wylie 2005)
In addition to differences in analysis of philosophical concepts like objectivity, rationality, truth, feminist philosophers of science have also debated the proper role of contextual (sometimes called, “external” or “social”) values. Some feminists argue that, given that values do play a role in scientific inquiry, socially progressive values ought to shape not only decisions about what to investigate but also the processes of justification. Philosophers of science should incorporate exemplification of the right values in their accounts of confirmation or justification. Others are less certain about the identification of the values that should and those that should not inform the conduct of science. These philosophers are dubious that a consensus exists, or is even possible in a pluralistic society, on what constitute the values that ought to guide inquiry. In an exchange with Ronald Giere, Kourany (2003a, 2003b) argues that not only science, but philosophy of science ought to be concerned with the promotion of socially progressive values. Giere (2003) replies that what counts as socially progressive will vary among philosophers, and that in a democracy, it is unlikely that a unanimous or near unanimous consensus regarding the values to inform philosophical analysis or scientific inquiry could be achieved either in the larger society or in the smaller social subset of philosophers of science.
4. Models of the Social Character of Knowledge
Since 1980, interest in developing philosophical accounts of scientific knowledge that incorporate the social dimensions of scientific practice has been on the increase. Some philosophers see attention to the social as a straightforward extension of already developed approaches in epistemology. Others, inclined toward some form of naturalism, have taken the work in empirical social studies of science discussed above seriously. They have, however, diverged quite considerably in their treatment of the social. Some understand the social as biasing or distorting, and hence see the social as opposed to or competing with the cognitive or epistemic. These philosophers see the sociologists' disdain for normative philosophical concerns as part of a general debunking of science that demands a response. They attempt either to rebut the claims of the sociologists or to reconcile the demonstration of the role of interests in science with its ultimate rationality. Others treat the social as instead constitutive of rationality. This division parallels to some degree the division between macro-analyses and micro-analyses in the sociology of science described above.
At least four issues have been discussed in the course of proposing models of the social character of scientific knowledge: how to represent and understand the division of cognitive labor in the sciences; whether scientific rationality and objectivity can be fully described independently of the social relations in the sciences; whether the ultimate goal of scientific inquiry should be a single account of phenomena; and what the locus of scientific knowledge is on a fully social account of science.
Division of cognitive labor. For philosophers who treat the individual knower as the primary locus of inquiry, rationality, and knowledge, the phenomena of the coexistence, however uneasy, of difference (even dissent) and of the ascendance of new ideas are the most salient features of a social community. But, it seems hard to account for that diversity if the goal of science is understood to be the achieving of a single encompassing and true theory. How can it be rational to adopt a research strategy other than the one deemed at the time most likely of success? Philip Kitcher in his (1993) was concerned to offer an alternative to the strong programme’s proposal that controversy and the persistence of alternative research programs were a function of the varying social or ideological commitments of researchers. However, he also acknowledged that if researchers followed only the strategy judged at the time most likely to lead to truth, they would not pursue unorthodox strategies that might lead to new discoveries. He therefore labeled the observed fact that researchers pursued different approaches to the same problem as the division of cognitive labor and proposed a decision model that attributed the pursuit of a nonorthodox (maverick) research strategy to a rational calculation about the chances of a positive payoff. This chance was calculated on the basis of the likelihood of the maverick strategy being successful (or more successful than the orthodox approach), the numbers of peers pursuing orthodox or other maverick strategies, and the anticipated reward of success. A community can allocate research resources in such a way as to maintain the balance of orthodox and maverick scientists most likely to facilitate progress. Thus, scientific progress can tolerate and indeed benefits from a certain amount of “impure” motivation. Michael Strevens (2003) argued that the pursuit of maverick research strategies was to be expected as a consequence of the priority rule. The priority rule refers to the practice of referring to a law or object with the name of the first individual to articulate or perceive and identify it. Think of Boyle’s Law, Halley’s comet, the Planck constant, Avogadro’s number, etc. There’s no such reward attached to pursuing a research strategy devised by another and “merely” adding to what that individual has already discovered. The rewards of research come from being first. And to be first requires pursuing a novel problem or strategy. The division of cognitive labor, understood as different researchers pursuing different research strategies, is a simple effect of the priority rule. Muldoon and Weisberg (2011) reject both Kitcher’s and Strevens’s accounts as presupposing unrealistically uniform and ideal agents. In reality, they observe, scientists have at best imperfect knowledge of the entire research situation, do not know the entirety of the research landscape, and when they do know, know different things. They do not have sufficient information to employ the decision methods Kitcher and Strevens attribute to them. Muldoon and Weisberg propose agent-based modeling as a means to represent the imperfect, non-overlapping, and partial knowledge of the agents deciding what research problems and strategies to pursue. Solomon’s advocacy of dissensus discussed below can be understood as rejecting the premises of the problem. From that point of view the aim of scientific organization ought to be to promote disagreement.
Sociality, rationality, and objectivity. Philosophers who treat the social as biasing or distorting tend to focus on the constructivists' view that there are no universal principles of rationality or principles of evidence that can be used to identify in any context-independent way which factors are evidential and which not. Reconciliationists tend to argue that what is correct in the sociologists' accounts can be accomodated in orthodox accounts of scientific knowledge. The key is sifting the correct from the exaggerated or misguided. Integrationists read the relevance of the sociologists' accounts as supporting new accounts of rationality or objectivity, rather than as grounds for rejecting the cogency of such normative ideals.
Philosophers concerned to defend the rationality of science against sociological misrepresentations include Larry Laudan (1984) James Brown (1989, 1994), Alvin Goldman (1987, 1995) and Susan Haack (1996). The details of these philosophers' approaches differ, but they agree in holding that scientists are persuaded by what they regard as the best evidence or argument, the evidence most indicative of the truth by their lights, and in holding that arguments and evidence are the appropriate focus of attention for understanding the production of scientific knowledge. When evidential considerations have not trumped non-evidential considerations, we have an instance of bad science. They read the sociologists as arguing that a principled distinction between evidential and nonevidential considerations cannot be drawn and devote considerable effort to refuting those arguments. In their positive proposals for accomodating the social character of science, sociality is understood as a matter of the aggregation of individuals, not their interactions, and public knowledge as simply the additive outcome of many individuals making sound epistemic judgments. Individual rationality and individual knowledge are thus the proper focus of philosophers of science. Exhibiting principles of rationality applicable to individual reasoning is sufficient to demonstrate the rationality of science, at least in its ideal form.
Reconciliationists include Ronald Giere, Mary Hesse, and Philip Kitcher. Giere (1988) models scientific judgment using decision theory. This permits incorporating scientists' interests as one of the parameters of the decision matrix. He also advocates a satisficing, rather than optimizing, approach to modeling the decision situation, thus enabling different interests interacting with the same empirical base to support different selections as long as they are consistent with that base. Mary Hesse (1980) employs a network model of scientific inference that resembles W.V.O. Quine's web of belief in that its constituents are heterogeneous in character, but all subject to revision in relation to changes elsewhere in the network. She understands the social factors as coherence conditions operating in tandem with logical constraints to determine the relative plausibility of beliefs in the network.
The most elaborate reconciliationist position is that developed in Philip Kitcher's (1993). In addition to modeling relations of authority and the division of cognitive labor as described above, he offers what he terms a compromise between extreme rationalists and sociological debunkers. The compromise model appeals to a principle of rationality, which Kitcher calls the External Standard. It is deemed external because it is proposed as holding independently of any particular historical, cultural or social context. Thus, not only is it external, but it is also universal. The principle applies to change of belief (or shift from one practice to another, in Kitcher's broader locution), not to belief. It treats a shift (in practice or belief) as rational if and only “the process through which the shift was made has a success ratio at least as high as that of any other process used by human beings (ever) ...” (Kitcher 1993, 303). Kitcher's compromise proposes that scientific ideas develop over time and benefit from the contributions of many differently motivated researchers. This is the concession to the sociologically oriented scholars. In the end, however, those theories that get accepted are those that satisfy Kitcher's External Standard. Kitcher thus joins Goldman, Haack, and Laudan in the view that it is possible to articulate a priori conditions of rationality or of epistemic warrant that operate independently of, or, perhaps one might say, orthogonally to, the social relations of science.
A third set of models is integrationist in character. Integrationists use the observations of sociologists of science to develop alternative account of scientific rationality and objectivity. Nelson (1990) focuses on a slightly different aspect of Quine's holism than does Hesse. Nelson uses Quine's arguments against the independently foundational status of observation statements as the basis for what she calls a feminist empiricism. According to Nelson, no principled distinction can be made between the theories, observations, or values of a community. What counts as evidence, in her view, is fixed by the entire complex of a community's theories, value commitments, and observations. There is neither knowledge nor evidence apart from such a shared complex. The community is the primary knower on this view and individual knowledge is dependent on the knowledge and values of the community.
Miriam Solomon's social empiricism is focused on scientific rationality (Solomon 2001). It, too, involves denying a universal principled distinction among the causes of belief. Solomon draws on contemporary cognitive science literature to argue that what are traditionally called biases are simply among the kinds of “decision vector” that influence belief. They are not necessarily undesirable elements from which science needs to be protected, and can be productive of insight and rational belief. Salience and availability (of data, of measurement technologies), also called cold biases, are decision vectors as much as social ideologies or other motivational factors, “hot biases.” The distinctive feature of Solomon's social empiricism is her contrast between individual and community rationality. Her (2001) urges the pluralistic view that a community is rational when the theories it accepts are those that have unique empirical successes. Individuals can persist in beliefs that are (from a panoptic perspective) less well supported than others on this view, if the totality of available evidence (or empirical data) is not available to them, or when their favored theory accounts for phenomena not accounted for other theories, even when those may have a greater quantity of empirical successes. What matters to science, however, is that the aggregated judgments of a community be rational. A community is rational when the theories it accepts are those with all or with unique empirical successes. It is collectively irrational to jettison a theory with unique empirical successes. Thus, the community can be rational even when its members are, as judged by traditional epistemic standards, individually irrational. Indeed, individual irrationality can contribute to community rationality in that individuals committed to a theory that accounts for their data keep that data in the range of phenomena any theory accepted by the entire community must eventually explain. In addition to empirical success, Solomon proposes an additional normative criterion. In order to secure appropriate distribution of scientific effort, biases must be appropriately distributed in the community. Solomon proposes a scheme for ascertaining when a distribution is normatively appropriate. Thus, for Solomon, a scientific community is rational when biases are appropriately distributed and it accepts only a theory with all or theories with unique empirical successes as the normative epistemological condition. Rationality accrues only to a community, and not to the individuals constituting the community.
Finally, in Longino's critical contextual empiricism, the cognitive processes that eventuate in scientific knowledge are themselves social (Longino 1990, 2002). Longino's starting point is a version of the underdetermination argument: the semantic gap between statements describing data and statements expressing hypotheses or theories to be confirmed or disconfirmed by that data. This gap, created by the difference in descriptive terms used in the description of data and in the expression of hypotheses, means that evidential relations cannot be formally specified and that data cannot support one theory or hypothesis to the exclusion of all alternatives. Instead, such relations are mediated by background assumptions. Eventually, in the chain of justification, one reaches assumptions for which no evidence is available. If these are the context in which evidential relations are constituted, questions arise concerning how the acceptance of such assumptions can be legitimated. According to Longino, the only check against the arbitrary dominance of subjective (metaphysical, political, aesthetic) preference in such cases is critical interaction among the members of the scientific community or among members of different communities. There is no higher authority or transcendent aperspectival position from which it is possible to adjudicate among foundational assumptions. Longino takes the underdetermination argument to express in logical terms the point made by the sociologically oriented researchers: the individuals participating in the production of scientific knowledge are historically, geographically, and socially situated and their observations and reasoning reflect their situations. This fact does not undermine the normative enterprise of philosophy, but requires its expansion to include within its scope the social interactions within and between scientific communities. What counts as knowledge is determined by such interactions.
Longino claims that scientific communities do institutionalize some critical practices (for example, peer review), but argues that such practices and institutions must satisfy conditions of effectiveness in order to qualify as objective. She argues, therefore, for the expansion of scientific norms to include norms that apply to communities. These are (1) the provision of venues in which critical interaction can take place, (2) the uptake of critical intervention as demonstrated in change of belief distribution in the community over time in a way that is sensitive to the cirtical discourse taking place within that community, (3) public accessibility of the standards that regulate discourse, and (4) tempered equality of intellectual authority. By this latter condition, perhaps the most controversial of her proposed norms, Longino means that any perspective has a prima facie capacity to contribute to the critical interactions of a community, though equal standing can be lost owing to failure to engage or to respond to criticism. In her 2002, Longino argues that the cognitive processes of science, such as observation and reasoning, are themselves social processes. Thus the interactions subject to community norms extend not only to discussion of assumptions in finished research, but to the constructive processes of research as well.
Solomon and Longino differ on where they locate normativity and on the role and effectiveness of deliberative processes in actual scientific inquiry. Solomon attends to the patterns of acceptance and to the distribution of decision vectors, regardless of the interactions among community members, while Longino attends to deliberative processes and interactions. They may also differ in their views of what constitutes scientific success.
One set of issues that has yet to give rise to extended philosophical reflection is the question how civilizational differences are expressed in scientific work (See Bala 2008). Here, too, there is a micro- and a macro- version. At the micro level, one might ask how the interactional culture of individual laboratories or theoretical subcommunities is or is not expressed in the outcome of their research. While at the macro level one might be asking how large scale cultural features are reflected in the content and practice of science in a given cultural formation. For example, Joseph Needham argued that features of the culture of ancient China directed their technical and intellectual ingenuity into channels that foreclosed the development of anything like the science that developed in Western Europe in the 14th through the 17th centuries. Other cultures developed some aspects of what we now think of as a cosmopolitan or global scientific culture (for example, the mathematics and astronomy of 10th through 14th century Islamic and South Asian scholars) without the theoretical content of early modern physics, as that developed in Western and Central Europe. The papers in Habib and Raina (2001) address aspects of these questions with respect to the history of science in India.
Unity, Plurality and the Aims of Inquiry. The variety of views on the degree of sociality assignable to the epistemological concepts of science lead to different views concerning the ultimate character of the outcome of inquiry. This difference can be summarized as the difference between monism and pluralism. Monism, as characterized in Kellert, Longino, and Waters (2006), holds that the goal of inquiry is and should be a unified, comprehensive, and complete account of phenomena (whether all phenomena, or the phenomena specific to a particular domain of inquiry). If this is so, then the norms of assessment should be informed by this goal and there should be one standard by which theories, models, and hypotheses in the sciences are assessed. Deviation from an accepted theoretical framework is problematic and requires explanation, such as the explanations offered for the division of cognitive labor. Monism, with its commitment to ultimate unity, requires ways to reconcile competing theories or to adjudicate controversy so as to eliminate competition in favor of the one true or best theory. Pluralism, on the other hand, holds that the observed plurality of approaches within a science is no flaw but rather reflects the complexity of the phenomena under investigation in interaction with the limitations of human cognitive capacities and the variety of human cognitive as well as pragmatic interests in representations of those phenomena.
Among pluralists, a diversity of views is to be found. Suppes (1978) emphasized the mutual untranslatability of the descriptive terms developed in the course of scientific specialization. Such incommensurability will resist evaluation by a common measure. Cartwright’s (1999) invocation of a dappled world emphasizes the complexity and diversity of the natural (and social) world. Scientific theories and models are representations of varying degrees of abstraction that manage to apply at best partially to whatever phenomena they purport to represent. To the extent they are taken to represent actual process in the real world, they must be hedged by ceteris paribus clauses. Scientific laws and models attach to patches of the world, but not to a seamlessly law-governed whole. Mitchell’s (2002, 2009) integrative pluralism is a rejection of the goal of unification by either reduction to a single (fundamental) level of explanation or abstraction to a single theoretical representation, in favor of a more pragmatically inflected set of explanatory strategies. The success for any particular investigation is answerable to the goals of the investigation, but there may be multiple compatible accounts reflecting both the contingency and partiality of the laws/generalizations that can figure in explanations and the different goals one may bring to investigation of the same phenomenon. The explanations sought in any particular explanatory situation will draw on these multiple accounts as appropriate for the level of representation adequate to achieve its pragmatic ends. Mitchell’s defense of integrative pluralism rests on both the partiality of representation and the complexity of the phenomena to be explained.
Kellert, Longino, and Waters advance a pluralism that sees multiplicity not only among but within levels of analysis. Furthermore they see no reason to require that the multiple accounts be compatible. The multiplicity of noncongruent empirically adequate accounts helps us appreciate the complexity of a phenomenon without being in a position to generate a single account of that complexity. They do not hold that all phenomena will support ineliminable pluralism, but that there are some phenomena that will require mutually irreducible or incompatible models. Which these are is determined by examining the phenomena, the models, and the match between phenomena and models. Like Mitchell, Kellert, Longino, and Waters hold that pragmatic considerations (broadly understood) will govern the choice of model to be used in particular circumstances. Both forms of pluralism (compatibilist and noncompatibilist) abandon the notion that there is a set of natural kinds whose causal interactions are the basis for fundamental explanations of natural processes. The noncompatibilist is open to multiple classification schemes answerable to different pragmatic interests in classifying. To this extent the noncompatibilist pluralist embraces a view close to the promiscuous realism articulated by John Dupré (1993). The compatibilist, or integrative pluralist, on the other hand, must hold that there is a way that different classification schemes can be reconciled to support the envisioned integration of explanatory models.
Pluralism receives support from several additional approaches. Giere (2006) uses the phenomenon of color vision to support a position he calls perspectival realism. Like the colors of objects, scientific representations are the result of interactions between human cognitive faculties and the world. Other species have different visual equipment and perceive the world differently. Our human cognitive faculties, then, constitute perspectives. We could have been built differently and hence perceived the world differently. Perspectival realism leads to pluralism, because perspectives are partial. While van Fraassen's (2008) does not take a position on pluralism vs. monism (and as an empiricist and antirealist van Fraassen would not have to), its emphasis on the partiality and perspective dependence of measurement provides a complementary point of entry to such diversity. Solomon (2006) urges a yet more welcoming attitude towards multiplicity. In her view, dissensus is a necessary component of well-functioning scientific communities and consensus can be epistemologically pernicious. In an extension of the arguments in Solomon (2001) she argues that different models and theoretical representations will be associated with particular insights or specific data that are likely to be lost if the aim is to integrate or otherwise combine the models to achieve a consensus understanding. The activity of integrating two or more models is different from the process of one of a set coming eventually to have all the empirical successes possessed independently by the individual models. In her examination of consensus conferences called by the United States National Institutes of Health (Solomon 2011), Solomon finds that such conferences do not resolve existing dissent in the scientific community. Instead, they tend to take place after a consensus has emerged in the research community and are directed more to the communication of such consensus to outside communities (such as clinicians, insurers, health policy experts, and the public) than to the assessment of evidence that might warrant consensus.
Researchers committed to a monist or unified science will see plurality as a problem to be overcome, while researchers already committed to a deeply social view of science will see plurality as a resource of communities rather than a problem. The diversity and partiality that characterizes both local and the global scientific community characterize the products of those communities as well as the producers. Universalism and unification require the elimination of epistemologically relevant diversity, while a pluralist stance promotes it and the deeply social conception of knowledge that follows.
Sociality and the structure of scientific knowledge. Attention to the social dimensions of scientific knowledge and the consequent potential for plurality has prompted philosophers to rethink the structure of scientific knowledge. Many philosophers (including Giere, Kitcher, and Longino) who advocate forms of pluralism invoke the metaphor of maps to explain how scientific representations can be both partial and adequate. Maps only represent those features of the territory mapped that are relevant for the purpose for which the map is drawn. Some maps may represent the physical area bounded by state boundaries, others may represent the population size, or the relative abundance/poverty of natural resources. But the map metaphor is only one of several ways to rethink the structure of scientific knowledge.
Other philosophers draw more heavily on cognitive science to represent the sociality of cognitive agents. Giere (2002) takes a naturalist approach to modeling, not so much the distribution of cognitive labor, but the distribution of cognition. This approach takes a system or interactive community as the locus of cognition, rather than the individual agent. Nersessian (2006) extends distributed cognition to model-based reasoning in the sciences. Models are artifacts that focus the cognitive activity of multiple individuals in particular settings. Knowledge is distributed across the minds interacting about the artifacts in that setting. Paul Thagard draws on the increasingly interdisciplinary (and hence social) nature of cognitive science itself to argue that not only does cognitive science (or certain lines of analysis in cognitive science) support a conception of cognition as distributed among interacting agents, but that this conception can be turned back upon cognitive science itself. (Thagard 2012). Finally Alexander Bird (2010) reflects on the sense of knowledge required for attributions such as: “the biomedical community now knows that peptic ulcers are often caused by the bacterium Helicobacter pylori.” Or “There was an explosive growth in scientific knowledge in the twentieth century.” Bird faults other social epistemologists for still making such collective knowledge supervenient on the states of individuals. Instead, he argues, we should understand social knowing as a functional analogue of individual knowing. Both are dependent on the existence and proper functioning of the relevant structures: reasoning and perception for individuals; libraries and journals and other social structures, for collectivities.
5. Social Direction of Science
Modern science has been regarded as both a model of democratic self-governance and an activity requiring and facilitating democratic practices in its supporting social context (Popper 1950, Bronowski 1956). In this perspective, science is seen as embedded in and dependent on its supporting social context, but insulated in its practices from the influence of that context. As the reach of science and science-based technologies has extended further and further into the economy and daily life of industrialized societies, new attention is paid to the governance of science. Regardless of one's views about the social character of knowledge, there are further questions concerning what research to pursue, what social resources to devote to it, who should make such decisions, and how they should be made.
Philip Kitcher (2001) has opened these questions to philosophical scrutiny. While Kitcher largely endorses the epistemological views of his (1993), in this work he argues that there is no absolute standard of the significance (practical or epistemic) of research projects, nor any standard of the good apart from subjective preferences. The only non-arbitrary way to defend judgments concerning research agendas in the absence of absolute standards is through democratic means of establishing collective preferences. Kitcher, thus, attempts to spell out procedures by which decisions concerning what research directions to pursue can be made in a democratic manner. The result, which he calls well-ordered science, is a system in which the decisions actually made track the decisions that would be a made by a suitably constituted representative body collectively deliberating with the assistance of relevant information (concerning, e.g., cost and feasibility) supplied by experts.
Kitcher's “well-ordered science” has attracted attention from other philosophers, from scientists, and from scholars of public policy. Winning praise as a first step, it has also elicited a variety of criticisms and further questions. The criticisms of his proposal range from worries about the excessive idealism of the conception to worries that it will enshrine the preferences of a much smaller group than those who will be affected by research decisions. Kitcher's proposal at best works for a system in which all or most scientific research is publicly funded. But the proportion of private, corporate, funding of science compared to that of public funding has been increasing, thus calling into question the effectiveness of a model that presupposes largely public control (Mirowski and Sent 2002, Krimsky 2003). Kitcher's model, it should be noted, still effects a significant separation between the actual conduct of research and decisions concerning the direction of research and scholars who see a more intimate relation between social processes and values in the context and those in the conduct of research will be dissatisfied with it. Kitcher himself (Kitcher 2011) seems to relax the separation somewhat.
The counterfactual character of the proposal raises questions about the extent to which well-ordered science really is democratic. If the actual decisions do not need to be the result of democratic procedures but only to be the same as those that would result, from such procedures how do we know which decisions those are without actually going through the deliberative exercise? Even if the process is actually carried out, there are places, e.g. in choice of experts whose advice is sought, which permit individual preferences to subvert or bias the preferences of the whole (Roth 2003). Furthermore, given that the effects of scientific research are potentially global, while democratic decisions are at best national, national decisions will have an effect well beyond the population represented by the decision makers. Sheila Jasanoff has also commented that even in contemporary industrialized democracies there are quite different science governance regimes. There is not one model of democratic decision making, but many, and the differences translate into quite different policies (Jasanoff 2005).
In his (2011) Kitcher abandons the counterfactual approach as he brings the ideal of well-orderedness into contact with actual debates in and about contemporary science. His concern here is the variety of ways in which scientific authority has been eroded by what he terms “chimeric epistemologies.” It’s not enough to say that the scientific community has concluded that, say, the MMR vaccine is safe, or that the climate is changing in a way that requires a change in human activities. In a democratic society, there are many other voices claiming authority, whether on presumed evidential grounds or as part of campaigns to manipulate public opinion. Kitcher suggests mechanisms whereby small groups trusted by their communities might develop the understanding of complicated technical issues through tutoring by members of the relevant research communities and then carry this understanding back to the public. He also endorses James Fishkin’s (2009) experiments in deliberative polling as a means to bring members of the public committed to different sides of a technical issue together with the scientific exponents of the issue and in a series of exchanges that cover the evidence, the different kinds of import different lines of reasoning possess, and the other elements of a reasoned discussion, bring the group to a consensus on the correct view. The pluralist and pragmatically inclined philosophers discussed in the previous section might worry that there is not a single correct view towards which such an encounter ought to converge, but that a broader discussion that incorporates deliberation about aims and values might produce sufficient (temporary) convergence to ground action or policy.
6. Conclusion
Philosophical study of the social dimensions of scientific knowledge has been intensifying in the decades since 1970. Social controversies about the sciences and science based technologies as well as developments in philosophical naturalism and social epistemology combine to drive thinking in this area forward. Scholars in a number of cognate disciplines continue to investigate the myriad social relations within scientific communities and between them and their social, economic, and institutional contexts.
While this area first came to prominence in the so-called science wars, attending to social dimensions of science has brought a number of topics to philosophical attention. The phenomenon of Big Science has encouraged philosophers to consider the epistemological significance of such phenomena as trust and cognitive interdependence and the division of cognitive labor. The increased economic and social dependence on science-based technologies has prompted attention to questions of inductive risk and the role of values in assessing hypotheses with social consequences. The controversies over health risks of certain vaccines, over the measurement of environmental pollution, and over the causes of climate change have expanded philosophy of science from its more accustomed areas of logical and epistemological analysis to incorporate concerns about the communication and uptake of scientific knowledge and the ethical dimensions of superficially factual debates.
Partly in response to the work of scholars in the social studies of science, partly in response to the changing role of scientific inquiry through the 20th and into the 21st centuries, philosophers have sought ways to either accommodate the (tenable) results of the sociologists and cultural historians or to modify traditional epistemological concepts used in the analysis of scientific knowledge. These investigations in turn lead to new thinking about the structure and location of the content of knowledge. While debates within philosophy of science between and among adherents to one or another of the models of the sociality of knowledge will continue, an important future step will be a fuller encounter between individual-based social epistemology with its focus on testimony and disagreement as transactions among individuals and the more fully social epistemologies that take social relations or interaction as partially constitutive of empirical knowledge.
Bibliography
Works Cited
Anderson, Elizabeth, 2004. “Uses of Value Judgments in Science” Hypatia, 19, 1–24.
–––, 2011. “Democracy, Public Policy, and Lay Assessments of Scientific Testimony,” Episteme, 8(2): 144–164.
Bala, Arun, 2008, The Dialogue of Civilizations in the Birth of Modern Science, New York, NY: Macmillan.
Barnes, Barry, 1977. Interests and the Growth of Knowledge, New York: Routledge.
–––, and David Bloor, 1982. “Relativism, Rationalism, and the Sociology of Knowledge,” in Rationality and Relativism, eds. Martin Hollis and Steven Lukes, pp. 21–47, Oxford: B. Blackwell.
Bird, Alexander, 2010, “Social Knowing: The Social Sense of ‘Scientific Knowledge’” Philosophical Perspectives 24: 23–56.
Bronowski, Jacob, 1956. Science and Human Values, New York: Harper and Bros.
Brown, James, 1989. The Rational and the Social, London: Routledge.
–––, 1994. Smoke and Mirrors: How Science Reflects Reality, New York: Routledge.
Cartwright, Nancy, 1999, The Dappled World, Cambridge: Cambridge University Press.
–––, 2012, “Will This Policy Work for You?” Philosophy of Science, 79, 5: 973–989.
–––, and Jeremy Hardie, 2012. Evidence-Based Policy: A Practical Guide to Doing It Better, New York, NY: Oxford University Press.
–––, and Jordi Cat, Lola Fleck, and Hasok Chang, 1996. Otto Neurath: Philosophy Between Science and Politics, New York, NY: Cambridge University Press.
Collins, Harry, 1983. “An Empirical Relativist Programme in the Sociology of Scientific Knowledge,” in Science Observed: Perspectives on the Social Study of Science, pp. 115–140, London: Sage.
Cranor, Carl F., 2004. “Toward Understanding Aspects of the Precautionary Principle,” Journal of Medicine and Philosophy, 29(3): 259–79.
Douglas, Heather, 2000. “Inductive Risk and Values in Science,” Philosophy of Science, 67(4): 559–579>
–––, 2009. Science, Policy, and the Value-Free Ideal, Pittsburgh, PA: University of Pittsburgh Press.
Dupré, John, 1993, The Disorder of Things, Cambridge, MA: Harvard University Press.
Elliot, Kevin, 2011, “Direct and Indirect Roles for Values in Science,” Philosophy of Science 78, 2: 303–324
Fausto-Sterling, Anne, 1992, Myths of Gender, New York, NY: Basic Books.
Fine, Arthur, 2007. “Relativism, Pragmatism, and the Practice of Science,” in New Pragmatists, Cheryl Misak (ed.), pp. 50–67, Oxford: Oxford University Press.
Fine, Cordelia, 2010, Delusions of Gender, New York, NY: W.W. Norton and Company.
Fuller, Steve, 1988. Social Epistemology, Bloomington, IN: Indiana University Press.
Gannett, Lisa, 2003, “Making Populations: Bounding Genes in Space and Time,”Philosophy of Science, 70(5): 989–1001.
Giere, Ronald, 1988. Explaining Science: A Cognitive Approach, Chicago: University of Chicago Press.
–––, 1991. “Knowledge, Values, and Technological Decisions: A Decision Theoretical Approach,” in Acceptable Evidence: Science and Values in Risk Management, Deborah Mayo and Rachelle Hollander (eds.), pp. 183–203, New York: Oxford University Press.
–––, 2002. “Scientific Cognition as Distributed Cognition,” in Cognitive Bases of Science Peter Carruthers, Stephen Stitch, and Michael Siegal (eds.), Cambridge, UK: Cambridge University Press.
–––, 2003, “A New Program for Philosophy of Science?” Philosophy of Science, 70(1): 15–21.
–––, 2006. Scientific Perspectivism, Chicago, IL: University of Chicago Press.
–––, and Alan Richardson (eds.), 1996. Origins of Logical Empiricism (Minnesota Studies in the Philosophy of Science, Vol. XVI), Minneapolis, MN: University of Minnesota Press.
Goldman, Alvin, 1987. “The Foundations of Social Epistemics,” Synthese, 73(1): 109–144.
–––, 1995. “Psychological, Social and Epistemic Factors in the Theory of Science,” in PSA 1994: Proceedings of the 1994 Biennial Meeting of the Philosophy of Science Association, Richard Burian, Mickey Forbes, and David Hull (eds.), pp. 277–286, East Lansing, MI: Philosophy of Science Association.
–––,1999. Ch. 8 “Science”, Knowledge in a Social World, pp. 224–271, New York: Oxford University Press.
Gould, Stephen J., 1981, The Mismeasure of Man, New York, NY: W.W. Norton and Company.
Haack, Susan, 1996. “Science as Social: Yes and No,” in Feminism, Science, and the Philosophy of Science, Lynn Hankinson Nelson and Jack Nelson (eds.), pp. 79–94, Dordrecht: Kluwer Academic Publishers.
Habib, S. Irfan and Dhruv Raina, 2001, Situating the History of Science: Dialogues with Joseph Needham, New Delhi, IN: Oxford University Press.
Haraway, Donna, 1978. “Animal Sociology and a Natural Economy of the Body Politic (Part II),” Signs, 4(1): 37–60.
–––, 1988. “Situated Knowledges,” Feminist Studies, 14(3): 575–600.
Harding, Sandra. 1986. The Science Question in Feminism, Ithaca, NY: Cornell University Press.
–––, 1993. “Rethinking Standpoint Epistemology,” in Feminist Epistemologies, Linda Alcoff and Elizabeth Potter (eds.), pp. 49–82, New York: Routledge.
Hardwig, John, 1985. “Epistemic Dependence,” Journal of Philosophy, 82(7): 335–349.
–––, 1988, “Evidence, Testimony, and the Problem of Individualism,” Social Epistemology, 2(4): 309–21.
Hesse, Mary, 1980. Revolutions and Reconstructions in the Philosophy of Science, Bloomington, IN: Indiana University Press.
Hull, David, 1988. Science As a Process: An Evolutionary Account of the Social and Conceptual Development of Science, Chicago: University of Chicago Press.
Jasanoff, Sheila, 2005. Designs on Nature: Science and Democracy in Europe and the United States, Princeton: Princeton University Press.
Jordan-Young, Rebecca, 2010, Brain Storm, Cambridge, MA: Harvard University Press.
Kaplan, Jonathan, and Rasmus Winther, 2013, “Prisoners of Abstraction? The Theory and Measure of Genetic Variation, and the Very Concept of Race,” Biological Theory, 7(4): 401–12.
Keller, Evelyn Fox, 1983. A Feeling for the Organism: The Life and Work of Barbara McClintock, San Francisco: W.H. Freeman.
–––, 1985. Reflections on Gender and Science, New Haven: Yale University Press.
Kellert, Stephen, 1993. In the Wake of Chaos, Chicago: University of Chicago Press.
–––, Helen Longino, and C. Kenneth Waters (eds.), 2006. Scientific Pluralism (Minnesota Studies in the Philosophy of Science, Vol. XIX), Minneapolis: University of Minnesota Press.
Kitcher, Phillip, 1985. Vaulting Ambition, Cambridge, MA: MIT Press.
–––, 1993. The Advancement of Science: Science Without Legend, Objectivity Without Illusions, Oxford: Oxford University Press.
–––, 2001. Science, Truth, and Democracy, New York: Oxford University Press.
–––, 2011. Science in a Democratic Society, Amherst, NY: Prometheus Press.
Knorr-Cetina, Karin, 1981. The Manufacture of Knowledge, Oxford: Pergamon Press.
Kourany, Janet, 2003. “A Philosophy of Science for the Twenty-First Century,” Philosophy of Science, 70(1): 1–14.
–––, 2010, Philosophy of Science After Feminism, New York, NY: Oxford University Press.
Krimsky, Sheldon, 2003. Science in the Private Interest, Lanham: Rowman and Littlefield.
Kuhn, Thomas, 1962. The Structure of Scientific Revolutions, Chicago: University of Chicago Press.
–––, 1977. The Essential Tension: Selected Studies in Scientific Tradition and Change, Chicago: University of Chicago Press.
Lacey, Hugh, 2005. Values and Objectivity: The Controversy over Transgenic Crops, Lanham: Rowman and Littlefield.
Latour, Bruno and Steven Woolgar, 1986. Laboratory Life: The Construction of Scientific Facts, 2d ed., Princeton: Princeton University Press.
Laudan, Larry, 1984a. “The Pseudo-Science of Science?” in Scientific Rationality: The Sociological Turn, James Brown (ed.), pp. 41–74, Dordrecht: D. Reidel.
Lee, Carole J., 2012. “A Kuhnian Critique of Psychometric Research on Peer Review,” Philosophy of Science, 79(5): 859–870.
–––, Cassidy R. Sugimoto, Guo Zhang, and Blaise Cronin, 2013, “Bias in Peer Review,” Journal of the American Society for Information Science and Technology, 64(1): 2–17.
Lewontin, Richard, Steven Rose, and Leon Kamin, 1984, Not in Our Genes, New York, NY: Pantheon.
Longino, Helen E., 1990. Science as Social Knowledge: Values and Objectivity in Scientific Inquiry, Princeton: Princeton University Press.
–––, 2002. The Fate of Knowledge, Princeton: Princeton University Press.
Mayo, Deborah, and Rachelle Hollander (eds.), 1991. Acceptable Evidence: Science and Values in Risk Management, New York: Oxford University Press.
Mill, John Stuart, 1859. On Liberty, London: John W. Parker and Son; reprinted 1974, 1982, Gertrude Himmelfarb (ed.), Harmondsworth: Penguin.
Mirowski, Philip, and Esther-Mirjam Sent (eds.), 2002. Science Bought and Sold, Chicago: University of Chicago Press.
Mitchell, Sandra, 2002. “Integrative Pluralism” Biology and Philosophy, 17: 55–70.
Muldoon, Ryan, and Michael Weisberg, 2011. “Robustness and Idealization in Models of Cognitive Labor,” Synthese, 183: 161–174.
Needham, Joseph, 1954. Science and Civilization in China, Cambridge: Cambridge University Press.
Nersessian, Nancy J., 2006. “Model-Based Reasoning in Distributed Cognitive Systems,” Philosophy of Science, 73(5): 699–709.
Nelson, Lynn Hankinson, 1990. Who Knows: From Quine to Feminist Empiricism, Philadelphia: Temple University Press.
Oreskes, Naomi, and Eric Conway, 2011. Merchants of Doubt, New York, NY: Bloomsbury Press.
Parker, Wendy, 2006. “Understanding Pluralism in Climate Modeling,” Foundations of Science, 11(4): 349–368.
–––, 2010. “Predicting Weather and Climate,” Studies in History and Philosophy of Science (Part B), 41(3): 263–272.
Peirce, Charles S., 1868. “Some Consequences of Four Incapacities,” Journal of Speculative Philosophy, 2: 140–157; reprinted in C.S. Peirce, Selected Writings, Philip Wiener (ed.), New York: Dover Publications, 1958, pp. 39–72.
–––, 1878. “How to Make Our Ideas Clear,” Popular Science Monthly, 12: 286–302; reprinted in C.S. Peirce, Selected Writings, Philip Wiener (ed.), New York: Dover Publications, 1958, pp. 114–136.
Pickering, Andrew, 1984. Constructing Quarks: A Sociological History of Particle Physics, Edinburgh: Edinburgh University Press.
Popper, Karl, 1950. The Open Society and its Enemies, Princeton: Princeton University Press.
–––, 1963. Conjectures and Refutations, London: Routledge and Kegan Paul.
–––, 1972. Objective Knowledge, Oxford: Oxford University Press.
Potter, Elizabeth, 2001. Gender and Boyle's Law of Gases, Bloomington: Indiana University Press.
Rose, Hilary, 1983. “Hand, Brain, and Heart,” Signs, 9(1): 73–96.
Roth, Paul, 2003. “Kitcher's Two Cultures,” Philosophy of the Social Sciences, 33(3): 386–405.
Rouse, Joseph, 1987. Knowledge and Power: Toward a Political Philosophy of Science, Ithaca: Cornell University Press.
Schmitt, Frederick, 1988. “On the Road to Social Epistemic Interdependence,” Social Epistemology, 2: 297–307.
Shapin, Steven, 1982. “The History of Science and Its Sociological Reconstruction,” History of Science, 20: 157–211.
–––, and Simon Schaffer, 1985. Leviathan and the Air Pump, Princeton: Princeton University Press.
Shrader-Frechette, Kristin, 1994. “Expert Judgment and Nuclear Risks: The Case for More Populist Policy,” Journal of Social Philosophy, 25: 45–70.
–––, 2002. Environmental Justice: Creating Equality; Reclaiming Democracy, New York: Oxford University Press.
Sober, Elliott, and David Sloan Wilson, 1998. Unto Others, Cambridge, MA: Harvard University Press
Solomon. Miriam, 1992. “Scientific Rationality and Human Reasoning,” Philosophy of Science, 59(3): 439–54.
–––, 1994a. “Social Empiricism,” Noûs, 28(3): 323–343.
–––, 1994b. “A More Social Epistemology,” in Socializing Epistemology: The Social Dimensions of Knowledge, Frederick Schmitt (ed.), pp. 217–233, Lanham: Rowman and Littlefield Publishers.
–––, 2001. Social Empiricism, Cambridge, MA: MIT Press.
–––, 2006. “Groupthink versus The Wisdom of Crowds: The Social Epistemology of Deliberation and Dissent,” The Southern Journal of Philosophy, XLIV: 28–42.
–––, 2011. “Group Judgment and the Medical Consensus Conference,” Handbook of the Philosophy of Science: Philosophy of Medicine, Fred Gifford (ed.), Amsterdam: Elsevier. pp. 239–254.
Spencer, Quayshawn, 2012. “What Biological Racial Realism Should Mean” Philosophical Studies, 159: 181–204.
–––, 2014. “Biological Theory and the Metaphysics of Race; A Reply to Kaplan and Winther,” Biological Theory, 8: 114–120.
Steele, Daniel and Kyle Whyte, 2012. “Environmental Justice, Values, and Scientific Expertise” Kennedy Institute of Ethics Journal, 22(2): 163–182.
Strevens, Michael, 2003. “The Role of the Priority Rule in Science,” Journal of Philosophy, 100: 55–79.
Tatsioni, Athina, with Nikolaos Bonitsis, and John Ioannidis, 2007. “The Persistence of Contradicted Claims in the Literature,” Journal of the American Medical Association, 298(21): 2517–26.
Thagard, Paul, 2012. The Cognitive Science of Science: Explanation, Discovery, and Conceptual Change, Cambridge, MA: MIT Press.
Traweek, Sharon, 1988. Beamtimes and Lifetimes: The World of High Energy Physicists, Cambridge, MA: Harvard University Press.
Uebel, Thomas, 2004. “Political Philosophy of Science in Logical Empiricism: The Left Vienna Circle,” Studies in History and Philosophy of Science, 36: 754“773.
van Fraassen, Bas, 2008. Scientific Representation, New York: Oxford University Press.
Welbourne, Michael, 1981. “The Community of Knowledge,” Philosophical Quarterly, 31(125): 302–314.
Wilholt, Torsten, 2013. “Epistemic Trust in Science,” British Journal for the Philosophy of Science, 24(2): 233–253.
Winsberg, Eric, 2012. “Values and Uncertainties in the Predictions of global Climate Models,” Kennedy Institute of Ethics Journal, 22(2): 111–137.
–––, Bryce Huebner, and Rebecca Kukla, 2014. “Accountability and Values in Radically Collaborative Research,” Studies in History and Philosophy of Science (Part A), 46: 16–23.
Wylie, Alison, 2002. Thinking from Things, Los Angeles: University of California Press.
Young, N.S., with John Ioannidis, O. Al-Ubaydli, 2008. “Why Current Publication Practices May Harm Science,” Public Library of Science Medicine, 5(10): e201, doi: 10.1371/journal.pmed.0050201.
Further Reading
Daston, Lorraine, and Peter Galison, 2010. Objectivity, Cambridge, MA: MIT Press.
Fleck, Ludwig, 1973. The Genesis and Development of a Scientific Fact, Chicago: University of Chicago Press.
Hacking, Ian, 1999. The Social Construction of What?, Cambridge, MA. Harvard University Press.
Latour, Bruno, 2004. Politics of Nature: How to Bring the Sciences into Democracy, Cambridge, MA: Harvard University Press.
Levi, Isaac, 1980. The Enterprise of Knowledge, Cambridge, MA: MIT Press.
Radder, Hans (ed.), 2010. The Commodification of Scientific Research, Pittsburgh, PA: University of Pittsburgh Press.
McMullin, Ernan (ed.), 1992. Social Dimensions of Scientific Knowledge, South Bend: Notre Dame University Press.
Sismondo, Sergio, 1996. Science Without Myth, Albany: State University of New York Press.
Academic ToolsMany-valued logics are non-classical logics. They are similar to classical logic because they accept the principle of truth-functionality, namely, that the truth of a compound sentence is determined by the truth values of its component sentences (and so remains unaffected when one of its component sentences is replaced by another sentence with the same truth value). But they differ from classical logic by the fundamental fact that they do not restrict the number of truth values to only two: they allow for a larger set W of truth degrees.
Just as the notion of ‘possible worlds’ in the semantics of modal logic can be reinterpreted (e.g., as ‘moments of time’ in the semantics of tense logic or as ‘states’ in the semantics of dynamic logic), there does not exist a standard interpretation of the truth degrees. How they are to be understood depends on the actual field of application. It is general usage, however, to assume that there are two particular truth degrees, usually denoted by “0” and “1”. These particular truth degrees act, respectively, like the traditional truth values “falsum” and “verum” – but sometimes also like “absolutely false” and “absolutely true”, particularly in cases in which the traditional truth values of classical logic “split” into a series of truth degrees.
Many-valued logics treat their truth degrees as technical tools, and intend to choose them suitably for particular applications. It is a rather difficult philosophical problem to discuss the (possible, non-technical) nature of such “truth degrees” or “truth values”. The interested reader can consult the monograph Shramko/Wansing (2011) or the entry on truth values.
The formalized languages for systems of many-valued logic (MVL) follow the two standard patterns for propositional and predicate logic, respectively:
there are propositional variables together with connectives and (possibly also) truth degree constants in the case of propositional languages,
there are object variables together with predicate symbols, possibly also object constants and function symbols, as well as quantifiers, connectives, and (possibly also) truth degree constants in the case of first-order languages.
As usual in logic, these languages are the basis for semantically as well as syntactically founded systems of logic.
Academic Tools
Related EntriesTruth
Truth is one of the central subjects in philosophy. It is also one of the largest. Truth has been a topic of discussion in its own right for thousands of years. Moreover, a huge variety of issues in philosophy relate to truth, either by relying on theses about truth, or implying theses about truth.
It would be impossible to survey all there is to say about truth in any coherent way. Instead, this essay will concentrate on the main themes in the study of truth in the contemporary philosophical literature. It will attempt to survey the key problems and theories of current interest, and show how they relate to one-another. A number of other entries investigate many of these topics in greater depth. Generally, discussion of the principal arguments is left to them. The goal of this essay is only to provide an overview of the current Theories. Many of the papers mentioned in this essay can be found in the anthologies edited by Blackburn and Simmons (1999) and Lynch (2001b). There are also a number of book-length surveys of the topics discussed here, including Burgess and Burgess (2011), Kirkham (1992), and Künne (2003).
The problem of truth is in a way easy to state: what truths are, and what (if anything) makes them true. But this simple statement masks a great deal of controversy. Whether there is a metaphysical problem of truth at all, and if there is, what kind of theory might address it, are all standing issues in the theory of truth. We will see a number of distinct ways of answering these questions.
Much of the contemporary literature on truth takes as its starting point some ideas which were prominent in the early part of the 20th century. There were a number of views of truth under discussion at that time, the most significant for the contemporary literature being the correspondence, coherence, and pragmatist theories of truth.
These theories all attempt to directly answer the nature question: what is the nature of truth? They take this question at face value: there are truths, and the question to be answered concerns their nature. In answering this question, each theory makes the notion of truth part of a more thoroughgoing metaphysics or epistemology. Explaining the nature of truth becomes an application of some metaphysical system, and truth inherits significant metaphysical presuppositions along the way.
The goal of this section is to characterize the ideas of the correspondence, coherence and pragmatist theories which animate the contemporary debate. In some cases, the received forms of these theories depart from the views that were actually defended in the early 20th century. We thus dub them the ‘neo-classical theories’. Where appropriate, we pause to indicate how the neo-classical theories emerge from their ‘classical’ roots in the early 20th century.
Perhaps the most important of the neo-classical theories for the contemporary literature is the correspondence theory. Ideas that sound strikingly like a correspondence theory are no doubt very old. They might well be found in Aristotle or Aquinas. When we turn to the late 19th and early 20th centuries where we pick up the story of the neo-classical theories of truth, it is clear that ideas about correspondence were central to the discussions of the time. In spite of their importance, however, it is strikingly difficult to find an accurate citation in the early 20th century for the received neo-classical view. Furthermore, the way the correspondence theory actually emerged will provide some valuable reference points for the contemporary debate. For these reasons, we dwell on the origins of the correspondence theory in the late 19th and early 20th centuries at greater length than those of the other neo-classical views, before turning to its contemporary neo-classical form.
The basic idea of the correspondence theory is that what we believe or say is true if it corresponds to the way things actually are—to the facts. This idea can be seen in various forms throughout the history of philosophy. Its modern history starts with the beginnings of analytic philosophy at the turn of the 20th century, particularly in the work of G. E. Moore and Bertrand Russell.
Let us pick up the thread of this story in the years between 1898 and about 1910. These years are marked by Moore and Russell's rejection of idealism. Yet at this point, they do not hold a correspondence theory of truth. Indeed Moore (1899) sees the correspondence theory as a source of idealism, and rejects it. Russell follows Moore in this regard. (For discussion of Moore's early critique of idealism, where he rejects the correspondence theory of truth, see Baldwin (1991). Hylton (1990) provides an extensive discussion of Russell in the context of British idealism.)
In this period, Moore and Russell hold a version of the identity theory of truth. They say comparatively little about it, but it is stated briefly in Moore (1899; 1902) and Russell (1904). According to the identity theory, a true proposition is identical to a fact. Specifically, in Moore and Russell's hands, the theory begins with propositions, understood as the objects of beliefs and other propositional attitudes. Propositions are what are believed, and give the contents of beliefs. They are also, according to this theory, the primary bearers of truth. When a proposition is true, it is identical to a fact, and a belief in that proposition is correct. (Related ideas about the identity theory and idealism are discussed by McDowell (1994) and further developed by Hornsby (2001).)
The identity theory Moore and Russell espoused takes truth to be a property of propositions. Furthermore, taking up an idea familiar to readers of Moore, the property of truth is a simple unanalyzable property. Facts are understood as simply those propositions which are true. There are true propositions and false ones, and facts just are true propositions. There is thus no “difference between truth and the reality to which it is supposed to correspond” (Moore, 1902, p. 21). (For further discussion of the identity theory of truth, see Baldwin (1991), Candlish (1999), Cartwright (1987), Dodd (2000), and the entry on the identity theory of truth.)
Moore and Russell came to reject the identity theory of truth in favor of a correspondence theory, sometime around 1910 (as we see in Moore, 1953, which reports lectures he gave in 1910–1911, and Russell, 1910b). They do so because they came to reject the existence of propositions. Why? Among reasons, they came to doubt that there could be any such things as false propositions, and then concluded that there are no such things as propositions at all.
Why did Moore and Russell find false propositions problematic? A full answer to this question is a point of scholarship that would take us too far afield. (Moore himself lamented that he could not “put the objection in a clear and convincing way” (1953, p. 263), but see Cartwright (1987) and David (2001) for careful and clear exploration of the arguments.) But very roughly, the identification of facts with true propositions left them unable to see what a false proposition could be other than something which is just like a fact, though false. If such things existed, we would have fact-like things in the world, which Moore and Russell now see as enough to make false propositions count as true. Hence, they cannot exist, and so there are no false propositions. As Russell (1956, p. 223) later says, propositions seem to be at best “curious shadowy things” in addition to facts.
As Cartwright (1987) reminds us, it is useful to think of this argument in the context of Russell's slightly earlier views about propositions. As we see clearly in Russell (1903), for instance, he takes propositions to have constituents. But they are not mere collections of constituents, but a ‘unity’ which brings the constituents together. (We thus confront the ‘problem of the unity of the proposition’.) But what, we might ask, would be the ‘unity’ of a proposition that Samuel Ramey sings—with constituents Ramey and singing—except Ramey bearing the property of singing? If that is what the unity consists in, then we seem to have nothing other than the fact that Ramey sings. But then we could not have genuine false propositions without having false facts.
As Cartwright also reminds us, there is some reason to doubt the cogency of this sort of argument. But let us put the assessment of the arguments aside, and continue the story. From the rejection of propositions a correspondence theory emerges. The primary bearers of truth are no longer propositions, but beliefs themselves. In a slogan:
A belief is true if and only if it corresponds to a fact.
Views like this are held by Moore (1953) and Russell (1910b; 1912). Of course, to understand such a theory, we need to understand the crucial relation of correspondence, as well as the notion of a fact to which a belief corresponds. We now turn to these questions. In doing so, we will leave the history, and present a somewhat more modern reconstruction of a correspondence theory.
The correspondence theory of truth is at its core an ontological thesis: a belief is true if there exists an appropriate entity—a fact—to which it corresponds. If there is no such entity, the belief is false.
Facts, for the neo-classical correspondence theory, are entities in their own right. Facts are generally taken to be composed of particulars and properties and relations or universals, at least. The neo-classical correspondence theory thus only makes sense within the setting of a metaphysics that includes such facts. Hence, it is no accident that as Moore and Russell turn away from the identity theory of truth, the metaphysics of facts takes on a much more significant role in their views. This perhaps becomes most vivid in the later Russell (1956, p. 182), where the existence of facts is the “first truism.” (The influence of Wittgenstein's ideas to appear in the Tractatus (1922) on Russell in this period was strong, and indeed, the Tractatus remains one of the important sources for the neo-classical correspondence theory. For more recent extensive discussions of facts, see Armstrong (1997) and Neale (2001).)
Consider, for example, the belief that Ramey sings. Let us grant that this belief is true. In what does its truth consist, according to the correspondence theory? It consists in there being a fact in the world, built from the individual Ramey, and the property of singing. Let us denote this <Ramey, Singing>. This fact exists. In contrast, the world (we presume) contains no fact <Ramey, Dancing>. The belief that Ramey sings stands in the relation of correspondence to the fact <Ramey, Singing>, and so the belief is true.
What is the relation of correspondence? One of the standing objections to the classical correspondence theory is that a fully adequate explanation of correspondence proves elusive. But for a simple belief, like that Ramey sings, we can observe that the structure of the fact <Ramey, Singing> matches the subject-predicate form of the that-clause which reports the belief, and may well match the structure of the belief itself.
So far, we have very much the kind of view that Moore and Russell would have found congenial. But the modern form of the correspondence theory seeks to round out the explanation of correspondence by appeal to propositions. Indeed, it is common to base a correspondence theory of truth upon the notion of a structured proposition. Propositions are again cast as the contents of beliefs and assertions, and propositions have structure which at least roughly corresponds to the structure of sentences. At least, for simple beliefs like that Ramey sings, the proposition has the same subject predicate structure as the sentence. (Proponents of structured propositions, such as Kaplan (1989), often look to Russell (1903) for inspiration, and find unconvincing Russell's reasons for rejecting them.)
With facts and structured propositions in hand, an attempt may be made to explain the relation of correspondence. Correspondence holds between a proposition and a fact when the proposition and fact have the same structure, and the same constituents at each structural position. When they correspond, the proposition and fact thus mirror each-other. In our simple example, we might have:
proposition that
Ramey
sings
fact
<Ramey,
Singing>
Propositions, though structured like facts, can be true or false. In a false case, like the proposition that Ramey dances, we would find no fact at the bottom of the corresponding diagram. Beliefs are true or false depending on whether the propositions which are believed are.
We have sketched this view for simple propositions like the proposition that Ramey sings. How to extend it to more complex cases, like general propositions or negative propositions, is an issue we will not delve into here. It requires deciding whether there are complex facts, such as general facts or negative facts, or whether there is a more complex relation of correspondence between complex propositions and simple facts. (The issue of whether there are such complex facts marks a break between Russell (1956) and Wittgenstein (1922) and the earlier views which Moore (1953) and Russell (1912) sketch.)
According to the correspondence theory as sketched here, what is key to truth is a relation between propositions and the world, which obtains when the world contains a fact that is structurally similar to the proposition. Though this is not the theory Moore and Russell held, it weaves together ideas of theirs with a more modern take on (structured) propositions. We will thus dub it the neo-classical correspondence theory. This theory offers us a paradigm example of a correspondence theory of truth.
The leading idea of the correspondence theory is familiar. It is a form of the older idea that true beliefs show the right kind of resemblance to what is believed. In contrast to earlier empiricist theories, the thesis is not that one's ideas per se resemble what they are about. Rather, the propositions which give the contents of one's true beliefs mirror reality, in virtue of entering into correspondence relations to the right pieces of it.
In this theory, it is the way the world provides us with appropriately structured entities that explains truth. Our metaphysics thus explains the nature of truth, by providing the entities needed to enter into correspondence relations.
For more on the correspondence theory, see David (1994) and the entry on the correspondance theory of truth.
Though initially the correspondence theory was seen by its developers as a competitor to the identity theory of truth, it was also understood as opposed to the coherence theory of truth.
We will be much briefer with the historical origins of the coherence theory than we were with the correspondence theory. Like the correspondence theory, versions of the coherence theory can be seen throughout the history of philosophy. (See, for instance, Walker (1989) for a discussion of its early modern lineage.) Like the correspondence theory, it was important in the early 20th century British origins of analytic philosophy. Particularly, the coherence theory of truth is associated with the British idealists to whom Moore and Russell were reacting.
Many idealists at that time did indeed hold coherence theories. Let us take as an example Joachim (1906). (This is the theory that Russell (1910a) attacks.) Joachim says that:
Truth in its essential nature is that systematic coherence which is the character of a significant whole (p. 76).
We will not attempt a full exposition of Joachim's view, which would take us well beyond the discussion of truth into the details of British idealism. But a few remarks about his theory will help to give substance to the quoted passage.
Perhaps most importantly, Joachim talks of ‘truth’ in the singular. This is not merely a turn of phrase, but a reflection of his monistic idealism. Joachim insists that what is true is the “whole complete truth” (p. 90). Individual judgments or beliefs are certainly not the whole complete truth. Such judgments are, according to Joachim, only true to a degree. One aspect of this doctrine is a kind of holism about content, which holds that any individual belief or judgment gets its content only in virtue of being part of a system of judgments. But even these systems are only true to a degree, measuring the extent to which they express the content of the single ‘whole complete truth’. Any real judgment we might make will only be partially true.
To flesh out Joachim's theory, we would have to explain what a significant whole is. We will not attempt that, as it leads us to some of the more formidable aspects of his view, e.g., that it is a “process of self-fulfillment” (p. 77). But it is clear that Joachim takes ‘systematic coherence’ to be stronger than consistency. In keeping with his holism about content, he rejects the idea that coherence is a relation between independently identified contents, and so finds it necessary to appeal to ‘significant wholes’.
As with the correspondence theory, it will be useful to recast the coherence theory in a more modern form, which will abstract away from some of the difficult features of British idealism. As with the correspondence theory, it can be put in a slogan:
A belief is true if and only if it is part of a coherent system of beliefs.
To further the contrast with the neo-classical correspondence theory, we may add that a proposition is true if it is the content of a belief in the system, or entailed by a belief in the system. We may assume, with Joachim, that the condition of coherence will be stronger than consistency. With the idealists generally, we might suppose that features of the believing subject will come into play.
This theory is offered as an analysis of the nature of truth, and not simply a test or criterion for truth. Put as such, it is clearly not Joachim's theory (it lacks his monism, and he rejects propositions), but it is a standard take on coherence in the contemporary literature. (It is the way the coherence theory is given in Walker (1989), for instance. See also Young (2001) for a recent defense of a coherence theory.) Let us take this as our neo-classical version of the coherence theory. The contrast with the correspondence theory of truth is clear. Far from being a matter of whether the world provides a suitable object to mirror a proposition, truth is a matter of how beliefs are related to each-other.
The coherence theory of truth enjoys two sorts of motivations. One is primarily epistemological. Most coherence theorists also hold a coherence theory of knowledge; more specifically, a coherence theory of justification. According to this theory, to be justified is to be part of a coherent system of beliefs. An argument for this is often based on the claim that only another belief could stand in a justification relation to a belief, allowing nothing but properties of systems of belief, including coherence, to be conditions for justification. Combining this with the thesis that a fully justified belief is true forms an argument for the coherence theory of truth. (An argument along these lines is found in Blanshard (1939), who holds a form of the coherence theory closely related to Joachim's.)
The steps in this argument may be questioned by a number of contemporary epistemological views. But the coherence theory also goes hand-in-hand with its own metaphysics as well. The coherence theory is typically associated with idealism. As we have already discussed, forms of it were held by British idealists such as Joachim, and later by Blanshard (in America). An idealist should see the last step in the justification argument as quite natural. More generally, an idealist will see little (if any) room between a system of beliefs and the world it is about, leaving the coherence theory of truth as an extremely natural option.
It is possible to be an idealist without adopting a coherence theory. (For instance, many scholars read Bradley as holding a version of the identity theory of truth. See Baldwin (1991) for some discussion.) However, it is hard to see much of a way to hold the coherence theory of truth without maintaining some form of idealism. If there is nothing to truth beyond what is to be found in an appropriate system of beliefs, then it would seem one's beliefs constitute the world in a way that amounts to idealism. (Walker (1989) argues that every coherence theorist must be an idealist, but not vice-versa.)
The neo-classical correspondence theory seeks to capture the intuition that truth is a content-to-world relation. It captures this in the most straightforward way, by asking for an object in the world to pair up with a true proposition. The neo-classical coherence theory, in contrast, insists that truth is not a content-to-world relation at all; rather, it is a content-to-content, or belief-to-belief, relation. The coherence theory requires some metaphysics which can make the world somehow reflect this, and idealism appears to be it. (A distant descendant of the neo-classical coherence theory that does not require idealism will be discussed in section 6.5 below.)
For more on the coherence theory, see the entry on the coherence theory of truth.
A different perspective on truth was offered by the American pragmatists. As with the neo-classical correspondence and coherence theories, the pragmatist theories go with some typical slogans. For example, Peirce is usually understood as holding the view that:
Truth is the end of inquiry.
(See, for instance Hartshorne et al., 1931–58, §3.432.) Both Peirce and James are associated with the slogan that:
Truth is satisfactory to believe.
James (e.g., 1907) understands this principle as telling us what practical value truth has. True beliefs are guaranteed not to conflict with subsequent experience. Likewise, Peirce's slogan tells us that true beliefs will remain settled at the end of prolonged inquiry. Peirce's slogan is perhaps most typically associated with pragmatist views of truth, so we might take it to be our canonical neo-classical theory. However, the contemporary literature does not seem to have firmly settled upon a received ‘neo-classical’ pragmatist theory.
In her reconstruction (upon which we have relied heavily), Haack (1976) notes that the pragmatists' views on truth also make room for the idea that truth involves a kind of correspondence, insofar as the scientific method of inquiry is answerable to some independent world. Peirce, for instance, does not reject a correspondence theory outright; rather, he complains that it provides merely a ‘nominal’ or ‘transcendental’ definition of truth (e.g Hartshorne et al., 1931–58, §5.553, §5.572), which is cut off from practical matters of experience, belief, and doubt (§5.416). (See Misak (2004) for an extended discussion.)
This marks an important difference between the pragmatist theories and the coherence theory we just considered. Even so, pragmatist theories also have an affinity with coherence theories, insofar as we expect the end of inquiry to be a coherent system of beliefs. As Haack also notes, James maintains an important verificationist idea: truth is what is verifiable. We will see this idea re-appear in section 4.
James' views are discussed further in the entry on William James. Peirce's views are discussed further in the entry on Charles Sanders Peirce.
2. Tarski's theory of truth
Modern forms of the classical theories survive. Many of these modern theories, notably correspondence theories, draw on ideas developed by Tarski.
In this regard, it is important to bear in mind that his seminal work on truth (1935) is very much of a piece with other works in mathematical logic, such as his (1931), and as much as anything this work lays the ground-work for the modern subject of model theory—a branch of mathematical logic, not the metaphysics of truth. In this respect, Tarski's work provides a set of highly useful tools that may be employed in a wide range of philosophical projects. (See Patterson (2012) for more on Tarski's work in its historical context.)
Tarski's work has a number of components, which we will consider in turn.
In the classical debate on truth at the beginning of the 20th century we considered in section 1, the issue of truth-bearers was of great significance. For instance, Moore and Russell's turn to the correspondence theory was driven by their views on whether there are propositions to be the bearers of truth. Many theories we reviewed took beliefs to be the bearers of truth.
In contrast, Tarski and much of the subsequent work on truth takes sentences to be the primary bearers of truth. This is not an entirely novel development: Russell (1956) also takes truth to apply to sentence (which he calls ‘propositions’ in that text). But whereas much of the classical debate takes the issue of the primary bearers of truth to be a substantial and important metaphysical one, Tarski is quite casual about it. His primary reason for taking sentences as truth-bearers is convenience, and he explicitly distances himself from any commitment about the philosophically contentious issues surrounding other candidate truth-bearers (e.g., Tarski, 1944). (Russell (1956) makes a similar suggestion that sentences are the appropriate truth-bearers “for the purposes of logic” (p. 184), though he still takes the classical metaphysical issues to be important.)
We will return to the issue of the primary bearers of truth in section 6.1. For the moment, it will be useful to simply follow Tarski's lead. But it should be stressed that for this discussion, sentences are fully interpreted sentences, having meanings. We will also assume that the sentences in question do not change their content across occasions of use, i.e., that they display no context-dependence. We are taking sentences to be what Quine (1960) calls ‘eternal sentences’.
In some places (e.g., Tarski, 1944), Tarski refers to his view as the ‘semantic conception of truth’. It is not entirely clear just what Tarski had in mind by this, but it is clear enough that Tarski's theory defines truth for sentences in terms of concepts like reference and satisfaction, which are intimately related to the basic semantic functions of names and predicates (according to many approaches to semantics).
Let us suppose we have a fixed language L whose sentences are fully interpreted. The basic question Tarski poses is what an adequate theory of truth for L would be. Tarski's answer is embodied in what he calls Convention T:
An adequate theory of truth for L must imply, for each sentence φ of L
⌈ φ ⌉ is true if and only if φ .
(We have simplified Tarski's presentation somewhat.) This is an adequacy condition for theories, not a theory itself. Given the assumption that L is fully interpreted, we may assume that each sentence φ in fact has a truth value. In light of this, Convention T guarantees that the truth predicate given by the theory will be extensionally correct, i.e., have as its extension all and only the true sentences of L .
Convention T draws our attention to the biconditionals of the form
⌈ ⌈ φ ⌉ is true if and only if φ ⌉,
which are usually called the Tarski biconditionals for a language L .
Tarski does not merely propose a condition of adequacy for theories of truth, he also shows how to meet it. One of his insights is that if the language L displays the right structure, then truth for L can be defined recursively. For instance, let us suppose that L is a simple formal language, containing two atomic sentences ‘snow is white’ and ‘grass is green’, and the sentential connectives ∨ and ¬.
In spite of its simplicity, L contains infinitely many distinct sentences. But truth can be defined for all of them by recursion.
Base clauses:
‘Snow is white’ is true if and only if snow is white.
‘Grass is green’ is true if and only if grass is green.
Recursion clauses. For any sentences φ and ψ of L:
⌈ φ ∨ ψ ⌉ is true if and only if ⌈ φ ⌉ is true or ⌈ ψ ⌉ is true.
⌈ ¬φ ⌉ is true if and only if it is not the case that ⌈ φ ⌉ is true.
This theory satisfies Convention T.
This may look trivial, but in defining an extensionally correct truth predicate for an infinite language with four clauses, we have made a modest application of a very powerful technique.
Tarski's techniques go further, however. They do not stop with atomic sentences. Tarski notes that truth for each atomic sentence can be defined in terms of two closely related notions: reference and satisfaction. Let us consider a language L′ , just like L except that instead of simply having two atomic sentences, L′ breaks atomic sentences into terms and predicates. L′ contains terms ‘snow’ and ‘grass’ (let us engage in the idealization that these are simply singular terms), and predicates ‘is white’ and ‘is green’. So L′ is like L , but also contains the sentences ‘Snow is green’ and ‘Grass is white’.)
We can define truth for atomic sentences of L′ in the following way.
Base clauses:
‘Snow’ refers to snow.
‘Grass’ refers to grass.
a satisfies ‘is white’ if and only if a is white.
a satisfies ‘is green’ if and only if a is green.
For any atomic sentence ⌈ t is P ⌉ : ⌈ t is P ⌉ is true if and only if the referent of ⌈ t ⌉ satisfies ⌈ P⌉.
One of Tarski's key insights is that the apparatus of satisfaction allows for a recursive definition of truth for sentences with quantifiers, though we will not examine that here. We could repeat the recursion clauses for L to produce a full theory of truth for L′.
Let us say that a Tarskian theory of truth is a recursive theory, built up in ways similar to the theory of truth for L′. Tarski goes on to demonstrate some key applications of such a theory of truth. A Tarskian theory of truth for a language L can be used to show that theories in L are consistent. This was especially important to Tarski, who was concerned the Liar paradox would make theories in languages containing a truth predicate inconsistent.
For more, see the entries on axiomatic theories of truth, the Liar paradox, and Tarski's truth definitions.
The correspondence theory of truth expresses the very natural idea that truth is a content-to-world or word-to-world relation: what we say or think is true or false in virtue of the way the world turns out to be. We suggested that, against a background like the metaphysics of facts, it does so in a straightforward way. But the idea of correspondence is certainly not specific to this framework. Indeed, it is controversial whether a correspondence theory should rely on any particular metaphysics at all. The basic idea of correspondence, as Tarski (1944) and others have suggested, is captured in the slogan from Aristotle's Metaphysics Γ 7.27, “to say of what is that it is, or of what is not that it is not, is true” (Ross, 1928). ‘What is’, it is natural enough to say, is a fact, but this natural turn of phrase may well not require a full-blown metaphysics of facts.
Yet without the metaphysics of facts, the notion of correspondence as discussed in section 1.1 loses substance. This has led to two distinct strands in contemporary thinking about the correspondence theory. One strand seeks to recast the correspondence theory in a way that does not rely on any particular ontology. Another seeks to find an appropriate ontology for correspondence, either in terms of facts or other entities. We will consider each in turn.
Tarski himself sometimes suggested that his theory was a kind of correspondence theory of truth. Whether his own theory is a correspondence theory, and even whether it provides any substantial philosophical account of truth at all, is a matter of controversy. (One rather drastic negative assessment from Putnam (1985–86, p. 333) is that “As a philosophical account of truth, Tarski's theory fails as badly as it is possible for an account to fail.”) But a number of philosophers (e.g., Davidson, 1969; Field, 1972) have seen Tarski's theory as providing at least the core of a correspondence theory of truth which dispenses with the metaphysics of facts.
Tarski's theory shows how truth for a sentence is determined by certain properties of its constituents; in particular, by properties of reference and satisfaction (as well as by the logical constants). As it is normally understood, reference is the preeminent word-to-world relation. Satisfaction is naturally understood as a word-to-world relation as well, which relates a predicate to the things in the world that bear it. The Tarskian recursive definition shows how truth is determined by reference and satisfaction, and so is in effect determined by the things in the world we refer to and the properties they bear. This, one might propose, is all the correspondence we need. It is not correspondence of sentences or propositions to facts; rather, it is correspondence of our expressions to objects and the properties they bear, and then ways of working out the truth of claims in terms of this.
This is certainly not the neo-classical idea of correspondence. In not positing facts, it does not posit any single object to which a true proposition or sentence might correspond. Rather, it shows how truth might be worked out from basic word-to-world relations. However, a number of authors have noted that Tarski's theory cannot by itself provide us with such an account of truth. As we will discuss more fully in section 4.2, Tarski's apparatus is in fact compatible with theories of truth that are certainly not correspondence theories.
Field (1972), in an influential discussion and diagnosis of what is lacking in Tarski's account, in effect points out that whether we really have something worthy of the name ‘correspondence’ depends on our having notions of reference and satisfaction which genuinely establish word-to-world relations. (Field does not use the term ‘correspondence’, but does talk about e.g., the “connection between words and things” (p. 373).) By itself, Field notes, Tarski's theory does not offer an account of reference and satisfaction at all. Rather, it offers a number of disquotation clauses, such as:
‘Snow’ refers to snow.
a satisfies ‘is white’ if and only if a is white.
These clauses have an air of triviality (though whether they are to be understood as trivial principles or statements of non-trivial semantic facts has been a matter of some debate). With Field, we might propose to supplement clauses like these with an account of reference and satisfaction. Such a theory should tell us what makes it the case that the word ‘snow’ refer to snow. (In 1972, Field was envisaging a physicalist account, along the lines of the causal theory of reference.) This should inter alia guarantee that truth is really determined by word-to-world relations, so in conjunction with the Tarskian recursive definition, it could provide a correspondence theory of truth.
Such a theory clearly does not rely on a metaphysics of facts. Indeed, it is in many ways metaphysically neutral, as it does not take a stand on the nature of particulars, or of the properties or universals that underwrite facts about satisfaction. However, it may not be entirely devoid of metaphysical implications, as we will discuss further in section 4.1.
Much of the subsequent discussion of Field-style approaches to correspondence has focused on the role of representation in these views. Field's own (1972) discussion relies on a causal relation between terms and their referents, and a similar relation for satisfaction. These are instances of representation relations. According to representational views, meaningful items, like perhaps thoughts or sentences or their constituents, have their contents in virtue of standing in the right relation to the things they represent. On many views, including Field's, a name stands in such a relation to its bearer, and the relation is a causal one.
The project of developing a naturalist account of the representation relation has been an important one in the philosophy of mind and language. (See the entry on mental representation.) But, it has implications for the theory of truth. Representational views of content lead naturally to correspondence theories of truth. To make this vivid, suppose you hold that sentences or beliefs stand in a representation relation to some objects. It is natural to suppose that for true beliefs or sentences, those objects would be facts. We then have a correspondence theory, with the correspondence relation explicated as a representation relation: a truth bearer is true if it represents a fact.
As we have discussed, many contemporary views reject facts, but one can hold a representational view of content without them. One interpretation of Field's theory is just that. The relations of reference and satisfaction are representation relations, and truth for sentences is determined compositionally in terms of those representation relations, and the nature of the objects they represent. If we have such relations, we have the building blocks for a correspondence theory without facts. Field (1972) anticipated a naturalist reduction of the representation via a causal theory, but any view that accepts representation relations for truth bearers or their constituents can provide a similar theory of truth. (See Jackson (2006) and Lynch (2009) for further discussion.)
Representational views of content provide a natural way to approach the correspondence theory of truth, and likewise, anti-representational views provide a natural way to avoid the correspondence theory of truth. This is most clear in the work of Davidson, as we will discuss more in section 6.5.
There have been a number of correspondence theories that do make use of facts. Some are notably different from the neo-classical theory sketched in section 1.1. For instance, Austin (1950) proposes a view in which each statement (understood roughly as an utterance event) corresponds to both a fact or situation, and a type of situation. It is true if the former is of the latter type. This theory, which has been developed by situation theory (e.g., Barwise and Perry, 1986), rejects the idea that correspondence is a kind of mirroring between a fact and a proposition. Rather, correspondence relations to Austin are entirely conventional. (See Vision (2004) for an extended defense of an Austinian correspondence theory.) As an ordinary language philosopher, Austin grounds his notion of fact more in linguistic usage than in an articulated metaphysics, but he defends his use of fact-talk in Austin (1961b).
In a somewhat more Tarskian spirit, formal theories of facts or states of affairs have also been developed. For instance, Taylor (1976) provides a recursive definition of a collection of ‘states of affairs’ for a given language. Taylor's states of affairs seem to reflect the notion of fact at work in the neo-classical theory, though as an exercise in logic, they are officially n-tuples of objects and intensions.
There are more metaphysically robust notions of fact in the current literature. For instance, Armstrong (1997) defends a metaphysics in which facts (under the name ‘states of affairs’) are metaphysically fundamental. The view has much in common with the neo-classical one. Like the neo-classical view, Armstrong endorses a version of the correspondence theory. States of affairs are truthmakers for propositions, though Armstrong argues that there may be many such truthmakers for a given proposition, and vice versa. (Armstrong also envisages a naturalistic account of propositions as classes of equivalent belief-tokens.)
Armstrong's primary argument is what he calls the ‘truthmaker argument’. It begins by advancing a truthmaker principle, which holds that for any given truth, there must be a truthmaker—a “something in the world which makes it the case, that serves as an ontological ground, for this truth” (p. 115). It is then argued that facts are the appropriate truthmakers.
In contrast to the approach to correspondence discussed in section 3.1, which offered correspondence with minimal ontological implications, this view returns to the ontological basis of correspondence that was characteristic of the neo-classical theory.
For more on facts, see the entry on facts.
The truthmaker principle is often put as the schema:
If φ , then there is an x such that necessarily, if x exists, then φ .
(Fox (1987) proposed putting the principle this way, rather than explicitly in terms of truth.)
The truthmaker principle expresses the ontological aspect of the neo-classical correspondence theory. Not merely must truth obtain in virtue of word-to-world relations, but there must be a thing that makes each truth true.
The neo-classical correspondence theory, and Armstrong, cast facts as the appropriate truthmakers. However, it is a non-trivial step from the truthmaker principle to the existence of facts. There are a number of proposals in the literature for how other sorts of objects could be truthmakers; for instance, tropes (called ‘moments’, in Mulligan et al., 1984). Parsons (1999) argues that the truthmaker principle (presented in a somewhat different form) is compatible with there being only concrete particulars.
As we saw in discussing the neo-classical correspondence theory, truthmaker theories, and fact theories in particular, raise a number of issues. One which has been discussed at length, for instance, is whether there are negative facts. Negative facts would be the truthmakers for negated sentences. Russell (1956) notoriously expresses ambivalence about whether there are negative facts. Armstrong (1997) rejects them, while Beall (2000) defends them. (For more discussion of truthmakers, see the papers in Beebee and Dodd (2005).)
The neo-classical theories we surveyed in section 1 made the theory of truth an application of their background metaphysics (and in some cases epistemology). In section 2 and especially in section 3, we returned to the issue of what sorts of ontological commitments might go with the theory of truth. There we saw a range of options, from relatively ontologically non-committal theories, to theories requiring highly specific ontologies.
There is another way in which truth relates to metaphysics. Many ideas about realism and anti-realism are closely related to ideas about truth. Indeed, many approaches to questions about realism and anti-realism simply make them questions about truth.
In discussing the approach to correspondence of section 3.1, we noted that it has few ontological requirements. It relies on there being objects of reference, and something about the world which makes for determinate satisfaction relations; but beyond that, it is ontologically neutral. But as we mentioned there, this is not to say that it has no metaphysical implications. A correspondence theory of truth, of any kind, is often taken to embody a form of realism.
The key features of realism, as we will take it, are that:
The world exists objectively, independently of the ways we think about it or describe it.
Our thoughts and claims are about that world.
(Wright (1992) offers a nice statement of this way of thinking about realism.) These theses imply that our claims are objectively true or false, depending on how the world they are about is. The world that we represent in our thoughts or language is an objective world. (Realism may be restricted to some subject-matter, or range of discourse, but for simplicity, we will talk about only its global form.)
It is often argued that these theses require some form of the correspondence theory of truth. (Putnam (1978, p. 18) notes, “Whatever else realists say, they typically say that they believe in a ‘correspondence theory of truth’.”) At least, they are supported by the kind of correspondence theory without facts discussed in section 3.1, such as Field's proposal. Such a theory will provide an account of objective relations of reference and satisfaction, and show how these determine the truth or falsehood of what we say about the world. Field's own approach (1972) to this problem seeks a physicalist explanation of reference. But realism is a more general idea than physicalism. Any theory that provides objective relations of reference and satisfaction, and builds up a theory of truth from them, would give a form of realism. (Making the objectivity of reference the key to realism is characteristic of work of Putnam, e.g., 1978.)
Another important mark of realism expressed in terms of truth is the property of bivalence. As Dummett has stressed (e.g., 1959; 1976; 1983; 1991), a realist should see there being a fact of the matter one way or the other about whether any given claim is correct. Hence, one important mark of realism is that it goes together with the principle of bivalence: every truth-bearer (sentence or proposition) is true or false. In much of his work, Dummett has made this the characteristic mark of realism, and often identifies realism about some subject-matter with accepting bivalence for discourse about that subject-matter. At the very least, it captures a great deal of what is more loosely put in the statement of realism above.
Either the approach makes the theory of truth—or truth-and-reference—the primary vehicle for an account of realism. A theory of truth which substantiates bivalence, or a determinate reference relation, does most of the work of giving a realistic metaphysics. It might even simply be a realistic metaphysics.
We have thus turned on its head the relation of truth to metaphysics we saw in our discussion of the neo-classical correspondence theory in section 1.1. There, a correspondence theory of truth was built upon a substantial metaphysics. Here, we have seen how articulating a theory that captures the idea of correspondence can be crucial to providing a realist metaphysics. (For another perspective on realism and truth, see Alston (1996). Devitt (1984) offers an opposing view to the kind we have sketched here, which rejects any characterization of realism in terms of truth or other semantic concepts.)
In light of our discussion in section 1.1.1, we should pause to note that the connection between realism and the correspondence theory of truth is not absolute. When Moore and Russell held the identity theory of truth, they were most certainly realists. The right kind of metaphysics of propositions can support a realist view, as can a metaphysics of facts. The modern form of realism we have been discussing here seeks to avoid basing itself on such particular ontological commitments, and so prefers to rely on the kind of correspondence-without-facts approach discussed in section 3.1. This is not to say that realism will be devoid of ontological commitments, but the commitments will flow from whichever specific claims about some subject-matter are taken to be true.
For more on realism and truth, see Fumerton (2002) and the entry on realism.
It should come as no surprise that the relation between truth and metaphysics seen by modern realists can also be exploited by anti-realists. Many modern anti-realists see the theory of truth as the key to formulating and defending their views. With Dummett (e.g., 1959; 1976; 1991), we might expect the characteristic mark of anti-realism to be the rejection of bivalence.
Indeed, many contemporary forms of anti-realism may be formulated as theories of truth, and they do typically deny bivalence. Anti-realism comes in many forms, but let us take as an example a (somewhat crude) form of verificationism. Such a theory holds that a claim is correct just insofar as it is in principle verifiable, i.e., there is a verification procedure we could in principle carry out which would yield the answer that the claim in question was verified.
So understood, verificationism is a theory of truth. The claim is not that verification is the most important epistemic notion, but that truth just is verifiability. As with the kind of realism we considered in section 4.1, this view expresses its metaphysical commitments in its explanation of the nature of truth. Truth is not, to this view, a fully objective matter, independent of us or our thoughts. Instead, truth is constrained by our abilities to verify, and is thus constrained by our epistemic situation. Truth is to a significant degree an epistemic matter, which is typical of many anti-realist positions.
As Dummett says, the verificationist notion of truth does not appear to support bivalence. Any statement that reaches beyond what we can in principle verify or refute (verify its negation) will be a counter-example to bivalence. Take, for instance, the claim that there is some substance, say uranium, present in some region of the universe too distant to be inspected by us within the expected lifespan of the universe. Insofar as this really would be in principle unverifiable, we have no reason to maintain it is true or false according to the verificationist theory of truth.
Verificationism of this sort is one of a family of anti-realist views. Another example is the view that identifies truth with warranted assertibility. Assertibility, as well as verifiability, has been important in Dummett's work. (See also works of McDowell, e.g., 1976 and Wright, e.g., 1976; 1982; 1992.)
Anti-realism of the Dummettian sort is not a descendant of the coherence theory of truth per se. But in some ways, as Dummett himself has noted, it might be construed as a descendant—perhaps very distant—of idealism. If idealism is the most drastic form of rejection of the independence of mind and world, Dummettian anti-realism is a more modest form, which sees epistemology imprinted in the world, rather than the wholesale embedding of world into mind. At the same time, the idea of truth as warranted assertibility or verifiability reiterates a theme from the pragmatist views of truth we surveyed in section 1.3.
Anti-realist theories of truth, like the realist ones we discussed in section 4.1, can generally make use of the Tarskian apparatus. Convention T, in particular, does not discriminate between realist and anti-realist notions of truth. Likewise, the base clauses of a Tarskian recursive theory are given as disquotation principles, which are neutral between realist and anti-realist understandings of notions like reference. As we saw with the correspondence theory, giving a full account of the nature of truth will generally require more than the Tarskian apparatus itself. How an anti-realist is to explain the basic concepts that go into a Tarskian theory is a delicate matter. As Dummett and Wright have investigated in great detail, it appears that the background logic in which the theory is developed will have to be non-classical.
For more on anti-realism and truth, see the papers in Greenough and Lynch (2006) and the entry on realism.
Many commentators see a close connection between Dummett's anti-realism and the pragmatists' views of truth, in that both put great weight on ideas of verifiability or assertibility. Dummett himself stressed parallels between anti-realism and intuitionism in the philosophy of mathematics.
Another view on truth which returns to pragmatist themes is the ‘internal realism’ of Putnam (1981). There Putnam glosses truth as what would be justified under ideal epistemic conditions. With the pragmatists, Putnam sees the ideal conditions as something which can be approximated, echoing the idea of truth as the end of inquiry.
Putnam is cautious about calling his view anti-realism, preferring the label ‘internal realism’. But he is clear that he sees his view as opposed to realism (‘metaphysical realism’, as he calls it).
Davidson's views on truth have also been associated with pragmatism, notably by Rorty (1986). Davidson has distanced himself from this interpretation (e.g., 1990), but he does highlight connections between truth and belief and meaning. Insofar as these are human attitudes or relate to human actions, Davidson grants there is some affinity between his views and those of some pragmatists (especially, he says, Dewey).
Another view that has grown out of the literature on realism and anti-realism, and has become increasingly important in the current literature, is that of pluralism about truth. This view, developed in work of Lynch (e.g. 2001b; 2009) and Wright (e.g. 1992; 1999), proposes that there are multiple ways for truth bearers to be true. Wright, in particular, suggests that in certain domains of discourse what we say is true in virtue of a correspondence-like relation, while in others it is its true in virtue of a kind of assertibility relation that is closer in spirit to the anti-realist views we have just discussed.
Such a proposal might suggest there are multiple concepts of truth, or that the term ‘true’ is itself ambiguous. However, whether or not a pluralist view is committed to such claims has been disputed. In particular, Lynch (2001b; 2009) develops a version of pluralism which takes truth to be a functional role concept. The functional role of truth is characterized by a range of principles that articulate such features of truth as its objectivity, its role in inquiry, and related ideas we have encountered in considering various theories of truth. (A related point about platitudes governing the concept of truth is made by Wright (1992).) But according to Lynch, these display the functional role of truth. Furthermore, Lynch claims that on analogy with analytic functionalism, these principles can be seen as deriving from our pre-theoretic or ‘folk’ ideas about truth.
Like all functional role concepts, truth must be realized, and according to Lynch it may be realized in different ways in different settings. Such multiple realizability has been one of the hallmarks of functional role concepts discussed in the philosophy of mind. For instance, Lynch suggests that for ordinary claims about material objects, truth might be realized by a correspondence property (which he links to representational views), while for moral claims truth might be manifest by an assertibility property along more anti-realist lines.
For more on pluralism about truth, see the entry on pluralist theories of truth.
5. Deflationism
We began in section 1 with the neo-classical theories, which explained the nature of truth within wider metaphysical systems. We then considered some alternatives in sections 2 and 3, some of which had more modest ontological implications. But we still saw in section 4 that substantial theories of truth tend to imply metaphysical theses, or even embody metaphysical positions.
One long-standing trend in the discussion of truth is to insist that truth really does not carry metaphysical significance at all. It does not, as it has no significance on its own. A number of different ideas have been advanced along these lines, under the general heading of deflationism.
Deflationist ideas appear quite early on, including a well-known argument against correspondence in Frege (1918–19). However, many deflationists take their cue from an idea of Ramsey (1927), often called the equivalence thesis:
⌈ ⌈ φ ⌉ is true ⌉ has the same meaning as φ.
(Ramsey himself takes truth-bearers to be propositions rather than sentences. Glanzberg (2003b) questions whether Ramsey's account of propositions really makes him a deflationist.)
This can be taken as the core of a theory of truth, often called the redundancy theory. The redundancy theory holds that there is no property of truth at all, and appearances of the expression ‘true’ in our sentences are redundant, having no effect on what we express.
The equivalence thesis can also be understood in terms of speech acts rather than meaning:
To assert that ⌈ φ ⌉ is true is just to assert that φ.
This view was advanced by Strawson (1949; 1950), though Strawson also argues that there are other important aspects of speech acts involving ‘true’ beyond what is asserted. For instance, they may be acts of confirming or granting what someone else said. (Strawson would also object to my making sentences the bearers of truth.)
In either its speech act or meaning form, the redundancy theory argues there is no property of truth. It is commonly noted that the equivalence thesis itself is not enough to sustain the redundancy theory. It merely holds that when truth occurs in the outermost position in a sentence, and the full sentence to which truth is predicated is quoted, then truth is eliminable. What happens in other environments is left to be seen. Modern developments of the redundancy theory include Grover et al. (1975).
The equivalence principle looks familiar: it has something like the form of the Tarski biconditionals discussed in section 2.2. However, it is a stronger principle, which identifies the two sides of the biconditional—either their meanings or the speech acts performed with them. The Tarski biconditionals themselves are simply material biconditionals.
A number of deflationary theories look to the Tarski biconditionals rather than the full equivalence principle. Their key idea is that even if we do not insist on redundancy, we may still hold the following theses:
For a given language L and every φ in L, the biconditionals ⌈ ⌈ φ ⌉ is true if and only if φ ⌉ hold by definition (or analytically, or trivially, or by stipulation …).
This is all there is to say about the concept of truth.
We will refer to views which adopt these as minimalist. Officially, this is the name of the view of Horwich (1990), but we will apply it somewhat more widely. (Horwich's view differs in some specific respects from what is presented here, such as predicating truth of propositions, but we believe it is close enough to what is sketched here to justify the name.)
The second thesis, that the Tarski biconditionals are all there is to say about truth, captures something similar to the redundancy theory's view. It comes near to saying that truth is not a property at all; to the extent that truth is a property, there is no more to it than the disquotational pattern of the Tarski biconditionals. As Horwich puts it, there is no substantial underlying metaphysics to truth. And as Soames (1984) stresses, certainly nothing that could ground as far-reaching a view as realism or anti-realism.
If there is no property of truth, or no substantial property of truth, what role does our term ‘true’ play? Deflationists typically note that the truth predicate provides us with a convenient device of disquotation. Such a device allows us to make some useful claims which we could not formulate otherwise, such as the blind ascription ‘The next thing that Bill says will be true’. (For more on blind ascriptions and their relation to deflationism, see Azzouni, 2001.) A predicate obeying the Tarski biconditionals can also be used to express what would otherwise be (potentially) infinite conjunctions or disjunctions, such as the notorious statement of Papal infallibility put ‘Everything the Pope says is true’. (Suggestions like this are found in Leeds, 1978 and Quine, 1970.)
Recognizing these uses for a truth predicate, we might simply think of it as introduced into a language by stipulation. The Tarski biconditionals themselves might be stipulated, as the minimalists envisage. One could also construe the clauses of a recursive Tarskian theory as stipulated. (There are some significant logical differences between these two options. See Halbach (1999) and Ketland (1999) for discussion.) Other deflationists, such as Beall (2005) or Field (1994), might prefer to focus here on rules of inference or rules of use, rather than the Tarski biconditionals themselves.
There are also important connections between deflationist ideas about truth and certain ideas about meaning. These are fundamental to the deflationism of Field (1986; 1994), which will be discussed in section 6.3. For an insightful critique of deflationism, see Gupta (1993).
For more on deflationism, see the entry on the deflationary theory of truth.
6. Truth and language
One of the important themes in the literature on truth is its connection to meaning, or more generally, to language. This has proved an important application of ideas about truth, and an important issue in the study of truth itself. This section will consider a number of issues relating truth and language.
There have been many debates in the literature over what the primary bearers of truth are. Candidates typically include beliefs, propositions, sentences, and utterances. We have already seen in section 1 that the classical debates on truth took this issue very seriously, and what sort of theory of truth was viable was often seen to depend on what the bearers of truth are.
In spite of the number of options under discussion, and the significance that has sometimes been placed on the choice, there is an important similarity between candidate truth-bearers. Consider the role of truth-bearers in the correspondence theory, for instance. We have seen versions of it which take beliefs, propositions, or interpreted sentences to be the primary bearers of truth. But all of them rely upon the idea that their truth-bearers are meaningful, and are thereby able to say something about what the world is like. (We might say that they are able to represent the world, but that is to use ‘represent’ in a wider sense than we saw in section 3.2. No assumptions about just what stands in relations to what objects are required to see truth-bearers as meaningful.) It is in virtue of being meaningful that truth-bearers are able to enter into correspondence relations. Truth-bearers are things which meaningfully make claims about what the world is like, and are true or false depending on whether the facts in the world are as described.
Exactly the same point can be made for the anti-realist theories of truth we saw in section 4.2, though with different accounts of how truth-bearers are meaningful, and what the world contributes. Though it is somewhat more delicate, something similar can be said for coherence theories, which usually take beliefs, or whole systems of beliefs, as the primary truth-bearers. Though a coherence theory will hardly talk of beliefs representing the facts, it is crucial to the coherence theory that beliefs are contentful beliefs of agents, and that they can enter into coherence relations. Noting the complications in interpreting the genuine classical coherence theories, it appears fair to note that this requires truth-bearers to be meaningful, however the background metaphysics (presumably idealism) understands meaning.
Though Tarski works with sentences, the same can be said of his theory. The sentences to which Tarski's theory applies are fully interpreted, and so also are meaningful. They characterize the world as being some way or another, and this in turn determines whether they are true or false. Indeed, Tarski needs there to be a fact of the matter about whether each sentence is true or false (abstracting away from context dependence), to ensure that the Tarski biconditionals do their job of fixing the extension of ‘is true’. (But note that just what this fact of the matter consists in is left open by the Tarskian apparatus.)
We thus find the usual candidate truth-bearers linked in a tight circle: interpreted sentences, the propositions they express, the belief speakers might hold towards them, and the acts of assertion they might perform with them are all connected by providing something meaningful. This makes them reasonable bearers of truth. For this reason, it seems, contemporary debates on truth have been much less concerned with the issue of truth-bearers than were the classical ones. Some issues remain, of course. Different metaphysical assumptions may place primary weight on some particular node in the circle, and some metaphysical views still challenge the existence of some of the nodes. Perhaps more importantly, different views on the nature of meaning itself might cast doubt on the coherence of some of the nodes. Notoriously for instance, Quineans (e.g., Quine, 1960) deny the existence of intensional entities, including propositions. Even so, it increasingly appears doubtful that attention to truth per se will bias us towards one particular primary bearer of truth.
There is a related, but somewhat different point, which is important to understanding the theories we have canvassed.
The neo-classical theories of truth start with truth-bearers which are already understood to be meaningful, and explain how they get their truth values. But along the way, they often do something more. Take the neo-classical correspondence theory, for instance. This theory, in effect, starts with a view of how propositions are meaningful. They are so in virtue of having constituents in the world, which are brought together in the right way. There are many complications about the nature of meaning, but at a minimum, this tells us what the truth conditions associated with a proposition are. The theory then explains how such truth conditions can lead to the truth value true, by the right fact existing.
Many theories of truth are like the neo-classical correspondence theory in being as much theories of how truth-bearers are meaningful as of how their truth values are fixed. Again, abstracting from some complications about meaning, this makes them theories both of truth conditions and truth values. The Tarskian theory of truth can be construed this way too. This can be seen both in the way the Tarski biconditionals are understood, and how a recursive theory of truth is understood. As we explained Convention T in section 2.2, the primary role of a Tarski biconditional of the form ⌈ ⌈ φ ⌉ is true if and only if φ ⌉ is to fix whether φ is in the extension of ‘is true’ or not. But it can also be seen as stating the truth conditions of φ. Both rely on the fact that the unquoted occurrence of φ is an occurrence of an interpreted sentence, which has a truth value, but also provides its truth conditions upon occasions of use.
Likewise, the base clauses of the recursive definition of truth, those for reference and satisfaction, are taken to state the relevant semantic properties of constituents of an interpreted sentence. In discussing Tarski's theory of truth in section 2, we focused on how these determine the truth value of a sentence. But they also show us the truth conditions of a sentence are determined by these semantic properties. For instance, for a simple sentence like ‘Snow is white’, the theory tells us that the sentence is true if the referent of ‘Snow’ satisfies ‘white’. This can be understood as telling us that the truth conditions of ‘Snow is white’ are those conditions in which the referent of ‘Snow’ satisfies the predicate ‘is white’.
As we saw in sections 3 and 4, the Tarskian apparatus is often seen as needing some kind of supplementation to provide a full theory of truth. A full theory of truth conditions will likewise rest on how the Tarskian apparatus is put to use. In particular, just what kinds of conditions those in which the referent of ‘snow’ satisfies the predicate ‘is white’ are will depend on whether we opt for realist or anti-realist theories. The realist option will simply look for the conditions under which the stuff snow bears the property of whiteness; the anti-realist option will look to the conditions under which it can be verified, or asserted with warrant, that snow is white.
There is a broad family of theories of truth which are theories of truth conditions as well as truth values. This family includes the correspondence theory in all its forms—classical and modern. Yet this family is much wider than the correspondence theory, and wider than realist theories of truth more generally. Indeed, virtually all the theories of truth that make contributions to the realism/anti-realism debate are theories of truth conditions. In a slogan, for many approaches to truth, a theory of truth is a theory of truth conditions.
Any theory that provides a substantial account of truth conditions can offer a simple account of truth values: a truth-bearer provides truth conditions, and it is true if and only if the actual way things are is among them. Because of this, any such theory will imply a strong, but very particular, biconditional, close in form to the Tarski biconditionals. It can be made most vivid if we think of propositions as sets of truth conditions. Let p be a proposition, i.e., a set of truth conditions, and let a be the ‘actual world’, the condition that actually obtains. Then we can almost trivially see:
p is true if and only if a ∈ p.
This is presumably necessary. But it is important to observe that it is in one respect crucially different from the genuine Tarski biconditionals. It makes no use of a non-quoted sentence, or in fact any sentence at all. It does not have the disquotational character of the Tarski biconditionals.
Though this may look like a principle that deflationists should applaud, it is not. Rather, it shows that deflationists cannot really hold a truth-conditional view of content at all. If they do, then they inter alia have a non-deflationary theory of truth, simply by linking truth value to truth conditions through the above biconditional. It is typical of thoroughgoing deflationist theories to present a non-truth-conditional theory of the contents of sentences: a non-truth-conditional account of what makes truth-bearers meaningful. We take it this is what is offered, for instance, by the use theory of propositions in Horwich (1990). It is certainly one of the leading ideas of Field (1986; 1994), which explore how a conceptual role account of content would ground a deflationist view of truth. Once one has a non-truth-conditional account of content, it is then possible to add a deflationist truth predicate, and use this to give purely deflationist statements of truth conditions. But the starting point must be a non-truth-conditional view of what makes truth-bearers meaningful.
Both deflationists and anti-realists start with something other than correspondence truth conditions. But whereas an anti-realist will propose a different theory of truth conditions, a deflationists will start with an account of content which is not a theory of truth conditions at all. The deflationist will then propose that the truth predicate, given by the Tarski biconditionals, is an additional device, not for understanding content, but for disquotation. It is a useful device, as we discussed in section 5.3, but it has nothing to do with content. To a deflationist, the meaningfulness of truth-bearers has nothing to do with truth.
It has been an influential idea, since the seminal work of Davidson (e.g., 1967), to see a Tarskian theory of truth as a theory of meaning. At least, as we have seen, a Tarskian theory can be seen as showing how the truth conditions of a sentence are determined by the semantic properties of its parts. More generally, as we see in much of the work of Davidson and of Dummett (e.g., 1959; 1976; 1983; 1991), giving a theory of truth conditions can be understood as a crucial part of giving a theory of meaning. Thus, any theory of truth that falls into the broad category of those which are theories of truth conditions can be seen as part of a theory of meaning. (For more discussion of these issues, see Higginbotham (1986; 1989) and the exchange between Higginbotham (1992) and Soames (1992).)
A number of commentators on Tarski (e.g., Etchemendy, 1988; Soames, 1984) have observed that the Tarskian apparatus needs to be understood in a particular way to make it suitable for giving a theory of meaning. Tarski's work is often taken to show how to define a truth predicate. If it is so used, then whether or not a sentence is true becomes, in essence, a truth of mathematics. Presumably what truth conditions sentences of a natural language have is a contingent matter, so a truth predicate defined in this way cannot be used to give a theory of meaning for them. But the Tarskian apparatus need not be used just to explicitly define truth. The recursive characterization of truth can be used to state the semantic properties of sentences and their constituents, as a theory of meaning should. In such an application, truth is not taken to be explicitly defined, but rather the truth conditions of sentences are taken to be described. (See Heck, 1997 for more discussion.)
Inspired by Quine (e.g., 1960), Davidson himself is well known for taking a different approach to using a theory of truth as a theory of meaning than is implicit in Field (1972). Whereas a Field-inspired representational approach is based on a causal account of reference, Davidson (e.g., 1973) proposes a process of radical interpretation in which an interpreter builds a Tarskian theory to interpret a speaker as holding beliefs which are consistent, coherent, and largely true.
This led Davidson (e.g. 1986) to argue that most of our beliefs are true—a conclusion that squares well with the coherence theory of truth. This is a weaker claim than the neo-classical coherence theory would make. It does not insist that all the members of any coherent set of beliefs are true, or that truth simply consists in being a member of such a coherent set. But all the same, the conclusion that most of our beliefs are true, because their contents are to be understood through a process of radical interpretation which will make them a coherent and rational system, has a clear affinity with the neo-classical coherence theory.
In Davidson (1986), he thought his view of truth had enough affinity with the neo-classical coherence theory to warrant being called a coherence theory of truth, while at the same time he saw the role of Tarskian apparatus as warranting the claim that his view was also compatible with a kind of correspondence theory of truth.
In later work, however, Davidson reconsidered this position. In fact, already in Davidson (1977) he had expressed doubt about any understanding of the role of Tarski's theory in radical interpretation that involves the kind of representational apparatus relied on by Field (1972), as we discussed in sections 3.1 and 3.2. In the “Afterthoughts” to Davidson (1986), he also concluded that his view departs too far from the neo-classical coherence theory to be named one. What is important is rather the role of radical interpretation in the theory of content, and its leading to the idea that belief is veridical. These are indeed points connected to coherence, but not to the coherence theory of truth per se. They also comprise a strong form of anti-representationalism. Thus, though he does not advance a coherence theory of truth, he does advance a theory that stands in opposition to the representational variants of the correspondence theory we discussed in section 3.2.
For more on Davidson, see Glanzberg (2013) and the entry on Donald Davidson.
The relation between truth and meaning is not the only place where truth and language relate closely. Another is the idea, also much-stressed in the writings of Dummett (e.g., 1959), of the relation between truth and assertion. Again, it fits into a platitude:
Truth is the aim of assertion.
A person making an assertion, the platitude holds, aims to say something true.
It is easy to cast this platitude in a way that appears false. Surely, many speakers do not aim to say something true. Any speaker who lies does not. Any speaker whose aim is to flatter, or to deceive, aims at something other than truth.
The motivation for the truth-assertion platitude is rather different. It looks at assertion as a practice, in which certain rules are constitutive. As is often noted, the natural parallel here is with games, like chess or baseball, which are defined by certain rules. The platitude holds that it is constitutive of the practice of making assertions that assertions aim at truth. An assertion by its nature presents what it is saying as true, and any assertion which fails to be true is ipso facto liable to criticism, whether or not the person making the assertion themself wished to have said something true or to have lied.
Dummett's original discussion of this idea was partially a criticism of deflationism (in particular, of views of Strawson, 1950). The idea that we fully explain the concept of truth by way of the Tarski biconditionals is challenged by the claim that the truth-assertion platitude is fundamental to truth. As Dummett there put it, what is left out by the Tarski biconditionals, and captured by the truth-assertion platitude, is the point of the concept of truth, or what the concept is used for. (For further discussion, see Glanzberg, 2003a and Wright, 1992.)
Whether or not assertion has such constitutive rules is, of course, controversial. But among those who accept that it does, the place of truth in the constitutive rules is itself controversial. The leading alternative, defended by Williamson (1996), is that knowledge, not truth, is fundamental to the constitutive rules of assertion. Williamson defends an account of assertion based on the rule that one must assert only what one knows.
For more on truth and assertion, see the papers in Brown and Cappelen (2011) and the entry on assertion.
Alston, William P., 1996, A Realistic Conception of Truth, Ithaca: Cornell University Press.
Armstrong, David M., 1997, A World of States of Affairs, Cambridge: Cambridge University Press.
Austin, J. L., 1950, “Truth”, Proceedings of the Aristotelian Society (Supplementary Volume), 24: 111–129. Reprinted in Austin (1961a).
Austin, J. L., 1961a, Philosophical Papers, Oxford: Clarendon Press. Edited by J. O. Urmson and G. J. Warnock.
Austin, J. L., 1961b, “Unfair to facts”, in Philosophical Papers, J. O. Urmson and G. J. Warnock (eds.), Oxford: Clarendon Press, 102–122.
Azzouni, Jody, 2001, “Truth via anaphorically unrestricted quantifiers”, Journal of Philosophical Logic, 30: 329–354.
Baldwin, Thomas, 1991, “The identity theory of truth”, Mind, 100: 35–52.
Barwise, Jon and Perry, John, 1986, Situations and Attitudes, Cambridge, MA: MIT Press.
Beall, Jc, 2000, “On truthmakers for negative truths”, Australasian Journal of Philosophy, 78: 264–268.
Beall, Jc, 2005, “Transparent disquotationalism”, in Deflationism and Paradox, Jc Beall and B. Armour-Garb (eds.), Oxford: Oxford University Press, 7–22.
Beebee, Helen and Dodd, Julian (eds.), 2005, Truthmakers: The Contemporary Debate, Oxford: Clarendon Press.
Blackburn, Simon and Simmons, Keith (eds.), 1999, Truth, Oxford: Oxford University Press.
Blanshard, Brand, 1939, The Nature of Thought, London: George Allen and Unwin.
Brown, Jessica and Cappelen, Herman (eds.), 2011, Assertion: New Philosophical Essays, Oxford: Oxford University Press.
Burgess, Alexis G. and Burgess, John P. (eds.), 2011, Truth, Princeton: Princeton University Press.
Candlish, Stewart, 1999, “Identifying the identity theory of truth”, Proceedings of the Aristotelian Society, 99: 233–240.
Cartwright, Richard, 1987, “A neglected theory of truth”, in Philosophical Essays, Cambridge, MA: MIT Press, 71–93.
David, Marian, 1994, Correspondence and Disquotation, Oxford: Oxford University Press.
David, Marian, 2001, “Truth as identity and truth as correspondence”, in The Nature of Truth, M. P. Lynch (ed.), Cambridge, MA: MIT Press, 683–704.
Davidson, Donald, 1967, “Truth and meaning”, Synthese, 17: 304–323. Reprinted in Davidson (1984).
Davidson, Donald, 1969, “True to the facts”, Journal of Philosophy, 66: 748–764. Reprinted in Davidson (1984).
Davidson, Donald, 1973, “Radical interpretation”, Dialectica, 27: 313–328. Reprinted in Davidson (1984).
Davidson, Donald, 1977, “Reality without reference”, Dialectica, 31: 247–253. Reprinted in Davidson (1984).
Davidson, Donald, 1984, Inquiries into Truth and Interpretation, Oxford: Oxford University Press.
Davidson, Donald, 1986, “A coherence theory of truth and knowledge”, in Truth and Interpretation, E. Lepore (ed.), Oxford: Basil Blackwell, 307–319. Reprinted with afterthoughts in Davidson (2001).
Davidson, Donald, 1990, “The structure and content of truth”, Journal of Philosophy, 87: 279–328. Reprinted in revised form in Davidson (2005).
Davidson, Donald, 2001, Subjective, Intersubjective, Objective, Oxford: Oxford University Press.
Davidson, Donald, 2005, Truth and Predication, Cambridge, MA: Harvard University Press.
Devitt, Michael, 1984, Realism and Truth, Oxford: Blackwell.
Dodd, Julian, 2000, An Identity Theory of Truth, New York: St. Martin's Press.
Dummett, Michael, 1959, “Truth”, Proceedings of the Aristotelian Society, 59: 141–162. Reprinted in Dummett (1978).
Dummett, Michael, 1976, “What is a theory of meaning? (II)”, in Truth and Meaning, G. Evans and J. McDowell (eds.), Oxford: Clarendon Press. Reprinted in Dummett (1993).
Dummett, Michael, 1978, Truth and Other Enigmas, Cambridge, MA: Harvard University Press.
Dummett, Michael, 1983, “Language and truth”, in Approaches to Language, Roy Harris (ed.), Oxford: Pergamon, 95–125. Reprinted in Dummett (1993).
Dummett, Michael, 1991, The Logical Basis of Metaphysics, Cambridge, MA: Harvard University Press.
Dummett, Michael, 1993, The Seas of Language, Oxford: Oxford University Press.
Etchemendy, John, 1988, “Tarski on truth and logical consequence”, Journal of Philosophical Logic, 43: 51–79.
Field, Hartry, 1972, “Tarski's theory of truth”, Journal of Philosophy, 69: 347–375.
Field, Hartry, 1986, “The deflationary conception of truth”, in Fact, Science and Value, C. Wright and G. MacDonald (eds.), Oxford: Basil Blackwell, 55–117.
Field, Hartry, 1994, “Deflationist views of meaning and content”, Mind, 103: 249–285.
Fox, John, 1987, “Truthmaker”, Australasian Journal of Philosophy, 65: 188–207.
Frege, Gottlob, 1918–19, “Der gedanke”, Beiträge zur Philosophie des deutschen Idealismus, 1: 58–77. Translated by P. Geach and R. H. Stoothoff as “Thoughts” in Frege (1984).
Frege, Gottlob, 1984, Collected Papers on Mathematics, Logic, and Philosophy, Oxford: Basil Blackwell. Edited by B. McGuiness.
Fumerton, Richard, 2002, Realism and the Correspondence Theory of Truth, New York: Rowman and Littlefield.
Glanzberg, Michael, 2003a, “Against truth-value gaps”, in Liars and Heaps, Jc Beall (ed.), Oxford: Oxford University Press, 151–194.
Glanzberg, Michael, 2003b, “Minimalism and paradoxes”, Synthese, 135: 13–36.
Glanzberg, Michael, 2013, “The concept of truth”, in Companion to Donald Davidson, E. Lepore and K. Ludwig (eds.), Boston: Wiley-Blackwell, in press.
Greenough, Patrick and Lynch, Michael P. (eds.), 2006, Truth and Realism, Oxford: Oxford University Press.
Grover, Dorothy L., Kamp, Joseph L., and Belnap, Nuel D., 1975, “A prosentential theory of truth”, Philosophical Studies, 27: 73–125.
Gupta, Anil, 1993, “A critique of deflationism”, Philosophical Topics, 21: 57–81.
Haack, Susan, 1976, “The pragmatist theory of truth”, British Journal for the Philosophy of Science, 27: 231–249.
Halbach, Volker, 1999, “Disquotationalism and infinite conjunctions”, Mind, 108: 1–22.
Hartshorne, C., Weiss, P., and Burks, A. W. (eds.), 1931–58, The Collected Papers of Charles Sanders Peirce, vol. 1–8, Cambridge, MA: Harvard University Press.
Heck, Richard, 1997, “Tarski, truth, and semantics”, Philosophical Review, 106: 533–554.
Higginbotham, James, 1986, “Linguistic theory and Davidson's program in semantics”, in Truth and Interpretation, E. Lepore (ed.), Oxford: Basil Blackwell, 29–48.
Higginbotham, James, 1989, “Knowledge of reference”, in Reflections on Chomsky, A. George (ed.), Oxford: Basil Blackwell, 153–174.
Higginbotham, James, 1992, “Truth and understanding”, Philosophical Studies, 65: 3–16.
Hornsby, Jennifer, 2001, “Truth: The identity theory”, in The Nature of Truth, M. P. Lynch (ed.), Cambridge: MIT Press, 663–681.
Horwich, Paul, 1990, Truth, Oxford: Basil Blackwell.
Hylton, Peter, 1990, Russell, Idealism and the Emergence of Analytic Philosophy, Oxford: Oxford University Press.
Jackson, Frank, 2006, “Representation, truth and realism”, The Monist, 89: 50–62.
James, William, 1907, “Pragmatism's conception of truth”, in Pragmatism, New York: Longmans, 197–236.
Joachim, H. H., 1906, The Nature of Truth, Oxford: Clarendon Press.
Kaplan, David, 1989, “Demonstratives”, in Themes From Kaplan, J. Almog, J. Perry, and H. Wettstein (eds.), Oxford: Oxford University Press, 481–563. First publication of a widely circulated manuscript dated 1977.
Ketland, Jeffrey, 1999, “Deflationism and Tarski's paradise”, Mind, 108: 69–94.
Kirkham, Richard L., 1992, Theories of Truth: A Critical Introduction, Cambridge, MA: MIT Press.
Künne, Wolfgang, 2003, Conceptions of Truth, Oxford: Clarendon Press.
Lackey, Douglas (ed.), 1973, Essays in Analysis, New York: George Braziller.
Leeds, Stephen, 1978, “Theories of reference and truth”, Erkenntnis, 13: 111–129.
Lynch, Michael P., 2001a, “A functionalist theory of truth”, in The Nature of Truth, M. P. Lynch (ed.), Cambridge, MA: MIT Press, 723–749.
Lynch, Michael P. (ed.), 2001b, The Nature of Truth: Classical and Contemporary Perspectives, Cambridge, MA: MIT Press.
Lynch, Michael P., 2009, Truth as One and Many, Oxford: Clarendon Press.
McDowell, John, 1976, “Truth-conditions, bivalence, and verificationism”, in Truth and Meaning, G. Evans and J. McDowell (eds.), Oxford: Clarendon Press, 42–66.
McDowell, John 1994, Mind and World, Cambridge, MA: Harvard University Press.
Misak, Cheryl J., 2004, Truth and the End of Inquiry, Oxford: Oxford University Press.
Moore, George Edward, 1899, “The nature of judgment”, Mind, 8: 176–193.
Moore, George Edward, 1902, “Truth”, in Dictionary of Philosophy and Psychology, J. M. Baldwin (ed.), London: Macmillan, vol. 2, 716–718.
Moore, George Edward, 1953, Some Main Problems of Philosophy, London: George Allen and Unwin.
Mulligan, Kevin, Simons, Peter, and Smith, Barry, 1984, “Truth-makers”, Philosophy and Phenomenological Research, 44: 287–321.
Neale, Stephen, 2001, Facing Facts, Oxford: Clarendon Press.
Parsons, Josh, 1999, “There is no ‘truthmaker’ argument against nominalism”, Australasian Journal of Philosophy, 77: 325–334.
Patterson, Douglas, 2012, Alfred Tarski: Philosophy of Language and Logic, New York: Palgrave Macmillan.
Putnam, Hilary, 1978, Meaning and the Moral Sciences, London: Routledge and Kegan Paul.
Putnam, Hilary, 1981, Reason, Truth and History, Cambridge: Cambridge University Press.
Putnam, Hilary, 1985–86, “A comparison of something with something else”, New Literary History, 17: 61–79. Reprinted in Putnam (1994).
Putnam, Hilary, 1994, Words and Life, Cambridge, MA: Harvard University Press.
Quine, W. V. O., 1960, Word and Object, Cambridge, MA: MIT Press.
Quine, W. V. O., 1970, Philosophy of Logic, Cambridge, MA: Harvard University Press.
Ramsey, Frank P., 1927, “Facts and propositions”, Aristotelian Society Supp. Vol., 7: 153–170. Reprinted in Ramsey (1931).
Ramsey, Frank P., 1931, The Foundations of Mathematics and Other Logical Essays, London: Routledge and Kegan Paul.
Rorty, Richard, 1986, “Pragmatism, Davidson and truth”, in Truth and Interpretation, E. Lepore (ed.), Oxford: Basil Blackwell, 333–355.
Ross, W. D. (ed.), 1928, The Works of Aristotle Translated into English, Oxford: Clarendon Press, second edn.
Russell, Bertrand, 1903, Principles of Mathematics, Cambridge: Cambridge University Press, first edn.
Russell, Bertrand, 1904, “Meinong's theory of complexes and assumptions I, II, III”, Mind, 13: 204–219, 336–354, 509–524. Reprinted in Lackey (1973).
Russell, Bertrand, 1910a, “The monistic theory of truth”, in Philosophical Essays, London: George Allen and Unwin, 131–146.
Russell, Bertrand, 1910b, “On the nature of truth and falsehood”, in Philosophical Essays, London: George Allen and Unwin, 147–159.
Russell, Bertrand, 1912, The Problems of Philosophy, London: Oxford University Press.
Russell, Bertrand, 1956, “The philosophy of logical atomism”, in Logic and Knowledge, R. C. Marsh (ed.), London: George Allen and Unwin, 177–281. Originally published in The Monist in 1918.
Soames, Scott, 1984, “What is a theory of truth?”, Journal of Philosophy, 81: 411–429.
Soames, Scott, 1992, “Truth, meaning, and understanding”, Philosophical Studies, 65: 17–35.
Strawson, Peter F., 1949, “Truth”, Analysis, 9: 83–97.
Strawson, Peter F., 1950, “Truth”, Aristotelian Society Supp. Vol., 24. Reprinted in Strawson (1971).
Strawson, Peter F., 1971, Logico-Linguistic Papers, London: Methuen.
Tarski, Alfred, 1931, “Sur les ensembles définissables de nombres réels. I.”, Fundamenta Mathematicae, 17: 210–239. References are to the translation by J. H. Woodger as “On definable sets of real numbers. I” in Tarski (1983).
Tarski, Alfred, 1935, “Der Wahrheitsbegriff in den formalisierten Sprachen”, Studia Philosophica, 1: 261–405. References are to the translation by J. H. Woodger as “The concept of truth in formalized languages” in Tarski (1983).
Tarski, Alfred, 1944, “The semantic conception of truth”, Philosophy and Phenomenological Research, 4: 341–375.
Tarski, Alfred, 1983, Logic, Semantics, Metamathematics, Indianapolis: Hackett, second edn. Edited by J. Corcoran with translations by J. H. Woodger.
Taylor, Barry, 1976, “States of affairs”, in Truth and Meaning, G. Evans and J. McDowell (eds.), Oxford: Clarendon Press, 263–284.
Vision, Gerald, 2004, Veritas: The Correspondence Theory and Its Critics, Cambridge, MA: MIT Press.
Walker, Ralph C. S., 1989, The Coherence Theory of Truth, London: Routledge.
Williamson, Timothy, 1996, “Knowing and asserting”, Philosophical Review, 104: 489–523.
Wittgenstein, Ludwig, 1922, Tractatus Logico-Philosophicus, New York: Harcourt, Brace and Co.
Wright, Crispin, 1976, “Truth-conditions and criteria”, Aristotelian Society Supp. Vol., 50: 217–245. Reprinted in Wright (1993).
Wright, Crispin, 1982, “Anti-realist semantics: The role of criteria”, in Idealism: Past and Present, G. Vesey (ed.), Cambridge: Cambridge University Press, 225–248. Reprinted in Wright (1993).
Wright, Crispin, 1992, Truth and Objectivity, Cambridge, MA: Harvard University Press.
Wright, Crispin, 1993, Realism, Meaning and Truth, Oxford: Blackwell, second edn.
Wright, Crispin, 1999, “Truth: A traditional debate reviewed”, Canadian Journal of Philosophy, 24: 31–74
Young, James O., 2001, “A defense of the coherence theory of truth”, Journal of Philosophical Research, 26: 89–101.
Open access to the SEP is made possible by a world-wide funding initiative.
Please Read How You Can Help Keep the Encyclopedia Free
The SEP would like to congratulate the National Endowment for the Humanities on its 50th anniversary and express our indebtedness for the five generous grants it awarded our project from 1997 to 2007. Readers who have benefited from the SEP are encouraged to examine the NEH’s anniversary page and, if inspired to do so, send a testimonial to neh50@neh.gov.Relativism
Relativism, roughly put, is the view that truth and falsity, right and wrong, standards of reasoning, and procedures of justification are products of differing conventions and frameworks of assessment and that their authority is confined to the context giving rise to them. More precisely, “relativism” covers views which maintain that—at a high level of abstraction—at least some class of things have the properties they have (e.g., beautiful, morally good, epistemically justified) not simpliciter, but only relative to a given framework of assessment (e.g., local cultural norms, individual standards), and correspondingly, that the truth of claims attributing these properties holds only once the relevant framework of assessment is specified or supplied. Relativists characteristically insist, furthermore, that if something is only relatively so, then there can be no framework-independent vantage point from which the matter of whether the thing in question is so can be established.
Relativism has been, in its various guises, both one of the most popular and most reviled philosophical doctrines of our time. Defenders see it as a harbinger of tolerance and the only ethical and epistemic stance worthy of the open-minded and tolerant. Detractors dismiss it for its alleged incoherence and uncritical intellectual permissiveness. Debates about relativism permeate the whole spectrum of philosophical sub-disciplines. From ethics to epistemology, science to religion, political theory to ontology, theories of meaning and even logic, philosophy has felt the need to respond to this heady and seemingly subversive idea. Discussions of relativism often also invoke considerations relevant to the very nature and methodology of philosophy and to the division between the so-called “analytic and continental” camps in philosophy. And yet, despite a long history of debate going back to Plato and an increasingly large body of writing, it is still difficult to come to an agreed definition of what, at its core, relativism is, and what philosophical import it has. This entry attempts to provide a broad account of the many ways in which “relativism” has been defined, explained, defended and criticized.
4. Varieties of Relativism
5. New Relativism
The label “relativism” has been attached to a wide range of ideas and positions which may explain the lack of consensus on how the term should be defined. The profusion of the use of the term “relativism” in contemporary philosophy means that there is no ready consensus on any one definition. Here are three prominent, but not necessarily incompatible, approaches:
A standard way of defining and distinguishing between different types of relativism is to begin with the claim that a phenomenon x (e.g., values, epistemic, aesthetic and ethical norms, experiences, judgments, and even the world) is somehow dependent on and co-varies with some underlying, independent variable y (e.g., paradigms, cultures, conceptual schemes, belief systems, language). The type of dependency relativists propose has a bearing on the question of definitions. Let us take some examples.
Each of (a)–(c) exhibits a relation of dependence where a change in the independent variable y will result in variations in the dependent variable x. However, of the three examples cited above, normally only (a) and (b) are deemed relevant to philosophical discussions of relativism, for one main attraction of relativism is that it offers a way of settling (or explaining away) what appear to be profound disagreements on questions of value, knowledge and ontology and the relativizing parameter often involves people, their beliefs, cultures or languages.
The co-variance definition proceeds by asking the dual questions: (i) what is relativized? and (ii) what is it relativized to? The first question enables us to distinguish forms of relativism in terms of their objects, for example, relativism about truth, goodness, beauty, and their subject matters, e.g., science, law, religion. The answer to the second question individuates forms of relativism in terms of their domains or frames of reference—e.g., conceptual frameworks, cultures, historical periods, etc. Such classifications have been proposed by Haack (1996), O’Grady (2002), Baghramian (2004), and Swoyer (2010). The following table classifies different relativistic positions according what is being relativized, or its objects, and what is being relativized to, or its domains.
N/A
N/A
N/A
N/A
New Relativism
Table 1 reflects the availability of fine-grained distinctions between different forms of relativism as functions of both objects (x) and domains (y) of relativization. In practice, however, much contemporary discussions of relativism focus on subjectivism, historicism, cultural relativism and conceptual relativism, along the axis of y, and cognitive/epistemic relativism, ethical or moral relativism and aesthetic relativism, along the axis of x. As we shall see in §5, New Relativism, where the objects of relativization (in the left column) are utterance tokens expressing claims about cognitive norms, moral values, etc. and the domain of relativization is the standards of an assessor, has also been the focus of much recent discussion.
A second approach to defining relativism casts its net more widely by focusing primarily on what relativists deny. Defined negatively, relativism amounts to the rejection of a number of interconnected philosophical positions. Traditionally, relativism is contrasted with:
Absolutism, the view that at least some truths or values in the relevant domain apply to all times, places or social and cultural frameworks. They are universal and not bound by historical or social conditions. Absolutism is often used as the key contrast idea to relativism.
Objectivism or the position that cognitive, ethical and aesthetic norms and values in general, but truth in particular, are independent of judgments and beliefs at particular times and places, or in other words they are (non-trivially) mind-independent. The anti-objectivist on the other hand, denies that there is such thing as simply being “true’, “good”, “tasty” or “beautiful” but argues that we can coherently discuss such values only in relation to parameters that have something to do with our mental lives.
Monism or the view that, in any given area or topic subject to disagreement, there can be no more than one correct opinion, judgment, or norm. The relativist often wishes to allow for a plurality of equally valid values or even truths.
Realism, when defined in such a way that it entails both the objectivity and singularity of truth, also stands in opposition to relativism.
Relativism in this negative sense is a prominent feature of the work of the relativists malgré eux such as Richard Rorty (1979) and Jacques Derrida (1974). What justifies the appellation “relativist”, rather than “skeptic”, is not only these philosophers’ suspicion of the possibility of objectivity but their insistence on the role of socio-historical, psychological and textual contexts in accounts of “truth” and “knowledge” claims.
What also binds various forms of relativism is an underlying idea that claims to truth, knowledge or justification have an implicit, maybe even unnoticed, relationship to a parameter or domain. Gilbert Harman (1975), Robert Nozick (2001), and Crispin Wright (2008) are among the philosophers to propose versions of this thesis. Paul Boghossian summarizes the position this way:
the relativist about a given domain, D, purports to have discovered that the truths of D involve an unexpected relation to a parameter. (Boghossian 2006b: 13)
To take an example, moral relativism, according to this approach, is the claim that the truth or justification of beliefs with moral content is relative to specific moral codes. So the sentence “It is wrong to sell people as slaves” is elliptical for “It is wrong to sell people as slaves relative to the moral code of …”. Or alternatively, as Kusch (2010) formulates the idea on behalf of the relativist: “It is wrong-relative-to-the-moral-code-of-…” to sell people as slaves. The resulting sentence(s) turns out to be true, according to the relativist, depending on how we fill in the “…”. So, “It is wrong to sell people as slaves” comes out true relative to the moral code of the United Nations Charter of Human Rights and false relative to the moral code of ancient Greece. The justifying thought is that judgments about the morality of slavery, or any other ethical issue, are based on differing conventions, and there is no universal or objective criterion for choosing among differing competing socio-historically constituted conventions. Moreover, as a corollary of this approach, there is no truth of the matter of whether it is wrong to sell people as slaves, independently of the specification of some standard. Thus on the hidden parameter account, a consequence is that the relevant claims will be true, if at all, only relative to some parameter.
This particular approach to relativism is often expressed in explicitly linguistic terms and is favored by philosophers interested in the semantic dimensions of relativism. The claim is that predicates such as “is true”, “is rational”, “is right”, “is good” etc. in a natural language have the apparent logical form of one-place predicates, but their surface grammatical form is misleading, because upon further investigation they prove to be elliptical for two-place predicates such as “is true relative to…”, “is right according to”, etc., (of course, where such predicates are available). Relativism, according to this approach, is the claim that a statement of the form “A is P” within a given domain (e.g., science, ethics, metaphysics, etc.) is elliptical for the statement “A is P in relation to C”, where A stands for an assertion, belief, judgment or action, P stands for a predicate such as “true”, “beautiful”, “right”, “rational”, “logical”, “known” etc., and C stands for a specific culture, epistemic framework, language, belief-system, etc.
The three approaches outlined here are compatible and sometimes complementary. A relativistic thesis as captured by the approach outlined in §1.1 for instance, will also be relativistic in at least one of the negative senses outlined in §1.2. Moreover, as we shall see, since various subdivisions of relativism appearing in table 1 could, with appropriate modification, be expressed as claims about the truth of sentences falling in a particular domain, then the hidden predicate approach is applicable to them as well. (See §5 for a more detailed way to give expression to the hidden parameter insight within recent work in the philosophy of language.)
A further consideration relevant to defining relativism is its scope.
The basic idea of global relativism is captured by the oft-repeated slogan “all is relative”. The claim is that all beliefs, regardless of their subject matter, are true only relative to a framework or parameter. Local relativists, by contrast, limit their claim of relativization to self-contained areas of discourse, e.g., ethics, aesthetics and taste but argue that, for instance, scientific truths are not suitable candidates for a relativistic understanding (but also see §4.4.3). It is worth noting that local relativisms, typically, are endorsed on the basis of philosophical considerations connected to the kinds of features that are claimed to be relative (e.g., aesthetic standards, epistemic principles), or relatedly, semantic considerations to do with discourse where such features are attributed. Global relativism, by contrast, seems to be motivated not so much by considerations about particular features, but by more general considerations about truth itself.
As we will see, global relativism is open to the charge of inconsistency and self-refutation, for if all is relative, then so is relativism. Local relativism is immune from this type of criticism, as it need not include its own statement in the scope of what is to be relativized. Unsurprisingly, local rather than global relativism is much more common within contemporary debates. There is also a question mark on whether we could apply relativism to all truths in a completely unrestricted way; for instance, Kölbel (2011) has argued that claims such as “an object is beautiful and not beautiful” and “an object is identical to itself” have to be excluded.
A further distinction is made between weak and strong forms of relativism. Strong relativism is the claim that one and the same belief or judgment may be true in one context (e.g., culture or framework or assessment) and false in another. Weak relativism is the claim that there may be beliefs or judgments that are true in one framework but not true in a second simply because they are not available or expressible in the second. Bernard Williams’ “relativism of distance” (Williams 1985) and Ian Hacking’s (1982) defense of variability in styles of reasoning are instances of weak relativism. Williams argues that certain concepts are only available to people who live a particular form of life. These are concepts that are not a part of what Williams calls the “absolute conception of the world” and do not express truths that any rational creature, regardless of her culture, would in principle acknowledge. Truths that require these concepts for their formulation are expressible only in languages whose speakers take part in that particular form of life. Such truths need not be true in a relativized sense—true relative to some parameters, false relative to others; rather, such truths are perspectival: real but visible only from a certain angle, i.e., for people who adopt a certain way of life. This weaker form of relativism, in so far as it denies the universality of certain truth claims, is captured more readily by the negative definition (§1.2) of relativism.
Interest in relativism as a philosophical doctrine goes back to ancient Greece. In more recent decades, however, relativism has also proven popular not only as a philosophical position but also as an idea underwriting a normative—ethical and political-outlook. (see Bloom 1987, in particular the Introduction). A number of philosophical considerations as well as socio-historical developments explain the enduring interest in and the more recent popularity of relativism.
Data regarding diversity of belief systems, conceptual frameworks and ways of life have frequently been used by philosophers and anthropologists alike to give credibility to philosophical arguments for relativism (For example see Hollis & Lukes 1982 and Wilson 1970). The mere fact of empirical diversity does not lead to relativism, but, relativism as a philosophical doctrine, has often been taken as a natural position to adopt in light of empirical diversity, in part, because relativism helps to make sense of such diversity without the burden of explaining who is in error.
Descriptive relativism, an empirical and methodological position adopted by social anthropologists, relies on ethnographic data to highlight the paucity of universally agreed upon norms, values and explanatory frameworks. From polygamy to cannibalism, from witchcraft to science we find major differences between the worldviews and outlooks of individuals and groups. Descriptive relativism is often used as the starting point for philosophical debates on relativism in general and cultural relativism in particular. The observed radical differences among cultures, it is argued, show the need for a relativistic assessment of value systems and conceptual commitments. Some anti-relativist universalists, on the other hand, argue that underlying the apparent individual and cultural differences, there are some core commonalities to all belief systems and socio-cultural outlooks (e.g., Nussbaum 1997). But the relativistically inclined respond by first pointing to the seeming incommensurability of various ethical and conceptual frameworks and the variability of cognitive norms and practices in difference cultures, and then, on this basis, maintain that the so-called “commonalities” belie significant differences. The anti-relativist may concede the point and insist that where such disagreements exist, at most one view is correct and the rest mistaken. But in so far as we are reluctant to impute widespread and systematic error to other cultures, or to our own, relativism remains an attractive option. Descriptive relativism is also central to the brand of relativism advocated by the sociologists of scientific knowledge and other social constructionists who argue that, even in the so-called “hard sciences”, we cannot escape the specter of irresolvable differences and even incommensurability (see §4.4.3).
There is not only a marked diversity of views on questions of right and wrong, truth and falsehood, etc., but more significantly, many disputes arising from such differences seem intractable. There are instances of long-standing disagreement, such that the disputants are very plausibly talking about the same subject matter (thus avoiding incommensurability) and genuinely disagreeing with each other; and yet, no amount of information and debate enables them or us to resolve the disagreement. And moreover, in such cases, it can seem that neither side seems to have made any obvious mistake (see, e.g., Hales 2014).
If well-informed, honest and intelligent people are unable to resolve conflicts of opinion, we should, some relativists argue, accept that all parties to such disputes could be right and their conflicting positions have equal claims to truth, each according to their own perspective or point of view. Their disagreement is faultless (Kölbel 2004; Brogaard 2007; Hales 2014). Many relativistically inclined philosophers, (e.g., Max Kölbel (2004), Wright (2006) and John MacFarlane with terminological qualification (2014: 133–136)) see the presence of faultless disagreements as central to motivating and justifying relativism. The anti-relativists counter that the very notion of a “faultless” disagreement is incompatible with our common understanding of what it means to disagree. It is a hallmark of disagreement, as commonly understood, that the parties involved find fault with the other sides’ views. When people disagree at least one of them is making a mistake or is failing to believe what he or she ought to believe given his or her cognitive aims. Relativism accordingly offers a revisionary account of what it means to disagree (e.g., MacFarlane 2007, 2014; see §5 where the point has been discussed in some detail); but it is not clear if the account can explain what is left of a disagreement to preserve once we allow that both parties to a disagreement could be right (Carter 2013; Dreier 2009).
A sophisticated semantic version of relativism about truth, known as truth-relativism, and alternatively as “new relativism”, has been proposed in recent years and which attempts to deal with some of these issues (e.g., MacFarlane 2014). We will return to this variety of relativism in §5.
A different perspective on the move from disagreement to relativism is offered in recent work by Carol Rovane (2012 and 2013), who rejects the prevailing consensus on what she calls the “disagreement intuition of relativism” in favor of an “alternatives intuition”. According to Rovane, relativism is motivated by the existence of truths that cannot be embraced together, not because they contradict and hence disagree with each other but because they are not universal truths. The example Rovane gives is conflict between a belief that deference to parents is morally obligatory in Indian traditionalist sense and the belief that it is not morally obligatory in the American individualist sense. Each belief is true within its particular ethical framework but the two beliefs cannot be conjoined or embraced together. Or more generally, it is not possible both to exercise full autonomy and simultaneously be dedicated to one’s community and its norms. The underlying thought, for Rovane, is that not all truth-value-bearers are in logical relations to one another, that there are many noncomprehensive bodies of truths that cannot be conjoined.
What the two approaches have in common is the claim that truth and justification are plural, that there could be more than one correct account of how things stand in at least some domains and their correctness has to be decided relative to a framework of context of assessment.
Additionally, the relativistically inclined find further support for their position in the contention that there is no meta-justification of our evaluative or normative systems, that all justifications have to start and end somewhere (see Sankey 2010 and 2011) and that there are no higher-order or meta-level standards available for adjudicating clashes between systems in a non-question begging way. Steven Hales, for instance, argues that faced with disagreement and given non-neutrality, relativism is the most viable non-skeptical conclusion to draw (Hales 2006: 98; 2014). Similar considerations apply to attempts to anchor beliefs on secure foundations. Various intellectual developments, leading to loss of old certainties in the scientific and social arena have strengthened the appeal of this point. The scientific revolution of the early 20th century, brought about by, for instance, the advent of Relativity Theory and Quantum Mechanics and the loss of faith in lasting religious or political truths (Marxism in particular), as well as the failure of foundationalist philosophical programs have been used in arguments to vindicate relativistic views (for relativism about science see §4.4.3). The relativists often argue that justifications are not only perspectival but also interest-relative and there is no neutral or objective starting ground for any of our beliefs (see Seidel 2014; Carter 2015: ch. 4 and Siegel in Hales 2011: 205 for criticisms of this type of justification of relativism).
Pierre Durham’s (1861–1916) thesis of underdetermination of theory by data, the claim that empirical evidence alone is not adequate for providing justification for any given scientific theory, has played an important role in building up a case both for conceptual relativism (§4.2) and for constructionism and relativism about science (§4.4.2 and §4.4.3). According to the underdetermination thesis, incompatible theories can be consistent with available evidence. Relativism threatens whenever conflicting theories or views appear to have equal claim to truth or justification. The relativistically inclined use underdetermination to claim that evidence could be brought to justify opposing explanations and justification. The underdetermination thesis is also used to highlight the absence of neutral starting points for our beliefs. Choices between incompatible but equally well-supported rival theories, it is argued, are often made based on interests and local preferences rather than neutral universal grounds.
Relativists argue that beliefs and values get their justification or truth only relative to specific epistemic systems or practices (see Kusch forthcoming). Strong support for this view has come from social scientists and cultural theorist who focus on the socio-cultural determinants of human beliefs and actions. The social sciences, from their very inception, were hospitable to relativism. Indeed, August Comte, the father of sociology, claimed that a strength of “positive sociology” was its “tendency to render relative the ideas which were at first absolute” (Comte 1976 [1830–42]: 89). Comte also was responsible for the battle cry “all is relative”, but immediately and no doubt self-consciously contradicted himself by adding “and that’s the only absolute”. Other social scientists, under the influence of Karl Marx (1818–1883), Max Weber (1864–1920), and Wilhelm Dilthey (1833–1911), have given credence to the idea that human beliefs and actions could be understood and evaluated only relative to their social and economic background and context. Beliefs, desires and actions, the argument goes, are never independent of a background of cultural presuppositions, interests and values. We cannot step out of our language, culture and socio-historical conditions to survey reality from an Archimedean vantage point. Even perceptions are “theory-laden” and could vary between linguistic and cultural groupings. The sociological view that beliefs are context-dependent, in the sense that their context helps explain why people have the beliefs they do, has also been used to support what is sometimes called “social” or “sociological relativism” or the view that truth or correctness is relative to social contexts because we can both understand and judge beliefs and values only relative to the context out of which they arise. Context-dependence is also used to explain empirical observations of diversity in beliefs and values; different social contexts, the argument goes, give rise to differing, possibly incompatible norms and values.
Advocates of relativism, particularly outside philosophical circles, often cite tolerance as a key normative reason for becoming a relativist. On this rationale, all ways of life and cultures are worthy of respect in their own terms, and it is a sign of unacceptable ethnocentrism to presume that we could single out one outlook or point of view as objectively superior to others. The Principle of Tolerance acquires an overtly socio-political form in the hand of Paul Feyerabend who maintains that “A free society is a society in which all traditions are given equal rights” (Feyerabend1978: 30). Anti-relativists find this normative advocacy of relativism unconvincing for two key kinds of reasons. Some anti-relativists (e.g., Rachels 2009) often appeal to cases at the limits (e.g., toleration of heinous crimes) to show the thesis to be implausibly overpermissive (see §4.5). Others argue that if all values are relative then tolerance and maximizing freedom are valuable only to those who have already embraced them. Relativists counter that they are not defending a global version of relativism regarding all truths and justification but local versions concerning the ethics and politics of belief and the usefulness of relativism in our attempt to become better, or at least more flexible and less dogmatic, thinkers and more tolerant citizens (e.g., Feyerabend 1978: 82–84). The anti-relativists counter-argue that even if we grant that political tolerance is an important value, and that accepting relativism would promote it, we should never adopt philosophical views about the nature of truth or justification simply because of their assumed good moral or political consequences. Second, and more importantly: political toleration does not require the strong and doctrine of philosophical relativism. Increased awareness of diversity together with an awareness of the historical contingency of one’s own convictions will promote political toleration just as effectively. As Knobe and Nichols point out, simply being made aware of radically different view points can lead to a:
…crisis akin to that of the [Christian] child confronted with religious diversity… For the discovery of religious diversity can prompt the thought that it’s in some sense accidental that one happens to be raised in a Christian household rather than a Hindu household. This kind of arbitrariness can make the child wonder whether there’s any reason to think that his religious beliefs are more likely to be right than those of the Hindu child (Knobe & Nichols 2007: 11)
The English term “relativism” came into usage only in the 19th Century. John Grote was probably the first to employ it when in Exploratio Philosophica (1865) he wrote:
The notion of the mask over the face of nature is…. what I have called “relativism”. If “the face of nature” is reality, then the mask over it, which is what theory gives us, is so much deception, and that is what relativism really comes to. (Grote 1865: I.xi, 229).
Its German counterpart, “Relativismus”, has a longer history. Wilhelm Traugott Krug, who succeeded Kant in the University of Konisberg in his philosophical lexicon, defines it as
the assumption that everything which we experience and think (the self, the idea of reason, truth, morality, religion etc.) is only something relative, and therefore has no essential endurance and no universal validity. (Krug 2010 [1838]: 224)
Although the term “relativism” is of recent coinage, doctrines and positions, with some of the hallmarks of contemporary relativism, date back to the very beginnings of Western philosophy. Protagoras of Abdera (c. 490–420 BC) is often considered the first overt champion of relativism, and his dictum
Man (anthrôpos) is the measure (metron) of all things (chrêmatôn), of the things which are, that they are, and of the things which are not, that they are not (tôn men ontôn hôs esti, tôn de mê ontôn hôs ouk estin) (from Plato’s Theaetetus 152a 2–4)
its first battle-cry. According to Plato, Protagoras thought:
Each thing appears (phainesthai) to me, so it is for me, and as it appears to you, so it is for you—you and I each being a man. (Theaetetus 152a 6–8)
For instance, the same wind could be cold to one person and hot to another. The extent to which Protagoras’s view, or at least what comes down to us from Plato, amounts to genuine relativism remains somewhat controversial. As Burnyeat (1976b: 172) notes, Sextus Empiricus thought—though Burnyeat thinks mistakenly—that the Protagorean measure doctrine was to be understood as the subjectivist thesis that every appearance is true (simpliciter). This kind of radical subjectivism, though, quickly can be shown to turn on itself: it can appear that the thesis that “every appearance is true” is false. And so this radical subjectivist interpretation, regardless of whether it is accurate, is as Sextus had thought, untenable. However, Plato also ascribes a social or ethical dimension to Protagorean relativism which seem to go beyond individualistic subjectivism. In Theaetetus 172a 2–6 he says
what may or may not fittingly be done, of just and unjust, of what is sanctioned by religion and what is not; and here the theory may be prepared to maintain that whatever view a city takes on these matters and establishes as its law or convention, is truth and fact for that city. In such matters, neither any individual nor any city can claim superior wisdom. [emphasis added]
Plato’s attempted refutation of Protagoras, known as peritrope or “turning around”, is the first of the many attempts to show that relativism is self-refuting.
Protagorean relativism directly influenced the Pyrrhonian Skeptics, who saw the “man is the measure” doctrine as a precursor to their brand of skepticism. Sextus Empiricus, for instance, in his “Relativity Mode” states that judgments and observations are relative to the person who makes them, to their context as well as the object being observed and goes on to say,
since we have established in this way that everything is relative (pros ti), it is clear then that we shall not be able to say what an existing object is like in its own nature and purely, but only what it appears to be like relative to something. (Sextus Empiricus PH I 140)
But the conclusion he draws favors skepticism rather than relativism as understood in modern philosophy, for he concludes, “It follows that we must suspend judgment about the nature of objects” (ibid.).
Glimpses of relativistic thinking were in evidence in Boethius (480–524) (see Marenbon 2003) as well as in the double truth doctrine, or the view that religion and philosophy are separate and at times conflicting sources of truth, originally found in Averroes (1126–1198) and the 13th century Latin Averroists. However, the dominant belief in a singular and absolute revealed truth within a Christian framework, on the whole, made the medieval period inhospitable to relativism. There was a renewed interest in both relativism and skepticism at the inception of modern philosophy inspired, in part, by Latin translations of Sextus Empiricus in the 16th century. Michel de Montaigne’s work (1533–1592), in common with others sympathetic towards relativism, ancient or contemporary, relies on accounts of faraway cultures to argue that “we have no other criterion of truth or right-reason than the example and form of the opinion and customs of our own country” (Montaigne 1991 [1580]: 152) (but also see Fricker 2013 for a dissenting view). His advocacy of toleration, even for the cannibal, paved the way for not only the acceptance but the valorization of idealized versions of alien creeds and distant cultures by Enlightenment figures such as Rousseau (1712–1778), Voltaire (1694–1778), Diderot (1713–1784), Montesquieu (1689–1755) and Condorcet (1743–1794), who in turn, were instrumental in establishing an intellectual climate hospitable to cultural relativism. These authors were also the first to explore the idea of viewing one’s culture from an outsider’s point of view and using this external perspective as a vehicle to criticize local customs and norms. To take just one example, Diderot, in his “Supplement to the Voyage of Bougainville”, tells us that the Tahitian is mild, innocent, and happy while civilized people are corrupt, vile, and wretched; the natives live according to customs and rules that vary greatly from the Western ones. They do not possess private property or operate their affairs based on egalitarian principles, and they exercise sexual freedom not accepted in “civilized societies”. Diderot accordingly opposes the European mission of civilizing the natives, and despite his belief in a common human nature, he advocates the relativistic sounding maxim to
be monks in France and savages in Tahiti. Put on the costume of the country you visit, but keep the suit of clothes you will need to go home in. (Diderot 1956 [1772]: 228 in Baghramian 2010: 37)
Discussions of relativism in the 19th century had two sources (see Gardiner 1981). On the one hand, figures from the so-called Counter-Enlightenment, a philosophical movement which arose in the late 18th century and the early 19th century in opposition to the Enlightenment, Johann Georg Hamann (1730–1788), Johann Gottfried Herder (1744–1803), Wilhelm von Humboldt (1767–1835) emphasized the diversity of languages and customs and their role in shaping human thought. Hamann’s views on language, for instance, foreshadow contemporary conceptual and epistemic relativism. He maintained that language is the “instrument and criterion of reason” as well as the source of all the confusions and fallacies of reason. Furthermore, the rules of rationality are embedded within language, which in turn, is governed by local norms of custom and use (Hamann 1967 [1759]). Relativism ensues because languages and their rules of rationality vary a great deal. Herder, on the other hand, not only railed against the rational, universalizing and science-oriented ethos of the Enlightenment but, much like later relativists, also argued that different nations and epochs have their distinct preferences in ethical and aesthetics matters as well as their varied conceptions of truth and we are not in a position to adjudicate between them (Herder 2002: 272–358).
The Counter Enlightenment had a significant influence on Hegel, Nietzsche, and Dilthey, who in turn have shaped relativistic thinking in certain strands of continental philosophy, postmodernism and cultural studies. Hamann’s rejection of objectivism was central to Nietzsche’s even more profound recoil from objectivity. And indeed, Nietzsche is possibly the single most influential voice in shaping relativistic sensibilities in 20th century continental philosophy. His declaration that all human conceptions and descriptions, including those advanced by scientists, are
only an interpretation and arrangement of the world (according to our own requirements, if I may say so!)—and not an explanation of the world. (Nietzsche 1996 [1886a]: §14)
and that “there is only a perspective seeing, only a perspective knowing” (Nietzsche 1968 [1886b]: §540), irrespective of how Nietzsche himself intended them, have been taken to express a core contention of relativism that no single account of truth or reality can occupy a privileged position, for such accounts are only one of many perspectives that prevail at a given time in history. We cannot appeal to any facts or standards of evaluation independently of their relation to the perspectives available to us; we can do little more than to insist on the legitimacy of our own perspective and try to impose it on other people through our “will to power”.
A second source was the German post-Kantian and British Idealist discussions of the “relativity of knowledge” taking place in the context of the distinction between being-for-other (für anderes sein) and being-for-itself (fürsichsein)—a distinction influenced by the Kantian idea that all knowledge is ultimately relational because knowledge of the Real or “the thing in itself” is impossible. John Stuart Mill, for instance ascribes to the Kantian William Hamilton the “doctrine of relativity of our human knowledge” because Hamilton, according to Mill, believed that there could be no unconditional or absolute knowledge for all knowledge is dependent on the knowing mind (Mill 1884: 8).
The end of 19th century witnessed the emergence of yet another strand of relativism motivated by empirical-psychological and physiological-interpretations of Kantian categories. The view, known as species relativism, and defended by neo-Kantian psychologists such as Theodore Lipps (1851–1914), holds that the rules of logic are products of the human mind and psychology and therefore may be unique to the human species; different species could have and use different logical principles. The view was vehemently, but quite effectively, attacked by and Frege and Husserl as part of their arguments against what they called “psychologism” and “speciesm” (Kusch 1995: 47). Logic in this approach is identified with the actual thinking processes of individuals or communities and its authority is seen to be local, or relative to the practices of particular epistemic groupings. But Frege and Husserl argued that with such relativization we would lose the ability to distinguish between reasoning correctly and merely seeming to do so.
Finally, the popularity of the very idea of relativism in the 20th century owes something to Einstein’s Special Theory of Relativity (1905) which was to be used both as model and as well as a vindication for various relativistic claims. Gilbert Harman is among the philosophers to use Einsteinian relativity as a model for philosophical versions of relativism. He says:
According to Einstein’s Theory of Relativity even an object’s mass is relative to a choice of spatio-temporal framework. An object can have one mass in relation to one such framework and a different mass in relation to another. …. I am going to argue for a similar claim about moral right and wrong. … I am going to argue that moral right and wrong …. are always relative to a choice of moral framework. (Harman 1996: 3)
The Sapir-Whorf theory of linguistic relativity (see §4.1) is also thought to have been inspired by the Relativity Theory. It is however worth noting that Einstein did not think that the Theory of Relativity supported relativism in ethics or epistemology because, although in his model simultaneity and sameness of place are relative to reference frames, the physical laws expressing such relativity are constant and universal and hence in no sense relative.
The different strands of the intellectual genealogy of relativism have shaped a variety of relativistic doctrines.
Relativism is discussed under a variety of headings some of which have been more prominent in recent philosophical and cultural debates.
Public debates about relativism often revolve around the frequently cited but unclear notion of cultural relativism. The idea that norms and values are born out of conventions can be traced back to the Greek historian Herodotus (c. 484–425 BC), but it is only in the 20th century, and particularly with the advent of social anthropology, that cultural relativism has gained wide currency. Franz Boas, responsible for the founding of social anthropology in the U.S., claimed that
The data of ethnology prove that not only our knowledge but also our emotions are the result of the form of our social life and of the history of the people to whom we belong. (Boas 1940: 636)
Boas’s views became the orthodoxy of anthropology through M. J. Herskovits’ “principle of cultural relativism” stating: “Judgments are based on experience, and experience is interpreted by each individual in terms of his own enculturation” (Herskovits 1955:15).
Since those early days, social anthropologists have come to develop more nuanced approaches to cultural relativism (see for instance Geertz 1993); however, its core tenet, a claim to the equal standing of all cultural perspectives and values which co-vary with their cultural and social background, has remained constant.
Cultural relativists justify their position by recourse to a combination of empirical, conceptual and normative considerations:
(a) The empirical observation that there is a significant degree of diversity in norms, values and beliefs across cultures and historic periods, known as descriptive relativism (see §2.1).
(b) An inductive argument to the effect that failures in previous attempts to resolve disagreements arising from (a) show that there are no universal criteria for adjudicating between differing world-views.
(c) The methodological assumption that human behavior and thought carry the imprint of their cultural and social context such that biology by itself is not sufficient for explaining many of their most important features, especially those with respect to which cultures differ.
(d) The normative principle of a need for tolerance and acceptance towards other points of view (see §2.6), which leads to so-called “normative or prescriptive cultural relativism”, or the positions that cultural relativism is a moral requirement (see also normative moral relativism in §4.5).
Claims (a)–(d) are open to a variety of objections. Some anthropologists and biologists have argued against the empirical assumption of the variability of cultures and have disputed its extent. Kinship, death and its attendant rituals of mourning, birth, the experience of empathy, expressions of sympathy and fear, and the biological needs that give rise to these, are some of the constant elements of human experience that belie the seeming diversity reported by ethnographers (Brown 2004). (c) has also been challenged by naturalistically inclined social scientists who believe that an evolutionary or a biologically informed approach can provide a context-independent, universally applicable theoretical framework for explaining what is common to all cultures, despite their superficial differences. Moreover, Moody-Adams (1997), among others, has argued that cultures are not integrated wholes that could determine uni-directionally the beliefs and experiences of their members; they are porous, riddled with inconsistencies and amenable to change. Finally, (d) is under pressure from the very relativism it advocates. Other critics, Pope Benedict XVI for instance, in his very first homily delivered upon election (18 April 2005), reject and condemn prescriptive cultural relativism as a harbinger of nihilism and an “anything goes” extreme permissiveness.
An influential form of descriptive cultural relativism owes its genesis to linguistics. Benjamin Whorf, inspired by his teacher Edward Sapir, who in turn was supervised by the social anthropologist Fran Boas, used ethnographic evidence from American Indian languages, such as Hopi, to argue that languages mold our views of the world and different languages do so differently, because “we dissect nature along lines laid down by our native languages” (Whorf 1956: 213). In the case of the Hopi, the claim was that their language imposes a conception of time very different from that of the speakers of the Indo-European languages. The so-called Sapir-Whorf hypothesis, and the position known as “linguistic relativity”, became popular in both psychology and social anthropology in the mid 20th century. However, the empirical work by the psychologists Berlin and Key (1969) and later by Eleanor Rosch (1974) pointed to the universality of color terms. The linguistic theories of Noam Chomsky regarding the universality of grammar were also widely taken to have discredited linguistic relativity. Moreover, Malotki (1983) had argued that, contrary to Whorf’s claim, the Hopi language does indeed have tense, as well as units of time, such as days, weeks, months and seasons, and terminology for yesterday and tomorrow. Things have changed recently and there has been a slight swing of the pendulum back in favor of linguistic relativity on the part of so called “neo-Whorfians”. Stephen Levinson, for instance, drawing on experimental evidence, has argued that the frame of reference that underlies any given language shapes our spatial experiences and perceptual modalities (see Gumperz & Levinson 1996). Similar claims have been made about emotions, object representation, and memory. But the claims of linguistic relativity in all these cases are much more modest than Whorf’s original thesis.
Historical relativism, or historicism, is the diachronic version of cultural relativism. As Clifford Geertz points out, cultural and historical relativism are in effect the same doctrine with a core claim that “we cannot apprehend another people’s or another period’s imagination neatly, as though it were our own” (1993: 44). Historicism originated in reaction to the universalist tendencies of the Enlightenment but proved most influential in the social sciences, particularly in the hands of 19th century theorists such as Karl Marx and Max Weber. Oswald Spengler, the then-influential turn-of-the-century German historian and philosopher, also declared that: “There are no eternal truths. Every philosophy is an expression of its time” (Spengler 1918: 58). Karl Mannheim, to whom we owe the sub-discipline of sociology of knowledge, pronounced that historicism is a significant intellectual force that epitomizes our worldview (Weltanschauung).
The historicist principle not only organizes, like an invisible hand, the work of the cultural sciences (Geisteswissenschaften), but also permeates everyday thinking. (Mannheim 1952 [1924]:84)
As we will see (§4.4.3), in more recent times historicist interpretations of science, chiefly those espoused by Thomas Kuhn and Paul Feyerabend, have played a major role in popularizing relativistic interpretations of scientific knowledge.
Conceptual relativism is a narrowly delineated form of relativism where ontology, or what exists, rather than ethical and epistemic norms, is relativized to conceptual schemes, scientific paradigms, or categorical frameworks. In this sense, conceptual relativism is often characterized as a metaphysical doctrine rather than as variant of epistemic or cultural relativism. The underlying rationale for this form of relativism is the anti-realist thesis that the world does not present itself to us ready-made or ready-carved; rather we supply different, and at times incompatible, ways of categorizing and conceptualizing it. Reflection on the connections between mind and the world, rather than empirical observations of historic and cultural diversity, is the primary engine driving various forms of conceptual relativism, but data from anthropology and linguistics are also used in its support. The thought, at least since Kant, is that the human mind is not a passive faculty merely representing an independent reality; rather, it has an active role in shaping, if not constructing, the “real”. The conceptual relativist adds, as Kant did not, that human beings may construct the real in different ways thanks to differences in language or culture.
In the 20th century, a variety of positions sympathetic to conceptual relativism were developed. Quine’s ontological relativity, Nelson Goodman’s “irrealism” with its claim of the plurality of “world-versions” and Hilary Putnam’s conceptual relativity are prominent examples. What these authors have in common is an insistence that there could be more than one “right” way of describing what there is, that incompatible “manuals of translation” and “world-versions” can be equally correct or acceptable.
Quine’s thesis of ontological relativity, probably the most influential of 20th century approaches to conceptual relativity, is expressed both in an epistemic as well as in a stronger metaphysical form. Quine supports an epistemic thesis when he claims that incompatible scientific theories can account equally adequately for the data available to us (his underdetermination thesis) and that “there are various defensible ways of conceiving the world”, (Quine 1992: 102). But his thesis of the indeterminacy of translation makes the stronger claim that different incompatible manuals of translation, or conceptual schemes, can account for one and the same verbal behavior and the indeterminacy resides at the level of facts rather than our knowledge, a position that leads to unavoidable ontological relativity.
Nelson Goodman’s irrealism is an even more radical claim to the effect that the existence of many adequate, and indeed correct, but irreconcilable descriptions and representations of the world shows that there is no such thing as one unique actual world; rather there are many worlds, one for each correct description (e.g., Goodman 1975; cf. Sider 2009). Hilary Putnam disagrees with Goodman’s formulation of relativity with its radical talk of “world-making” but relies on arguments from conceptual plurality to reject metaphysical realism, the view that there is one single correct account of what the world is like. According to Putnam, our most basic metaphysical categories, e.g., objecthood and existence, could be defined variously depending on what conceptual scheme we use. What counts as an object itself, he argues, is determined by and hence is relative to the ontological framework we opt for.
Thomas Kuhn’s highly influential discussion of the governing role of paradigms in science (see §4.4.3) has also been interpreted as a form of conceptual relativism by friends (Kusch 2002) and critics (Davidson 1974) of relativism alike.
The key difficulty facing conceptual relativism is that of formulating the position in a coherent but non-trivial manner. Trivial versions allow that the world can be described in different ways, but make no claims to the incompatibility of these descriptions. The charge of incoherence arises from the claim that there could be genuinely conflicting and equally true accounts or descriptions of one and the same phenomenon. To use an example that is the corner-stone of Hilary Putnam’s conceptual relativity, Putnam claims that the simple question how many objects there are (say on a given table) could be answered variously depending on whether we use “a mereological or a Carnapian, common-sense, method of individuating objects. In circumstances where a Carnapian counts three objects A, B and C, a mereologist will count seven: A, B, C, plus the mereological sum objects A+B, A+C, B+C, A+B+C. As Putnam puts it:
The suggestion … is that what is (by commonsense standards) the same situation can be described in many different ways, depending on how we use the words. The situation does not itself legislate how words like “object”, “entity”, and “exist” must be used. What is wrong with the notion of objects existing “independently” of conceptual schemes is that there are no standards for the use of even the logical notions apart from conceptual choices. (Putnam 1988: 114)
The puzzle is to explain how both the Carnapian and mereological answers to the one and same question could be correct and yet mutually incompatible, for unless we abandon the most fundamental law of logic, the law of non-contradiction, we cannot deem one and the same proposition true and not true. Relativists respond that both answers are correct, each relative to the conceptual scheme it invokes. So, once we accept the insight that there is no Archimedean vantage point for choosing among conflicting frameworks, we no longer face a genuine contradiction. The response invokes, often implicitly, a relativized conception of truth, which as we shall see below, faces its own difficulties.
Relativism about truth, or alethic relativism, at its simplest, is the claim that what is true for one individual or social group may not be true for another, and there is no context-independent vantage point to adjudicate the matter. What is true or false is always relative to a conceptual, cultural, or linguistic framework.
Alethic relativism is the most central of all relativistic positions since other subdivisions of the philosophical theses of relativism—with the possible exception of some narrowly defined versions of conceptual relativism such as Nelson Goodman’s irrealism (see §4.2)—are in principle, reducible to it (Baghramian 2004: 92). For instance, relativism about logic may be restated as a view according to which the standing of logical truths (including truths about consequence relations) is relative to cultures or cognitive schemes. Ethical relativism can be seen as the claim that the truth of ethical judgments, if such truths exist, is relative to context or culture. If truth is to be seen as equally applicable to all areas of discourse and also unitary, rather than domain specific or plural, then alethic relativism is not only a strong form of global relativism but it also entails the denial of the possibility of more local forms of relativism because all localized relativistic claims are also attempts at relativizing truth (seemingly in a particular domain of discourse).
The central claim of the alethic relativism is that “is true”, despite appearances to the contrary, is (at least, in some relevant domains of discourse) not a one-place but a two-place predicate such that “P is true” should correctly be understood as (modulo differences in particular ways of developing this idea) shorthand for “P is true for X”, where X is a culture, conceptual scheme, belief framework, etc. And within the broad camp of alethic relativists, the matter of how it is that which we should opt for “P-is-true-for-X”, rather than “P is true”, simpliciter, is developed in different ways (e.g., see Meiland 1977; MacFarlane 2014: ch. 5; Egan 2007). One shared commitment of relativizing the truth predicate is that claims such as “misfortune is caused by witchcraft” could be true according to the Azande cultural framework and false in the Western scientific framework. One major difficulty facing alethic relativists is to explain what “true for” actually means, and how “true for” should be understood as related to the more familiar absolutist truth predicate. For instance, should relative truth be understood as a modification on an already familiar strategy for thinking about truth (e.g., the correspondence, pragmatic or epistemic model) or in some different way, entirely? (MacFarlane 2014: ch. 2). Much of the work of New Relativists such as John MacFarlane (see §5) can be see as an attempt to clarify this thorny issue.
The strongest and most persistent charge leveled against all types of relativism, but (global) alethic relativism in particular, is the accusation of self-refutation. Here is for instance Harvey Siegel:
This incoherence charge is by far the most difficult problem facing the relativist. It is worth noting that attempts to overcome the problem by appealing to the notion of relative truth appear not to succeed. Many versions of relativism rely on such a notion, but it is very difficult to make sense of it. An assertion that a proposition is “true for me” (or “true for members of my culture”) is more readily understood as a claim concerning what I (or members of my culture, scheme, etc.) believe than it is as a claim ascribing to that proposition some special sort of truth. Constructing a conception of relative truth such that “p is relatively true” (or “p is true for S”, or “p is true for members of culture C”) amounts to something stronger than “S believes that p” (or “members of culture C believe that p”), but weaker than “p is true (simpliciter)”, has proved to be quite difficult, and is arguably beyond the conceptual resources available to the relativist. (Siegel 2011: 203)
The original argument goes back to Plato’s criticism of Protagoras in the Theaetetus where he argues:
Most people believe that Protagoras’s doctrine is false.
Protagoras, on the other hand, believes his doctrine to be true.
By his own doctrine, Protagoras must believe that his opponents’ view is true.
Therefore, Protagoras must believe that his own doctrine is false (see Theaetetus: 171a–c)
Plato’s argument, as it stands, appears to be damaging only if we assume that Protagoras, at least implicitly, is committed to the universal or objective truth of relativism. On this view, Plato begs the question on behalf of an absolutist conception of truth (Burnyeat 1976a: 44). Protagoras, the relativists counter, could indeed accept that his own doctrine is false for those who accept absolutism but continue believing that his doctrine is true for him. He could also try to persuade others to become the sort of thinker for whom relativism is true without being entangled in self-contradiction. Such an effort at persuasions, however, could involve Protagoras in a performative contradiction as the relativist cannot assume that her arguments are good for persuading others. Ordinarily, the very act of defending a philosophical position commits us to the dialectical move of attempting to convince our interlocutors of the superior value of what we are arguing for. The relativist cannot make such a commitment and therefore his attempts to persuade others to accept his position may be pragmatically self-refuting. The relativist can avoid the standard charge of self-refutation by accepting that relativism cannot be proven true in any non-relative sense—viz., that relativism itself as a philosophical position is at best true only relative to a cultural or historical context and therefore could be false in other frameworks or cultures. But such an admission will undermine the relativist’s attempt to convince others of her position, for the very act of argumentation, as it is commonly understood, is an attempt to convince those who disagree with us of the falsehood of their position. In other words, if Protagoras really believes in relativism why would he bother to argue for it?
It may be argued that Protagoras could have opted for a more sensible form of alethic relativism where a person’s beliefs are not automatically true relative to the framework she accepts. Rather a belief p is true according to X’s framework iff (roughly) X would believe that p if she were to reason cogently by her own standards on the basis of full relevant information. This form of alethic relativism allows for argument and persuasion among people who initially disagree, for despite their disagreement they may share or come to share a framework. Protagoras may, on this reinterpretation, be trying to persuade his interlocutor that if she were to reason cogently by her own standards from their shared framework, she would accept relativism. However, it is not clear how the relativist could share a framework with the absolutist on the nature of truth or what argumentative strategies he can use to convert the absolutist without presupposing a shared (relativist or absolutist) conceptions of truth. In particular, a consistent relativist will have only a relativized criteria of what counts as “true” information, which presumably will not be shared by the absolutist.
A second strand of the self-refutation argument focuses on the nature and role of truth. J.L. Mackie, for instance, has argued that alethic absolutism is a requisite of a coherent notion of truth and that a claim to the effect that “There are no absolute truths” is absolutely self-refuting (Mackie 1964: 200). But the relativists reject the quick move that presupposes the very conception of truth they are at pains to undermine and have offered sophisticated approaches of defense. A good example of such a defense is Hales’ (1997)—who uses a “u” operator to represent “It is true in some perspectives that” and a “n” operator to represent “It is true in all perspectives that”—in order to establish that there could indeed be a consistent relativist logic which avoids the charge of self-refutation). Key to this approach, according to Hales, is that we abandon a conception of global relativism on which the lose thesis “everything is relative” is embraced—a thesis Hales concedes to be inconsistent—for the thesis “everything that is true is relatively true”, which he maintains is not (cf. Shogenji 1997 for a criticism of Hales on this point).
It has also been claimed that alethic relativism gives rise to what J.L. Mackie calls “operational” (Mackie 1964: 202) and Max Kölbel “conversational” self-refutation (Kölbel 2011) by flouting one or more crucial norms of discourse and thereby undermines the very possibility of coherent discourse. One version of the argument, advanced most notably by Gareth Evans (1985: 346–63), begins with the premise that a publicly shared distinction between correct and incorrect, and hence true and false, assertion is a necessary condition for coherent assertoric discourse. As Evans puts it, a theory that
permits a subject to deduce merely that a particular utterance is now correct but later will be incorrect … cannot assist the subject in deciding what to say, nor in interpreting the remarks of others. What should we aim at, or take others to be aiming at?. (1985: 349)
And if truth is relative, then there is no single shared definite aim for any given assertion (see MacFarlane 2014: ch. 12 for a discussion). The relativists however, could respond that truth is relative to a group (conceptual scheme, framework) and they take speakers to be aiming a truth relative to the scheme that they and their interlocutors are presumed to share. The difficulty with this approach is that it seems to make communication across frameworks impossible.
Such a response, however, will be answerable to the charge of incoherence raised by Donald Davidson against both alethic and conceptual relativism. According to Davidson, the principle of charity—the assumption that other speakers by and large speak truly (by our lights)—is a pre-requisite of all interpretation. He takes this to imply that there could not be languages or conceptual schemes that we cannot in principle understand and interpret, in other words, if a system of signs L is not recognizable as a language by us then L is not a language. Languages are either inter-translatable and hence not radically different from ours, or incommensurable and beyond our ability to recognize them as languages (Davidson 1974). The relativist, in effect, places other speakers and their languages beyond our recognitional reach and thereby undermines the initial claim that they could be radically different or incommensurable.
New Relativism, as we shall see, offers a novel take on the old question of alethic relativism and gives weight to Alasdair MacIntyre’s observation that relativism may have been refuted a number of times too often, whereas genuinely refutable doctrines only need to be refuted once (MacIntyre 1982: 22).
Claims to knowledge and justification have proven receptive to relativistic interpretations. Epistemic relativism is the thesis that cognitive norms that determine what counts as knowledge, or whether a belief is rational, justifiable, etc. could vary with and are dependent on local conceptual or cultural frameworks and lack the universality they aspire or pretend to. The three key assumptions underlying epistemic relativism are:
(a) Epistemic justification is framework relative. It makes no sense to ask whether a belief is justified simpliciter; we can only ask questions about justification relative to an epistemic system, which casts doubts on the very possibility of objectivity.
(b) There are many genuinely alternative, even incompatible, epistemic systems.
(c) We cannot demonstrate in a non-circular way that our epistemic system is superior to any other. (see Williams 2007: 94 for one version of this approach to epistemic relativism; cf. Carter 2015)
The epistemic relativist, as Paul Boghossian in developing his trenchant criticisms of relativism points out, is committed to a “doctrine of equal validity”, the view that “there are many radically different, incompatible, yet, ‘equally valid’ ways of knowing the world, with science being just one of them” (Boghossian 2006a: 2). The relativist’s key claim is that either we can chauvinistically maintain that our epistemic system is superior to all or accept the equal legitimacy of varying epistemic systems.
One crucial question facing epistemic relativism is how to identify and individuate alternative epistemic systems. The intuitive idea is that varying and possibly incompatible cognitive principles, ground-level beliefs and presuppositions, or what Wittgenstein calls “hinge” and “bedrock” propositions (Wittgenstein 1969: §§341–343) separate non-convergent epistemic schemes. A simple and quite commonly used example is the contrast between scientific and religious belief systems. Boghossian, for instance, uses the debate between Galileo and Cardinal Bellarmine as a case study of an encounter between antagonists operating within putatively different epistemic frameworks, who use different frameworks, or as Rorty (1979) put it “grids”, for determining what would count as appropriate evidence on planetary movements. The relativist claims that there is no fact of the matter about whether the Copernican theory or the geocentric view is justified by the evidence, “for there are no absolute facts about what justifies what” (Boghossian 2006a: 62) while the anti-relativist attempts to show the unintelligibility or the implausibility of such a claim.
Boghossian has been criticized however for his characterization of epistemic relativism. One notable such criticism has been advanced by Crispin Wright (2008), who takes issue with Boghossian’s attributing to the epistemic relativist a version of (a) above, what Boghossian calls epistemic relationism, or the thesis that any claim of the form “Evidence E justifies belief B”, if it is to have any prospect of being true, must be construed as expressing the claim According to the epistemic system C, that I, S accept, information E justifies belief B (Boghossian 2006a:73). Having characterized the relativist’s position in this fashion, Boghossian suggests—after considering various ways of articulating what the relativist might say about the untruth of claims of the form “Evidence E justifies belief B”—that the relativist is left, ultimately, with no coherent way to account for how she should count as accepting or adhering to a given epistemic system. And on this basis, Boghossian concludes that there is no coherent way to formulate the position because the relativist in formulating his position and setting up the opposition between two or more alternative non-convergent epistemic systems cannot but assume the universality of at least some epistemic principles, including deduction, induction, warrant through empirical evidence, etc. (see Boghossian 2006a).
As Wright sees it, however, Boghossian’s attributing the relationist clause to the epistemic relativist is to simply
fail to take seriously the thesis that claims such as [Evidence E justifies belief B] can indeed by true or false, albeit only relatively so. (Wright 2008: 383, our italics)
Moreover, Wright argues, the epistemic relationist clause Boghossian includes in the kind of epistemic relativism he challenges betrays a failure to distinguish between (i) making a judgment in the light of certain standards and (ii) judging that those standards mandate that judgment. (See also MacFarlane (2008b) for a different critique of Boghossian’s argument against the epistemic relativist.)
Conceptions of rationality, and its key components of logic and and justification, are some of the principles that are often used to differentiate between epistemic systems. Below we look at attempts at relativizing each.
Earlier defenses of epistemic relativism centered on the idea of alternative rationalities and were often developed as a reaction to the charge of irrationality leveled at non-Western tribal people. Rationality traditionally is seen as a cognitive virtue as well as a hallmark of the scientific method. The complex notion of rationality is intimately tied to requirements of consistency, justification, warrant and evidence for beliefs. Relativists about rationality cast doubt on the universal applicability of one or more of these features of rational thought, and deem them merely local epistemic values. Peter Winch’s treatment of E.E. Evans-Pritchard’s account of the Azande tribe’s beliefs in witchcraft and magic is now a classic of the “rationality wars” of the 1960s and 70s. Winch had argued that since standards of rationality in different societies do not always coincide, we should use only contextually and internally given criteria of rationality in our assessment of the systems of belief of other cultures and societies. Under the influence of the later Wittgenstein, he maintained that it does not make sense to speak of a universal standard of rationality because what is rational is decided by a backdrop of norms governing a given language and form of life. As outside observers, we are not in a position to impute irrationality or illogicality to the Azande or any other group whose practices and language-games may differ from ours. Critics of Winch, Steven Lukes, for instance, using considerations reminiscent of Davidson’s principle of charity, have argued that we will not be in a position to understand a language or culture with standards of rationality radically different from ours, and that we must have at least some core principles, or what Martin Hollis had called a “bridgehead” with elements such as consistency and the goal of truth, in common with the Azande in order to understand them (Hollis 1968; Lukes 1970). They, thereby, conclude that an all-out or strong relativism about rationality is not tenable. The weaker claim is that some elements of rationality, for instance what counts as good evidence or a better style of reasoning, could vary with historic conditions and traditions of enquiry and therefore a degree of relativization of such norms, without succumbing to irrationalism, is acceptable (see Hacking 1982 and MacIntyre 1988).
Being rational also means having warrant, in the form of good reasons and justification for one’s beliefs. Epistemic relativists maintain that the legitimacy of a justificatory system and the presumed strength of epistemic warrants are decided locally. Richard Rorty has made the influential claim that
there is nothing to be said about either truth or rationality apart from descriptions of the familiar procedures of justification which a given society—ours—uses in one or another area of inquiry. (Rorty 1991: 23)
For Rorty, warrant is a “sociological matter, to be ascertained by observing the reception of [a speaker’s] statement by her peers” (1993: 449). Rorty also claims that knowledge and truth are compliments “paid to beliefs which we think so well justified that, for the moment, further justification is not needed” (Rorty 1991: 24) where the “we” is historically conditioned community of enquirers. Rorty rejects the label “relativist” because he insists that, unlike the relativists, he does not subscribe to the view that all beliefs are equally true or good. He calls his position “ethnocentrism”, because the only form of warrant available to any of us is the one provided through solidarity with our peers. His rejection of the label “relativist” has had little effect on critics such as Hilary Putnam (1999) or Paul Boghossian (2006a) who do not see the distinction Rorty wishes to draw between his brand of ethnocentrism and relativism
Debates about the scope and authority of logic have also focal to discussions of rationality. The argument for relativism about logic is usually traced to the French anthropologist Lucien Lévy-Bruhl (1857–1939) who claimed that tribal or “primitive” cultures did not subscribe to universal laws of logic such as the principles of non-contradiction and identity and were in a pre-logical stage of thinking (Lévy-Bruhl 1922/1923). In a posthumous publication, Lévy-Bruhl renounced his earlier views, finding them “simplistic and rather crude” (Lévy-Bruhl 1949/1975: 48) but he remains the standard bearer for relativism about logic.
Peter Winch’s interpretation of the Azande material became the impetus for a new wave of arguments for relativism about logic. Barry Barnes and David Bloor, for instance, have argued that different societies may have incompatible but internally coherent systems of logic because validity and rules of inference are defined by, and hence are relative to, the practices of a given community, rather than a priori universal restrictions on all thought. According to Bloor,
The Azande have the same psychology as us but radically different institutions. If we relate logic to the psychology of reasoning we shall be inclined to say that they have the same logic; if we relate logic more closely to the institutional framework of thought then we shall incline to the view that the two cultures have different logics. (Bloor 1976: 129–130)
Even the status of “contradictions” is at times seen as culturally relative and the Azande’s application of witchcraft in determining guilt is cited as an example. The Azande, according to Evans-Prichard, believe that it is possible to identify a witch by examining the contents of his intestine (through the use of a poison oracle). They also believe that Witchhood is inherited patrilineally. Since the Azande clan members are related to each other through the male line, it follows that if one person is shown to be a witch, then all the members of his clan must also be witches. Evans-Pritchard tells us that although the Azande see the sense of this argument they do not accept the conclusion; they seem to side-step the contradiction in their belief-system. Relativistically inclined commentators have argued that the Azande both do and do not contradict themselves depending on, or relative to, the culture that is being taken as the vantage point (Bloor 1976: 124 and Jennings 1989: 281). See Seidel (2014) for a sustained critique.
More recently, Peng and Nisbett, using experimental data, have argued that Chinese and American students have different attitudes towards the Law of Non-Contradiction. The Chinese, they claim, are more willing to accept that conflicting views may be compatible and therefore are less disposed to recognize or condemn contradictions (Peng & Nisbett 1999). In his The Geography of Thought (2003), Nisbett has generalized his results to claim that Asian and European structures of thinking, including perception and conceptualization, differ significantly.
Nesbitt’s data, as well as the claims by Barnes and Bloor, are contributions to a long-standing debate about the status of logic. Their approach attempts to naturalize logic by tying it to the actual practices of the human subjects, The relativistically inclined, however, argue that to think of logic as singular, a priori, and universal speaks of a philosophical prejudice and does not sit well with a naturalistic and scientific attitude. As to the claim by Quine and Davidson, that an allegedly illogical culture is in fact a misinterpreted or badly interpreted culture—that if the speakers of a language seem to accept sentence of the form “P and not-P”, this is conclusive evidence that “and” and “not” in their language do not mean what these words mean in English (Quine 1960)—the relativistically inclined point out that reasoning in deviant ways is quite common and is not an impediment to understanding or translating others (e.g., Stich 2012). They further argue that such diversity is better explained by the relativist’s claim that the correctness of the principles of reasoning is relative to their cultural background rather than by the absolutist approach that attributes wholesale error to alternative epistemic systems or to the members of other cultures.
Discussions of relativism about science gained currency with the publication of Thomas Kuhn’s The Structure of Scientific Revolutions (1962) and the emergence of a historicist approach to question of change and progress in science. Pronouncements such as
In so far as their only recourse to [the] world is through what they see and do, we may want to say that after a revolution scientists are responding to a different world (Kuhn 1970 [1962]: 111)
and
The very ease and rapidity with which astronomers saw new things when looking at old objects with old instruments may make us wish to say that, after Copernicus, astronomers lived in a different world (Kuhn 1970 [1962]: 117)
were taken to suggest that not only standards of epistemic appraisal but even the data gathered by scientists were, to a significant extent, determined by governing paradigms and hence relative to them. Although Kuhn stepped back from such radical relativism, his views gave currency to relativistic interpretations of science.
Relativism about science is motivated by considerations arising from the methodology and history of science (Baghramian 2007). As we saw in §4.2, Quine has argued that
Physical theories can be at odds with each other and yet compatible with all possible data even in the broadest possible sense. In a word, they can be logically incompatible and empirically equivalent. (1970: 179)
Relativists about science have argued that only with the addition of auxiliary hypotheses could the scientist choose between various theories and that such auxiliary hypotheses are colored by socially and historically grounded norms as well as by personal and group interests. Paul Feyerabend’s “democratic relativism”—the view that different societies may look at the world in different ways and regard different things as acceptable (1987: 59) and that we need to give equal voice to these differing perspectives—is one instance of the use of the underdetermination thesis in support of relativism. According to Feyerabend, underdetermination ultimately demonstrates that
for every statement, theory, point of view believed (to be true) with good reason there exist arguments showing a conflicting alternative to be at least as good, or even better. (1987: 76)
Larry Laudan usefully lists the ways underdetermination is used to motivate relativism or its proximate doctrines. He says:
Lakatos and Feyerabend have taken the underdetermination of theories to justify the claim that the only difference between empirically successful and empirically unsuccessful theories lies in the talents and resources of their respective advocates (i.e., with sufficient ingenuity, more or less any theory can be made to look methodologically respectable). Hesse and Bloor have claimed that underdetermination shows the necessity for bringing noncognitive, social factors into play in explaining the theory choices of scientists (on the grounds that methodological and evidential considerations alone are demonstrably insufficient to account for such choices). H. M. Collins, and several of his fellow sociologists of knowledge, have asserted that underdetermination lends credence to the view that the world does little if anything to shape or constrain our beliefs about it. (Laudan 1990: 321)
Laudan even connects Derrida’s deconstructionism and the view that texts do not lend themselves to determinate readings with underdetermination (ibid.). He also believes that an appropriately modest understanding of what underdetermination entails will distance it from relativism, but most relativistically inclined advocates of underdetermination are not willing to follow Laudan’s advice to circumscribe its scope. The key issue is that both the relativists and the anti-relativists could agree that the totality of evidence available does not prove the truth of any given theory. But the anti-relativists responds to this fact of underdetermination by pointing out that the we have good reasons for embracing the best theory available and moreover that there are indeed objective facts about the world, even if we are not in possession of them. The relativist, in contrast, argues that there are many, equally acceptable principles for accepting theories, all on the basis of evidence available, but such theories could result in very different verdicts. They also argue that in the absence of any strong epistemic grounds for accepting the existence of absolute facts in any given domain, we have no grounds, other than some kind of metaphysical faith, for thinking that there are such facts.
Relativism about science is also influenced by the related doctrine that all observations are theory-laden. Even anti-relativists such as Karl Popper admit that the idea that observations are not in some way tinted by theoretical assumptions is naïve. But some relativists about science offer a particularly extreme form of the doctrine of the widely accepted thesis of theory-ladenness. Feyerabend, for instance, goes so far as to argue that different systems of classification can result in perceptual objects that are not easily comparable.
Relativists about science also point to the prevalence of both synchronic and diachronic disagreement among scientists as a justification of their view. Looking at the history of science, Kuhn and his followers argued that Aristotelian physics presupposes a totally different conception of the universe compared to Newtonian physics; the same is true of Einsteinian physics compared to its predecessors. Moreover, these differing conceptions may be incommensurable in the sense that they are not readily amenable to comparison or inter-theoretical translation. There are also strong and unresolved disagreements between scientists working contemporaneously. The many different interpretations of quantum mechanics are a case in point.
Anti-relativist philosophers of science are often willing to concede all three points above, but insist that they do not, singly or jointly, justify the claim that scientific knowledge, in any philosophically interesting sense, is relative to its context of production. The success of science, both theoretical and applied, indicates that progress does take place. Fallibilism, the view that all scientific claims are provisional and liable to fail, they argue, is sufficient for dealing with difficulties arising from considerations of underdetermination and theory-ladenness of observations. Relativism, with its attendant denial that there could be objective and universal scientific truths or knowledge exacts too high a price for dealing with these allegedly troublesome features of the methodology and history of science.
Social constructionism is a particularly radical form of conceptual relativism with implications for our understanding of the methodology and subject matter of the sciences. According to social constructionism, nature as studied by scientists does not come carved at its joints (to use Plato’s metaphor from Phaedrus: 265d–266a). Reality—with its objects, entities, properties and categories—is not simply “out there” to be discovered only by empirical investigation or observation; rather, it is constructed through a variety of norm-governed socially sanctioned cognitive activities such as interpretation, description, manipulation of data, etc. Social constructionism has relativistic consequences insofar as it claims that different social forces lead to the construction of different “worlds” and that there is no neutral ground for adjudicating between them. The “Science Studies” approach of Bruno Latour is a prime example of constructionism with relativistic consequences. Latour and Woolgar (1986) have argued that so-called “scientific facts” and the “truths” of science emerge out of social and conceptual practices and inevitably bear their imprints. This is because the very idea of a mind-independent reality open to scientific study, or as they call it “out-there-ness”, itself is the consequence of scientific work rather than the cause. A crucial difference between scientific realists and constructionists is that whereas the realists see nature and society as the causes that explain the outcomes of scientific enquiry, for the constructionists the activity of
scientists and engineers and of all their human and non-human allies is the cause, of which various states of nature and societies are the consequence. (Callon & Latour 1992: 350–1)
Scientific theories are also products of socially constituted practices. They are
contextually specific constructions which bear the mark of the situated contingency and interest structure of the process by which they are generated. (Knorr-Cetina 1981: 226)
So called “scientific facts” and “natural kinds”, the primary subjects of scientific investigation are, at least in part, the products of the contingent social and epistemic norms that define the very subject matter of science. It may be argued that the view, if taken literally, entails a counter-intuitive form of backward causation to the effect that, for instance, the scientific facts about dinosaur anatomy 50 million years ago were caused in the 20th century when a scientific consensus about dinosaur anatomy was formed (see Boghossian 2006a). But constructionism, at least in its most extreme form, accepts this consequence, insisting that there are indeed no facts except for socially constructed ones, created and modified at particular times and places courtesy of prevailing theoretical and conceptual frameworks.
Moral or ethical relativism is simultaneously the most influential and the most reviled of all relativistic positions. Supporters see it as a harbinger of tolerance (see §2.6), open-mindedness and anti-authoritarianism. Detractors think it undermines the very possibility of ethics and signals either confused thinking or moral turpitude.
Briefly stated, moral relativism is the view that moral judgments, beliefs about right and wrong, good and bad, not only vary greatly across time and contexts, but that their correctness is dependent on or relative to individual or cultural perspectives and frameworks. Moral subjectivism is the view that moral judgments are judgments about contingent and variable features of our moral sensibilities. For the subjectivist, to say that abortion is wrong is to say something like, “I disapprove of abortion”, or “Around here, we disapprove of abortion”. Once the content of the subjectivist’s claim is made explicit, the truth or acceptability of a subjectivist moral judgment is no longer a relative matter. Moral relativism proper, on the other hand, is the claim that facts about right and wrong vary with and are dependent on social and cultural background. Understood in this way, moral relativism could be seen as a sub-division of cultural relativism. Values may also be relativized to frameworks of assessment, independent of specific cultures or social settings.
Moral relativism, like most relativistic positions, comes in various forms and strengths. It is customary to distinguish between descriptive or empirical, prescriptive or normative, and meta-ethical versions of moral relativism. These views in turn are motivated by a number of empirical and philosophical considerations similar to those introduced in defense of cultural relativism. The purported fact of ethical diversity, the claim that there are no universally agreed moral norms or values, conjoined with the intractability of the arguments about them, are the core components of descriptive moral relativism. The anti-relativists counter-argue that the observed diversity and lack of convergence in local norms can in fact be explained by some very general universal norms, which combine with the different circumstances (or false empirical beliefs) of the different groups to entail different particular norms. The objectivist, thereby can accommodate diversity and lack of agreement at this higher level of generalization (see Philippa Foot (1982) for this type of argument)
As in the case of cultural relativism, the imperative of tolerance is often seen as a normative reason for adopting moral relativism,. Moral relativism, it is argued, leads to tolerance by making us not only more open-minded but also alerting us to the limitations of our own views. Edward Westermarck, for instance, in his early classic defense of relativism writes:
Could it be brought home to people that there is no absolute standard in morality, they would perhaps be on the one hand more tolerant and on the other more critical in their judgments. (Westermarck 1932: 59)
Critics however point out that for the consistent relativist tolerance can be only a framework-dependent virtue, while Westermarck, and others, seem to recommend it as a universal desideratum. A second problem with arguing for normative moral relativism on the grounds of tolerance is known as the Argumentum ad Nazium. Relativists, as this argument goes, are not in a position to condemn even the most abhorrent of worldviews as they are forced to admit that every point of view is right (relative to the perspective of its beholder). W.T. Stace, arguing against Westermarck’s relativism gives an early example of this type of criticism:
Certainly, if we believe that any one moral standard is as good as any other, we are likely to be more tolerant. We shall tolerate widow-burning, human sacrifice, cannibalism, slavery, the infliction of physical torture, or any other of the thousand and one abominations which are, or have been, from time approved by moral code or another. But this is not the kind of toleration that we want, and I do not think its cultivation will prove “an advantage to morality”. (Stace 1937: 58–59)
More moderate forms of normative moral relativism, positions that sometimes are characterized as moral pluralism, have been defended by David Wong (2006) and David Velleman (2013). Moderate moral relativists endorse the idea of diversity and plurality of ethical values and accept that such values are justified according to differing local normative frameworks, but they avoid a full blown “anything goes” relativism by maintaining that all such frameworks are ultimately answerable to conditions for human flourishing and other overarching universal constraints such as the value of accommodation (Wong 2006). (It should however be noted that while theses under the description of pluralism needn’t entail a commitment to relativism, some formulations of relativism (such as Boghossian’s 2006b), include, as an essential ingredient, a “pluralist” clause. Whether particular instances of moral pluralism entail moral relativism depends entirely on the details of relevant claim to pluralism).
Metaethical versions of moral relativism are often motivated by the thought that ethical positions, unlike scientific beliefs, are not apt for objective truth-evaluation. Strong realists about science such as Gilbert Harman have argued that the intractability of moral disagreements, the absence of convergence in ethics as opposed to the natural sciences and mathematics, point to fundamental differences between natural facts and ethical values (Harman & Thompson 1996). This is a metaethical, rather than a descriptive or normative position, because it is a theory about the nature of ethics or morality. The ethical domain, Harman argue, is such that all relevant evaluations could be undertaken only in the context of social norms or personal preferences and commitments. Values are not objective—they are not part of the fabric of the universe. Rather they always arise from some form of convention and agreement among people. Therefore, there can be no objective or externally justified ethical knowledge or judgment (Harman 1975). In this sense, metaethical relativism shares common concerns with non-cognitivist approaches to ethics. What distinguishes it, however, is the insistence on the part of metaethical relativists that moral judgments contain an implicit relativization to the speaker’s moral outlook (Dreier 2006: 261). It is possible to talk about the truth or falsity of a moral judgment but only in the context of pre-existing standards or value systems. For instance, we can ask questions about just actions or judgments in the context of standards of justice prevalent in a society at a given time; but questions about the objective standing of these standards do not make sense. (For further discussion of moral relativism see the separate entry on this topic. What has become known as New Moral Relativism will be discussed below).
There is a recent version of relativism according to which some of the views considered so far—for instance, Harman’s (1975) variety of moral relativism—will be regarded varieties of contextualism as opposed to bona fide relativism. This recent version—sufficiently distinct from the relativisms so far considered that it is deserving of attention in its own right—we are calling “New Relativism”, a variety of relativism that has arisen out of work in the philosophy of language in the analytic tradition, and for which the leading proponents have included Max Kölbel (2003, 2004), Peter Lasersohn (2005), Crispin Wright (2006) and, in particular, John MacFarlane (2005b, 2007, 2014). In this section we aim to (i) outline several features that individuate New Relativism; (ii) consider in turn motivations for (and objections to) several prominent strands of it; and, finally, (iii) conclude with some philosophical problems that face New Relativism more generally.
It is a commonplace that the truth-value of an utterance can depend on the context in which it is uttered. If you say “I’m happy” and I say the same sentence, your utterance may be true and mine false. In such cases, the context of utterance plays a role in determining which proposition the sentence expresses. This can happen even when the sentence does not contain an overtly indexical expression. Thus Harman and Dreier hold that a statement of the form “A is wrong” is roughly equivalent to “A is wrong according to the moral system I accept”. So two utterances of (say) “Torture is wrong” can differ in truth-value if they are uttered by speakers who accept very different moral systems. Contextualists about (for instance) moral, aesthetic and epistemic discourse will view moral, aesthetic and epistemic expressions likewise as indexical expressions but (as we’ll see) with some difficulty explaining apparent genuine disagreement in these areas of discourse. On this point, New Relativists claim an important advantage over contextualists. New relativism, by contrast with contextualism, aims to achieve this advantage via a much less familiar form of context dependence.
Truth-relativism with respect to utterances in area of discourse D is the claim that, following MacFarlane’s notable version of the view: the truth of S’s D-utterance u depends (in part) on a context of assessment; that is (and in short) what S asserts, u, gets a truth value—according to the truth-relativist’s D-semantics—only once the D-standard of the assessor is specified. Independent of the specification of such a standard, S’s u assertion lacks a truth-value much as, by comparison, indexical expressions such as “The barn is nearby” do not get a truth-value independent of contextual facts about the context of use (i.e. the context in which the utterance is made). And, as a further point of clarification here: while the contextualist can, no less than the relativist, recognize a “standards” or “judge” parameter, for the contextualist, its value will be supplied by the context of use, whereas the relativist takes it to be supplied completely independently of the context of use, by the context of evaluation (or, as MacFarlane calls it, the context of assessment).
To see how this view is claimed to offer a satisfying take on disagreement, consider a simple example, concerning predicates of personal taste. A utters, “Pretzels are tasty”, and B utters, “Pretzels are not tasty”. While the semantic invariantist (for whom the truth-value of taste predications is in no way context sensitive) will insist that the above exchange constitutes a genuine disagreement about whether pretzels are tasty and that at least one party is wrong, contextualists and truth-relativists have the prima facie advantageous resources to avoid the result that at least one party to the apparent disagreement has made a mistake.
The contextualist claims that the truth-evaluable content expressed by A’s utterance encodes A’s standards (cf. non-indexical contextualism). Thus, in this apparent disagreement, the proposition expressed by A is “Pretzels are tasty relative to my [A’s] standards” while B expresses the proposition “Pretzels are not tasty relative to my [B’s] standards”. This maneuver avoids the result that at least one of the two parties has uttered something false, but (as the new relativist points out) this result comes at the price of being unable to offer a clear explanation of our intuition that there is some uniform content about which A and B disagree.
The new relativist, on the other hand, claims to be able to preserve both the apparent subjectivity of taste discourse and (and, unlike the contextualist) our intuition that exchanges of the form mentioned constitute genuine disagreements. They do this by first insisting (unlike the contextualist) that there is a single truth-evaluable proposition which A affirms and B denies. In the case where A says “Pretzels are tasty”, and B denies this, there is a uniform content that is affirmed by A’s utterance and denied by B’s, namely the proposition that pretzels are tasty, period. So we have a genuine disagreement. Unlike the truth-absolutist, however, the new relativist will add that the disagreement is faultless because the proposition affirmed in A’s utterance has a truth value only relative to a judge or standards parameter, and in this case: A’s standards, when A is the assessor, B’s standards, when B is the assessor. Hence, the truth-relativist about predicates of personal taste will, by insisting that the truth of Pretzels are tasty depends on the context of assessment, allow a single proposition to be (at the same time):
(ii) false relative to the context of assessment where B’s standards of taste are operative.
New Relativist views, which endorse truth-relativism locally for some domain of discourse, stand in opposition to the more traditional view of propositional content (what Cappelen & Hawthorne call “The Simple View”) according to which propositions bear truth and falsity as monadic properties (cf. however, MacFarlane 2011a for some resistance to Cappelen & Hawthorne’s claim that this simple characterization should be regarded as the “received” view.)
A key source of philosophical motivation for relativizing truth in the fashion of New Relativism traces to Lewis’s (1980) and Kaplan’s (1989) foundational work in semantics, according to which sentence truth is to be understood as relative to a circumstance of evaluation that includes world, time and location. New Relativists inherit the formal apparatus of Lewis and Kaplan and add another parameter, but their reasons for doing so are quite different from the reasons that motivated the framework in the first place. While Lewis’s and Kaplan’s reasons for “proliferating” parameters were primarily based on considerations to do with intensional operators, the more contemporary reasons for adding a judge or standard parameter are often to do with respecting (for instance) disagreement data. (For further discussion here, see Kölbel (2015)). (Note that “old-style contextualism” can also be stated in Kaplan’s framework; it involves variation in content with respect to the context of utterance rather than in truth value with respect to the circumstance of evaluation).
Kaplan’s view specifically was that the need for particular parameters in the circumstance of evaluation was a function of the non-specificity of certain propositional contents with respect to world, time and location (see Kaplan’s (1989) analysis of indexicals). On Kaplan’s view:
A circumstance will usually include a possible state or history of the world, a time, and perhaps other features as well. The amount of information we require from a circumstance is linked to the degree of specificity of contents and thus to the kinds of operators in the language…. (1989: 502)
John MacFarlane, a leading contemporary relativist, writes:
Taking this line of thought a little farther, the relativist might envision contents that are “sense-of-humor neutral” or “standard-of-taste neutral” or “epistemic-state neutral”, and circumstances of evaluation that include parameters for a sense of humor, a standard of taste or an epistemic state. This move would open up room for the truth value of a proposition to vary with these “subjective” factors in much the same way that it varies with the world of evaluation. (MacFarlane 2007: 6–7)
Similarly, Cappelen and Hawthorne write:
Contemporary analytic relativists reason as follows: ‘Lewis and Kaplan have shown that we need to relativize truth to triples of <world, time, location>[’]. … But, having already started down this road, why not exploit these strategies further? In particular, by adding new and exotic parameters into the circumstances of evaluation, we can allow the contents of thought and talk to be non-specific (in Kaplan’s sense) along dimensions other than world, time and location. (2009: 10; edited)
A question on which New Relativists are divided, however, is: what contents are non-specific along dimensions other than world, time and location? It is with respect to this general question that different families of New Relativism are generated.
The taxonomy we offer is that a view falls within the category of New Relativism if, and only if, the view endorses a truth-relativist semantics (as previously outlined) for utterance tokens in some domain of discourse, such as: discourse about predicates of personal taste (Lasersohn 2005; Kölbel 2003), epistemic modals (Egan 2007; Egan, Hawthorne & Weatherson 2005; MacFarlane 2011b; Stephenson 2007), future contingents (MacFarlane 2003), indicative conditionals (Weatherson 2009; Kolodny & MacFarlane 2010) gradable adjectives (Richard 2004), deontic modals (Kolodny & MacFarlane 2010 and MacFarlane 2014: ch. 11) and knowledge attributions (Richard 2004); MacFarlane 2005b, 2011c, 2014). The motivations for truth-relativism in each of these domains include various considerations unique to those domains. We consider some of the arguments for New Relativism in four of these domains in the following sections.
One area of discourse that has been particularly fertile ground for New Relativism is discourse that concerns predicates of personal taste (e.g., “tasty” and “fun”.)
Take a case where Mary says: “The chili is tasty” and John says, “The chili is not tasty”. Lasersohn argues (much as Kölbel does) that only the truth-relativist can make sense of the nature of John and Mary’s disagreement: It is a genuine disagreement. One affirms what the other denies. And yet neither is wrong. Lasersohn argues that there is an elegant way to make sense of the idea that John and Mary are both (in some sense) right, even though John asserts the negation of what is expressed by Mary. What Lasersohn) suggests, more formally, is the introduction of a judge parameter.
Instead of treating the content of a sentence as a set of time-world pairs, we should treat it as a set of time-world-individual triples. We assume that the content will provide an individual to be used in evaluating the sentences for truth and falsity, just as it provides a time and world. (Lasersohn: 2005: 17)
Lasersohn adds (2005: 23) that in order to maintain an authentically subjective assignment of truth-values to sentences containing predicates of personal taste, we must allow that the objective facts of the situation of utterance do not uniquely determine a judge. But who is the judge? Typically, it is us, and when it is, the evaluation is from what Lasersohn calls an autocentric perspective. Importantly, Lasersohn allows that in certain circumstances we take an exocentric perspective when assessing predicates of personal taste: assessing these sentences for truth relative to contexts in which someone other than ourselves is specified as the judge (cf. “Come on, it’ll be fun!” “Is this fun?” (2005: 26); cf. Stanley (2005: 10) for a response to Lasersohn’s program).
Kölbel’s (2003) faultless disagreement argument for relativism about predicates of personal taste features a “proof” that there is no faultless disagreement followed by a demonstration that the proof is indefensible. The proof proceeds from two premises: an equivalence schema
and an apparent truism about mistakes:
(ES) and (T) generate the conclusion that there is no faultless disagreement through the following proof (see also Wright 2001:52)
But because Kölbel takes (9) to be implausible in what Kölbel takes to be “discretionary” (non-objective, as Kölbel sees it) areas of discourse he contends that we should introduce a relativized version of (T) to avoid the conclusion that at least one party has made a mistake.
(T***) It is a mistake to believe a discretionary proposition that is not true as evaluated from one’s own perspective. (2003: 70)
Kölbel claims further that, for reasons of uniformity, we should “relativize truth of all propositions across the board…” and he accordingly endorses the following version of truth relativism:
(TR) It is a mistake to believe a proposition that is not true in one’s own perspective. (2003: 70).
Kölbel (2003: 71) thinks that this position allows the possibility of maintaining that faultless disagreement is impossible in some non-discretionary (objective) areas, and this will depend on the relation of perspective possession (but see also Boghossian 2011 for the contrary view). An implication of the position is that Kölbel’s view will allow assertions of the form: “Pretzels are not tasty, though John believes they are. And yet John is not mistaken”. For other discussions of faultless disagreement, see Richard (2008), MacFarlane (2012, 2014: ch. 6).
There is a version of moral relativism (e.g., Kölbel 2004) that falls squarely within the New Relativist tradition. We can think of this relativism simply as a generalization of the position just discussed that treats moral terms (e.g., “right”, “good”) as assessment-sensitive along with predicates of personal taste.
Such an extension faces problems analogous to those faced by truth-relativists about predicates of personal taste (cf. Beebe (2010) for a helpful discussion of truth-relativist semantics versus varieties of contextualist competitors).
A broader kind of problem for this semantic thesis (as well as to moral relativists more generally), raised by Coliva and Moruzzi (2012) is that it succumbs to the progress argument, an argument that famously challenges, in particular, cultural relativists (as well as indexical contextualists) about moral judgments by insisting that moral progress is both evident and not something the relativist can countenance (e.g., Rachels 2009). A third and particularly important kind of worry, addressed by Capps, Lynch and Massey (2009), involves explaining the source and nature of moral relativity, on a truth-relativist framework. Specifically, they claim that
we ought to have some account of why it is that truth in the moral domain is such that it varies with a parameter set by the context of assessment. (Capps, Lynch & Massey 2009: 416)
Epistemic modality (e.g., claims of the form “S might be F”) is another particularly fertile ground for New Relativists. A key reason for this is the dialectical force of Eavesdropper Arguments, which attempt to show the perils of contextualist treatments of utterances containing epistemic modals. Another prominent argument concerns metasemantic complexity. We will examine both of these argument strategies. But first, let’s distinguish epistemic modality from metaphysical modality. To say that p is metaphysically possible is to say that p might have been the case in the sense that: in some possible world, p is true. To say that p is epistemically possible is by contrast to say that p might be the case, or that p is the case for all we know (see the entry on Varieties of Modality). A canonical example of a statement expressing an epistemic modal is the claim A might be F. The truth of claims of the form A might be F will depend on whether F is an epistemic possibility for some individual or group, which is to say, that F must not be ruled out by what some individual or group knows. But which individual or group? This is not always clear. As Egan and Weatherson (2011: 4) remark:
…statements of epistemic possibility in plain English do not make any explicit reference to such a person, group, evidence set, or information state. One of the key issues confronting a semanticist attempting to theorize about epistemic modals is what to do about this lack of reference.
Eavesdropper-style cases highlight the difficulty of determining exactly which individual’s or group’s body of information is relevant to the truth of claims of epistemic possibility and are taken by defenders of truth-relativism about epistemic modals to motivate their position. A variety of different eavesdropper cases have been given by different proponents (and attempted refuters) of truth-relativism about epistemic modals in the literature. For ease of exposition, we will use an especially simple version of the case, from Hawthorne’s (2007), slightly amended:
EAVESDROPPER: [Sandra] is on the way to the grocery store. I hear her say: “Susan might be at the store. I could run into her”. No party to the conversation that I am listening in on knows that Susan is on vacation. But I know that she is. Despite the fact that it is compatible with what the conversants know that Susan is in the store and that the speaker will run into her, I am inclined to judge the speaker’s [Sandra’s] modal judgments to be incorrect. (Hawthorne 2007: 92)
Egan (2007), Egan, Hawthorne and Weatherson (2005) and MacFarlane (2011b) share a similar set of diagnoses here: (i) it seems that while Sandra and I disagree about the truth value of Sandra’s statement, neither she nor I have made a mistake; (ii) the contextualist can’t explain this; (iii) the truth-relativist can.
Why can’t the contextualist explain this? As noted, the truth of claims expressing epistemic modals must depend on what some individual or group knows. But in these cases the context of use does not pick out a single such individual or group. After all, if it did, then either Sandra or I would be wrong, but it seems that neither of us is. That the context of use does not uniquely pick out one relevant body of knowledge for determining the truth of epistemic modal statements is not, as MacFarlane notes, something that can be accommodated by “the framework of contextualism, which requires that the relevant body of knowledge be determined by features of the context of use”. (MacFarlane 2011c)
Additionally, as Egan and Weatherson (2011) suggest, any contextualist account of the semantics of epistemic modals that could handle eavesdropper-style cases in a principled way would be hideously complicated. This motivates a metasemantic argument against contextualism (and a corresponding argument for relativism): if contextualism about epistemic modals is correct, then the semantics for epistemic modals will be hideously complicated; the semantics is not hideously complicated on the truth-relativist’s proposal, therefore, ceteris paribus, truth-relativism for epistemic modals is more plausible than contextualism. However, Glanzberg (2007) notably denies that metasemantic complexity in this case must be problematic.
How can the relativist accommodate eavesdropper cases? MacFarlane (2011b) articulates the relativist solution: Sandra and I disagree about the truth-value of a single proposition, the proposition that Susan might be at the store. This proposition, even when fully articulated, makes no reference to any particular body of knowledge. But such propositions cannot be true or false simpliciter. They are true only relative to a context of assessment that includes a body of knowledge. In this case, the proposition is true relative to a context of assessment where what Sandra knows is operative—a context in which Sandra is the evaluator—and false relative to a context of assessment where what I know is operative because I am the evaluator. Thus: both disagreement and faultlessness are preserved (cf. Ross & Schroeder 2013 for criticism).
Along with MacFarlane, Egan (2007) and Stephenson (2007) have also offered positive defenses of truth-relativism about epistemic modals; their defenses share MacFarlane’s view that propositions expressing epistemic modals are non-specific along dimensions that include the body of information possessed by a judge or assessor.
Propositions termed “future contingents” are about the future and their truth-values are not settled by the state of the world in the past or present (see entry on Future Contingents, and MacFarlane 2014: ch. 9). In a deterministic world there are no future contingent statements in this sense. But in an indeterministic world, statements partly about the future will often satisfy these conditions. Consider Aristotle’s oft-cited example: the proposition There will be a sea battle tomorrow, uttered at t. Contrast now two intuitions: the determinacy intuition that utterances that “turned out true” were true at the time of utterance; and the indeterminacy intuition that, at the time of the utterance, multiple histories are possible, including one where there was a sea battle and the proposition is true, and one where there was not, and the proposition is false. The indeterminacy intuition leads us to think the truth-value of future contingents is indeterminate at the time of utterance, and either true or false at a later time (cf. MacFarlane 2003; Carter 2011).
John MacFarlane (2003) thinks that both the indeterminacy intuition and the determinacy intuition should be taken at face value and that the only way to account for the semantics of future contingents is to allow the truth of future contingent statements to be, as he puts it, doubly relativized: to both the context of utterance and the context of assessment. When we evaluate a single token utterance of “There will be a sea battle tomorrow” produced on (say) Monday, this counts as neither true nor false when the context of assessment is the context in which the utterance is being made (as multiple possible histories are open at this point). However the very same statement will have a determinate truth-value relative to the context of assessment of the following day. So we can have faultless transtemporal disagreement about the truth-value of a single utterance (MacFarlane 2003: 36; cf. Carter 2011).
MacFarlane (2005b) argues that “know” is sensitive to the epistemic standards at play in the context of assessment; that is, the extension of “know” varies with the context of assessment. Much as the relativist about future contingents aimed to accommodate both the determinacy and indeterminacy intuitions, the relativist about knowledge attributions can be viewed as offering an attempted synthesis between the contextualist and both sensitive and insensitive varieties of invariantist (see entry on Epistemic Contextualism). As MacFarlane (2014: 190) puts it:
Invariantism is right that there is a single knowledge relation, and that the accuracy of knowledge ascriptions does not depend on which epistemic standard is relevant at the context of use. But contextualism is right that the accuracy of such ascriptions depends somehow on contextually relevant standards. Relativism seeks to synthesize these insights into a more satisfactory picture.
To apply this view, suppose George says, “Bill knows that his car is in the driveway”, while Barry says, “Bill doesn’t know that his car is in the driveway”. According to the relativist, the assessment of the truth-values of Bill’s and Barry’s statements depends also on the specification of some epistemic standard. For the truth-relativist, the standard will be the operative standard in the context of assessment. George’s utterance may be true (and Barry’s false) relative to a context of assessment in which ordinary “low” standards are in place, whereas Barry’s may be true (and George’s false) relative to a context of assessment in which high “Cartesian” standards are in place. See Stanley (2005: ch. 7) for a detailed criticism of this position, though see also MacFarlane (2014: §8.5 for a reply). See also Richard (2004), for another version of truth-relativism for knowledge attributions. In MacFarlane’s more recent (2014) defense of a truth-relativist semantics for “knows”, the context of assessment is taken to fix which alternatives count as relevant. See, however, Carter 2015 for an argument that MacFarlane’s more recent view generates counterintuitive results in cases of environmental epistemic luck (e.g., barn façade-style cases) and normative defeaters.
We turn now to two general arguments against New Relativism in all its forms. The first is an argument from assertion, the second an argument from simplicity.
Two assertion-related objections to New Relativism arise from work by Gareth Evans (1985) and Robert Stalnaker (1978), respectively. Greenough (2010: 2) concisely captures Evans’s challenge to truth-relativism on assertoric grounds as follows:
(2) Any legitimate answer to this question will generate a once-and-for-all answer.
The relativist must plausibly take issue with (2) or (3), (or both). For an attempt to meet Evans’ challenge, MacFarlane has defended a way to effectively reject (2) via what Marques has called a “meet-the-challenge” norm of assertion (cf. MacFarlane 2003; though see also his 2014: ch. 5)—according to which (à la Brandom 1983), in asserting p one undertakes a commitment to either defending p or giving up p if the challenge cannot be met satisfactorily (see Kölbel (2004: 308) for some other discussions of this objection).
A related assertion-based challenge to truth-relativism emerges by appeal to Stalnaker’s (1978) belief transfer model of assertion (cf. 2011). The idea here is to appeal to a plausible view of the purpose of assertion—to “transfer beliefs from assertor to members of her audience” (Egan 2007: 15) and then to object that what is asserted, according to the truth-relativist, cannot play this characteristic role; specifically, this will be because, for the truth-relativist, the asserted contents are liable to be true relative to the speaker but false relative to the audience. For instance, Sam hardly (on the truth-relativist’s program) seems to “transfer” to Dean his belief Apples are tasty (which is true) by asserting this to Dean, when what Dean comes to believe Apples are tasty is something (on the assumption that Dean doesn’t like apples) that will be false. Thus, and more generally, it’s not clear what, exactly, could be said to be transferred and a fortiori asserted. See Egan (2007) for an attempt to reconcile truth-relativism (about epistemic modals) with Stalnaker’s belief-transfer model of assertion.
Cappelen and Hawthorne (2009) assess the merits of New Relativism as it stands to challenge what they take to be the received view of the objects of thought and talk, “Simplicity”, the core tenets of which are:
(T1) There are propositions and they instantiate the fundamental monadic properties of truth simpliciter and falsity simpliciter.
(T2) The semantic values of declarative sentences relative to contexts of utterance are propositions.
(T3) Propositions are, unsurprisingly, the objects of propositional attitudes, such as belief, hope, wish, doubt.
(T4) Propositions are the objects of illocutionary acts; they are, e.g., what we assert and deny.
(T5) Propositions are the objects of agreement and disagreement. (Cappelen & Hawthorne 2009: 1)
Cappelen and Hawthorne understand New Relativism (what they call analytic relativism) as a direct challenge to (T1) and that, if this challenge were successful, it would consequently bring down the more general picture they call “simplicity”. Accordingly, Cappelen and Hawthorne’s central objective is to show that truth-relativist’s arguments aimed at undermining (T1) are ultimately unsuccessful; more specifically, their broad strategy is to insist that the arguments adduced in favor of truth-relativism—when thoroughly understood—constitute a presumptive case for contextualism (in the domains where relativism was defended, and in particularly, in the domain of predicates of personal taste).
Relativism comes in a plethora of forms that are themselves grounded in disparate philosophical motivations. There is no such thing as Relativism simpliciter, and no single argument that would establish or refute every relativistic position that has been proposed. Despite this diversity, however, there are commonalities and family resemblances that justify the use of the label “relativism” for the various views we have discussed. Relativism remains a hotly disputed topic still surviving various attempts to eliminate it from philosophical discourse. What is most surprising, however, is the recent popularity of some versions of the doctrine in at least some circles of analytic philosophy.
Aristotle, Metaphysics, in The Works of Aristotle Translated into English, vol. VIII, trans J. A. Smith and W. D. Ross, Oxford: Clarendon Press, 1908.
Ashman, K.M. & P.S. Baringer (eds), 2001, After the Science Wars, London: Routledge.
Baghramian, M., 2004, Relativism, London, New York: Rutledge.
–––, 2007, “Relativism about Science”, in Routledge Companion to Philosophy of Science, London, New York: Routledge :236 –247.
–––, 2010, “Relativism: A Brief History”, in Krausz 2010: 31–50.
–––, 2011, “Constructed Worlds, Contested Truths”, in Richard Schantz & Markus Seidel (eds), The Problem of Relativism in the Sociology of (Scientific) Knowledge, Heusenstamm, Ontos Verlag.
Barnes, B., 1977, Interest and Growth of Knowledge, London: Routledge.
Barnes, B. & D. Bloor, 1982, “Rationalism and the Sociology of Knowledge”, in Hollis and Lukes 1982: 21 –47.
Barry, B., 2000, Culture and Equality, Cambridge: Cambridge University Press.
Beebe, J.R., 2010, “Moral Relativism in Context”, Noûs, 44(4): 691–724.
Berlin, B. & P. Kay, 1969, Basic Color Terms. Their Universality and Evolution, Berkeley: University of California Press.
Bloom, A., 1987, The Closing of the American Mind, New York: Simon & Schuster.
Bloor, D., 1976, Knowledge and Social Imagery, London: Routledge & Kegan Paul.
Boas, F., 1940, Race, Language, and Culture. Chicago: University of Chicago Press.
Boghossian, P., 2006a, Fear of Knowledge, Oxford: Oxford University Press.
–––, 2006b, “What is Relativism?”, in P. Greenough & M. Lynch (eds), Truth and Realism, Oxford: Oxford University Press.
–––, 2011, “Three Kinds of Relativism”, in Hales 2011:53 – 69.
Boroditsky, Lera, 2001, “Does Language Shape Thought? Mandarin and English Speakers’ Conceptions of Time”, Cognitive Psychology, 43: 1–22.
Brandom, R., 1983, “Asserting”, Noûs, 17(4): 637–650.
Brink, D., 1989, “Moral Realism Defended”, in L. Pojman (ed.), Ethical Theory: Classical and Contemporary Readings, Wadsworth, Belmont CA.
Brogaard, B., 2007, “Moral Contextualism and Moral Relativism”, The Philosophical Quarterly, 58(232): 385–409.
Brown, D.E., 2004, “Human Universals, Human Nature & Human Culture”, Daedalus, 133(4): 47. [Brown 2004 available online]
Burnyeat, M.F., 1976a, “Protagoras and Self-Refutation in Later Greek Philosophy”, The Philosophical Review, 85(1): 44–69
–––, 1976b, “Protagoras and Self-refutation in Plato’s Theaetetus”, The Philosophical Review, 172–195.
Callon, M. & B. Latour, 1992, “Don’t Throw the Baby Out with the Bath School! A Reply to Collins and Yearley”, in Andrew Pickering (ed.), Science as Practice and Culture, University of Chicago Press. [Callon & Latour 1992 available online]
Cappelen, H., 2008, “Content Relativism and Semantic Blindness”, in M. García-Carpintero & Max Kölbel (eds) Relative Truth: Oxford: OUP.
Cappelen, H. & J. Hawthorne, 2009, Relativism and Monadic Truth, Oxford: OUP.
Capps, D., M.P. Lynch, & D. Massey, 2009, “A Coherent Moral Relativism”, Synthese, 166(2): 413–430.
Carter, J.A., 2011, “A Note on Assertion, Relativism and Future Contingents”, Logos & Episteme, III(I): 139–144.
–––, 2013, “Disagreement, Relativism and Doxastic Revision”, Erkenntnis, special issue on Disagreements. Eds. Marques, T. & Cohnitz, D.
–––, 2014, “Relativism, Knowledge and Understanding”, Episteme, 11(1): 35–52.
–––, 2016, Metaepistemology and Relativism, Palgrave-MacMillan, forthcoming.
Coliva, A., & Moruzzi, S., 2012, “Truth Relativists Can’t Trump Moral Progress”, Analytic Philosophy, 53(1), 48–57.
Comte, A., 1976 [1830], System of Positive Philosophy, Paris: Bachelier.
Davidson, D., 1974, “On the Very Idea of a Conceptual Scheme”, in D. Davidson (1984) Inquiries into Truth and Interpretation, Oxford: Oxford University Press.
DeRose, K., 2004, “Single Scoreboard Semantics”, in Philosophical Studies, 119: 1–21.
Derrida, J., 1974, Of Grammatology, tr., Gayatri Spivak, Baltimore: The Johns Hopkins University Press.
Diderot, 1956 [1772], “Supplement to Bougainville’s ‘Voyage’”, in Rameau’s Nephew and Other Works, J. Barzum & R. H. Bowen (transs), New York: Doubleday, pp. 183–239.
Dreier, J., 1990, “Internalism and Speaker Relativism”, Ethics, 101(1): 6–26.
–––, 2006, “Moral Relativism and Moral Nihilism”, in D. Copp (ed.) The Oxford Handbook of Ethical Theory, New York: Oxford University Press, pp. 240–64.
–––, 2009, “Relativism (and Expressivism) and the Problem of Disagreement.” Philosophical perspectives, 23(1): 79–110.
Egan, A., 2007, “Epistemic Modals, Relativism and Assertion”, Philosophical Studies, 133: 1–22.
–––, 2011, “Relativism about Epistemic Modals”, in Hales 2011: 219– 241.
Egan, A. & B. Weatherson (eds), 2011, Epistemic Modality, Oxford: Oxford University Press.
Egan, A., J. Hawthorne, & B. Weatherson, 2005, “Epistemic Modals in Context”, in Gerhard Preyer & Georg Peter (eds) Contextualism in Philosophy: Knowledge, Meaning and Truth, Oxford: Oxford University Press, pp. 131–170.
Evans-Pritchard, E.E., 1937, Witchcraft, Oracles and Magic among the Azande, Oxford: Clarendon Press.
Evans, G., 1985, Collected Papers, Oxford: Oxford University Press.
Feyerabend, P., 1978, Against Method, London: New Left Books.
–––, 1987, Farewell to Reason, London: Verso.
Foot, P., 1982, “Moral Relativism”, in Michael Krausz & Jack Meiland (eds), Relativism: Cognitive and Moral, Notre Dame, IN: University of Notre Dame Press, pp. 152–166.
Fricker, M., 2013, “Styles of Moral Relativism : a Critical Family Tree”, in Roger Crisp (ed.),The Oxford Handbook of the History of Ethics, Oxford: Oxford University Press. [Fricker 2013 available online]
Gardiner, P., 1981, “German Philosophy and the Rise of Relativism”, The Monist, 64(2): 138–154.
Geertz, C., 1993, Local Knowledge, London, Fontana.
Glanzberg, M., 2007, “Context, Content, and Relativism”, Philosophical Studies 136(1): 1–29.
Goldman, A., 2010, “Epistemic Relativism and Reasonable Disagreement”, in Disagreement, Richard Feldman and Ted A. Warfield, Oxford: Oxford University Press, pp. 187–215.
Goodman, N., 1978, Ways of Worldmaking, Indianapolis, IN: Hackett.
–––, 1975, “Words, Works, Worlds”, Erkenntnis, 9(1):57–73.
Greenough, P., 2010, “Relativism, Assertion and Belief”, in Assertion, (ed). Brown and Cappelen, Oxford: University Press.
Grote, J., 1865, Exploratio Philosophica: Rough Notes on Modern Intellectual Science, Cambridge: Deighton, Bell and Co.
Gumperz, J. & S. Levinson (eds), 1996, Rethinking Linguistic Relativity, Cambridge: Cambridge University Press
Haack, S., 1996, “Reflections on Relativism: From Momentous Tautology to Seductive Contradiction”, Philosophical Perspectives, 10: 297–315.
Hacking, I., 1982, “Language, Truth and Reason”, in Hollis & Lukes 1982: 48–66. [Hacking 1982 available online]
Hales, S.D., 1997, “A Consistent Relativism”, Mind, 106(421): 33–52.
–––, 2006, Relativism and the Foundations of Philosophy, Cambridge MA.: The MIT Press.
––– (ed.), 2011, A Companion to Relativism, Oxford: Blackwell Publishing.
–––, 2014, “Motivations for Relativism as a Solution to Disagreements”, Philosophy, 89 (01): 63–82.
Hamann, J.G., 1967 [1759], Hamann’s Socratic Memorabilia. A Translation and Commentary, James C. O’Flaherty (trans and ed.), Baltimore, MD: The Johns Hopkins University Press.
Harman, G., 1975, “Moral Relativism Defended”, The Philosophical Review, 84(1): 3–22.
Harman, G. & J.J. Thomson, 1996, Moral Relativism and Moral Objectivity, Oxford: Blackwell.
Harre, R. & M. Krausz, 1996, Varieties of Relativism, Oxford, UK: Blackwell.
Hawthorne, J., 2007, “Eavesdroppers and Epistemic Modals”, in Philosophical Issues 17, The Metaphysics of Epistemology.
Herder, J.G., 2002, Philosophical Writings, M. N. Forster (ed.), "This Too a Philosophy of History for the Formation of Humanity" (1774), Cambridge: Cambridge University Press. 272–358,
Hollis, M, 1968, “Reason and Ritual”, Philosophy, 43(165): 231–247.
Hollis, M. & S. Lukes (eds), 1982, Rationality and Relativism, Oxford: Basil Blackwell.
Jennings, Richard C., 1989, “Zande Logic and Western Logic”, British Journal for the Philosophy of Science, 40(2): 275–285
Kaplan, D., 1989, “Demonstratives: an Essay on the Semantics, Logic, Metaphysics, and Epistemology of Demonstratives and other Indexicals”, in J. Almog, J. Perry, & H. Wettstein (eds.), Themes from Kaplan, Oxford: Oxford University Press, pp. 481–566.
Knobe, J. & S. Nichols, 2007, “An Experimental Philosophy Manifesto”, in Knobe & Nichols (eds), Experimental Philosophy, Oxford: Oxford University Press, pp. 3–14.
Knorr-Cetina, K., 1981, The Manufacture of Knowledge, Oxford: Pergamon Press.
Kölbel, M., 2003, “Faultless Disagreement”, Proceedings of the Aristotelian Society, New Series, 104(1): 53–73
–––, 2004, “Indexical Relativism Versus Genuine Relativism”, International Journal of Philosophical Studies, 12(3): 297–313.
–––, 2011, “Global Relativism and Self-Refutation”, in Hales 2011: 11– 30.
–––, 2013, “Relativism”, Philosophy Compass, 10(1): 38–51.
–––, 2015, “Relativism 2: Semantic Content”, Philosophy Compass, 10(1): 52–67.
Kolodny, N. & J. MacFarlane, 2010, “Ifs and Oughts”, The Journal of Philosophy, 107(3): 115–143.
Kompa, N., 2002, “The Context Sensitivity of Knowledge Ascriptions”, Grazer Philosophische Studien, 64: 79–96.
Krausz, M. (ed.), 1989, Relativism: Interpretation and Confrontation, Notre Dame, IN: University of Notre Dame Press.
––– (ed.), 2010, Relativism: A Contemporary Anthology, New York: Columbia University Press.
Krug, W.T., 2010 [1838], Encyklopädisches Lexikon in Bezug auf die neueste Literatur und Geschichte der Philosophie, Leipzig: Nabu Press.
Kuhn, T.S., 1970 [1962], The Structure of Scientific Revolutions, 2nd ed., Chicago: University of Chicago Press.
Kusch, M., 1995, Psychologism, London, New York: Routledge.
–––, 2002, Knowledge by Agreement, Oxford: Oxford University Press.
–––, 2010, “Epistemic Replacement Relativism Defended.” In Mauricio Suarez (ed), EPSA Epistemology and Methodology of Science: Launch of the European Philosophy of Science Association: 165–75.
–––, forthcoming, “Scientific Pluralism and the Chemical Revolution”, Studies in History and Philosophy of Science.
Lasersohn, P., 2005, “Context Dependence, Disagreement, and Predicates of Personal Taste”, Linguistics and Philosophy, 28: 643–86.
Latour, B. & S. Woolgar, 1986, Laboratory Life: The Construction of Scientific Facts, Princeton: Princeton University Press.
Laudan, L., 1990, “Demystifying Underdetermination”, , Scientific Theories, C. Wade (ed.) , University of Minnesota Press: 267–97.
Levinson, S., 1996, “Frames of Reference and Molyneux’s Question: Crosslinguistic Evidence”, in Paul Bloom, M.F. Garrett, L. Nadel, & M.A. Peterson (eds). Language and Space, MIT Press, pp. 109–169.
Lévy-Bruhl, L., 1922/1923, Primitive Mentality, trans. Lilian Clare, London: George Allen & Unwin.
–––, 1949/1975, The Notebooks on Primitive Mentality, Oxford: Blackwell.
Lewis, D., 1980, “Index, Context, and Content”, in Stig Kanger & Sven Öhman (eds), Philosophy and Grammar, Reidel.
–––, 1979, “Scorekeeping in a Language Game”, Journal of Philosophical Logic, 8: 339–359.
López de Sa, D., 2012, “What Does it Take to Enter into the Circumstance?”, Philosophical Studies, 1–7.
Ludlow, P., 2005, “Contextualism and the New Linguistic Turn in Epistemology”, in Contextualism in Philosophy: Knowledge, Meaning, and Truth, G. Preyer and G. Peter (eds), Oxford: Oxford University Press, pp. 11–50.
Lukes, S., 1970, “Some Problems about Rationality”, Rationality, Bryan Wilson (ed.), Oxford: Blackwell.
MacFarlane, J., 2003, “Future Contingents and Relative Truth”, The Philosophical Quarterly, 53: 321–336. [MacFarlane 2003 available online]
–––, 2005a, “Semantic Minimalism and Nonindexical Contextualism”, in G. Preyer & G. Peter (eds), Content and Context: Essays on Semantics and Pragmatics, Oxford: Oxford University Press.
–––, 2005b, “The Assessment Sensitivity of Knowledge Attributions”, in T. Szabo Gendler and J. Hawthorne (eds) Oxford Studies in Epistemology, 1: 197–233.
–––, 2007, “Relativism and Disagreement”, Philosophical Studies, 132: 17–31.
–––, 2008a, “Truth in the Garden of Forking Paths”, in M. Kölbel and M. Garcia-Carpintero (eds), Relative Truth, Oxford: Oxford University Press, pp. 81–102.
–––, 2008b, “Boghossian, Bellarmine, and Bayes”, Philosophical Studies, 141(3): 391–98.
–––, 2011a, “Simplicity made Difficult”, Philosophical studies, 156(3): 441–448.
–––, 2011b, “Epistemic Modals are Assessment Sensitive”, in Egan and Weatherson 2011: 144 –178.
–––, 2011c, “Relativism and Knowledge Attributions”, in Pritchard and Sven Bernecker (eds.), The Routledge Companion to Epistemology. London: Routledge, 536–544.
–––, 2012, “Richard on Truth and Commitment”, Philosophical Studies, 1–9.
–––, 2014, Assessment Sensitivity: Relative Truth and its Applications, Oxford: Oxford University Press.
MacIntyre, A., 1982, “Philosophy, the Other Disciplines, and Their Histories: A Rejoinder to Richard Rorty.” Soundings, 127–145.
–––, 1985, “Relativism, Power and Philosophy”, Proceedings and Addresses of the American Philosophical Association 59: 5–22.
–––, 1988, Whose Justice? Which Rationality?, Notre Dame, IN: University of Notre Dame Press.
Mackie, J.L., 1964, “Self-Refutation—a Formal Analysis”, Philosophical Quarterly, 14(56): 193–203.
–––, 1977, Ethics: Inventing Right and Wrong, Penguin.
Malotki, E., 1983, Hopi Time: A Linguistic Analysis of the Temporal Concepts in the Hopi Language, Trends in Linguistics. Studies and Monographs 20, Berlin, New York, Amsterdam: Mouton Publishers.
Mannheim, K., 1952 [1924], “Historicism”, in Essays in the Sociology of Knowledge, P. Kecskemeti (ed. and trans.), London: Routledge & Kegan Paul.
Marenbon, J., 2003, Boethius, Oxford: Oxford University Press
Margolis, J., 1991, The Truth About Relativism, Oxford, UK: Blackwell.
Meiland, J., 1977, “Concepts of Relative Truth”. The Monist, 568–582.
Mill, J.S., 1884, An Examination of Sir William Hamilton’s Philosophy and of the Principal Philosophical Questions Discussed in his Writings, New York: Henry Holt and Company.
Montaigne, M., 1991 [1580], “On Cannibals”, in Essays, London: Penguin, 1991.
Moody-Adams, M., 1997, Fieldwork in Familiar Places: Morality, Culture, and Philosophy, Cambridge, Mass.: Harvard University Press.
Nietzsche, F., 1996 [1886a], Beyond Good and Evil, W. Kaufmann (trans.), New York: Vintage.
–––, 1968 [1886b], The Will to Power, W. Kaufmann (trans.), New York: Vintage.
Nisbett, R.E., 2003, The Geography of Thought: How Asians and Westerners Think Differently and Why, New York: Free Press.
Norris, C., 1997, Against Relativism: Philosophy of Science, Deconstruction and Critical Theory, Oxford, UK: Blackwell.
Nozick, R., 2001, Invariances: The Structure of the Objective World, Cambridge: Harvard University Press.
Nussbaum, M. C., 1997, Cultivating Humanity: A Classical Defense of Reform in Liberal Education, Harvard: Harvard University Press.
O’Grady, P., 2002, Relativism, Acumen Press.
Peng, K and. Nisbett, R.E., 1999, “Culture, Dialectic, and Reasoning about Contradiction”, American Psychologist, 54(9): 741.
Pickering, A., 1999, Constructing Quarks: A Sociological History of Particle Physics, Chicago: University of Chicago Press.
Plato, Theaetetus and Phaedrus, in Complete Works, M. J. Levett (trans.), Myles Burnyeat (rev.), John M. Cooper and D. S. Hutchinson (eds), Indianapolis, IN: Hackett, 1997.
Popper, K., 1994, The Myth of the Framework: In Defence of Science and Rationality, London: Routledge.
Putnam, H., 1987, “Truth and Convention: On Davidson’s Refutation of Conceptual Relativism”, Dialectica, 41(1–2): 69–77.
–––, 1988, Representation and Reality, Cambridge, MA & London: Harvard University Press.
–––, 1999, Realism with a Human Face, Cambridge, MA: Harvard University Press.
Quine, W.V., 1960, Word and Object, Cambridge, MA: MIT Press
–––, 1970, “On the Reasons for Indeterminacy of Translation”, Journal of Philosophy, 67(6): 178–183.
–––, 1992, Pursuit of Truth, Revised edition, Cambridge, MA: Harvard University Press.
Rachels, J., 2009, “The Challenge of Cultural Relativism”, in Steven M. Cahn (ed.), Exploring Philosophy: An Introductory Anthology, Oxford: Oxford University Press. [Rachels 2009 available online]
Ratzinger, J. 2005,“Homily of His Eminence Card. Joseph Ratzinger, Dean of the College of Cardinals ”, Vatican Basilica, Monday 18 April 2005. [Available online]
Richard, M., 2004, “Contextualism and Relativism.” Philosophical Studies, 119(1): 215–242.
–––, 2008, When Truth Gives Out, Oxford: Oxford University Press.
Rorty, R., 1979, Philosophy and the Mirror of Nature, Princeton: Princeton UP.
–––, 1982, Consequences of Pragmatism, Minneapolis: University of Minnesota Press.
–––, 1991, Objectivity, Relativism, and Truth: Philosophical Papers, Vol. 1, Cambridge: Cambridge University Press.
–––, 1993, “Putnam and the Relativist Menace”, The Journal of Philosophy, 90(9): 443–461.
Rosch, E., 1974, Linguistic relativity, in A. Silverstein (ed.), Human communication: Theoretical perspectives, New York: Halstead.
Ross, J., & Schroeder, M., 2013, “Reversibility or Disagreement”, Mind, 122(485): 43–84.
Rovane, C., 2012, “How to Formulate Relativism”, in Crispin Wright & Annalisa Coliva (eds), Mind, Meaning, and Knowledge: Themes From the Philosophy of Crispin Wright, Oxford: Oxford University Press.
–––, 2013, The Metaphysics and Ethics of Relativism, Cambridge MA: Harvard University Press.
Sankey, H., 2010, “Witchcraft, Relativism and the Problem of the Criterion”, Erkenntnis, 72(1): 1–16.
–––, 2011, “Epistemic Relativism and the Problem of the Criterion”, Studies in History and Philosophy of Science Part A, 42(4): 562–570.
Seidel, M., 2014, Epistemic Relativism: A Constructive Critique, Palgrave Macmillan.
Sextus Empiricus, [PH], Outlines of Pyrrhonism, J. Annas and J. Barnes (transs), Cambridge: Cambridge University Press, 1994,.
Shogenji, T., 1997, “The Consistency of Global Relativism”, Mind, 106(424): 745–747.
Sider, T., 2009, “Ontological Realism”, in Metametaphysics, D. Chalmers, D. Manley, and R. Wasserman (eds), Oxford: Oxford University Press.
Siegel, H., 1987, Relativism Refuted: A Critique of Contemporary Epistemological Relativism, Dordrecht, The Netherlands: D. Reidel Publishing Company.
–––, 2011, “Epistemological Relativism: Arguments Pro and Con”, in Hales 2011: 201–218.
Sokal, A. and J. Bricmont, 1998, Intellectual Impostures, London: Profile Books.
Spengler, O., 1918, The Decline of the West. London: Allen and Unwinn.
Stace, W.T., 1937, The Concept of Morals, New York: The Macmillan Company.
Stalnaker, R., 1978, “Assertion”, in Syntax and Semantics New York Academic Press, 9: 315–332.
Stanley, J., 2005, Knowledge and Practical Interests, Oxford: Oxford University Press.
Stich, S., 2012, Collected Papers, Volume 2: Knowledge, Rationality, and Morality, 1978–2010, Oxford: Oxford University Press.
Stephenson, T., 2007, “Judge Dependence, Epistemic Modals, and Predicates of Personal Taste”, Linguistics and Philosophy, 30: 487–525.
Swoyer, C., 2010, “Relativism”, The Stanford Encyclopedia of Philosophy, (Winter 2010 Edition), Edward N. Zalta (ed.).
Velleman, J.D., 2013, Foundations for Moral Relativism, OpenBook Publishers.
von Fintel, K. & Gillies, A., 2011, “Might Made Right”, in Egan & Weatherson 2011: 108–130.
Weatherson, B., 2001, “Indicative and Subjunctive Conditionals”, Philosophical Quarterly, 51(203): 200–16.
–––, 2009, “Conditionals and Indexical Relativism”, Synthese, 166(2): 333–57.
Westermarck, E., 1932. Ethical Relativity, London: Kegan Paul, Trench, Trubner & Co., Ltd.
Whorf, B.L., 1956, Language, Thought, and Reality, Cambridge: MIT Press.
Williams, B., 1975, “The Truth in Relativism”, reprinted in Krausz 2010: 242–253
–––, 1985, Ethics and the Limits of Philosophy, Cambridge, MA: Harvard University Press.
Williams, M., 2007, “Why Wittgensteinian Contextualism is not Relativism”, Episteme: A Journal of Social Epistemology, 4(1): 93–114. [Williams 2007 available online]
Williamson, T., 2015, Tetralogue: I’m Right, You’re Wrong, Oxford: Oxford University Press.
Wilson, B., (ed.), 1970, Rationality, Oxford: Basil Blackwell.
Winch, P., (1958), The Idea of a Social Science and its Relation to Philosophy, London: Routledge & Kegan Paul.
–––, 1964, “Understanding a Primitive Society”, American Philosophical Quarterly, 1(4): 307–324.
Wittgenstein, L., 1969, On Certainty, Oxford: Basil Blackwell.
Wong, D., 1984, Moral Relativity, Berkeley: University of California Press.
–––, 2006, Natural Moralities: A Defense of Pluralistic Relativism, Oxford: Oxford University Press.
Wright, C., 2001, “On Being in a Quandary”, Mind, 110: 45–98.
–––, 2006, “Intuitionism, Realism, Relativism and Rhubarb”, in P. Greenough & M.P. Lynch (eds), Truth and Realism, Oxford: Clarendon Press, pp. 38–60.
–––, 2007, “New Age Relativism and Epistemic Possibility: The Question of Evidence”, Philosophical Issues, 17(1): 262–283.
–––, 2008, “Fear of Relativism?”, Philosophical Studies, 141: 379–390.
Yalcin, S., 2011, “Nonfactualism about Epistemic Modality”, in Egan and Weatherson 2011: 295–332.
We would like to thank Paul Boghossian, Annalisa Coliva, Steven Hales, Max Kölbel, Martin Kusch, John MacFarlane, Michela Massimi, Brian Morrissey, Brian Rabern, Tim Williamson and two anonymous referees for their valuable comments on various earlier drafts of this paper.
Open access to the SEP is made possible by a world-wide funding initiative.
Please Read How You Can Help Keep the Encyclopedia Free
The SEP would like to congratulate the National Endowment for the Humanities on its 50th anniversary and express our indebtedness for the five generous grants it awarded our project from 1997 to 2007. Readers who have benefited from the SEP are encouraged to examine the NEH’s anniversary page and, if inspired to do so, send a testimonial to neh50@neh.gov.Pacifism
Pacifism is a commitment to peace and opposition to war. Our ordinary language allows a diverse set of beliefs and commitments to be held together under the general rubric of pacifism. This article will explain the family resemblance among the variety of pacifisms. It will locate pacifism within deontological and consequentialist approaches to ethics. And it will consider and reply to objections to pacifism.
The word “pacifism” is derived from the word “pacific,” which means “peace making” [Latin, paci- (from pax) meaning “peace” and -ficus meaning “making”]. Pacifism in the West appears to begin with Christianity. Perhaps the most famous use of the word pacifism is found in the Sermon on the Mount (Matthew 5), where Jesus claims that the “peacemakers” are blessed. In this passage, the Greek word eirenopoios is translated into Latin as pacifici, which means those who work for peace. The Greek eirenopoios is derived from the Greek eirênê [peace] in conjunction with poiesis [to make].
Philosophical discussions of pacifism have clarified the concept by distinguishing the more general commitment to nonviolence from a narrower anti-war position. Pacifism is further defined through its dialectical relation to the idea of justified violence that is found in the Western just war tradition, with many locating pacifism on a continuum for assessing the morality of war that includes realism, just war theory, and pacifism. Indeed, there is an ongoing debate about the proper relation between just war theory and pacifism that focuses on the question of whether the just war theory begins with a pacifist presumption against war. Some authors (May, for example) have used the just war theory to derive a version of pacifism described as “contingent pacifism” or “just war pacifism.”
Some have tried to distinguish “pacific-ism” from pacifism, where pacific-ism is a commitment to peace and peacefulness that is not strictly opposed to war while pacifism is a more principled or absolute rejection of violence. But this distinction is not widely accepted (although Dower has employed it recently). William James used the term “pacific-ism” in 1910 to describe his rejection of militarism. The shorter term, “pacifism,” has become more common in English usage during the 20th Century to describe a variety of views that are critical of war.
Generally pacifism is thought to be a principled rejection of war and killing. Oddly enough, the term pacifism has occasionally been used to describe a pragmatic commitment to using war to create peace. Thus some who called themselves “pacifists” (for example, during the First World War) supported war as a suitable means toward peace. Richard Nixon once called himself a pacifist, even as he continued to support the Vietnam War. This perverse use of pacifism is connected to the way a term like “pacification” can be employed in military usage to describe a violent process of suppressing violence, as when an enemy territory is “pacified” by killing or disabling the enemy. While George Orwell and others have complained about such euphemistic descriptions of violence, the just war tradition does hold that war can be a suitable means to bring about peace. Despite these complications, pacifism generally connotes a commitment to making peace that rejects violent means for obtaining this end. One reason to reject violent means is the fact that might does not make right. While violence can destroy an enemy, victory does not amount to justification.
Pacifism, as it is understood in ordinary discourse today, includes a variety of commitments on a continuum from an absolute adherence to nonviolence in all actions to a more focused or minimal sort of anti-warism. In contrast to the just war tradition, pacifism rejects war as an acceptable means for obtaining peace. Pacifists will often refuse to serve in the military. And some refuse to support political and social systems that promote war by, for example, withholding their taxes. Pacifism can be used to describe a commitment to nonviolence in one's personal life that might include the attempt to cultivate pacific virtues such as tolerance, patience, mercy, forgiveness, and love. It might also be extended to include nonviolence toward all sentient beings and thus result in a commitment to vegetarianism and what Albert Schweitzer called, “reverence for life.” And pacifism can be connected to a larger project of spiritual transformation, as in Gandhi's commitment to ahimsa or nonviolence.
Pacifism is the broad commitment to making peace. The idea is complicated by the fact that peace is a family resemblance term: there are many varieties of peace. Peace is easiest to define dialectically as the opposite of war or violence. Pacifism has thus been described simply as anti-warism or as commitment to nonviolence. One conceptual difficulty here is that when peace is defined negatively, pacifism appears as a reactionary response to war and violence. Discussions of peace thus often employ negative terms and creative neologisms to express the concept of peace: “nonviolence,” “nonwar,” “nonkilling,” “nonconflict,” or “nonwar.” Peace advocates will however insist that peace should be understood as a primary concept connected to cooperation, harmony, and positive human relations and that it is a mistake to understand peace in merely negative terms (see Fox 2014). At any rate, peace scholarship has long emphasized the distinction between negative peace and positive peace: negative peace is the absence of violence or war while positive peace encompasses cooperative, tranquil, and harmonious relations and the broader concerns of human flourishing and integration (see Galtung 1969).
When pacifism is defined as anti-warism, we encounter the difficulty of defining war. War is usually thought of as violence between states or, more broadly speaking, political communities. But the term “war” can also be applied to violent conflicts among individuals, as in Hobbes’ idea that the state of nature is a state of war. Similarly, although peace is usually thought of as a political condition of amicable relations between states, terms like “peace” or “peaceful” can also be used to describe a relation between individuals or even a person's state of mind.
If pacifism is defined as a commitment to nonviolence, we encounter the same problem of definition. Violence usually has a normative value and is defined as something like “an unjustified injury or harm.” But it is possible to speak of justified violence—as in the just war ideal; so not all violence is unjustified. The concept of violence can also be extended metaphorically and used as an adjective—“violent”—to mean something like unbridled, uncontrolled, rough, or intense. Thus we speak of “violent storms” or “violent emotions.” A commitment to nonviolence is, at least, a commitment to avoiding unjustified intentional injury. Pacifists will tend to think that most intentionally caused harms are unjustifiable. But the ideal of nonviolence might be extended to include the idea of controlling rough and intense emotions. In his essay, “Journey to Nonviolence,” for example, Martin Luther King Jr. claimed that a commitment to nonviolence required overcoming the “internal violence” of hatred and anger by cultivating love and compassion (King 1986, 46).
There are a variety of possibilities for thinking about the nature of peace and thus for understanding what pacifism aims at creating.
Peace can result from submission to power; and war can end with unconditional surrender. Rousseau maligned this sort of peace by calling it the “peace of Ulysses and his comrades, imprisoned in the cave of the Cyclops and waiting their turn to be devoured” (Rousseau 1917, 125). We might claim that absolute rule and absolute submission produce a sort of peace. But this is peace conjoined with injustice. So it is clear that the sort of peace that is worth pursuing is peace that is also linked to justice. The idea of justice is at the heart of the just war tradition, which claims that we are entitled to fight back against injustice. As Patrick Henry asked in his famous “Give me Liberty or Give me Death Speech”: “Is life so dear, or peace so sweet, as to be purchased at the price of chains and slavery?” One might claim that the peace of the Cyclops’ cave is not peace at all but a state of war.
Most pacifists will claim that the peace of slavery is not what they have in mind. Rather, for the majority of pacifists, pacifism is not simply acquiescing passively to evil—pacifism is not passive-ism. Rather, pacifism involves actively but nonviolently resisting evil. Nonetheless, some pacifists, such as Tolstoy, do advocate nonresistance. Nonresistant pacifists in the Christian tradition often base the idea of submitting to evil on Jesus’ ideas as expressed in the Sermon on the Mount. “Do not resist one who is evil” and “love your enemies and pray for those who persecute you” (Matthew 5.39 and 5.44; Luke 6.27–30). Some Christian martyrs take this ideal seriously and look to Jesus’ life and execution as a model of pacific virtue.
The dialectical definition of peace as the absence of war can encompass the idea of the armed peace of the Cold War. Peace as the absence of war may be a mere modus vivendi in which armed opponents refrain from attacking one another out of fear. This sort of peace is the peace of a truce or stalemate. While it is true that in such conditions, there is no overt damage done, the opponents have not been reconciled and hostile intentions have not been eliminated. Some may claim that the best we can do to make peace is to reach a state of detente that is made possible by mutual deterrent force. Related to this is what might be called, following Raymond Aron, “peace by impotence” or peace by exhaustion (Aron 1966, 159 ff). In this sort of peace, the antagonistic parties are simply no longer willing to fight. Hostile intentions may persist; but the will to fight can no longer be actualized. Kant rejected this sort of peace, claiming that peace means “an end to all hostilities” (Kant 1991, 93). This is why Kant maintains that the first principle of perpetual peace is that states should not make “secret reservation of the material for future war” (93).
Those who call themselves “pacifists” will usually agree with Kant that a mere modus vivendi produced by impotence or exhaustion is not actually peace, since hostile intent remains. And pacifists will argue that the peace of deterrence and detente are not really peace either, because they are the result of an increase in armaments and the threat of escalated violence.
Opposed to peace as modus vivendi is what Aron calls, “peace by satisfaction” (Aron 1966, 160 ff). This is a peace that results from a lack of grievances and hostility. In the history of the West, this sort of peace is often linked to what Augustine called the “tranquility of order” (Augustine 1958, Book 19, Chapter 13) In recent Western thought, this idea often follows Kant in claiming that liberal democracy is the key to such a tranquil order.
Francis Fukuyama's Hegelian idea about the “end of history,” for example, hoped that the end of the Cold War would bring about the end of war in general, as liberal-democracy spread. Similarly, Michael Doyle has claimed that democracies do not go to war with one another. John Rawls has explained the stability of well-ordered democratic states as follows: “There is true peace among them because all societies are satisfied with the status quo for the right reasons” (Rawls 1999, 47). More recently, this idea about the stabilizing and peace-making power of democracy has influenced neo-conservative ideas in U.S. foreign policy, where the hope is that peace will occur as democracy is spread.
The idea that peace is founded in a just political order is connected to the ideas of the just war tradition. Defenders of the just war tradition—from Augustine to Walzer—argue that occasionally it is necessary to make war in order to establish such a tranquil and just social condition. More recent defenders of the just war idea—such as Luban, Lucas, and Teson—have argued that interventionist wars should be fought in order to create stable conditions by defending human rights.
Pacifists will disagree with those who claim that wars should be fought in pursuit of the ideal of a just and stable social order. Proponents of humanitarian intervention maintain that war is a suitable means for attaining the goal of respect for human rights and satisfaction of human needs; but pacifists will argue that only nonviolent means are coherent with the these intended ends.
Positive definitions of peace go beyond merely dialectical definitions of peace as the opposite of war and instead focus on peace as a state of rest, wholeness, or completion. The peace of a just and tranquil order points toward something like a condition of wholeness in which there is solidarity, mutual respect, and satisfaction of needs. In this vision of peace there is genuine community and human flourishing. One central concern from the standpoint of positive peace is the work of peace education, as well as work on nonviolent conflict resolution and mediation (see Fitz-Gibbon 2010). Related concerns point toward the importance of justice, with a special focus on restorative justice and community building.
The positive ideal of peace can point beyond the merely political realm and aim toward spiritual transformation. In Christian contexts this is related to the peace of God that surpasses all understanding (as in Philippians 4.7). In Buddhism, this is related to the idea propounded by Thich Nhat Hanh of “being peace” that is connected to Buddhist practice. The Dalai Lama claims that peace is more than the absence of war and he connects his vision of world peace to peacefulness as a state of mind: “peace is a state of tranquility founded on the deep sense of security that arises from mutual understanding, tolerance of others’ point of view, and respect for their rights” (Dalai Lama, 202). This is closely related to the ideal of social stability; but the Dalai Lama also connects it to the deeper process of personal transformation. Building upon these ideas, Michael Fox has described “peace as a way of life”: “a peaceful way of life will be such as to incorporate nonviolence toward oneself and others, and will be guided by cooperation, mutual respect, creative problem-solving, negotiation of differences, and caring concern or compassion” (Fox 2014, 202).
Positive peace can be best understood from the tradition of virtue ethics, where peacefulness is understood as a virtue that is connected to other virtues such as modesty, tolerance, and mercy. It is important to note that peace is not mere quietism and the passivity of meditation or contemplation. Jay McDaniel has recently argued in favor of a notion of “creative peace” in which there is tension and activity as individuals and cultures must learn to listen to and interact with one another.
2. Varieties of Pacifism
Pacifism includes a wide variety of ideas that can be gathered under the general idea that war and violence are morally wrong. This variety can be organized in several ways according to various interrelated conceptual distinctions: absolute and contingent pacifism; maximal and minimal pacifism; universal vs. particular pacifism. These distinctions overlap, as we shall see here.
This distinction organizes different answers to the question of how obligated we are to reject violence and war. Absolute pacifism is understood as a maximal and universal rejection of violence and war. Absolutism in ethics (or moral absolutism) holds that moral principles are eternal and unchanging and that they admit no exceptions. So, absolute pacifism holds that war and violence are always wrong. One recent proponent of a version of absolute pacifism is Michael Allen Fox. Fox argues that war is inconsistent with morality and with human well-being. He concludes by asserting a “very strong form of pacifism” and admits that this results in some uncomfortable conclusions, such as that “even military action aimed at protecting people against acute and systematic human-rights violations cannot be justified” (Fox 2014, 126). Fox explains that pacifism results in a difficult dilemma that is reminiscent of the question of whether two wrongs can make a right. Fox asks, “Should immoral actions be used to stop other (perhaps gravely more) immoral actions?”(Fox 2014, 127). He answers “No,” and maintains that this shows us that we have to work to find ways to move beyond our reliance on war as the solution to social and political problems.
Non-absolute pacifism may be called contingent pacifism. While absolute pacifism admits no exceptions to the rejection of war and violence, contingent pacifism is usually understood as a principled rejection of a particular war. A different version of contingent pacifism can also be understood to hold that pacifism is only an obligation for a particular group of individuals and not for everyone. Contingent pacifism can also be a principled rejection of a particular military system or set of military policies. Contingent pacifists may accept the permissibility or even necessity of war in some circumstances and reject it in others, while absolute pacifists will always and everywhere reject war and violence.
Absolute pacifism is often connected with a religious standpoint in which nonviolence is seen as a religious commandment. Thomas Merton explains that Gandhi and most other absolute pacifists have a larger metaphysical view: “as Gandhi saw, the fully consistent practice of nonviolence demands a solid metaphysical basis both in being and in God” (Merton 1971, 209). In the West, absolute pacifism is often derived from the Christian ideal of nonresistance to evil as required by Jesus’ pronouncements about nonresistance in the Sermon on the Mount (in Matthew) or the Sermon on the Plain (in Luke). In Indian traditions, it is grounded in the commitment to ahimsa or nonviolence that is derived from a larger metaphysical picture which emphasizes karmic interdependence, ascetic self-abnegation, and compassion. The religious foundation of absolute pacifism is often tied to the idea that there is merit in suffering violence without retaliating. As Martin Luther King Jr. puts this, “unearned suffering is redemptive” (King 1986, 18).
Absolute pacifism is an ideal. Some versions of absolute pacifism go so far as to abjure the idea of personal self-defense. Other absolute pacifists may allow for personal self-defense while rejecting the impersonal and political violence of war. Almost every defender of absolute pacifism recognizes the difficulty of attaining to the absolute idea. Gandhi writes the following in his autobiography: “Man cannot for a moment live without consciously or unconsciously committing outward himsa (violence)… A votary of ahimsa (nonviolence) therefore remains true to this faith if the spring of all his actions is compassion, if he shuns to the best of his ability the destruction of the tiniest creature, tries to save it, and thus incessantly strives to be free from the deadly coil of himsa. He will be constantly growing in self-restraint and compassion, but he can never become entirely free from outward himsa” (Gandhi 1993, 439). The absolute ideal is nearly impossible to achieve because we must harm other beings in order to survive: we must kill in order to eat. And the world often presents us with difficult “kill or be killed” choices as in the question of self-defense or war. Absolute pacifists may hold that it is better to be killed than to kill. But such a choice may be impossible for many of us to make. Pacifists will often argue that this way of describing a situation—as one where the choice is “kill or be killed”—usually presents us with a false dilemma: often there are other nonviolent alternatives to either killing or being killed. But when presented with such a stark choice, absolute pacifism may require self-sacrifice.
Contingent or conditional pacifism qualifies such an uncompromising condemnation of violence and warfare. Albert Einstein and Bertrand Russell, for example, were both supporters of the war against Nazi Germany, despite the fact that each considered himself to be a pacifist. Russell identified his position as what he called “relative political pacifism” (Russell 1943). Russell uses the word “relative” to describe the contingent nature of the commitment to peace: one's commitment to pacifism depends upon or is relative to the nature of the war. Relative pacifism means, for Russell, “that very few wars are worth fighting, and that the evils of war are almost always greater than they seem to excited populations at the moment when war breaks out” (Russell 1943, 8). Russell calls his position “political” because his emphasis is on war and political institutions, not on a personal commitment to nonviolence.
Along these lines, David Cortright has recently described what he calls “realistic pacifism.” Cortright claims that in the realm of nuclear war, pacifism is absolute. But in other sorts of conflict, pacifism is “conditional and pragmatic” and “predicated on a presumption against armed violence, but it acknowledges that the use of force, constrained by rigorous ethical standards, may be necessary at times for self-defense and the protection of the innocent” (Cortright 2008, 334). Such an idea is clearly related to just war theory. Indeed, some authors (such as Larry May) have derived contingent pacifism from just war thinking.
There are several varieties of contingent pacifism.
First, pacifism may not be required of all moral agents. Thus pacifism may only be required for members of particular professions. Pacifism is often thought to be a professional obligation of certain religious vocations. But such a vocation may be thought of as a choice of conscience that is not universally required. In this version of contingent pacifism, the prohibition against violence only applies to those who take a vow or make a pledge to renounce violence and war. Within this two-tiered approach, the vow of peacefulness might be considered as a sort of supererogatory ideal that is not required of others. But it is also possible for the two-tier approach to contain an implicit condemnation of those who do not take up the higher calling of pacifism.
A second sort of contingent pacifism holds that if a particular war or military policy is prudentially unwise it should be resisted. Such prudential pacifism is based upon cost-benefit analyses focused on the facts of particular conflicts. A more principled sort of prudential pacifism can be based upon the general claim that war usually causes more harm than good.
A third sort of contingent pacifism will appeal to the just war theory and claim that a given war is unjust according to this theory. As John Rawls says of what he calls “contingent pacifism,” “the possibility of a just war is conceded but not under present circumstances” (Rawls 1971, 382). This idea is closely related to “just war pacifism” as developed in the last couple of decades by critics of the just war tradition: just war pacifism maintains that modern wars are not fought according to the standards of the just war theory because, for example, they make use of aerial bombardment and other means that do not adequately discriminate between combatants and noncombatants. Such a claim may result in a nearly absolute proscription against war under present circumstances. And it may contain an absolute prohibition against certain sorts of war, such as nuclear war. Most so-called “just war pacifists” are contingent pacifists in this sense: they object to the way modern wars are fought.
With the just war theory in mind, contingent pacifism may focus either on the basis for war (as in the just war idea of jus ad bellum), on the way that the war is being fought (as in the just war idea of jus in bello), or on the expected outcome of the war (as in the idea of jus post bellum). With regard to jus ad bellum, contingent pacifists may reject the legitimacy of the authority who is fighting, they may claim that war is not being fought as a last resort, or they may deny that the war is being fought for a just cause. With regard to jus in bello, contingent pacifist may worry that innocent noncombatants are being harmed or that soldiers are employing means mala in se (such as rape or torture). Finally, with regard to jus post bellum, contingent pacifists may object to wars that will undermine long-term peace, justice, and stability.
A fourth form of contingent pacifism might be called “political pacifism.” This approach adheres to pacifism as a strategic political commitment within an adversarial system. In political discourse, the so-called “doves” are usually not absolute pacifists. Rather, they define themselves in opposition to the “hawks” who advocate war and funding for the war-system. Political pacifists need not have an absolute commitment to nonviolence; nor need they have a principled commitment to the ideas of the just war theory. Rather, they can reject militaristic policies for strategic political purposes that have to do with budget priorities or other issues. Political pacifism may seem to be merely opportunistic; but opposition parties who offer critical perspectives on militarism are an important component of adversarial democracy. Moreover, political pacifists can end up forming useful coalitions with other more principled pacifists and absolute pacifists.
Finally, another version of contingent pacifism can be called, following Robert Holmes, “liberal-democratic” or “liberal pacifism.” Holmes argues that modern warfare runs counter to the values of liberal-democracy. Thus those who are committed to liberal values should not support war. Essential for this claim is the idea that “no one has a right to command others to kill, and no one is justified in killing on command” (Holmes 1999, 398). The sort of pacifism that is derived from this claim is contingent upon the fact that modern warfare involves a hierarchically organized military system and mass conscription. It is possible that war could be fought without conscription or without military hierarchy; but Holmes argues that this is unlikely in the modern world. Moreover, this sort of pacifism is contingent upon our social and political commitments. Those who are committed to other social and political ideologies may find that war and the war system are morally and politically acceptable.
Contingent pacifism is often based upon empirical and historical judgments about the way wars are fought. Such judgments will vary depending upon changing circumstances. And these judgments are also contingent upon the availability of information about why and how wars are fought. It is possible, then, that contingent pacifists can admit that there may be conflicting judgments about the justice of a particular war. Unlike contingent pacifism, absolute pacifism rejects war in an a priori fashion: one of the first principles of absolute pacifism is that war (or violence more generally) is always wrong. Thus absolute pacifism will claim that any judgment that leads to the justification of war is wrong.
The difference between maximal (or broad) and minimal (or narrow) pacifism has to do with the extent of the commitment to nonviolence. This difference can be explained with reference to the questions of what sorts of violence are rejected, and who is the recipient or beneficiary of nonviolent concern. Pacifists reject violence and war. But there is an open question about how war and violence are defined and thus about what sorts of actions are rejected by pacifists. There is, of course, a continuum between maximal and minimal pacifism, with maximal pacifism rejecting all forms of war and violence. Minimal versions of pacifism fall away from this in various directions. Maximal pacifism is closely related to absolute and universal formulations of pacifism; minimal pacifism has more in common with contingent and particular versions of pacifism.
There are a variety of actions that can be described as “war”: terrorism, insurgency, civil war, humanitarian intervention, full-fledged inter-state conflict, and world war that includes the possible employment of nuclear weapons. Most pacifists will reject nuclear war and full-fledged inter-state conflict. But there are differences about whether, for example, civil war or humanitarian intervention can be justified. For example, some who could be described as pacifists supported the use of military force during the American Civil War (William Lloyd Garrison, for example, compromised his pacifist beliefs to support the cause of emancipating the slaves). At issue in thinking about these differences are questions about the importance of key values such as sovereignty and human rights, as well as the question of how best to create stability in the face of social unrest. One difficult issue for some pacifists is the question of using violence in defense of human rights or in opposition to tyranny. Maximal pacifists will reject all use of military force, even in defense against dictators or in response to human rights violations.
Maximal versions of pacifism will condemn all taking of life. Pacifists may also extend their rejection of violence to include a rejection of the death penalty, meat-eating, and abortion. More narrow versions of pacifism may take into account the distinction between the innocent and the guilty, holding only that the innocent may not be harmed. This distinction is important for thinking about the question of noncombatant immunity in war, with many pacifists arguing that war is wrong because it puts the innocent at risk. Some opponents of the death penalty will make a similar argument about the death penalty and the risk of executing the innocent. And opponents of abortion will also claim that it harms the innocent. The connection between war, the death penalty, and abortion is made in the Catholic “seamless garment” approach to the problem of developing a “consistent ethic of life.” This approach condemns all actions that harm innocent persons; and it is often extended toward a rejection of all harm, without regard for the distinction between innocence and guilt. Such a view has been defended most famously by Pope John Paul II, who rejected (or was skeptical toward) all sorts of violence including war, the death penalty, suicide, euthanasia, and abortion. Pacifists may also extend moral concern to include concern for all sentient beings; and thus pacifists may also condemn meat-eating and animal cruelty. Gandhi, for example, extended ahimsa maximally to include avoiding harm to sentient beings.
This distinction has to do with the issue of whether everyone is required to be a pacifist or whether pacifism can be a moral choice of some particular individuals. This is related to the question of whether pacifism is a duty for all or whether it supererogatory. While the distinction between universal and particular pacifism is related to the distinction between absolute and contingent pacifism, it is primarily focused on the question of who is obligated by pacifism. Universalism in thinking about pacifism will hold that if war is wrong, it is wrong for everyone and thus that soldiers who fight are wrong, as are those who support the war system that encourages them to fight. Particular pacifists articulate their position as merely personal and do not condemn the war system or soldiers who choose to fight. Universal pacifism is closely connected with absolute and maximal versions of pacifism; particular pacifism is related to contingent and minimal pacifisms.
One way that this distinction between universal and particular pacifism has been enacted in history is through the idea of vocational pacifism discussed above Vocational pacifism holds that pacifism is a special obligation of a particular vocational service; but that it is not required of all. In this sense, pacifism is a supererogatory obligation. Religious clerics may thus be required to renounce violence, while ordinary members of their congregations may not be so obliged. Particular pacifism is thus connected to contingent pacifism: the moral demand of pacifism may be contingent upon one's social position.
This distinction can be understood by considering whether pacifism is morally necessary or whether it is merely morally permitted. The universalist answer to this question is: if war and violence are wrong, then pacifism is morally necessary and those who fight are wrong. But some pacifist appear to hold that it is not wrong to fight (or that some persons are permitted to fight), even though the pacifists herself may choose (or is obliged by some vocational commitment) not to fight. A conscientious objector may thus choose not to fight while not condemning those who do. Conscientious refusal may be articulated as a personal belief about pacifism that does not apply to others. This is one way pacifists who refuse to fight may avoid the charge that they are traitors who are opposed to their compatriots who fight: they may deny that their refusal has any universal moral significance or application. Eric Reitan has argued that one may adopt a sort of “personal pacifism” that need not be universally applied. One way of understanding this is to connect it with the idea of tolerance. A personal pacifist may believe that pacifism is the right choice; but she may choose to tolerate others who do not make the same choice. A personal pacifist may also espouse a sort of relativism that holds that a commitment to pacifism is merely a personal commitment that cannot be used to condemn others who make different commitments.
This idea of particular pacifism is a subtle one. And critics will argue that it is incoherent, especially if it is understood as a sort of relativism. Those who claim that conscientious objectors are traitors may argue that pacifism cannot be a particular or personal choice. Critics of pacifism will argue that pacifism is morally wrong because they think that patriotism or justice requires fighting or at least supporting the war effort. This objection would hold that if a war is justified, then conscientious objectors are wrong to reject it. Particularists may reply by claiming that their rejection of war is a personal choice without universal significance.
Arguments in defense of pacifism are usually based on assertions about the immorality of violence and war. Thus pacifism is usually derived by negation. Pacifism, primarily, tells us what not to do. As Cheyney Ryan has argued, pacifism is a “skeptical position.” As Ryan puts this: “its general claim is that the proponent of killing cannot produce a single compelling argument for why killing another person is permissible” (Ryan 1983, 509). One of the skeptical problems that Ryan addresses is the problem that occurs in killing in self-defense. When a Victim kills an Aggressor in self-defense, this killing occurs before the Aggressor has actualized his malicious intention. In this case, killing in self-defense is out of proportion to the harm done, since the Victim who kills in self-defense was not himself killed. A skeptical version of pacifism can thus develop from the worry that when we choose to kill in self-defense, we never know whether this killing is in fact justifiable.
This sort of skeptical position can be linked to the just war tradition's concern with the question of “last resort” in thinking about jus ad bellum. Skeptical pacifists wonder how we would know that we ever reach the stage of last resort, when violence becomes necessary. One way that pacifists articulate this concern is to focus on the variety of nonviolent measures that could be employed before it becomes necessary to resort to force. Indeed, it may be argued that to resort to violence is to admit to a failure of imagination and to give up hope that more humane forms of problem solving and conflict resolution can be effective. Moreover, pacifists will note that it is not sufficient to try nonviolent methods once and then disregard them. Rather, one must engage in a variety of nonviolent actions; and one must try these nonviolent alternatives more than once.
A somewhat different version of skeptical pacifism can be found in critiques of militarism and the ideology and propaganda that lead people to support war. This skeptical stance has been defended by the author of the present entry (Fiala 2008 and 2010). In this approach, skepticism produces a practical political pacifism that is based upon the fact that citizens have no good reason to trust that their governments are telling them the truth about war and its justification. This skepticism is derived from historical judgments about the tendency of governments to manipulate information in order to provoke the citizenry toward war. In light of such skepticism, the burden of proof for the justification of war is placed upon the government, who must prove that the dangerous and presumptively immoral activity of war can in fact be justified.
This sort of skepticism might also be called “prima facie pacifism”: this is the idea that war is usually wrong except in certain extraordinary circumstances when it is compellingly shown that the evil of war is a sort of lesser evil that is necessary for some greater good. Prima facie pacifism presumes that war is wrong but allows for exceptions. Prima facie pacifism places the burden of proof upon the proponent of war: it is up to the proponent of war to prove, in a given circumstance, that war is in fact morally necessary.
Transformational pacifism is understood as aiming at a transformation of psychological, cultural, social, and moral sensibility away from acceptance of violence and war. Transformational pacifism articulates a broad framework of cultural criticism and includes an effort to reform educational and cultural practices that tend to support violence and war. The goal of transformational pacifism is a world in which war and violence appear to be archaic remnants of less civilized past.
One traditional version of transformational pacifism can be found in pacifist religious traditions. For example, Jesus articulated a revaluation of values from the standpoint of a more pacific understanding of God's commandments. Instead of retaliation and the logic of “an eye for eye,” Jesus claimed that we must evolve a new idea—of not returning evil for evil. Transformational pacifism is often connected to a progressive interpretation of history that points toward a pacifist goal for human evolution. Gandhi thought that such progress was already underway and that history “has been steadily progressing towards ahimsa (nonviolence)” (Gandhi 1972, 310–11).
Transformational pacifism has been described by Joseph J. Fahey—who also calls it “reconstructionist” pacifism—as follows: “transformational pacifists stress the spiritual unity of all people… they seek not only the abolition of war, but also the creation of an international juridical, political, and economic order that will promote the rights of all species” (Fahey 1997, 393). War resistance can be located under this general rubric—insofar as war resistance is linked to a general criticism of those structures of authority, economic and political choices, and institutional frameworks that support what is often called “the war system” (see Atack 2001).
Transformational pacifism can also be linked to feminism and feminist critiques of the masculine values found in warrior cultures and the war system. Nobel Peace Prize winner Jane Addams is a prominent figure here. Addams connected her pragmatic hope for peace to democracy and the empowerment of women and the oppressed masses, who had in the past silently suffered from the horrors of war. During World War I, Addams and her Women's Peace Party worked to end the war and eventually ended up creating the Women's International League for Peace and Freedom. More recently authors such as Sara Ruddick and Nel Noddings have connected feminist criticism with pacifism and the ethics of care. Ruddick notes that military thinking utilizes a variety of conceptual strategies that create a myth of “the manly just warrior, which interlocks myths of masculinity, sacrifice, and heroic death” (Ruddick 1995, 202). Noddings has noted that “care ethics” does not support absolute pacifism, since care-givers may in rare circumstances kill in order to defend those they love. Nonetheless, Noddings argues that care ethics and feminism are concerned with a general critique of the militaristic and violent assumptions of male-dominant culture. Noddings contends that our culture “puts a high value on the aggressive tendencies of males” (Noddings 2010, 215). Her solution is to re-create culture and education in such as way as to devalue aggression and provide support for love, nurturance, solidarity, and care.
3. Consequentialist Pacifism
Deontological prohibitions against war are usually absolute, while consequentialist prohibitions against war are for the most part contingent.
Consequentialist pacifism is usually grounded in some sort of rule-utilitarianism. A utilitarian pacifist may argue that a rule against war or other sorts of violence will tend to promote the greatest happiness for the greatest number. A broader prohibition against violence other than war can extend the “greatest happiness” concept to take into account the happiness of sentient beings other than humans.
Utilitarian pacifists must appeal to empirical and historical data to support this rule. A utilitarian argument for pacifism could be grounded in the claim that history shows us that wars tend to produce more harm than good. As Bentham put it, “The happiest of mankind are sufferers by war; and the wisest, nay, even the least wise, are wise enough to ascribe the chief of their sufferings to that cause” (Bentham 1789, Fourth Essay) One of the problems for consequentialist arguments against war is that judgments vary about whether war always causes more suffering than it prevents. Utilitarian defenders of the just war theory will argue that some wars help alleviate suffering, as for example, in the case of humanitarian wars in defense of human rights.
Utilitarian pacifists may articulate a rule-based argument that holds that a general rule against war will, in the long run, produce more happiness. A utilitarian might support such an argument by also arguing that economic and other resources that are spent on war and preparation for war could produce more happiness if spent on peaceful goods such as education, hunger relief, and so on. And a rule-utilitarian might argue that a rule against humanitarian intervention would produce more happiness in the long run by protecting international stability and preserving important values like national sovereignty.
It is important to note that, unlike deontological pacifism, consequentialist pacifism is not opposed to killing per se. Nor is the consequentialist approach especially concerned with the distinction between combatants and noncombatants, since the “greatest happiness” principle adopts a perspective that includes both combatants and noncombatants. Indeed, the combatant/noncombatant distinction is better understood as a deontological principle, as discussed below. It is difficult to see how absolute pacifism can develop from act-utilitarianism that is devoid of side-constraints against killing. The rule-utilitarian approach can, however, allow for general rules that allow killing in certain circumstances, say in self-defense. The idea of proportionality in just war theory is an example of such a rule: killing in war is justifiable if it promotes general long-term happiness.
The claim that war produces more harm than good is disputable; at least, it requires empirical research to decide if it is true. Empirical research into the consequences of war provides mixed results depending upon contexts and circumstances in which wars are fought and the range of consequences considered (whether short-term or long-term). Some authors (Pinker and Goldstein) suggest that the use of judicious military power during the last several decades has produced good results. But other authors reach different conclusions. Ian Bickerton concludes that the wars of the past 200 years have produced ambiguous results: “victory did not achieve its desired results and war sacrifices were largely in vain. The reality is that the costs of war are rarely, if ever, worthwhile” (Bickerton 2011, xi).
Given the difficulty of assessing the empirical data, consequentialist pacifism will usually be a sort of contingent pacifism. But this is not always true, since absolute pacifism might be justifiable on consequentialist grounds as a rule that will in the long run produce good consequences. There may be variable judgments among consequentialists about whether some wars produce more harm than good. Thus pacifists such as Einstein and Russell could agree that the First World War was wrong, while admitting that the Second World War could be justified. The Second World War is in fact often used as an example of a war that can be justified in consequentialist terms: the good produced by the war—the defeat of Nazism in Europe, for example—is thought to outweigh its negative consequences, especially the massive numbers of persons killed in the war. In response, consequentialist pacifists might emphasize the negative utility of the deaths caused by the war while also arguing that the Second World War produced long-term negative consequences with the introduction of nuclear weapons, the partition of Europe, and the madness of the Cold War. Consequentialist defenders of pacifism will also argue that creative and coordinated nonviolent action can produce good consequences that are at least as good as the consequences of war.
One of the issues that consequentialists must consider is the temporal and spatial scope of our concern for consequences. It is possible that wars may produce short-term benefits for some and long-term disadvantages for others. Judgments about benefits and harms are thus complex and we must clarify our understanding of what matters in thinking about consequences. Often consequentialist arguments for pacifism emphasize the short-term damage of war. It is obviously true that wars kill people. But the further question to be asked from the standpoint of consequentialism is whether the harms that occur in the near-term are outweighed by the long-term benefits of the war. Just war theorists believe that some wars do have positive long-term consequences. Pacifists do not think that long-term benefits outweigh such near-term harms. Consequentialist pacifists often also consider the broad and long-term negative effects of war on the economy, on culture, on political life, and on the environment. Moreover, pacifists worry that war contributes to long-term international instability.
When thinking about the negative consequences of war it is important to recognize that we are engaged in comparative cost-benefit analysis. Critics of consequentialist pacifism often skew the results of such cost-benefit analysis by comparing war to passivity or inaction. But most forms of pacifism do not advocate complete passivity. It is a mistake to compare the consequences of going to war to the consequences of doing nothing. Rather, the cost-benefit analysis must compare the costs and benefits of going to war against those of creative, organized, and sustained nonviolent action.
A further consequentialist argument claims that cultures and states that fight wars tend to become militaristic and expansionist. This argument focuses on the long-term negative consequences of a social and political system that is committed to militarism. One of these negative consequences is the rise of the so-called “military-industrial complex” in which social capital is expended on military infrastructure at the expense of other social projects. A negative consequence of militarism is the tendency of militarist states to become centralized, secretive, and imperial. This critique of military expansionism can be connected to a general critique of the potential negative consequences of imperial power. One such negative consequence is found in the illiberal tendencies of military power. Another negative consequence can be found in the possibility of “blow-back” or retaliation in which those who are subjugated turn against the colonial power. And other negative consequences include the danger of an arms races and the wasted money and energy that are spent on preparing for war.
Empirical research is required to say whether it is true that what pacifists often call “the war system” does produce these negative political consequences. Judgment about these empirical facts will likely vary in accord with historical, geographical, and political differences, as well as in light of which consequences we chose to emphasize. Thus while pacifists argue that resources are squandered in war and environmentalists will point out the military is one of the largest polluters on the planet, proponents of war argue that war and the military produces goods and technologies, such as airplanes, satellites, and so on, that are useful for civilians (Ruttan 2006).
Another consequentialist argument can be located in the idea of the sort of “just war pacifism” that developed during the late 20th Century. The worry of just war pacifism is that modern wars fought with weapons of mass destruction can never be justified. There are deontological concerns behind this sort of pacifism—with regard to concern for noncombatants. But there are also consequentialist reasons to be skeptical of wars fought with weapons of mass destruction, most notably the problem of escalation. Nuclear deterrent strategy relies upon the threat of escalation to keep antagonists in check. The idea of deterrent strategy is to make the negative consequences of war for the enemy so horrifying that war will not occur. But if the threat of escalation is real and the results of war are really so atrocious, then there are good consequentialist reasons to be opposed to war: wars fought with weapons of mass destruction will tend to produce horrifying consequences including the potentially total devastation of what was called during the Cold War, “mutually assured destruction.” During the Cold War, this concern was located in the worry about “nuclear winter,” which was the catastrophic destruction of the earth's climate and biosphere that would occur if an all out nuclear war had erupted. Even more limited conflicts that occur among states that possess weapons of mass destruction could produce horrible consequences. Nuclear proliferation remains a concern along with the general threat of terrorists in possession of weapons of mass destruction.
Just war pacifists generally claim that the negative consequences of modern war make war unjustifiable. Just war pacifism might be more narrowly focused on the immorality of nuclear war and nuclear deterrence strategy. But those who reject nuclear warfare might still allow that limited defensive or even humanitarian wars can be fought provided we could be sure that just war principles were respected. Perhaps the most important conclusion of just war pacifism is that the burden of proof rests on the proponent of war: for just war pacifists who base their conclusions on consequentialist reasoning, war is presumed to produce negative consequences until is proved otherwise.
Related to these consequentialist arguments against war is a more positive consequentialist argument about the positive power of nonviolence as a social force. This is grounded in a consequentialist argument that active nonviolence can produce social goods like respect for human rights as well as peace and reconciliation.
The basic theory and strategy of nonviolent action were worked out by Mohandas Gandhi, Martin Luther King Jr., Cesar Chavez, Gene Sharp, and others who were engaged in nonviolent social protest in the 20th Century. Although the roots of this approach can be found in the long history of pacifism from Jesus onward, the Gandhi-King approach both clarified the basic principles of nonviolent resistance and successfully put these principles into action in the Indian struggle for self-determination and in the American civil rights movement. One of the important contributions of this approach is the idea that there should be a coordination between means and ends. Peaceful means should be employed in pursuit of the end of peace and justice.
For peaceful means of social change to be effective, they must be coordinated and organized. Gandhi and King thought that the power of nonviolence was linked to its ability to motivate and move large numbers of people. Pacifism as a personal stance will not be effective at creating social change: it requires a coordinated social effort.
Proponents of active nonviolence will claim that coordinated nonviolence can be successful even in the face of aggression. Advocates of this position will point to the successes of Gandhi and King. They will also point to the “velvet revolutions” that occurred in Eastern Europe in the late 1980's and early 1990's. And they will point to the example of Lithuania in 1990–91, when unarmed civilians succeeded in turning back Soviet troops. Some initially viewed the so-called “Arab Spring” that began in late 2010 as an example of the power of nonviolence. However, subsequent oppression by military and police forces remind us of the fragility of nonviolent social movements. Proponents of nonviolent action argue that nonviolence could be even more effective if society focused its resources on training citizens for nonviolent resistance and on coordinating nonviolent action. The ideal here would be a sort of nonviolent “army” that is funded, trained, and coordinated for national self-defense in a way that mimics military training. For pacifism to be effective, the social resources—money, technology, and investment of labor and creative power—that are currently used for military training would have to be converted to nonviolent applications. This idea draws on what James called “the moral equivalent of war” and what Gandhi called the “nonviolent army.”
4. Deontological Pacifism
Deontological pacifism is closely related to absolute pacifism. Deontological approaches to morality focus on duty and right. One typical idea for deontological pacifism is that there is a basic law or principle that prohibits killing, such as “thou shall not kill.”
The most famous theory of deontological ethics is Kant's. Kant's categorical imperative is formulated as follows: “Act according to that maxim by which you can at the same time will that it should become a universal law” (Kant 1990, 38). It is difficult to supply content to this imperative. Thus, it is not clear that the Kantian imperative can be used to rule out war. Indeed, Kant is a defender of a version of the just war theory, in part because he believes that states have a duty to defend their citizens. Although Kant is not himself a pacifist, one might be able to ground pacifism in Kant's alternative version of the moral law: “Act so that you treat humanity, whether in your own person or in that of another, always as an end and never as a means only” (Kant 1990, 46). Some pacifists use the second formulation of the categorical imperative to support their position by claiming that war treats persons as means and does not respect them as ends in themselves. One version of this idea has been defended by Soran Reader, who argues that the basic presumption of the “moral status of persons” leads to pacifism. Although Reader argues that one can arrive at this perspective from both a consequentialist approach and a Kantian one, she relies on the basic intuition that respect for persons as ends in themselves requires us not to kill them. It is possible to use this deontological principle to support a maximal extension of pacifism such that the prohibition against killing might be extended to include a prohibition against killing non-human persons. This interpretation would obviously require a further analysis of the notion of personhood.
In addition to killing human persons, war violates the moral status of persons when, for example, soldiers are viewed as interchangeable cogs in the war machine. One might then criticize the apparent “herd mentality” of militarism, as Albert Einstein did when he called the militaristic patriotism of the masses a sort of “loathsome nonsense” (Einstein 1954, 8) The idea of conscription seems to run counter to the idea of respect for persons. And pacifists may argue that it is somehow disrespectful to require soldiers to conform to military virtues such as obedience to authority. Arguments against militarism along these lines were made famous by Thoreau who claimed that in military service “the mass of men serve the State thus, not as men mainly, but as machines, with their bodies” (Thoreau 2000, 669)
The more important critique of the way that war betrays human dignity can be found in the pacifist critique of the killing that happens in war. Pacifists might claim that war is a violation of human rights. More concretely the pacifist may claim that all human beings have a right to life and that killing in war violates this right.
This idea has been rejected by Anscombe, Narveson, and others who argue that the idea of human dignity or human rights can necessitate the use of violence in defense of these rights. This sort of objection holds that it is both inconsistent and immoral for pacifists to reject the use of violence in defense of human rights. As David Luban puts this: “Such rights are worth fighting for. They are worth fighting for not only by those to whom they are denied but, if we take seriously the obligation which is indicated when we speak of human rights, by the rest of us as well” (Luban 1980, 170).
One of the ways that pacifists can reply to this objection is to emphasize the difference between personal nonviolence and war. Pacifists may accept that personal self-defense is acceptable; and they may accept the idea of using violence in defense of the innocent in concrete personal encounters. (Of course, absolute pacifists who emphasized complete nonresistance will not accept such violence at all). But pacifism as anti-warism will argue that the violence of war is of a different kind. War is dehumanizing violence that kills masses of persons without any concern for them as persons. Along these lines, Thomas Nagel claims that we should be able to justify to the victim what is being done to them, in light of morally relevant facts about them. At the level of personal violence, it is possible to say that an aggressor deserves the violence that is inflicted upon him. But at the level of war, this personal element is lost and instead we have killing en masse, which is an assault on human dignity.
One aspect of the deontological condemnation of war focuses on the killing of combatants. A pacifist might argue that it is wrong to kill enemy combatants because killing is always wrong. Such an argument runs counter to the just war ideal that combatants can be killed. Critics will argue that pacifism thus fails to distinguish between “innocence” and “guilt.” As Anscombe puts this, “pacifism teaches people to make no distinction between the shedding of innocent blood and the shedding of any human blood” (Anscombe 1981a, 58) The just war tradition holds that it is permissible to kill enemy combatants because these combatants are, in some sense, no longer innocent. Those who claim that it is acceptable to kill enemy combatants claim that enemy soldiers deserve to die; or at least that it is not wrong to kill them. There are open questions in just war theory about how this notion of desert functions. One of the problems is that young conscripted soldiers may not fully support the war into which they are drafted; and thus it may seem odd to claim that such soldiers are guilty for or deserve to be killed in a war for which they hold no personal responsibility (see McMahan 2009). But the most obvious way to justify killing combatants is to link such killing to the notion of self-defense. In war, soldiers are confronted with enemy combatants who will kill them and their comrades, if they aren't killed first. In the language of just war theory, an enemy combatant is guilty of the crime of aggression; and in the context of war, this crime is punishable by death.
This notion of killing as punishment can easily be connected to the issue of the death penalty. For deontological proponents of the death penalty, murderers can be executed because the nature of their crime merits death. While consequentialists add in other considerations such as the deterrent value of the death penalty, the deontological approach focuses on the moral desert that is connected to the guilt of the murderer. This notion of guilt—as a moral quality that adheres to an individual in light of his past actions—is also found in the idea that enemy combatants may be killed. Those individuals who are engaged in fighting have done something (or have adopted some characteristic) that makes it permissible to kill them.
Absolute and maximal versions of deontological pacifism maintain that killing is never permitted, even the killing of enemy soldiers. They may also claim that the death penalty is wrong; and they may deny that killing in self-defense is ever justifiable. Opponents of war may also deny that international aggression is punishable by death.
A more subtle argument along these lines will claim that it is wrong to kill enemy combatants because enemy combatants are occasionally (or usually—depending on the strength of this particular claim) not responsible for their participation in war. This is especially true of conscript armies who are forced to fight. A pacifist might want to make an exception for killing soldiers who have malicious intent; but they may argue that it is immoral to kill soldiers who are forced to fight.
Although some maximal versions of deontological pacifism will claim that it is wrong even to kill combatants in war, other versions will argue that war is wrong primarily because of the risk to noncombatants. A cherished principle of the just war tradition is the idea of noncombatant immunity. This idea holds that those not actually engaged in the fighting should not be put at risk and should not be deliberately targeted. This idea is often connected to the idea that the innocent should not be killed. Noncombatants are presumed to be innocent and thus immune from being killed. There is an open question as to whether all noncombatants are really innocent. But the just war tradition stipulates that noncombatants should be immune from intentional harm. A version of pacifism can thus be derived from this principle of the just war tradition by arguing against wars that do in fact end up killing innocent noncombatants. Just war pacifists will argue that this is especially true given the nature of modern warfare, which includes the use of mechanized weapons, aerial bombardment, and weapons of mass destruction. Such weaponry does not adequately discriminate between combatants and noncombatants. Thus modern war cannot be just, according to the pacifist interpretation of the just war tradition.
The just war tradition, however, allows that innocent noncombatants may be killed according to the principle of double effect. This idea is derived in the Christian tradition from Aquinas, who holds that a single act may have two effects. Aquinas uses an example of killing in self-defense: the act has one effect of saving a life but another effect of killing the aggressor. Killing an aggressor in self-defense may be permitted, if the death of the aggressor is not the primary intention of the defensive act. It is significant that Aquinas does not expand this discussion to make it permissible to kill an innocent third party. But the just war tradition has employed this idea in a way that makes it permissible to kill innocent third parties (i.e., noncombatants) in war, so long as the primary intention is to accomplish a legitimate war aim and so long as the killing of innocents is merely a foreseen but unintended secondary effect. Absolute pacifists will argue against this employment of the doctrine of double effect and will claim that the killing of the innocent in war is always wrong, even if it is an unintended effect.
Indeed, some pacifists may also claim that since we know that war will kill noncombatants, it is disingenuous to claim that the deaths of innocent noncombatants are not intended. The pacifist may claim that the real problem of war is that noncombatants are killed intentionally as a means of warfare. Although Anscombe argued against pacifism, she made a similar argument in her criticism of the attacks on Hiroshima and Nagasaki, “it is nonsense to pretend that you do not intend to do what is the means you take to your chosen end” (1981a). Anscombe thought that war could be justified—if it did not directly intend to kill noncombatants. And Anscombe thought that pacifists were wrong to ignore the distinction between shedding innocent blood and shedding blood in just warfare. But pacifist might argue in response that war is wrong because innocent noncombatants are killed—whether intentionally or not.
Pacifism that is absolutist and deontological is often grounded in religious belief. Christian philosopher Stanley Hauerwas has claimed that pacifism is a theological position because it is as much about eschatological faith as it is about ethics and politics (Hauerwas 2006). A variety of religions have supported pacifist positions. Hindus, Jains, and Buddhists share a concern for ahimsa or nonviolence as a basic moral virtue. Likewise, Christians also find a commitment to nonviolence at the heart of their tradition. One reason that absolutist and deontological pacifism appears to require a religious foundation is that the commitment to peace can lead to suffering in the ‘real’ world of political life. But for some religious believers the world of political life is only an apparent world and not the real world at all. In the Buddhist tradition, the world of dependent arising is a world of appearances in which suffering is ubiquitous. One of the ways to overcome this suffering is to see through the veil of maya and the illusions of this world. Ahimsa or nonviolence is a virtue that renounces the ubiquitous violence of the ‘real’ world. In a different way, the Christian tradition holds that the ‘city of God’ or divine providence is a mysterious reality that is infinitely more important than the reality of the ‘city of Man.’
The structure of this sort of religious belief is closely related to the absolute, deontological, and transformational nature of religious pacifism. In Christian pacifism, it is God's commandments as articulated by Jesus that necessitate a commitment to pacifism. Of course, this is a contentious point; and some deny that Christianity requires pacifism (see Fiala 2007). But Christian pacifists maintain that Christians should refuse to kill regardless of the consequences in the ‘real’ world. Related to this is the faith that God will provide both the strength to endure suffering and a final reward for those who remain committed to principles of nonviolence. Even though pacifism may seem imprudent or even idiotic from the standpoint of consequentialism or political realism, these consequences have no lasting significance from the standpoint of Providence. Indeed, religious pacifists are not averse to the pain that they might suffer as a result of their refusal to take part in violence because they believe that this suffering will be redeemed in the larger structure of divine justice.
A further variety of religious pacifism is closely connected with the ideas of virtue ethics. Virtue ethics emphasizes the cultivation of virtues over the course of a lifetime. Virtue ethicists are reluctant to judge actions in isolation from the total context of an individual's life. Religious pacifism has a virtue ethics component when the commitment to peace is conceived as a lifelong project of personal transformation. In the Christian tradition this is understood as a project in which human beings learn to imitate Jesus in order to become closer to God. The Christian model of virtue is Jesus, and Jesus’ practice of nonviolence culminated in his crucifixion. Christian martyrs have looked to this paradigm for millennia.
A similar idea about the practice of nonviolence is found in the Indian traditions. Gandhi's practice of self-renunciation (brahmacharya) including his vow of poverty and his fasts were closely tied to his commitment to ahimsa. For Gandhi, nonviolence is part of a total practice of virtue. In the Buddhist tradition this is developed for example, in Thich Nhat Hahn's idea of “being peace.” The virtue approach emphasizes that pacifism is a lifelong project that requires discipline and practice. This is true because we are not born virtuous. Rather, we learn to cultivate the virtue of peacefulness by gradually learning habits that help us control and resist anger, hatred, pride, competitiveness and the other emotions that lead to violence. In the Christian tradition this is linked to the idea of original sin: we are born in violence and have to learn to overcome violence. Theological questions arise in Christianity about whether human beings can overcome violence by themselves or whether grace is needed in order to cultivate the virtue of peace.
It is possible to develop a version of virtue-pacifism from a non-religious standpoint. In the ancient world, some versions of Stoicism and Epicureanism come close to this. Stoics, for example, emphasize the virtue of tranquility or undisturbedness. One attains this state by learning proper discipline and by cultivating the other virtues that are essential for reigning in hubris. Hubris is wanton violence or pride run amok. Since Plato, the Greek tradition has claimed that justice, courage, moderation, and wisdom were needed to overcome hubris. It is conceivable that these virtues would conjoin in a sort of peacefulness. Indeed, one can see the roots of nonviolent social protest in Socrates’ nonresistance to the Athenian state. It should be noted, however, that although Socrates refused to carry out unjust orders, he did serve the state in battle.
A non-religious version of virtue-pacifism can be found in the ideas of 20th Century humanists such as William James. At the beginning of the 20th Century, James acknowledged that war and military service did produce certain virtues, such as courage and discipline. But James hoped that there could be a non-military way of producing these virtues. This was the basic idea behind his proposal for a “moral equivalent to war,” which was an attempt to find a way to produce virtues without connecting them to militarism.
The general rejection of war has a long history that parallels the just war tradition and its idea that wars should be fought for the sake of peace and justice. In the West, pacifism and the just war tradition have roots in both Christian and non-Christian sources. For Christian thinkers, one of the primary problems is trying to reconcile the pacific commandments of Jesus with the apparent moral necessity of using war to defend the innocent. This problem is acute for Christians since Jesus seems to advocate an ethic of nonviolence both in the Sermon on the Mount and in his submission to violence, while Augustine and others use both Biblical sources (such as Paul's letter to the Romans) and natural law to argue in favor of the just war idea. In the Western tradition, pacifism is an ideal that develops alongside of and in contrast to the just war tradition, with adherents of pacifism including the Mennonites and Quakers, as well as Christian humanists such as Erasmus.
The problem of justifying war is also found in Greek thinkers, such as Plato, who argued in the Laws that war should only be waged for the sake of peace and that “it is peace in which each of us should spend most of his life and spend it best” (803d). And in the Crito, Socrates considers the problem of whether it is ever justified to return evil for evil. Socrates begins with the assumption that we must do no harm; and he and Crito agree at one point that one “ought not retaliate or render evil for evil to anyone, whatever evil we may have suffered from him” (49d). It seems that this idea is behind Socrates decision to remain in prison and allow himself to be executed.
Pacifism shows up in non-Western traditions as well. Jains, Buddhists, and others in the Indian tradition share a commitment to ahimsa or nonviolence as a cardinal virtue. The ideal in these traditions is a sort of selflessness in which, through the dissolution of the self, a larger truth emerges. For Buddhists this is based upon the idea of nonattachment: war, violence, anger, and hatred result from our attachment to material things. Ahimsa is also linked to the idea that all sentient beings are interdependent. Thus nonviolence is extended toward a rejection of violence toward sentient beings in general and a commitment to vegetarianism. Mohandas Gandhi is perhaps the most famous adherent of ahimsa of the last century. Gandhi based his commitment to nonviolence on a spiritual foundation that emphasized self-renunciation (brahmacharya) and the positive action of the force of love or force of truth that he called satyagraha.
It is important to note that the distinction between Western and non-Western traditions breaks down in the 20th Century: Gandhi was inspired by Thoreau and by Tolstoy; and Gandhi in turn inspired Western pacifists such as Albert Einstein, Bertrand Russell, and Martin Luther King Jr. Gandhi and King both claim that one of the most important ideas underlying this sort of pacifism is love, especially the disinterested brotherly love that is described in the Greek New Testament using the word agape. King explains it this way: “In the final analysis, agape means recognition of the fact that all life is interrelated. All humanity is involved in a single process, and all men are brothers. To the degree that I harm my brother, no matter what he is doing to me, to that extent I am harming myself” (King 1986, 20) This idea represents the extension of Christian pacifism in light of Gandhian principles.
Further discussions should consider how such ideas have spread to Latin America, East Asia, and the Muslim world, as well as the ways that nonviolence shows up in the religious and philosophical traditions of the rest of the world. Research projects in pacifism and peace studies should continue to explore ideas found in the variety of world traditions including Taoism, African thought, and indigenous American philosophies.
Here we will summarize briefly several objections to pacifism and pacifist replies to these objections. These objections and replies will, of course, vary according to the different sorts of pacifism being attacked or defended.
Objection: This objection holds that the reason pacifists advocate nonviolence is that they are afraid of suffering from violence; or that they are too lazy or self-interested to take up arms to fight. This objection focuses on the motivation and psychology of pacifists and accuses pacifists of the vice of cowardice. Moreover, such an objection may also argue that pacifists are egoists who are too selfish to do what is required to serve justice, protect the innocent, and defend the nation. The free rider objection adds that pacifists benefit from social goods that are produced through military power, while they contribute nothing substantial to the production of these goods. This objection thus claims that pacifism is unjust since pacifists share in social benefits, without also taking up the burdens and obligations that are tied to these benefits. Related to this is the charge that pacifism is unpatriotic and even treasonous. The concern here is that if pacifists are unwilling to fight to defend the nation, then they effectively betray the nation and help the enemy. As Jan Narveson has recently put this, pacifists have “too many friends” (Narveson 2003) since they are unwilling to take up arms against their enemies. A more forceful ad hominem argument against pacifism can be found in Ward Churchill's idea that pacifism is a pathology of the privileged, a point that has been reiterated by Derek Jensen. This objection holds that it is easy for those who are not oppressed to advocate nonviolence and indeed, that the powerful can use the ideology of pacifism as a tool with which to further oppress those who are unwilling to take up arms in defense of human rights. This idea can be traced back to ideas found in Marcuse, who argued that the weaker parties in social conflict are forced by the stronger party to employ nonviolence and thus that resort to nonviolence is both ineffective and an admission of weakness.
Reply: One way that a pacifist might reply to this objection is to argue that pacifism results from noble motives and not vicious ones. To support this reply, pacifists might show examples of the virtuous individuals who have advocated pacifism, while also emphasizing the ethical basis on which pacifism is grounded. Indeed, pacifists can avoid the cowardice objection by stressing that pacifists are willing to suffer violence even though they refuse to participate in it. With regard to the free rider problem, a principled pacifist can argue that her moral principles require that she be a pacifist and that these principles also require that she work to transform society. Moreover, pacifists can engage in productive social endeavors that do not necessitate the use of violence or war. This sort of compromise occurs when military states find ways to employ the talents of conscientious objectors. Pacifists who refuse to fight can volunteer their talents and energies in nonviolent activities that support the common good. With regard to the accusation of treason, a pacifist might claim that there are higher goods than the state. Indeed some pacifists—such as Tolstoy or Hauerwas—are also anarchists who claim that Christian faith requires that one overcome one's attachment to the state as well as one's hatred of enemies. A similar argument can be made against Churchill's “pacifism as pathology” objection, with principled pacifists claiming that nonviolence is a moral requirement that transcends class and national ideology. Finally, a consequentialist pacifist can reply that she is concerned with the long-term interests of the community and not with the short-term question of winning a war or staging a revolution. While violence may create short term benefits, the long term project of creating a stable peace will require nonviolent means and projects focused on reconciliation and restorative justice. And contra the Churchill/Jensen objection, pacifists will emphasize the moral and political importance of unifying means and end.
6.2 Pacifists are wrong to aspire for the purity of “clean hands”; and pacifism is based on bad theology
Objection: The clean hands objection holds that pacifists are so committed to keeping their hands clean that they fail to act on other requirements of life. The clean hands objection holds that pacifists are disconnected from the world of concrete human reality. As Anscombe puts this in her critique of pacifism, the pacifist holds “withdrawal from the world as man's only salvation” (Anscombe 1981a, 52). This is tied to a theological objection that holds that pacifists incorrectly believe that they can overcome the limits of human nature. A version of this objection that is often directed against Christian pacifism holds that war will remain necessary because of the fallen and sinful nature of human beings. This objection also reminds Christian pacifists that there is explicit advocacy for war in the Old Testament and that Paul's letter to the Romans allows the sovereign to use the sword to execute God's wrath. The objection holds that since we are not perfect, we must employ the imperfect means of war and violence to attain moral ends. From this standpoint, defenders of the idea of a just war argue that love of the neighbor and the need for a just social order will occasionally necessitate just wars.
Reply: Pacifists might reply to this sort of objection by delving deeper into the requirements of both religious faith and ethics. This objection is tied to a much larger problem of coordinating the demands of ordinary political life with the requirements of morality and religion. Christian pacifists will reply to the “bad theology” objection by focusing on the message of Jesus in the Gospels; and they will argue, as John Howard Yoder does, that just war theory is a later development of a lapsed sort of “Constantinian” (or Augustinian) Christianity. Moreover, Christian pacifists will argue that pacifism is part of a religious worldview that looks beyond a materialistic defense of the finite goods of this world. For religiously oriented pacifists in many traditions, a commitment to nonviolence is tied to the attempt to see through the vanity of temporal things. Nonreligious pacifists will reply to this objection by clarifying the importance of clean hands in morality. Absolutists will claim that we have an obligation to uphold the requirements of morality and keep our hands as clean as possible. They will also claim that the world would be a better place if everyone took this obligation seriously and refused to compromise with evil.
Objection: This objection claims that pacifism results in a performative contradiction because an absolute pacifist who is unwilling to defend himself simply ends up dead. A more subtle version of this argument has been articulated by Jan Narveson (Narveson 1965) who argued that pacifism involves an internal contradiction that is related to the idea of justice and human rights. Pacifists are unwilling to use violence to defend against aggression because they respect life or respect persons. But a contradiction occurs when the pacifist who claims that life is an absolute good is unwilling to take the necessary steps to defend lives that are threatened by aggression. This objection shares something with those defenders of the just war idea who, like George Weigel, are inspired by the Augustinian ideal of using war to defend a tranquil and just social order. The objection holds that it is immoral to avoid war, when war could be used to defend the innocent, protect sovereignty, and uphold a just international order. This objection can be applied both to defensive wars, in which the state has an obligation to protect its own citizens, and to wars of humanitarian intervention, in which military power is used to defend the human rights and to establish domestic tranquility and social order in pursuit of peace. Related to this is the claim that nonviolent means of producing social change are ineffective. Critics will claim, for example, that although there appear to be cases of successful nonviolent action in India or in the American civil rights movements, these movements were successful because of unique set of historical circumstances. Critics will argue that Gandhi's success was made possible by British exhaustion from the World Wars; and they will argue that Martin Luther King Jr.'s success was made possible by the threat of violence from radicals such as the Black Panthers. Moreover, critics will argue that Gandhi and King were successful because their opponents were for the most part sympathetic to their cause from the beginning. But such critics will argue that non-violence will simply not work against Nazis or terrorists; and that those who think so are dangerously deluded. President Barack Obama articulated this sort of objection to pacifism in his Nobel Peace Prize acceptance speech. Obama expressed respect for pacifists such as Gandhi and King. He said, “there is nothing weak, nothing passive, nothing naive in the creed and lives of Gandhi and King.” But he claimed that a head of state cannot be guided by pacifism. And he concluded: “A nonviolent movement could not have halted Hitler's armies. Negotiations cannot convince al-Qaeda's leaders to lay down their arms.” A similar argument about the efficacy of violence has been made by defenders of insurrectionary violence such as Marcuse, Fanon, and Sartre.
Reply: One way that a pacifist may reply to this objection is to focus on pacifism as a skeptical political stance about war. Some political pacifists do allow for personal self-defense and defense of loved-ones while remaining skeptical of war as a social movement. Another way that a pacifist may reply is to focus on consequences and argue that war produces more negative consequences than nonviolence. Against Narveson, the pacifist might argue that pacifism is no more contradictory than the idea that we might kill in order to defend life. Deontological pacifists will also reply that while they do value a just and tranquil social order, and may even be willing to die in defense of such as just order, their basic principles prohibit them from killing in its defense. A pacifist might further reply to this objection by arguing that the idea that war can be used to defend the innocent is also imprudent and unwise. Pacifists will argue that nonviolent means of defending the just political order are the best means to be employed in practice because they remain consistent with the ideals of justice and order that are to be defended. This claim about the unity of means and ends can be used to argue against the Fanon/Marcuse justification of violence in insurrection by noting a contradiction in revolutionaries using violence to oppose the violence of oppressive states. A pacifist might add that history shows that violent revolution often either escalates or provokes more oppression. With regard to humanitarian intervention, some deontological pacifists will worry that interventions by outsiders will run counter to the national right to self-determination. And more prudentially minded pacifists will worry that humanitarian intervention will produce resistance and an escalation of violence that will undermine the long-term goals of political stabilization, justice, and reconciliation. Finally, the pacifist might also appeal to the tragic element in human life: that we often have to make tragic choices in which there is no genuinely good alternative. When confronted with such tragic conflicts, the pacifist will argue that we should err on the side of peace and take care that we do no harm. The examples of King and Gandhi may in fact require careful historical analysis; and different historical circumstances will require different sorts of nonviolent action. But, for the pacifist, history shows us the horror of war; and the success of Gandhi and King reminds us that there is an alternative. Finally, a pacifist might also point out that the long term goal of a transformation beyond war is shared by a variety of people, including those who are reluctant to call themselves pacifists. As Obama pointed out in his Nobel Peace Prize speech, even if war may be necessary, it is also “at some level an expression of human folly.” Pacifists usually deny that war is necessary. But they agree that war is usually an expression of human folly.
Alexandra, Andrew, 2003. “Political Pacifism”, Social Theory and Practice, 29 (4): 589–606.
Anscombe, G.E.M., 1981a. “War and Murder” in Ethics, Religion, and Politics, Minneapolis: University of Minnesota Press.
–––, 1981b. “Mr. Truman's Degree” in Ethics, Religion, and Politics, Minneapolis: University of Minnesota Press.
Aron, Raymond, 1966. Peace and War, New York: Doubleday.
Atack, Iain, 2001. “From Pacifism to War Resistance” Peace and Change, 26 (2): 177–186.
Augustine, City of God, New York: Doubleday, 1958.
Benjamin, Martin, 1973. “Pacifism for Pragmatists” Ethics, 83 (3): 196–213.
Bentham, Jeremy, 1789. “A Plan for Universal and Perpetual Peace”, in Principles of International Law, in The Works of Jeremy Bentham, New York: Russell & Russell, Inc.(reprint 1962).
Bickerton, Ian, 2011. The Illusion of Victory: The True Costs of War, Melbourne: Melbourne University Press.
Brandt, Richard, 1972. “Utilitarianism and the Rules of War”, Philosophy and Public Affairs, 1 (2): 145–165
Brock, Peter, 1998. Varieties of Pacifism: A Survey from Antiquity to the Outset of the Twentieth Century. Syracuse, NY: Syracuse University Press.
–––, 2000–2001. “Personal Pacifism: In Historical Perspective” The Acorn, 9 (1): 53–59.
Cady, Duane L., 1989. From Warism to Pacifism, Philadelphia: Temple University Press.
Chapple, Christopher Key, 1993. Nonviolence to Animals, Earth, and Self in Asian Traditions, Albany, NY: State University of New York Press.
Churchill, Ward and Mike Ryan, 1998. Pacifism as Pathology, Winnipeg: Arbeiter Ring.
Cochran, David Carroll, 1996. “War-Pacifism” Social Theory and Practice, 22: 161–80.
Cortright, David, 2008. Peace: A History of Movements and Ideas, Cambridge: Cambridge University Press, 2008.
Dalai Lama, 1999. Ethics for the New Millenium, New York: Riverhead Books.
Dallmayr, Fred, 2004. Peace Talks—Who Will Listen?, Notre Dame: University of Notre Dame Press.
Dombrowski, Daniel, 1991. Christian Pacifism, Philadelphia: Temple University Press.
Dower, Nigel, 2009. The Ethics of War and Peace, Cambridge: Polity Press.
Doyle, Michael, 1997. Ways of War and Peace, New York: WW Norton and Co.
Einstein, Albert, 1954. Ideas and Opinions, New York: Random House.
Erasmus. “The Complaint of Peace”, in The Essential Erasmus, John P. Dolan (ed.), New York: Penguin, 1983.
–––. “War and the Christian Prince”, in War and Christian Ethics, 2nd edition, Arthur F. Holmes (ed.), Grand Rapids, MI: Baker Academic, 2005.
Fahey, Joseph J., 1997. “Varieties of Pacifism” in Protest, Power, and Change: An Encyclopedia of Nonviolent Action from ACT-UP to Women's Suffrage, Roger S. Powers, William B. Voegele, Christopher Kruegler, and Ronald M. McCarthy (eds.), New York: Taylor and Francis.
Fanon, Frantz, 2004. The Wretched of the Earth, New York: Grove/Atlantic. With preface by Jean-Paul Sartre.
Fiala, Andrew, 2004a. “Citizenship, Epistemology, and the Just War Theory”, in Logos: A Journal of Catholic Thought and Culture, 7 (2): 100–117.
–––, 2004b. Practical Pacifism, New York: Algora Press.
–––, 2005. “Practical Pacifism after the War in Iraq”, Journal for the Study of Peace and Conflict, Wisconsin Institute Peace and Conflict Studies, 2004–2005 Annual Edition, pp. 90–100.
–––, 2007. What Would Jesus Really Do? The Power and Limits of Jesus' Moral Teachings, Lanham, MD: Rowman and Littlefield.
–––, 2008. The Just War Myth: The Moral Illusions of War, Lanham, MD: Rowman and Littlefield.
–––, 2010. Public War, Private Conscience, London: Continuum.
–––, 2013. Against Religion, Wars, and States, Lanham, MD: Rowman and Littlefield.
Fitz-Gibbon, Andrew, 2010. Positive Peace: Reflections on Peace Education, Nonviolence, and Social Change, Amsterdam/New York: Rodopi.
Fox, Michael Allen, 2014. Understanding Peace: A Comprehensive Introduction, New York/London: Routledge.
French, Shannon E., 2001. “With Your Shield or on It: Challenging the Pacifist Mother Archetype”, Public Affairs Quarterly, 15: 51–63.
Fukuyama, Francis, 1992. The End of History and the Last Man, New York: The Free Press.
Galtung, Johan, 1969. “Violence, Peace, and Peace Research” The Journal of Peace Research, 6(3): 167–191.
Gandhi, Mohandas K., 1972. Non-Violence in Peace and War, 1942–1949, New York: Garland Press.
–––, 1993. Autobiography: The Story of My Experiments with Truth, Boston: Beacon Press.
Glover, Jonathan, 1977. Causing Death and Saving Lives, New York: Penguin.
–––, 2000. Humanity: A Moral History of the 20th Century, New Haven: Yale University Press.
Goldstein, Joshua S., 2011. Winning the War on War: The Decline of Armed Conflict Worldwide, New York: Penguin.
Hanh, Thich Nhat, 1987. Being Peace, Berkeley, CA: Parallax Press.
Hauerwas, Stanley, 1984. Should War be Eliminated?, Milwaukee, WI: Marquette University Press.
–––, 2004. Performing the Faith: Bonhoeffer and the Practice of Nonviolence, Grand Rapids: Brazos.
–––, 2006. “Pacifism: Some Philosophical Considerations”, in Larry May et al. (eds.), The Morality of War: Classical and Contemporary Readings, Upper Saddle River, NJ: Prentice Hall.
Hobbes, Thomas, 1985. Leviathan, London: Penguin Classics.
Holmes, Robert, 1989. On War and Morality, Princeton: Princeton University Press.
–––, 1994. “Pacifism and Wartime Innocence: A Response”, Social Theory and Practice, 20: 193–202.
–––, 1999. “Pacifism for Nonpacifists”, Journal of Social Philosophy, 30 (3): 387–400.
James V, Schall. 2004. “When War Must Be the Answer”, Policy Review, 128: 59–70.
James, William. “The Moral Equivalent of War”, in Larry May, Eric Rovie, and Steve Viner (eds.), The Morality of War, Upper Saddle River, NJ: Prentice Hall, 2006.
Jensen, Derek, 2006. Endgame, New York: Seven Stories Press.
Johnson, James Turner, 1981. Just War Tradition and the Restraint of War, Princeton: Princeton University Press.
Kant, Immanuel. Foundations of the Metaphysics of Morals, New York: MacMillan Publishing, 1990.
–––. Perpetual Peace, in Kant's Political Writings. Cambridge: Cambridge University Press, 1991.
King Jr., Martin Luther, 1986. A Testament of Hope: The Essential Writings of Martin Luther King Jr., James Melvin Washington (ed.), San Francisco: Harper and Row.
Kurlansky, Mark, 2006. Nonviolence: 25 Lessons Fromm the History of a Dangerous Idea, New York: Modern Library.
Lewis, C.S., 1965. “Why I am not a Pacifist”, in C.S. Lewis, The Weight of Glory and Other Addresses, New York: Macmillan.
Luban, David, 1980. “Just War and Human Rights”, Philosophy and Public Affairs, 9 (2): 160–181.
–––, 2006. “The Romance of the Nation State” in Larry May et al. (eds.), The Morality of War: Classical and Contemporary Readings, Upper Saddle River, NJ: Prentice Hall.
Lucas, George Jr., 2006. “From Jus ad Bellum to Jus ad Pacem” in Larry May et al. (eds.), The Morality of War: Classical and Contemporary Readings, Upper Saddle River, NJ: Prentice Hall.
MacGregor, G.H.C., 1952. The New Testament Basis of Pacifism, London: Fellowship of Reconciliation.
Marcuse, Herbert, 1969. Repressive Tolerance, Boston: Beacon Press.
Martin, Benjamin, 1973. “Pacifism for Pragmatists,” Ethics, 83 (3): 196–213.
May, Larry, 2012. “Contingent Pacifism and Selective Refusal” Journal of Social Philosophy, 43(1): 1–18.
McMahan, Jeff, 2009. Killing in War, Oxford: Oxford University Press.
McDaniel, Jay, 2005. Gandhi's Hope: Learning From Other Religions as a Path to Peace, Maryknoll, NY: Orbis.
Merton, Thomas, 1971. Thomas Merton on Peace, New York: McCall Publishing.
Miller, Richard B., 1991. Interpretations of Conflict, Chicago: University of Chicago Press.
Nagel, Thomas, 1972. “War and Massacre”, Philosophy and Public Affairs, 1 (2): 123–144.
Narveson, Jan, 1965. “Pacifism: A Philosophical Analysis”, Ethics, 75 (4): 259–271.
–––, 1968. “Is Pacifism Consistent?”, Ethics, 78 (2): 148–150.
–––, 2003. “Terrorism and Pacifism: Why We Should Condemn Both”, International Journal of Applied Philosophy, 17 (2): 157–172.
Noddings, Nel, 2010. The Maternal Factor, Berkeley: University of California Press.
Norman, Richard, 1988. “The Case for Pacifism”, Journal of Applied Philosophy, 5: 197–210.
Orend, Brian, 2000. War and International Justice: A Kantian Perspective, Waterloo, Ontario: Wilfrid Laurier University Press.
–––, 2001. “Evaluating Pacifism”, Dialogue, 40: 3–24.
Orwell, George, 2002. “Politics and the English Language”, in George Orwell, Essays, New York: Alfred Knopf.
Pinker, Steven, 2011. The Better Angels of our Nature, New York: Viking.
Plato. The Collected Dialogues of Plato, Princeton: Princeton University Press, 1961.
Ramsey, Paul and Stanley Hauerwas, 1988. Speak up for Just War or Pacifism, University Park: Pennsylvania State University Press.
–––, 1968. The Just War, New York: Charles Scribner's Sons.
–––, 1985. War and the Christian Conscience, Durham, NC: Duke University Press.
Rawls, John, 1971. A Theory of Justice, Cambridge: Harvard University Press.
–––, 1999. The Law of Peoples, Cambridge: Harvard University Press.
Reader, Soran, 2000. “Making Pacifism Plausible” Journal of Applied Philosophy, 17: 169–80.
Reitan, Eric, 2000. “Personally Committed to Nonviolence: Toward a Vindication of Personal Pacifism”, The Acorn, 10 (2): 30–41.
–––, 2000–2001. “Eric Reitan Replies [to Peter Brock]: Personal Pacifism, Another Look”, The Acorn 11 (1): 59–61.
–––, 2002. “The Moral Justification of Violence: Epistemic Considerations”, Social Theory and Practice, 28: 445–64.
Rousseau, Jean-Jacques. A Lasting Peace Through the Federation of Europe and The State of War, London: Constable and Co., 1917 [Available online].
Ruddick, Sara, 1995 Maternal Thinking: Toward a Politics of Peace, 2nd Edition, Boston: Beacon Press.
Russell, Bertrand, 1915. “The Ethics of War”, International Journal of Ethics, 25 (2): 127–142.
–––, 1943. “The Future of Pacifism”, The American Scholar, 13: 7–13.
–––, 2003. Man's Peril, 1954–55, in The Collected Papers of Bertrand Russell: Volume 28, London: Routledge.
Ryan, Cheyney C., 1983. “Self-Defense, Pacifism and Rights”, Ethics, 93: 508–24.
Schell, Jonathan, 2003. The Unconquerable World: Power, Nonviolence, and the Will of the People, New York: Henry Holt.
Schweitzer, Albert, 1967. Civilization and Ethics, London: Unwin Books.
Sharp, Gene, 1973. The Politics of Nonviolent Action, Boston: Porter Sargent.
–––, 1983. Making the Abolition of War a Realistic Goal, New York: Institute for World Order.
–––, 2005. Waging Nonviolent Struggle, Boston: Porter Sargent.
Teichman, Jenny, 1986. Pacifism and the Just War, Oxford: Basil Blackwell.
Teson, Fernando, 2006. “The Liberal Case for Humanitarian Intervention”, in Larry May et al. (eds.), The Morality of War: Classical and Contemporary Readings, Upper Saddle River, NJ: Prentice Hall.
Thoreau, Henry David. “Civil Disobedience”, in Walden and Other Writings, New York: The Modern Library, 2000.
U.S. Conference of Catholic Bishops, 1983. “The Challenge of Peace: God's Promise and Our Response”, Washington, D.C.: United States Catholic Conference.
Vorobej, Mark, 1994. “Pacifism and Wartime Innocence”, Social Theory and Practice, 20: 171–91.
Walzer, Michael, 1977. Just and Unjust Wars, New York: Basic Books.
–––, 2004. Arguing About War, New Haven: Yale University Press.
Weigel, George, 1987. Tranquillitas Ordinis, Oxford University Press.
–––, 2002. “The Just War Tradition and the World after September 11”, Logos: A Journal of Catholic Thought, 5 (3): 13–44.
–––, 2003. “Moral Clarity in a Time of War”, First Things, 128: 20–27.
Weiss, Paul, 1943. “The Ethics of Pacifism”, The Philosophical Review, 51 (5): 476–496.
Yoder, John Howard, 1971. The Original Revolution, Scottdale, PN: Herald Press.
–––, 1972. The Politics of Jesus, Grand Rapids, MI: William B. Erdmans Publishing Co.
–––, 1984. When War is Unjust, Minneapolis: Augsburg Publishing.
“The Russell-Einstein Manifesto,” originally issued by Bertrand Russell and Albert Einstein at the first Pugwash Conference on Science and World Affairs in London, July 9, 1955.
Open access to the SEP is made possible by a world-wide funding initiative.
Please Read How You Can Help Keep the Encyclopedia Free
The SEP would like to congratulate the National Endowment for the Humanities on its 50th anniversary and express our indebtedness for the five generous grants it awarded our project from 1997 to 2007. Readers who have benefited from the SEP are encouraged to examine the NEH’s anniversary page and, if inspired to do so, send a testimonial to neh50@neh.gov.Identity is often said to be a relation each thing bears to itself and to no other thing (e.g., Zalabardo 2000). This characterization is clearly circular ("no other thing") and paradoxical too, unless the notion of "each thing" is qualified. More satisfactory (though partial) characterizations are available and the idea that such a relation of absolute identity exists is commonplace. Some, however, deny that a relation of absolute identity exists. Identity, they say, is relative: It is possible for objects x and y to be the same F and yet not the same G, (where F and G are predicates representing kinds of things (apples, ships, passengers) rather than merely properties of things (colors, shapes)). In such a case ‘same’ cannot mean absolute identity. For example, the same person might be two different passengers, since one person may be counted twice as a passenger. If to say that x and y are the same person is to say that x and y are persons and are (absolutely) identical, and to say that x and y are different passengers is to say that x and y are passengers and are (absolutely) distinct, we have a contradiction. Others maintain that while there are such cases of "relative identity," there is also such a thing as absolute identity. According to this view, identity comes in two forms: trivial or absolute and nontrivial or relative (Gupta 1980). These maverick views present a serious challenge to the received, absolutist doctrine of identity. In the first place, cases such as the passenger/person case are more difficult to dismiss than might be supposed (but see below, §3). Secondly, the standard view of identity is troubled by many persistent puzzles and problems, some of recent and some of ancient origin. The relative identity alternative sheds considerable light on these problems even if it does not promise a resolution of them all.
A word about notation. In what follows, lower case italic letters ‘x’, ‘y’, etc., are used informally either as variables (bound or free) or as (place-holders for) individual constants. The context should make clear which usage is in play. Occasionally, for emphasis or in deference to logical tradition, other expressions for individual constants are employed. Also, the use/mention distinction is not strictly observed; but again the context should resolve any ambiguity.
1. The Standard Account of Identity
2. Paradoxes of Identity
3. Relative Identity
4. The Paradoxes Reconsidered
5. Absolute Identity
Bibliography
Academic Tools
Other Internet Resources
Related Entries
1. The Standard Account of Identity
[Note: The following material is somewhat technical. The reader may wish to casually review it now and return to it as needed, especially in connection with §5. The propositions Ref, LL, Ref′, LL′, NI, and ND are identified in the present section and are referred to as such in the rest of the entry.]
Identity may be formalized in the language L of classical first-order logic (FOL) by selecting a two place predicate of L, rewriting it as ‘=’, and adopting the universal closures of the following two postulates:
Ref: x = x
LL: x = y → [φ(x) → φ(y)],
where the formula φ(x) is like the formula φ(y) except for having occurrences of x at some or all of the places φ(y) has occurrences of y (see Enderton 2000, for a precise definition). Ref is the principle of the reflexivity of identity and LL (Leibniz’ Law) is the principle of the indiscernibility of identicals. It says in effect that identical objects cannot differ in any respect. The other characteristic properties of identity, symmetry (x = y → y = x), and transitivity (x = y & y = z → x = z), may be deduced from Ref and LL. Any relation that is reflexive, transitive, and symmetric is called an ‘equivalence relation’. Thus, identity is an equivalence relation satisfying LL. But not all equivalence relations satisfy LL. For example, the relation x and y are the same size is an equivalence relation that does not satisfy LL (with respect to a rich language such as English).
Let E be an equivalence relation defined on a set A. For x in A, [x] is the set of all y in A such that E(x, y); this is the equivalence class of x determined by E. The equivalence relation E divides the set A into mutually exclusive equivalence classes whose union is A. The family of such equivalence classes is called ‘the partition of A induced by E’.
Now let A be a set and define the relation I(A,x,y) as follows: For x and y in A, I(A,x,y) if and only if for each subset X of A, either x and y are both elements of X or neither is an element of X. This definition is equivalent to the more usual one identifying the identity relation on a set A with the set of ordered pairs of the form <x,x> for x in A. The present definition proves more helpful in what follows.
Suppose for the moment that we do not assign any special interpretation to the identity symbol. We treat it like any other two place predicate. Let M be a structure for L and assume that Ref and LL are true in M. Call the relation defined in M by the conjunction of Ref and LL ‘indiscernibility’ (see Enderton 2000, for the definition of definability in a structure). There are three important points to note about the relationship between indiscernibility, and the relation I(A,x,y). First, indiscernibility need not be the relation I(A,x,y) (where A is the domain of the structure). It might be an equivalence relation E having the property that for some elements u,v, of the domain, E(u,v) holds, although I(A,u,v) fails. Secondly, there is no way to "correct for" this possibility. There is no sentence or set of sentences that could be added to the list beginning with Ref and LL that would guarantee that indiscernibility coincides with I(A,x,y). This fact is usually expressed by saying that identity is not a first-order or "elementary" relation. (For a proof, see Hodges 1983.) However, in a language such as set theory (as usually interpreted) or second-order logic, in which there is a quantifier ‘all X’ permitting quantification over all subsets of a given set, I(A,x,y) is definable.
Third, given any structure M for L in which Ref and LL are true, there is a corresponding structure QM, the ‘quotient structure’ determined by M, in which indiscernibility does coincide with I(A,x,y). QM is obtained in roughly the following way: Let the elements of QM be the equivalence classes [x], for elements x of M determined by indiscernibility in M. If F is a one-place predicate true in M of some object x in M, then define F to be true of [x] in QM, and similarly for many-place predicates and constants. It can then be shown that any sentence true in M is true in QM, and vice versa. The existence of quotient structures makes it possible to treat the identity symbol as a logical constant interpreted in terms of I(A,x,y). There is in fact in general no other way to guarantee that Ref and LL will hold in every structure. (As Quine (1970) points out, however, a finite language will always contain a predicate satisfying Ref and LL in any structure; cf. Hodges 1983.) The alternative, however, is to view FOL with Ref and LL (FOL=) as a proper theory in whose models (structures in which Ref and LL hold) there will be an equivalence relation E such that if E(x,y) holds, then x and y will be indiscernible with respect to the defined subsets of the domain. But we cannot in general assume that every subset of the domain is definable. If the domain is infinite, L runs out of defining formulas long before the domain runs out of subsets. Nonetheless, a strong metatheorem asserts that any set of formulas that has a model, has a countable (finite or denumerable) model. This means that the difference between indiscernibility and I(A,x,y) is minimized at least to the extent that, for a sufficiently rich language such as L, the valid formulas concerning indiscernibility (i.e., the formulas true in every model of what is termed below ‘the pure L-theory with identity’) coincide with the valid formulas concerning I(A,x,y). (See Epstein 2001 for a sketch of a proof of this fact.) This is not to say, however, that there isn't a significant difference between identity qua indiscernibility and identity qua I(A,x,y) (see below). Both points of view — that FOL= is a proper theory and that it is a logic — may be found in the literature (Quine 1970). The latter is the more usual view and it will count here as part of the standard account of identity.
Assume that L′ is some fragment of L containing a subset of the predicate symbols of L and the identity symbol. Let M be a structure for L′ and suppose that some identity statement a = b (where a and b are individual constants) is true in M, and that Ref and LL are true in M. Now expand M to a structure M′ for a richer language — perhaps L itself. That is, assume we add some predicates to L′ and interpret them as usual in M to obtain an expansion M′ of M. Assume that Ref and LL are true in M′ and that the interpretation of the terms a and b remains the same. Is a = b true in M′? That depends. If the identity symbol is treated as a logical constant, the answer is "yes." But if it is treated as a non-logical symbol, then it can happen that a = b is false in M′. The indiscernibility relation defined by the identity symbol in M may differ from the one it defines in M′; and in particular, the latter may be more "fine-grained" than the former. In this sense, if identity is treated as a logical constant, identity is not "language relative;" whereas if identity is treated as a non-logical notion, it is language relative. For this reason we can say that, treated as a logical constant, identity is ‘unrestricted’. For example, let L′ be a fragment of L containing only the identity symbol and a single one-place predicate symbol; and suppose that the identity symbol is treated as non-logical. The formula
∀x∀y∀z(x = y ∨ x = z ∨ y = z)
is then true in any structure for L′ in which Ref and LL are true. The reason is that the unique one-place predicate of L′ divides the domain of a structure into those objects it satisfies and those it does not. Hence, at least two of any group of three objects will be indiscernible. On the other hand, if the identity symbol is interpreted as I(A,x,y), this formula is false in any structure for L′ with three or more elements.
If we do wish to view identity as a non-logical notion, then the phenomenon of language relativity suggests that it is best not to formalize identity using a single identity predicate ‘=’. Instead, we have the following picture: We begin with a language L and define an L-theory with identity to be a theory whose logical axioms are those of FOL and which is such that L contains a two-place predicate EL satisfying the non-logical axiom Ref’ and the non-logical axiom schema LL′:
Ref′: EL(x,x)
LL′: EL(x,y) → (φ(x) → φ(y)).
The pure L-theory with identity is the L-theory whose sole non-logical axiom is Ref’ and whose sole non-logical axiom schema is LL′.
Now the phenomenon of language relativity can be described more accurately as follows. Let L1 be a sublanguage of L2 and assume that T1 and T2 are, respectively, the pure L1-theory with identity and the pure L2-theory with identity. Let M1 and M2 be models of T1 and T2, respectively, having the same domain. Assume that a and b are individual constants having the same interpretation in M1 and M2. Let E1 and E2 be the identity symbols of L1 and L2. It can happen that E1(a,b) is true in M1 but E2(a,b) is false in M2. We can then say, with Geach (1967; see §4) and others, that the self-same objects indiscernible according to one theory may be discernible according to another.
There are two further philosophically significant features of the standard account of identity. First, identity is a necessary relation: If a and b are rigid terms (terms whose reference does not vary with respect to parameters such as time or possible world) then
NI: If a = b is true, then it is necessarily true.
Assuming certain modal principles, the necessity of distinctness (ND) follows from NI.
ND: If a ≠ b is true, then it is necessarily true.
Note that the necessary truth of a = b does not imply the necessary existence of objects a or b. We may assume that what a rigid term a denotes at a possible world (or moment of time) w need not exist in w. Secondly, we do not ordinarily say things of the form "x is the same as y". Instead, we say "x and y are the same person" or "x and y are the same book". The standard view is that the identity component of such statements is just ‘x is the same as y’. For example, according to the standard view, ‘x and y are the same person’ reduces to ‘x and y are persons and x is the same as y’, where the second conjunct may be formalized as in FOL=.
2. Paradoxes of Identity
The concept of identity, simple and settled though it may seem (as characterized by the standard account), gives rise to a great deal of philosophical perplexity. A few (by no means all) of the salient problems are outlined below. These are presented in the form of paradoxes — arguments from apparently undeniable premises to obviously unacceptable conclusions. The aim here is to make clear just what options are available to one who would stick close to the standard account. Often (but not always) little or no defense or critique of any particular option is offered. In the next section, we shall see what the relative identity alternative offers by comparison.
2.1 The Paradox of Change
The most fundamental puzzle about identity is the problem of change. Suppose we have two photographs of a dog, Oscar. In one, A, Oscar is a puppy, in the other, B, he is old and gray muzzled. Yet we hold that he is the same dog, in, it appears, direct violation of LL. More explicitly, B is a photograph of an old dog with a gray muzzle; A is a photograph of a young dog without a gray muzzle. A and B are photographs of the same dog. But according to LL, if the dog in B has a property (e.g., having a gray muzzle) that the dog in A lacks, then A and B are not photographs of the same dog. Contradiction.
Various solutions have been proposed. The most popular are the following two: (1) Simple properties such as having or lacking a gray muzzle are actually relations to times. Oscar has the property of lacking a gray muzzle at time t and the property of having a gray muzzle at (a later) t′; but there is no incompatibility, since being thus and so related to time t and not being thus and so related to time t′ are compatible conditions, and hence change involves no violation of LL. (2) Oscar is an object that is extended in time as well as space. The puppy Oscar and old gray muzzled Oscar are distinct temporal parts or stages of the whole temporally extended Oscar. The photograph of Oscar as a puppy is therefore not a photograph of Oscar at all. There cannot be still photographs of Oscar.
These proposals may seem plausible, and indeed most philosophers subscribe to one or other of them. The most common objections — that on the temporal parts account, objects are not "wholly present" at any given time, and that on the relations-to-times account, seemingly simply properties of objects, such as Oscar having a gray muzzle, are complicated relations — do little more than affirm what their targets deny. Yet the objections are an attempt to give voice to a strong intuition concerning our experience as creatures existing in time. Both (1) and (2) treat time and change from a "God's eye" point of view. (1) presupposes time laid out "all at once", so to speak, and similarly for (2). But we experience no such thing. Instead, while we are prepared to wait to see the whole of a baseball game we are watching, we are not prepared to wait to see the whole of painting we are viewing..
2.2 Chrysippus' Paradox
The following paradox — a variation of the paradox of change — raises some new questions. It is due to the Stoic philosopher Chrysippus (c.280 B.C.-c.206 B.C.) and has recently been resurrected by Michael Burke (Burke 1994). Suppose that at some point t′ in the future poor Oscar loses his tail. Consider the proper part of Oscar, as he is now (at t), consisting of the whole of Oscar minus his tail. Call this object ‘ Oscar-minus ‘. Chrysippus wished to know which of these objects — Oscar or Oscar-minus — survives at t′. According to the standard account of identity, Oscar and Oscar-minus are distinct at t. and hence, by ND, they are distinct at t′. (Intuitively, Oscar and Oscar-minus are distinct at t′ since Oscar has a property at t′ that Oscar-minus lacks, namely, the property of having had a tail at t. Notice that this argument involves a tacit appeal to ND — or NI, depending on how you look at it). Hence, if both survive, we have a case of two distinct physical objects occupying exactly the same space at the same time. Assuming that is impossible, and assuming, as commonsense demands, that Oscar survives the loss of his tail, it follows that Oscar-minus does not survive. This conclusion is paradoxical because it appears that nothing happens to Oscar-minus in the interval between t and t′ that would cause it to perish.
One extreme option is to deny that there are such things as Oscar-minus. Undetached proper parts of objects don't exist (van Inwagen 1981). Another is to claim that the parts of an object are essential to it (Chisholm 1973). A third, less extreme, option is to insist that objects of different kinds, e.g., a clay statue and the piece of clay it is composed of, can occupy the same space at the same time, but objects of the same kind, e.g., two statues, cannot (Wiggins 1968; for refinements, see Oderberg 1996). A fourth option is to claim that Oscar and Oscar-minus are two distinct, temporally extended objects — a dog part, Oscar-minus, and a dog, Oscar — that overlap at t′. Temporal parts of distinct objects can occupy the same space at the same time.
2.3 The Paradox of 101 Dalmatians
(This paradox is also known as the paradox of 1001 cats; Geach 1980, Lewis 1993): Focus on Oscar and Oscar-minus at t — before Oscar loses his tail. Is Oscar-minus a dog? When Oscar loses his tail the resulting creature is certainly a dog. Why then should we deny that Oscar-minus is a dog? We saw above that one possible response to Chrysippus' paradox was to claim that Oscar-minus does not exist at t′. But even if we adopt this view, how does it follow that Oscar-minus, existing as it does at t, is not a dog? Yet if Oscar-minus is a dog, then, given the standard account of identity, there are two dogs where we would normally count only one. In fact, for each of Oscar's hairs, of which there are at least 101, there is a proper part of Oscar — Oscar minus a hair — which is just as much a dog as Oscar-minus. There are then at least 101 dogs (and in fact many more) where we would count only one. Some claim that things such as dogs are "maximal." No proper part of a dog is a dog (Burke 1993). One might conclude as much simply to avoid multiplying the number of dogs populating the space reserved for Oscar alone. But the maximality principle may seem to be independently justified as well. When Oscar barks, do all these different dogs bark in unison? If a thing is a dog, shouldn't it be capable of independent action? Yet Oscar-minus cannot act independently of Oscar. Nevertheless, David Lewis (1993) has suggested a reason for counting Oscar-minus and all the 101 dog parts that differ (in various different ways) from one another and Oscar by a hair, as dogs, and in fact as Dalmatians (Oscar is a Dalmatian). Lewis invokes Unger's (1980) "problem of the many." Oscar sheds continuously but gradually. His hairs loosen and then dislodge, some such remaining still in place. Hence, within Oscar's compass at any given time there are congeries of Dalmatian parts sooner or later to become definitely Dalmatians; some in a day, some in a second, or a split second. It seems arbitrary to proclaim a Dalmatian part that is a split second away from becoming definitely a Dalmatian, a Dalmatian, while denying that one a day away is a Dalmatian. As Lewis puts it, we must either deny that the "many" are Dalmatians, or we must deny that the Dalmatians are many. Lewis endorses proposals of both types but seems to favor one of the latter type according to which the Dalmatians are not many but rather "almost one" In any case, the standard account of identity seems unable on its own to handle the paradox of 101 Dalmatians. It requires that we either deny that Oscar minus a hair is a dog — and a Dalmatian — or else that we must affirm that there is a multiplicity of Dalmatians, all but one of which is incapable of independent action and all of which bark in unison no more loudly than Oscar barks alone.
2.4 The Paradox of Constitution
Suppose that on day 1 Jones purchases a piece of clay c and fashions it into a statue s1. On day 2, Jones destroys s1, but not c, by squeezing s1 into a ball and fashions a new statue s2 out of c. On day 3, Jones removes a part of s2, discards it, and replaces it using a new piece of clay, thereby destroying c and replacing it by a new piece of clay, c′. Presumably, s2 survives this change. Now what is the relationship between the pieces of clay and the statues they "constitute?" A natural answer is: identity. On day 1, c is identical to s1 and on day 2, c is identical to s2. On day 3, s2 is identical to c′. But this conclusion directly contradicts NI. If, on day 1, c is (identical to) s1, then it follows, given NI, that on day 2, s1 is s2 (since c is identical to s2 on day 2) and hence that s1 exists on day 2, which it does not. By a similar argument, on day 3, c is c′ (since s2 is identical to both) and so c exists on day 3, which it does not. We might conclude, then, that either constitution is not identity or that NI is false. Neither conclusion is wholly welcome. Once we adopt the standard account less NI, the latter principle follows directly from the assumption that individual variables and constants in quantified modal logic are to be handled exactly as they are in first-order logic. And if constitution is not identity, and yet statues, as well as pieces of clay, are physical objects (and what else would they be?), then we are again forced to affirm that distinct physical objects may occupy (exactly) the same space at the same time. The statue s1 and the piece of clay c occupy the same space on day 1. Even if this is deemed possible (Wiggins 1980), it is unparsimonious. The standard account is thus prima facie incompatible with the natural idea that constitution is identity.
Philosophers have not argued by direct appeal to NI or ND. Typically, (e.g., Gibbard 1975, Noonan 1993, Johnston 1992), arguments that c and s1 are not identical run as follows: c exists prior to the existence of s1 and hence the two are not identical. Again, s1 possesses the property of being such that it will be destroyed by being squeezed into a ball, but c does not possess this property (c will be squeezed into a ball but it will not thereby be destroyed). So again the two are not identical. Further, whatever the future in fact brings, c might have been squeezed into a ball and not destroyed. Since that is not true of s1, the two are not identical. On a careful analysis, however, each of these arguments can be seen to rely on NI or ND, provided one adopts the standard account of modal/temporal predicates. This last proviso suggests an interesting way out for one who adheres to the standard account of identity but who also holds that constitution is identity (see below).
Some philosophers find it important or at least expedient to frame the issue in terms of the case of a statue s and piece of clay c that coincide throughout their entire existence. We bring both c and s into existence by joining two other pieces of clay together, or we do something else that guarantees total coincidence. It seems that total coincidence is supposed to lend plausibility to the claim that, in such a case at least, constitution is identity (and hence NI is false — Gibbard 1975). It may do so, psychologically, but not logically. The same sorts of arguments against the thesis that constitution is identity apply in such a case. For example, s may be admired for its aesthetic traits, even long after it ceases to exist, but this need not be true of c. And s has the property, which c lacks, of being destroyed if squeezed into a ball. Those who defend the thesis that constitution is identity need to defend it in the general case of partial coincidence; and those who attack the thesis do so with arguments that work equal well against both total and partial coincidence. The assumption that s and c are totally coincident is therefore inessential.
The doctrine of temporal parts offers only limited help. The statement that c is identical to s1on day 1 but identical to s2 on day 2 can be construed to mean that c is a temporally extended object whose day 1 stage is identical to s1 and whose day 2 stage is identical to s2. Since the two stages are not identical, NI does not apply. Similarly, we can regard s2 as a temporally extended object that overlaps c on day 2 and c′ on day 3. But unless temporal parts theorists are prepared to defend a doctrine of modally extended objects — objects extended through possible worlds analogous to objects extended in time, there remains a problem. s2 might have been made of a different piece of clay, as is in fact the case on day 3. That is, it is logically possible for s2 to fail to coincide with the day 2 stage of c. But it is not logically possible for the day 2 stage of c to fail to coincide with itself.
Lewis recognizes this difficulty and proposes to deal with it by appealing to his counterpart theory (Lewis 1971, 1986, and 1993). Different concepts, e.g., statue and piece of clay are associated with different counterpart relations and hence with different criteria of trans-world identity. This has the effect of rendering modal predicates "Abelardian" (Noonan 1991, 1993). The property determined by a modal predicate may be affected by the subject term of a sentence containing the predicate. The subject term denotes an object belonging to this or that kind or sort. But different kinds or sorts may determine different properties (or different counterpart relations). In particular, the properties determined by the predicate ‘might not have coincided with c2’ (where c2 names the day 2 stage of c) in the following sentences,
(a) s2 might not have coincided with c2,
(b) c2 might not have coincided with c2,
are different, and hence (a) and (b) are compatible, even assuming that s2 and c2 are identical. (It should be emphasized that counterpart theory is not the only means of obtaining Abelardian predicates. See Noonan 1991.)
The upshot seems to be that that the advocate of the standard account of identity must maintain either that constitution is not identity or that modal predicates are Abelardian. The latter option may be the fruitful one, since for one thing it seems to have applications that go beyond the issue of constitution.
2.5 The Ship of Theseus Paradox
(See Plutarch, Life of Theseus.) Imagine a wooden ship restored by replacing all its planks and beams (and other parts) by new ones. Plutarch reports that such a ship was "… a model for the philosophers with respect to the disputed arguments … some of them saying it remained the same, some of them saying it did not remain the same" (cf. Rea 1995). Hobbes added the catch that the old parts are reassembled to create another ship exactly like the original. Both the restored ship and the reassembled one appear to qualify equally to be the original. In the one case, the original is "remodeled", in the other, it is reassembled. Yet the two resulting ships are clearly not the same ship.
Some have proposed that in a case like this our ordinary "criteria of identity" fail us. The process of dismantling and reassembling usually preserves identity, as does the process of part replacement (otherwise no soldier could be issued just one rifle and body shops would function as manufacturers). But in this case the two processes produce conflicting results: We get two ships, one of which is the same ship as the original, by one set of criteria, and the other is the original ship by another set of criteria. There is a similar conflict of criteria in the case of personal identity: Brain duplication scenarios (Wiggins 1967, Parfit 1984) suggest that it is logically possible for one person to split into two competitors, each with equal claim to be the original person. We take it for granted that brain duplication will preserve the psychological properties normally relevant to reidentifying persons and we also take it for granted that the original brain continues to embody these properties even after it is duplicated. In this sense there is a conflict of criteria. Such a case of "fission" gives us two distinct embodiments of these properties.
Perhaps we should conclude that identity is not what matters. Instead, what matters is some other relation, but one that accounts as readily as identity for such facts as that the owner of the original ship would be entitled to both the restored version and the reassembled one. For the case of personal identity, Parfit (1984) develops such a response in detail. A related reaction would be to claim that if both competitors have equal claim to be the original, then neither is the original. If, however, one competitor is inferior, then the other wins the day and counts as the original. It seems that on this view certain contingencies can establish or falsify identity claims. That conflicts with NI. Suppose that w is a possible world in which no ship is assembled from the discarded parts of the remodeled ship. In this world, then, the remodeled ship is the original. By NI, the restored ship and the original are identical in the actual world, contrary to the claim of the "best candidate" doctrine (which says that neither the remodeled nor the reassembled ship is the original). There are, however, more sophisticated "best candidate" theories that are not vulnerable to this objection (Nozick 1982).
Some are convinced that the remodeled ship has the best claim to be the original, since it exhibits a greater degree of spatio-temporal continuity with the original (Wiggins 1967). But it is unclear why the intuition that identity is preserved by spatio-temporal continuity should take precedence over the intuition that identity is preserved in the process of dismantlement and reassembly. Furthermore, certain versions of the ship of Theseus problem do not involve the feature that one of the ships competing to be the original possesses a greater degree of spatio-temporal continuity with the original than does the other (see below). Others are equally convinced that identity is not preserved by total part replacement. This view is often suggested blindly, as a stab in the dark, but there is in fact an interesting argument in its favor. Kripke (1980) argues that a table made out of a particular hunk of wood could not have been made out of a (totally) different hunk of wood. His reasoning is this: Suppose that in the actual world a table T is made out of a hunk of wood H; and suppose that there is a possible world w in which this very table, T, is made out of a different hunk of wood, H′. Then assuming that H and H′ are completely unrelated (for example, they do not overlap), so that making a table out of the one is not somehow dependent upon making a table out of the other, there is another possible world w′ in which T, as in the actual world, is made out of H, and another table T′, exactly similar to T, is made out of H′. Since T and T′ are not identical in w′, it follows by ND that the table made out of H′ in w is not T. Note, however, that the argument assumes that the table made out of H′ in w′ is the same table as the table made out of H′ in w.
Kripke's reasoning can be applied to the present case (Kripke and others might dispute this claim; see below). Let w be a possible world just like the actual world in that O, the original ship, is manufactured exactly as it is in the actual world. In w, however, another ship, S′, exactly similar to O, is simultaneously built out of precisely the same parts that S, the remodeled ship, is built out of in the actual world. Since S′ and O are clearly different ships in w, it follows by ND that O and S are not the same ship in the actual world. Note again that the argument assumes that S and S′ are the same ship, but it seems quite a stretch to deny that. Nevertheless, some have done so. Carter,1987 claims (in effect) that S and S′ are not identical, but his argument simply assumes that O and S are the same ship. Alternatively, one might view the (Kripkean) argument as showing only that while S is the same ship as O in the actual world, S (that is, S′) is not the same ship as O in w. But this is not an option for one who adheres to the standard account and hence adheres to ND. In defending this view, however, Gallois, (1986, 1988) suggests a weakened notion of rigid designation and a corresponding weakened formulation of ND. (See Carter 1987 for criticism of Gallois' proposals. See also Chandler 1975 for a precursor of Gallois' argument.)
If we grant that O and S cannot be the same ship, we seem to have a solution to the ship of Theseus paradox. By the Kripkean argument, only the reassembled ship has any claim to being the original ship, O. But this success is short lived. For we are left with the following additional paradox: Suppose that S eventuates from O by replacing one part of O one day at a time. There seems to be widespread agreement that replacing just one part of a thing by a new exactly similar part preserves the identity of the thing. If so, then, by the transitivity of identity, O and S must be the same ship. It follows that either the Kripkean argument is incorrect, or replacement of even a single part (or small portion) does not preserve identity (a view known as "mereological essentialism;" Chisholm 1973).
As indicated, Kripke denies that his argument (for the necessity of origin) applies to the case of change over time: "The question whether the table could have changed into ice is irrelevant here" (1972, 1980). So the question whether O could change into S is supposedly "irrelevant." But Kripke does not give a reason for this claim, and if cases of trans-temporal identity and trans-world identity differ markedly in relevant respects — repsects relevant to Kripke's argument for the necessity of origin, it is not obvious what they are. (But see Forbes 1985, and Lewis 1986, for discussion.) The argument above was simply that O and S cannot be the same ship since there is a possible world in which they differ. If this argument is incorrect it is no doubt because there are conclusive reasons showing that S and S′ differ. Even so, such reasons are clearly not "irrelevant." One may suspect that, if applied to the trans-temporal case, Kripke's reasoning will yield an argument for mereological essentialism. Indeed, a trans-world counterpart of such an argument has been tried (Chandler 1976, though Chandler views his argument somewhat differently). In its effect, this argument does not differ essentially from the "paradox" sketched in the previous paragraph (which may well be viewed as an argument for mereological essentialism). Subsequent commentators, e.g., Salmon, (1979) and Chandler (1975, 1976), do not seem to take Kripke's admonition of irrelevance seriously.
In any case, there is a close connection between the two issues (the ship of Theseus problem and the question of the necessity of origin). This can be seen (though it may already be clear) by considering a modified version of the ship of Theseus problem. Suppose that when O is built, another ship O′, exactly like O, is also built. Suppose that O′ never sets sail, but instead is used as a kind of graphic repair manual and parts repository for O. Over time, planks are removed from O′ and used to replace corresponding planks of O. The result is a ship S made wholly of planks from O′ and standing (in the end), we may suppose, in exactly the place O′ has always stood. Now do O and O′ have equal claim to be S? And can we then declare that neither is S? Not according to the Kripkean line of thought. It looks for all the world as though the process of "remodeling" O is really just an elaborate means of dismantling and reassembling O′. And if O′ and S are the same ship, then since O and O′ are distinct, O and S cannot be the same ship.
This argument is vulnerable to the following two important criticisms: First, it conflicts with the common sense principle that (1) the material of an object can be totally replenished or replaced without affecting its identity (Salmon 1979); and secondly, as mentioned, it conflicts with the additional common sense principle that (2) replacement by a single part or small portion preserves identity. These objections may seem to provide sufficient grounds for rejecting the Kripkean argument and perhaps restricting the application of Kripke's original argument for the necessity of origin (Noonan 1983). There is, however, a rather striking problem with (2), and it is uncleear whether the conflict between (1) and the Kripkean argument should be resolved in favor of the former.
The problem with (2) is this. Pick a simple sort of objects, say, shoes, or better, sandals. Suppose A and B are two exactly similar sandals, one of which (A) is brand new and the other (B) is worn out. Each consists of a top strap and a sole, nothing more. If B's worn strap is replaced by A's new one, (2) dictates that the resulting sandal is B "refurbished." In fact, if the parts of A and B are simply exchanged, (2) dictates that that the sandal with the new parts, A′, is B and the sandal with the old parts, B′, is A. It follows by ND that A and A′ and B and B′ are distinct. This is surely the wrong result. The intuition that A and A′ are the same sandal is very strong; and the process of exchanging the parts of A and B seems to amount to nothing more than the dismantling and reassembling of each. This example is no different in principle than the more elaborate trans-world cases discussed by Chisholm (1967), Chandler (1976), Salmon (1979), or Gupta (1980). (One who claims that A and A′ differ in that A′ comes into existence after A, does not have much to go on. A cannot be supposed to persist after A′ comes into existence. We do not end up with two new sandals and one old one. Why then couldn't it be A itself that reappears at the later time?)
2.6 Church's Paradox
The following paradox — perhaps the ultimate paradox of identity — derives from an argument of Church (1982). Suppose Pierre thinks that London and Londres are different cities, but of course doesn't think that London is different from London, or that Londres is different from Londres. Assuming that proper names lack Fregean senses, we can apply LL to get the result that London and Londres are distinct. We have here an argument that, given the standard account of identity, merely thinking that x and y are distinct is enough to make them so. There are, of course, a number of ways around this conclusion without abandoning the standard account of identity. Church himself saw the argument (his version of it) as demonstrating the inadequacy of Russellian intensional logic — in which variables and constants operate as they do in extensional logic, i.e., unequipped with senses. (For another reaction, see Salmon 1986.) But there are strong arguments against the view that names (or variables) have senses (Kripke 1980). In light of these arguments, Church's argument may be viewed as posing yet another paradox of identity.
The general form of Church's argument has been exploited by others to reach further puzzling conclusions. For example, it has been used to show that there can be no such thing as vague or "indeterminate" identity (Evans 1978; and for discussion, Parsons 2000). For x is not vaguely identical to x; hence, if x is assumed to be vaguely identical to y, then by LL, x and y are (absolutely) distinct. As it stands, Evans' argument shows at best that vaguely identical objects must be absolutely distinct, not that there is no such thing as vague identity. But some have tried to amend the argument to get Evans' conclusion (Parsons 2000; and see the entry on vagueness). In any case, it is useful to see the connection between Evans' argument and Church's. If, for example, ‘vaguely identical’ is taken to mean ‘thought to be identical’, then the two arguments collapse into one another. Church's line of argument would seem to lead ultimately to the extreme antirealist position that any perceived difference among objects is a real difference. If one resolves not to attempt to escape the clutches of LL by some clever dodge — by disallowing straightforward quantifying-in, for example, as with the doctrine of Abelardian predicates — one comes quickly to the absurd conclusion that no statement of the form x = y, where the terms are different, or are just different tokens of the same type, can be true. Yet it might just be that the fault lies not in ourselves, but in LL.
3. Relative Identity
The fundamental claim of relative identity-the claim the various versions of the idea have in common-is that, as it seems in the passenger/person case, it can and does happen that x and y are the same F and (yet) x and y are not the same G. Now it is usually supposed that if x and y are the same F (G etc.), then that implies that x and y are Fs (Gs, etc.) If so, then the above schema is trivially satisfied by the case in which x and y are the same person but x (y) is not a passenger at all. But let us resolve to use the phrase ‘x and y are different Gs’ to mean ‘x and y are Gs and x and y are not the same G’. Then the nontrivial core claim about relative identity is that the following may well be true:
RI: x and y are the same F but x and y are different Gs.
RI is a very interesting thesis. It seems to yield dramatically simple solutions to (at least some of) the puzzles about identity. We appear to be in a position to assert that young Oscar and old Oscar are the same dog but nonetheless distinct "temporary" objects; that Oscar and Oscar-minus are the same dog but different dog parts; that the same piece of clay can be now (identical to) one statue and now another; that London and Londres are the same city but different "objects of thought," and so forth. Doubts develop quickly, however. Either the same dog relation satisfies LL or it does not. If it does not, it is unclear why it should be taken to be a relation of identity. But if it satisfies LL, then it follows, given that Oscar and Oscar-minus are different dog parts, that Oscar-minus is not the same dog part as Oscar-minus. Furthermore, assuming that the same dog part relation is reflexive, it follows from the assumption that Oscar-minus and Oscar-minus are the same dog (and that LL is in force), that Oscar and Oscar-minus are indeed the same dog part, which in fact they are not.
It may seem, then, that RI is simply incoherent. These arguments, however, are a bit too quick. On analysis, they show only that the following three conditions form an inconsistent triad: (1) RI is true (for some fixed predicates F and G). (2) Identity relations are equivalence relations. (3) The relation x and y are the same F figuring in (1) satisfies LL. For suppose that the relation x and y are the same G, figuring in (1), is reflexive and that x is a G. Then x is the same G as x. But according to (1), x and y are not the same Gs; hence, according to (3), it is not the case that x and y are the same F; yet (1) asserts otherwise. Now, most relative identity theorists maintain that while identity relations are equivalence relations, they do not in general satisfy LL. However, according to at least one analysis of the passenger/person case (and others), the same person relation satisfies LL but the same passenger relation is not straightforwardly an equivalence relation (Gupta 1980). It should be clear though that this view is incompatible with the principle of the identity of indiscernibles: If x and y are different passengers, there must be, by the latter principle, some property x possesses that y does not. Hence if the same person relation satisfies LL, it follows that x and y are not the same person. For the remainder we will assume that identity relations are equivalence relations. Given this assumption, (and assuming that the underlying propositional logic is classical — cf. Parsons 2000) RI and LL are incompatible in the sense that within the framework of a single fixed language for which LL is defined, RI and LL are incompatible.
Yet the advocate of relative identity cannot simply reject any form of LL. There are true and indispensable instances of LL: If x and y are the same dog, then, surely, if x is a Dalmatian, so is y. The problem is that of formulating and motivating restricted forms of LL that are nonetheless strong enough to bear the burden of identity claims. There has been little systematic work done in this direction, crucial though it is to the relative identity project. (See Deutsch 1997 for discussion of this issue.) There are, however, equivalence relations that do satisfy restricted forms of LL. These are sometimes called ‘congruence relations’ and they turn up frequently in mathematics. For example, say that integers n and m are congruent if their difference n − m is a multiple of 3. This relation preserves multiplication and addition, but not every property. The numbers 2 and 11 are thus congruent but 2 is even and 11 is not. There are also non-mathematical congruencies. For example, the relation x and y are traveling at the same speed preserves certain properties and not others. If objects x and y are traveling at the same speed and x is traveling faster than z, the same is true of y. Such similarity relations satisfy restricted forms of LL. In fact, any equivalence relation satisfies a certain minimal form of LL (see below).
There are strong and weak versions of RI. The weak version says that RI has some (in fact, many) true instances but also that there are predicates F such that if x and y are the same F, then, for any equivalence relation, E, whatsoever (whether or not an identity relation), E(x,y). This last condition implies that the relation x and y are the same F satisfies LL. The relation P defined so that P(x,y) if and only if H(x) and H(y), where H is some predicate, is an equivalence relation. Hence, if H holds of x but not of y, there is an equivalence relation (namely, P(x,y)) that fails to hold of x and y. If we add that in this instance ‘x and y are the same F’ is to be interpreted in terms of the relation I(A,x,y), then the weak version of RI says that there is such a thing as relative identity and such a thing as absolute identity as well. The strong version, by contrast, says that there are (many) true instances of RI but there is no such thing as absolute identity. It is difficult to know what to make of the latter claim. Taken literally, it is false. The notion of unrestricted identity (in the sense of ‘unrestricted’ explained in §1) is demonstrably coherent. We return to this matter in §5 .
The puzzles about identity outlined in §2 (and there are many others, as well as many variants of these) put considerable pressure on the standard account. A theory of identity that allows for instances of RI is an attractive alternative (see below §4). But there is a certain kind of example of RI, frequently discussed in the literature, that has given relative identity something of a bad name. The passenger/person example is a case in point. The noun ‘passenger’ is derived from the corresponding relational expression ‘passenger in (on) …’. A passenger is someone who is a passenger in some vehicle (on some flight, etc.). Similarly, a father is man who fathers someone or who is the father of someone. This way of defining a kind of things from a relation between things is perfectly legitimate and altogether open-ended. Given any relation R, we can define ‘an R’ to apply to anything x that stands in R to something y. For example, we can define a ‘schmapple’ to be an apple in a barrel. All this is fine. But we can't infer from such a definition that the same apple might be two different schmapples. From the fact that someone is the father of two different children, we don't judge that he is two different fathers. The fact that airlines choose to count passengers as they do, rather than track persons, is their business, not logic's.
However, when R is an equivalence relation, we are entitled to such an inference. Consider the notorious case of "surmen" (Geach 1967). A pair of men are the "same surman" if they have the same surname; and a surman is a man who bears this relation to someone. So now it appears that that two different men can be the same surman, since two different men can have the same surname. As Geach (1967) insists (also Geach 1973), surmen are defined to be men, so they are not merely classes of men. Hence we seem to have an instance of RI, and obviously any similarity relation (e.g., x and y have the same shape) will give rise to a similar case. Yet such instances of RI are not very interesting. It is granted all around that when ‘F’ is adjectival, different Gs may be the same F. Different men may have the same surname, different objects, the same color, etc. Turning an adjectival similarity relation into a substantival one having the form of an identity statement yields an identity statement in name only.
A word about the point of view of those who subscribe to the weak version of RI. The view (call it the ‘weak view’) is that ordinary identity relations concerning (largely) the world of contingency and change are equivalence relations answering to restricted forms of LL. The exact nature of the restriction depends on the equivalence relation itself, though there is an element of generality. The kinds of properties preserved by the same dog relation are intuitively the same kinds of properties as are preserved by the same cat relation. From a logical point of view the best that can be said is that any identity relation, like any equivalence relation, preserves a certain minimal set of properties. For suppose E is some equivalence relation. Let S be the set containing all formulas of the form E(x,y), and closed under the formation of negations, conjunctions, and quantification. Then E preserves any property expressed by a formula in S. Furthermore, on this view, although absolutely distinct objects may be the same F, absolutely identical objects cannot differ at all. Any instance of RI implies that
x and y are absolutely distinct.
4. The Paradoxes Reconsidered
Let us look back at the paradoxes of identity outlined in §2 from the perspective of the weak view regarding relative identity. That view allows that absolutely distinct objects may be the same F, but denies that absolutely identical objects can be different G's. This implies that if x and y are relatively different objects, then x and y are absolutely distinct, and hence only pairs of absolutely distinct objects can satisfy RI. If x and y are absolutely distinct, we shall say that x and y are distinct ‘logical objects’; and similarly, if x and y are absolutely identical objects, then x and y are identical logical objects. The term ‘logical object’ does not stand for some new and special kind of thing. Absolutely distinct apples, for example, are distinct logical objects.
The following is the barest sketch of relativist solutions to the paradoxes of identity discussed in §2. No attempt is made to fully justify any proposed solution, though a modicum of justification emerges in the course of §6. It should be kept in mind that some of the strength of the relativist solutions derives from the weaknesses of the absolutist alternatives, some of which are discussed in §2.
4.1 The Paradox of Change
Young Oscar and old Oscar are the same dog but absolutely different things, i.e. different logical objects. The material conditions rendering young Oscar and old Oscar the same dog (and the same Dalmatian) are precisely the same as the material conditions under which young Oscar and old Oscar would qualify as temporal parts of the same dog. The only difference is logical. The identity relation between young Oscar and old Oscar can be formalized in an extensional logic (Deutsch 1997), but a theory of temporal parts requires a modal/temporal apparatus. Young Oscar is wholly present during his youth and possesses the simple, non-relational, property of not having a gray muzzle.
4.2 Chrysippus' Paradox
Oscar and Oscar-minus both survive Oscar's loss of a tail. At both t and t′ Oscar and Oscar-minus are the same dog, but at t, Oscar and Oscar-minus are distinct logical objects. This implies (by ND) that Oscar and Oscar-minus are distinct logical objects even at t′ Hence, we must allow that distinct logical objects may occupy the same space at the same time. This is not a problem, however. For although Oscar and Oscar-minus are distinct logical objects at t′, they are physically coincident.
4.3 The Paradox of 101 Dalmatians
The relativist denies that dogs are "maximal." It is not true that no proper part of a dog is dog. All the 101 (and more) proper parts of Oscar differing from him and from one another by a hair are dogs. In fact, many (though of course not all) identity preserving changes Oscar might undergo correspond directly to proper parts of (an unchanged) Oscar. But there is no problem about barking in unison, and no problem about acting independently. All 101 are the same dog, despite their differences, just as young Oscar and old Oscar are the same dog, . The relativist denies that the dogs are many rather than deny that the many are dogs (Lewis 1993).
4.4 The Paradox of Constitution
Constitution is identity, absolute identity. The relation between the piece of clay c and the statue s1 on day 1 is one of absolute identity. So we have that c = s1 on day 1, and for the same reason, c = s2 on day 2. Furthermore, since s1 and s2 are different statues, it follows (on the weak view) that s1≠s2. In addition, the piece of clay c constituting s1 on day 1 is (relatively) the same piece of clay as the piece of clay constituting s2 on day 2. (The identity is relative because we have distinct objects — the two statues — that are the same piece of clay.) It follows that no name of the piece of clay c can be a rigid designator in the standard sense. That is, no name of c denotes absolutely the same thing on day 1 and on day 2. For on day 1, a name of the piece of clay c would denote s1 and on day 2, it would denote s2, and s1 and s2 are absolutely distinct. Nevertheless, a name of the piece of clay may be relatively rigid: it may denote at each time the same piece of clay. Although no name of the piece of clay c is absolutely rigid, that does not prevent the introduction of a name of c that denotes c at any time (or possible world). (Kraut 1980 discusses a related notion of relative rigidity.)
There is, however, a certain ambiguity in the notion of a name of the piece of clay, inasmuch as the piece of clay may be any number of absolutely distinct objects. The notion of relative rigidity presupposes that a name for the piece of clay refers, with respect to some parameter p, to whatever object counts as the piece of clay relative to that parameter. This may be sufficient in the case of the piece of clay, but in other cases it is not. With respect to a fixed parameter p there may be no unique object to serve as the referent of the name. For example, if any number of dog parts count, at a fixed time, as the same dog, then which of these objects serves as the referent of ‘Oscar’? We shall leave this question open for the time being but suggest that it may be worthwhile to view names such as ‘Oscar’ as instantial terms — terms introduced into discourse by means of existential instantiation. The name ‘Oscar’ might be taken as denoting a representative member of the equivalence class of distinct objects qualifiying as the same dog as Oscar. It would follow, then, that most ordinary names are instantial terms. (An alternative is that of Geach 1980, who draws a distinction between a name of and a name for an object; see Noonan 1997 for discussion of Geach's distinction.)
4.5 The Ship of Theseus Paradox
In this case, the relativist, as so far understood, may seem to enjoy no advantage over the absolutist. The problem is not clearly one of reconciling LL with ordinary judgments of identity, and the advantage afforded by RI does not seem applicable. Griffin (1977), for example, relying on RI, claims that the original and remodeled ship are the same ship but not the same collection of planks, whereas the reassembled ship is the same collection of planks as the original but not the same ship. This simply doesn't resolve the problem. The problem is that the reassembled and remodeled ships have, prima facie, equal claim to be the original and so the bald claims that the reassembled ship is not—and the remodeled ship is—the original are unsupported. The problem is that of reconciling the intuition that certain small changes (replacement of a single part or small portion) preserve identity, with the problem illustrated by the sandals example of §2.5. It turns out, nevertheless, that the problem is one of dealing with the excesses of LL. To resolve the problem, we need an additional level of relativity. To motivate this development, consider the following abstract counterpart of the sandals example:
On the left there is an object P composed of three parts, P1, P2, and P3. On the right is an exactly similar but non-identical object, Q, composed of exactly similar parts, Q1, Q2, and Q3, in exactly the same arrangement. For the sake of illustration, we adopt the rule that only replacement of (at most) a single part by an exactly similar part preserves identity. Suppose we now interchange the parts of P and Q. We begin by replacing P1 by Q1 in P and replacing Q1 by P1 in Q, to obtain objects P1 and Q1. So P1 is composed of parts Q1, P2, and P3, and Q1 is composed of parts P1, Q2, and Q3. We then replace P2 in P1 by Q2, to obtain P2, and so on. Given our sample criterion of identity, and assuming the transitivity of identity, P and P3 are counted the same, as are Q and Q3. But this appears to be entirely the wrong result. Intuitively, P and Q3 are the same, as are Q and P3. For P and Q3 are composed of exactly the same parts put together in exactly the same way, and similarly for Q and P3. Futhermore, Q3 (P3) can be viewed as simply the result of taking P (Q) apart and putting it back together in a slightly different location. And this last difference can be eliminated by switching the locations of P3 and Q3 as a last step in the process.
Suppose, however, that we replace our criterion of identity by the following more complicated rule: x and y are the same relative to z, if both x and y differ from z at most by a single part. (This relation is transitive, and is in fact an equivalence relation.) For example, relative to P, P, P1, Q2, and Q3 are the same, but Q, Q1, P2 and P3, are not. Of course, replacement by a single part is an artificial criterion of identity. In actual cases, it will be a matter of the degree or kind of deviation from the original (represented by the third parameter, z). The basic idea is that identity through change is not a matter of identity through successive, accumulated changes — that notion conflicts with both intuition (e.g., the sandals example) and the Kripkean argument: Through successive changes objects can evolve into other objects. The three-place relation of idenitity does not satisfy LL and is consistent with the outlook of the relativist. Gupta (1980) develops a somewhat similar idea in detail. Williamson (1990) suggests a rather different approach, but one that, like the above, treats identity through change as an equivalence relation that does not satisfy LL.
4.6 Church's Paradox
Church's argument implies that if Pierre's doxastic position is as described (in §2.6), then London and Londres are distinct objects. Assuming the standard account of identity, the result is that either Pierre's doxastic position cannot be as described or else London and Londres are different cities (or else we must punt). Since London and Londres are not different cities, the standard account entails that Pierre's doxastic position cannot be as described (or else we must punt). This was Church's own position as regards certain puzzles about synonymy, such as Mate's puzzle (Mates 1952). Church held that one who believes that lawyers are lawyers, must indeed believe that lawyers are attorneys, despite any refusal to assent to (or desire to dissent from) ‘Lawyers are attorneys’ (Church 1954). Kripke later argued (Kripke 1979) that assent and failure to assent must be taken at face value (at least in the case of Pierre) and Pierre's doxastic position is as described. Kripke chose to punt — concluding that the problem is a problem for any "logic" of belief. The relativist concludes instead that (a) Pierre's doxastic position is as described, (b) if so, London and Londres are distinct objects, and (c) London and Londres are nonetheless the same city. Whether this resolution of Church's paradox can be exploited to yield solutions to Frege's puzzle (Salmon 1986) or Kripke's puzzle (1979) remains to be seen. Crimmins (1998) has recently suggested that the analysis of propositional attitudes requires a notion of "semantic pretense." In reporting Pierre's doxastic position we engage in a pretense to the effect that London and Londres are different cities associated with different Fregean senses. Crimmins' goal is to reconcile (a), (c) and the following, (d): that the pure semantics of proper names (’London’, ‘Londres’) is Millian or directly referential (Kripke 1979). The relativist proposes just such a reconciliation but suggests that the pretense can be dropped.
5. Absolute Identity
The philosopher P.T. Geach first broached the subject of relative identity and introduced the phrase ‘relative identity’. Over the years, Geach has suggested specific instances of RI (a variant of the case of Oscar and his tail is due to Geach (Geach 1980)) and in this way he has contributed to the development of the weak view concerning relative identity, i.e. the view that while ordinary identity relations are often relative, some are not. But Geach maintains that absolute identity does not exist. What is his argument?
That is hard to say. Geach sets up two strawman candidates for absolute identity, one at the beginning of his discussion and one at the end, and he easily disposes of both. In between he develops an interesting and influential argument to the effect that identity, even as formalized in the system FOL=, is relative identity. However, Geach takes himself to have shown, by this argument, that absolute identity does not exist. At the end of his initial presentation of the argument in his 1967 paper, Geach remarks:
We thought we had a criterion for a predicable's expressing strict identity [i.e., as Geach says, "strict, absolute, unqualified identity"] but the thing has come apart in our hands; and no alternative rigorous criterion that could replace this one has thus far been suggested. (Geach 1972, p. 241)
It turns out, as we'll see, that all that comes apart is the false notion that in FOL= the identity symbol defines the relation I(A,x,y). Let us examine Geach's line of reasoning in detail, focusing on the presentation in his 1967 article, the locus classicus of the notion of relative identity.
Geach begins by urging that a plain identity statement ‘x and y are the same’ is in need of a completing predicate: ‘x and y are the same F’. Frege had argued that statements of number such as ‘this is one’ require a completing predicate: ‘this is one F’, and so it is, Geach claims, with identity statements. This is a natural view for one who subscribes to RI. The latter cannot even be stated without the completing predicates. Nevertheless, both the claim itself and the analogy with Frege have been questioned. Some argue that the analogy with Frege is incorrect, others that while the analogy is correct, both Frege and Geach are wrong (Perry 1978 and Bennett and Alston 1984). These matters will be discussed in greater detail in an updated version of this article. They do not bear directly on the question of the coherence and truth of RI or the question of absolute identity. One who adopts the weak view would not want to follow Geach on this score. And one could maintain the "completing thesis" without being committed to RI. Furthermore, the completing thesis occupies a puzzling role in Geach's dialectic. Immediately following his statement of the thesis, Geach formalizes FOL= on the basis of the single formula:
W: φ(a) ↔ ∃x(φ(x) ∧ x = a)
(The ‘W’ is for Hao Wang, who first suggested it. The reader is invited to prove Ref and LL from W.) But we hear no complaint about the syntax of W despite its involving a seemingly unrelativized identity symbol. It turns out, however, that Geach apparently thinks of the completing predicate as being given by the whole descriptive apparatus of L or a fragment thereof.
Geach now observes
… if we consider a moment, we see that an I-predicable in given theory T need not express strict, absolute, unqualified identity; it need mean no more than that two objects are indiscernible by the predicables that form the descriptive resources of the theory — the ideology of the theory … . (p. 240)
Here an ‘I-predicable’ is a binary relation symbol ‘=’ satisfying (W). Geach's focus at this point is on the need to relativize an I-predicable to a theory T. Geach then immediately saddles the friend of absolute identity with the view that for "real identity" we need not bring in the ideology of a definite theory. This is Geach's first strawman. When logicians, in discussing FOL=, speak of "real identity" — and they often do (see Enderton 2000 or Silver 1994, for example) — they do not mean a relation of universal identity, since the universal set does not exist. Nor do they intend, in formulating LL, to use ‘true of’ in a completely unrestrained way which gives rise to semantic paradox. It is no argument against those who wish to distinguish mere indiscernibility from real identity to say that they "will soon fall into contradictions," e.g., Grelling's or Russell's. The relation I(A,x,y) is sufficiently relativized. (It is relativized to a set A.)
We come next to the main point:
Objects that are indiscernible when we are confined to the ideology of T may perfectly well be discernible in ideology of a theory T1 of which T is a fragment. (p. 240)
The warrant for this claim can only be the language relativity of identity when treated as a non-logical notion (see §1). That this is what Geach has in mind is clear from some approving remarks he makes in his 1973 article about Quine's (1970) proposal to treat identity as a non-logical notion. But how does it follow that absolute identity does not exist? Geach seems to think that the defender of absolute identity will look to Ref and LL (or W) — and not beyond — for a full account of "strict, absolute, unqualified" identity. That is not so. The fact that these formulas in themselves define only indiscernibility relations is a logical commonplace. So this is Geach's second strawman.
Is Geach's argument at least an argument that identity is relative? Does language relativity support the conclusion that RI is true even of identity as formalized in FOL=? The general idea appears to be that language relativity suggests that we take identity to be indiscernibility, and conclude that objects identical relative to one ideology F may be different relative to another ideology G, and that this confirms RI. Notice first of all that this argument relies on the identity of indiscernibles: that indiscernibility implies identity. This principle is not valid in FOL= even when the latter is treated as a proper theory. Language relativity does not imply that the distinctness of distinct objects cannot go unnoticed.
Secondly, the interesting cases of RI do not involve a shift from an impoverished point of view to an improved one — whether this is seen in epistemic terms (which Geach disputes — Geach, (1973)) or in purely logical terms. We do not affirm that old Oscar and young Oscar, for example, are the same dog on the grounds that there is an ideology with respect to which old Oscar and young Oscar are indistinguishable. Such an ideology would be incapable of describing any change in Oscar. It is true that the same dog relation determines a set of predicates that do not discriminate between the members of certain pairs of dogs — the dogs in the photographs mentioned in earlier, for example. And it is true that these predicates determine a sublanguage in which the same dog relation is a congruence, i.e. no predicate of the sublanguage distinguishes x from y, if x and y are the same dog. But the very sense of such statements as that old Oscar and young Oscar are the same dog requires a language in which a change in Oscar is expressible. We are talking, after all, about old Oscar and young Oscar. If we take seriously the idea that change involves the application of incompatible predicates, then the sublanguage cannot express the contrast between old Oscar and young Oscar.
Third, the phenomenon of language relativity (in the technical sense discussed in §1) has led many philosophers, including Geach, to the view that ideology creates ontology. There is no antecedently given domain of objects, already individuated, and waiting to be described. Instead, theories carve up the world in various ways, rendering some things noticeably distinct and others indiscernible, depending on a theories' descriptive resources. The very notion of object is theory-bound (Kraut 1980). This sort of anti-realism may seem to go hand in hand with relative identity. Model theory, however, is realist to its core and language relativity is a model-theoretic phenomenon. It is a matter of definability (in a structure). Referring back to §1, in order to make sense of language relativity we have to start with a pair of distinct objects, a and b, (distinct from the standpoint of the metalanguage), and hence a pair of objects we assume are already individuated. These objects, however, are indistinguishable in M, since no formula of L′ defines a subset of M containing the one object and not the other. When we move to M′, we find that there is a formula of the enriched language that defines such a subset in M′. Thus, language relativity is not really any sort relativity of identity at all. We must assume that the objects a and b are distinct in order to describe the phenomenon. If we are living in M, and suspect that Martians living in M′ can distinguish a from b, our suspicion is not merely to the effect that Martians carve things up differently than we do. Our own model theory tells us that there is more to it than that. Our suspicion must be to the effect that a and b are absolutely distinct. If we are blind to the difference between a and b, but the Martians are not, then there must be a difference; and even if we are living in M, we know there's a difference, or at least we can suspect there is, since model theory tells us that such suspicion is well founded.
Let us go back to Geach's remark that we "need not" interpret identity absolutely. While this is true, we need not interpret it as indiscernibility either. There are always the quotient structures (Quine 1963) . Instead of taking our "reality" to be M, and our "identity" to be indiscernibility in M, we can move to the quotient structure, QM, whose elements are the equivalence classes, [x], for x in M. If x and y are indiscernible in M, then in QM, [x] and [y] are absolutely identical. We can do this even if we wish to treat FOL= as a proper theory. For example, suppose L′ is a language in which people having the same income are indiscernible. The domain of M now consists of people. QM, however, consists of income groups, equivalence classes of people having the same income, and identity in QM is absolute. Geach objects to such reinterpretation in terms of the quotient structures on the grounds that it increases the ontological commitments not only of L′ but of any language of which L′ is a sublanguage.
Let's focus on L′ first. From a purely model-theoretic point of view the question is moot. We cannot deny that QM is a structure for L′. Thus, L′ is committed to people vis à vis one structure and to income groups vis à vis the corresponding quotient structure. But let's pretend that the structures are "representations of reality," and so the question now becomes: Which representation is preferable? Is there then any reason to prefer the ontology of M to that of QM? M contains people but no sets of people, whereas QM contains sets of people but no people. By Quine's criterion of ontological commitment — that to be is to be the value of a variable — commitment to a set of objects does not carry a commitment to its elements. That is one of the odd consequences of Quine's criterion. Unless there is some ontological reason to prefer people to sets of people (perhaps because sets are never to be preferred), the ontologies of M and QM seem pretty much on a par. Both commit L′ to one kind of thing.
Geach makes the additional claim that the ontological commitments of a sublanguage L′ of a language L are inherited by L (Geach 1973). Suppose then that L is a language containing expressions for several equivalence relations defined on people: say, same income, same surname, and same job. Geach argues that L need only be committed to the existence of people. Things such as income groups, job groups (equivalence classes of people with the same job), and surmen can all be counted using the equivalencies, without bringing surmen, job groups, and income groups into the picture. Consider any sublanguage for which any one of these equivalence relations is a congruence, i.e. for which LL′ holds. Pick the language, L1, for example, in which people having the same job are indiscernible. More precisely, we assume that T1 is the pure theory with identity whose ideology is confined to the language L1. Let M1 be a model of T1. We may imagine the domain of M1 to consist of people, and we can interpret indiscernibility in M1 to be the relation x and y have the same job. Geach would argue that if L1 is committed to the elements of QM1 — the job groups — then so is L. But that is not true. If T is a theory of the three distinct equivalence relations formulated in L, the most T (or L) would be committed to are the partitions determined by the equivalence relations; and in any case, it would be perfectly consistent to insist that, whatever the ontological commitments of L1, reality, as described by L, consists of people.
The foregoing considerations are rather abstract. To see more clearly what is at stake, let us focus on a specific example. Geach (1967) mentions that rational numbers are defined set-theoretically to be equivalence classes of integers determined by a certain equivalence relation defined on "fractions," i.e. ordered pairs of integers (1/2 is <1,2>, 2/4 is <2,4>, etc.). He suggests that we can instead construe our theory of rational numbers to be about the fractions themselves, taking the I-predicable of our theory to be the following equivalence relation, E:
R: E(<x,y>, <u,v>) iff xv = yu.
This approach, Geach says, would have "the advantage of lightening a theory's set-theoretical burdens. (In our present example, we need not bring in infinite sets of ordered pairs of integers into the theory of rationals.)."
The first thing to notice about this example is that E cannot be the I-predicable of such a theory, since E is defined in terms of identity (look at the right side of R). It is ‘=’ that must serve as the I-predicable, and it renders distinct ordered pairs of integers discernible. The moral is that not all equivalence relations can be drafted to do the job of identity, even given a limited ideology. There is, indeed, a plausible argument that any equivalence relation presupposes identity — not necessarily in the direct way illustrated by (R), but indirectly, nonetheless (see §6). Moreover, from the standpoint of general mathematics, once we have (R), we have the (infinite) equivalence classes it determines and the partition it induces. These are inescapable. Even from a more limited viewpoint, it seems that once we have enough set theory to give us ordered pairs of integers and the ability to define (R), we get the partition it induces as well.
Geach perceives an ontological advantage in relative identity; but his argument is unconvincing. Shifting to the quotient structures, as Quine suggested, does not induce a "baroque, Meinongian ontology" (Geach 1967). In particular, the "home language" (L) does not inherit the commitment of the fragment (L1), and the ontology of an arbitrary model of the pure theory of identity based on the latter language is at least no more various than that of the corresponding quotient model. There are, however, a number of ways in which relative identity does succeed in avoiding commitment to certain entities required by its absolute rival. These are discussed in the replies to objections 4 and 5 in the next section.
6. Objections and Replies
The following constitute a "start up" set of objections and replies concerning relative identity and/or aspects of the foregoing account of relative identity and its rival. Time and space constraints prevent a more extended initial discussion. In addition, there is no presumption that the objections discussed below are the most important or that the initial replies to them are without fault. It is hoped that the present discussion will evolve into a more full blown one, involving contributions by the author and readers alike. Should the discussion become lengthy, old or unchallenged objections and/or replies can be placed in the archives.
Objection 1: "Relativist theories of identity, all of which are inconsistent with Leibniz's principle [LL], currently enjoy little support. The doubts about them are (a) whether they really are theories of numerical identity, (b) whether they can be made internally consistent, and (c) whether they are sufficiently motivated." (Burke 1994.)
Reply: In reverse order: (c) The issues discussed in §2 and §4 surely provide sufficient motivation. (b) No proof of inconsistency has ever been forthcoming from opponents of relative identity, and in fact the weak view is consistent inasmuch as it has a model in the theory of similarity relations. The arguments outlined in the second paragraph of §3 are frequently cited as showing that relative identity is incoherent; but they show only that RI is incompatible with (unrestricted) LL. (a) See the replies to objections 2 and 3 below.
Objection 2: If an identity relation obeys only a restricted form of LL — if it preserves only some properties and not all — then how do we tell which properties serve to individuate a pair of distinct objects?
Reply: Similarity relations satisfy only restricted forms of LL. How then do we tell which properties are preserved by the same shape relation and which are not? It is no objection to the thesis that identity relations in general preserve some properties and not others to demand to know which are which. At best the objection points to a problem we must face anyway (for the case of similarity). In general, a property is preserved by an equivalence relation if it "spreads" in an equivalence class determined by the relation: If one member of the class has the property, then every member does. Every property spreads in a singleton, as absolute identity demands.
Objection 3: If identity statements are mere equivalencies, what distinguishes identity from mere similarity?
Reply: The distinction between identity and similarity statements (or sentences) is usually drawn in terms of the distinction between substantival and adjectival common nouns. If F is a common noun standing for a kind of things e.g., ‘horse’, then ‘x and y are the same F’ is a statement of identity, whereas if F is an a common noun standing for a kind of properties of things, then ‘x and y are the same F’ is a statement of similarity. (It's interesting to note that when the noun is proper, i.e. a proper name, the result is a statement of similarity, not identity — as in ‘He's not the same Bill we knew before’.) This distinction rests ultimately on the metaphysical distinction between substance and attribute, object and property. While the distinction no doubt presupposes the concept of individuation (the bundle theory, for example, presupposes that we have the means to individuate properties), there is no obvious reason to suppose that it entails the denial of RI, i.e. the claim that no instance of RI is true. For a beginner's review — from an historical perspective — of the issues concerning substance and attribute, see O'Connor, (1967); and for more recent and advanced discussion and bibliography, see the entry on properties.
Objection 4: Consider the following alleged instance of RI:
A is the same word type as B, but A and B are different word tokens.
"If ‘A’ and ‘B’ refer to the same objects throughout (1), the first conjunct of (1) is not an identity statement, and the counterexample (to the thesis that no instance of RI is true) fails. If both conjuncts are identity statements in the required sense, ‘A’ and ‘B’ must refer to word types in the first conjunct and word tokens in the second, and the counterexample fails" (Perry 1970).
Reply: First, if "in the required sense" means "satisfies LL," then the objection buys correctness only at the price of begging the question. Advocates of relative identity will maintain that the relation A is the same word type as B is an identity relation, defined on tokens, that does not satisfy LL.
Secondly, even if one insists that in this case intuition dictates that if A and B refer to tokens in both conjuncts of (1), then ‘A is the same word type as B’ expresses only the similarity relation: A and B are tokens of the same type, there are other cases where, intuitively, both conjuncts of RI involve identity relations and yet the relevant terms all refer to the same kind of things; for example,
A and B are the same dog but A and B are different physical objects,
as said of young Oscar and old Oscar. Here there is no temptation to suppose that the relation A and B are the same dog is not an identity relation. One may invoke a theory — a theory of temporal parts, for example — that construes the relation as a certain kind of similarity, but that is theory, not pretheoretical intuition. It is no objection to the relativist's theory, which holds in part that ‘A and B are the same dog’ expresses a relation of primitive identity, that there is an alternative theory according to which it expresses a similarity relation obtaining between two temporal parts of the same object. Furthermore, in the case of (2), A and B refer, again intuitively, to the same things in both conjuncts.
Third, there are cases in which the relative identity view does possess an ontological advantage. Consider
A and B are the same piece of clay but A and B are different statues.
Suppose A and B are understood to refer to one sort of thing — pieces of clay — in the first conjunct and another — statues — in the second conjunct. Assume that the piece of clay c denoted by A in the first conjunct constitutes, at time t, the statue s. Then assuming that statues are physical objects, there are two distinct physical objects belonging to different kinds occupying the same space at t. Some, notably Wiggins (1980), hold that this is entirely possible: Distinct physical objects may occupy the same space at the same time, provided they belong to different kinds. The temporal parts doctrine supports and encourages this view. A statue may be a temporal part of a temporally extended piece of clay. But one statue, it seems, cannot be a temporal part of another. Even so, however, the duality of constituter and thing constituted is unparsimonious (cf. Lewis 1993), and the relativist is not committed to it.
Again, consider
A and B are the same book but A and B are different copies (of the book).
One can say that in the first conjunct, A and B refer to books (absolutely the same book), whereas in the second conjunct, A and B refer to (absolutely distinct) copies. But the alleged duality of books and copies of books is unparsimonious and the relativist is not committed to it. There is no reason to concede to the philosopher that we do not actually purchase or read books; instead we purchase and read only copies of books. Any copy of a book is just as much the "book itself" as is any other copy. Any copy of a book is the same book as any other copy. Nelson Goodman once remarked that "Any accurate copy of a poem is as much the original work as any other" (Goodman 1968). Goodman was not suggesting that the distinction between poem and copy collapses. If it does collapse, however, we have an explanation of why any accurate copy is as much the original work as any other: any such copy is the same work as any other.
Objection 5: Geach remarks that "As for our recognizing relative identity predicables: any equivalence relation…can be used to specify a criterion of relative identity." But §3 above contains a counterexample. Some equivalence relations are defined in terms of the I-predicable of a theory and hence cannot serve as such. (Any pair of I-predicables for a fixed theory are equivalent.) In fact it seems that any equivalence relation presupposes identity (cf. McGinn 2000). For example, the relation x and y are the same color presupposes identity of colors, since it means that there are colors C and C′ such that x has C and y has C′, and C = C′. Identity, therefore, is logically prior to equivalence.
Reply: This is a good objection. It does seem to show, as the objector says, that identity is logically prior to ordinary similarity relations. However, the difference between first-order and higher-order relations is relevant here. Traditionally, similarity relations such as x and y are the same color have been represented, in the way indicated in the objection, as higher-order relations involving identities between higher order objects (properties). Yet this treatment may not be inevitable. In Deutsch (1997), an attempt is made to treat similarity relations of the form ‘x and y are the same F’ (where F is adjectival) as primitive, first-order, purely logical relations (see also Williamson 1988). If successful, a first-order treatment of similarity would show that the impression that identity is prior to equivalence is merely a misimpression — due to the assumption that the usual higher-order account of similarity relations is the only option.
Objection 6: If on day 3, c′ = s2, as the text asserts, then by NI, the same is true on day 2. But the text also asserts that on day 2, c = s2; yet c ≠ c′. This is incoherent.
Reply: The term s2 is not an absolutely rigid designator and so NI does not apply.
Objection 7: The notion of relative identity is incoherent: "If a cat and one of its proper parts are one and the same cat, what is the mass of that one cat?" (Burke 1994)
Reply: Young Oscar and Old Oscar are the same dog, but it makes no sense to ask: "What is the mass of that one dog." Given the possibility of change, identical objects may differ in mass. On the relative identity account, that means that distinct logical objects that are the same F may differ in mass — and may differ with respect to a host of other properties as well. Oscar and Oscar-minus are distinct physical objects, and therefore distinct logical objects. Distinct physical objects may differ in mass.
Objection 8: We can solve the paradox of 101 Dalmatians by appeal to a notion of "almost identity" (Lewis 1993). We can admit, in light of the "problem of the many" (Unger 1980), that the 101 dog parts are dogs, but we can also affirm that the 101 dogs are not many; for they are "almost one." Almost-identity is not a relation of indiscernibility, since it is not transitive, and so it differs from relative identity. It is a matter of negligible difference. A series of negligible differences can add up to one that is not negligible.
Reply: The difference between Oscar and Oscar-minus is not negligible and the two are not almost-identical. Lewis concedes this point but proposes to combine almost-identity with supervaluations to give a mixed solution to the paradox. The supervaluation solution starts from the assumption that one and only one of the dog parts is a dog (and a Dalmatian, and Oscar), but it doesn't matter which. It doesn't matter which because we haven't decided as much, and we aren't going to. Since it is true that any such decision renders one and only one dog part a dog, it is plain-true, i.e. supertrue, that there is one and only one dog in the picture. But it is not clear that this approach enjoys any advantage over that of relative identity; in fact, it seems to produce instances of RI. Compare: Fred's bicycle has a basket attached to it. Ordinarily, our discourse slides over the difference between Fred's bicycle with its basket attached and Fred's bicycle minus the basket. (In this respect, the case of Fred's bicycle differs somewhat from that of Oscar and Oscar-minus. We tend not to ignore that difference.) In particular, we don't say that Fred has two bicycles even if we allow that Fred's bicycle-minus is a bicycle. Both relative identity and supervaluations validate this intuition. However, both relative identity and supervaluations also affirm that Fred's bicycle and Fred's bicycle-minus are absolutely distinct objects. That is, the statement that Fred's bicycle and Fred's bicycle-minus are distinct is supertrue. So the supervaluation technique affirms both that Fred's bicycle and Fred's bicycle-minus are distinct objects and that there is one and only one (relevant) bicycle. That is RI, or close enough. The supervaluation approach is not so much an alternative to relative identity as a form of it.
Bibliography
Baker, L. R., 1997: "Why Constitution is not Identity," Journal of Philosophy, 94: 599-621.
Bennett, J., and Alston, W., 1984: "Identity and Cardinality: Geach an Frege," Philosophical Review 93: 553-568.
Blanchette, P., 1999: "Relative Identity and Cardinality," Canadian Journal of Philosophy, 29: 205-224.
Burke, M., 1992: "Copper Statues and Pieces of Copper: A Challenge to the Standard Account," Analysis, 52: 12-17.
–––, 1995: "Dion and Theon: An Essentialist Solution to an Ancient Problem," The Journal of Philosophy, 91: 129-139.
Carrara, M., and Sacchi, E., "Cardinality and Identity," Journal of Philosophical Logic, 36: 539-556.
Carter, W. R., 1982: "On Contingent Identity and Temporal Worms," Philosophical Studies, 41: 213-230.
–––, 1987: "Contingent Identity and Rigid Designation," Mind, 96: 250-255.
–––, 1990: Elements of Metaphysics. New York: McGraw-Hill.
Cartwright, R., 1987: "On the Logical Problem of the Trinity." In Cartwright, R., Philosophical Essays. Cambridge, Mass.: MIT Press.
Chandler, H., 1971: "constitutivity and Identity," Noûs, 5: 513-519.
–––, 1975: "Rigid Designation," The Journal of Philosophy, 72: 363-369.
–––, 1976: "Plantinga on the Contingently Possible," Analysis, 36: 106-109.
Chisholm, R. M., 1967: "Identity through Possible Worlds: Some Questions," Noûs, 1: 1-8
–––, 1969: "The Loose and Popular and Strict and Philosophical Senses of Identity." In Grim, R. H. and Case, R. (eds.), Perception and Personal Identity. Cleveland: Ohio University Press.
–––, 1973: "Parts as Essential to their Wholes," Review of Metaphysics, 26: 581-603.
Church, A., 1954: "Intensional Isomorphism and Identity of Belief," Philosophical Studies, 5: 65-73; reprinted in N. Salmon and S. Soames, 1988.
–––, 1982: "A Remark Concerning Quine's Paradox About Modality," Analisis Filosophico 2, (Spanish version). Reprinted in N. Salmon and S. Soames, 1988.
Crimmins, M., 1998: "Hesperus and Phosphorus: Sense, Pretense, and Reference", Philosophical Review, 107: 1-48.
Deutsch, H., 1997: "Identity and General Similarity," Philosophical Perspectives 12: 177-200.
Dummett, M., 1991: "Does Quantification involve Identity?", in H.A. Lewis (ed.), Peter Geach: Philosophical Encounters. Dordrecht: Kluwer Academic Publishers.
Eglueta, R. and Jansana, R., 1999: "Definability of Leibniz Equality," Studia Logica, 63: 223-243.
Enderton, H., 2000: A Mathematical Introduction to Logic. New York: Academic Press.
Epstein, R., 2001: Predicate Logic. Belmont, CA: Wadsworth.
Evans, G., 1978: "Can There be Vague Objects?", Analysis, 38: 308.
Forbes, G., 1985: The Metaphysics of Modality. Oxford: Oxford University Press.
–––, 1994: "A New Riddle of Existence," Philosophical Perspectives, 8: 415-430.
Gallois, A., 1986: "Rigid Designation and the Contingency of Identity," Mind, 95: 57-76.
–––, 1988: "Carter on Contingent Identity and Rigid Designation," Mind, 97: 273-278.
–––, 1990: "Occasional Identity," Philosophical Studies, 58: 203-224.
Garbacz, P., 2002: "Logics of Relative Identity" Notre Dame Journal of Formal Logic, 43: 27-50.
–––, 1998: Occasions of Identity: A Study in the Metaphysics of Persistence, Change and Sameness. Oxford: Clarendon Press.
Geach, P.T., 1967: "Identity," Review of Metaphysics, 21: 3-12. Reprinted in Geach 1972, pp. 238-247.
–––, 1972: Logic Matters. Oxford: Blackwell.
–––, 1973: "Ontological Relativity and Relative Identity." In Munitz, M. (ed), Logic and Ontology. New York: New York University Press.
–––, 1980: Reference and Generality (third edition). Ithaca: Cornell University Press.
Gibbard, A., 1975: "Contingent Identity," Journal of Philosophical Logic, 4: 187-221.
Goodman, N., 1968: Languages of Art. Indianapolis and New York: Bobbs-Merrill Company.
Griffin, N., 1977: Relative Identity. New York: Oxford University Press.
Gupta, A., 1980: The Logic of Common Nouns. New Haven and London: Yale University Press.
Heller, M., 1990: The Ontology of Physical Objects. New York: Cambridge University Press.
Hinchliff, M., 1996: "The Puzzle of Change," Philosophical Perspectives, 10: 119-133.
Hodges, W., 1983: "Elementary Predicate Logic," in D. Gabbay and F. Guenthner, (eds), Handbook of Philosophical Logic, v.1, Dordrecht: Reidel.
Johnston, M., 1992: "Constitution is not Identity," Mind, 101: 89-105.
Koslicki, K., 2005: "Almost Indiscernible Objects and the Suspect Strategy," The Journal of Philosophy, 102: 55-77.
Kraut, R., 1980: "Indiscernibility and Ontology," Synthese 44: 113-135.
Kripke, S., 1971: "Identity and Necessity," in M. Munitz, (ed.), Identity and Individuation. New York: New York University Press.
–––, 1972: "Naming and Necessity," in D. Davidson and G. Harmon, (eds.), Semantics of Natural Language. Boston: Reidel. Revised and reprinted as Kripke, 1980.
–––, 1979: "A Puzzle about Belief," in A. Margalit, (ed.), Meaning and Use. Dordrecht: Reidel. Reprinted in Salnon and Soames, 1988.
–––, 1980: Naming and Necessity. Oxford: Blackwell.
Lewis, D. K., 1986: On the Plurality of Worlds. Oxford: Blackwell.
–––, 1993: "Many But Almost One," in K. Campbell, J. Bacon, and L. Reinhardt (eds.), Ontology, Causality and Mind: Essays on the Philosophy of D.M Armstrong. Cambridge, England: Cambridge University Press. Reprinted in Lewis, 1999.
–––, 1999: Papers in Metaphysics and Epistemology. Cambridge, England: Cambridge University Press.
Lowe, E. J., 1982: "The Paradox of the 1,001 Cats," Analysis, 42: 128-130.
–––, 1989: Kinds of Being. Oxford: Basil Blackwell.
–––, 1995: "Coinciding Objects: In Defense of the ‘Standard Account," Analysis, 55: 171-178.
Mates, B., 1952: "Synonymity," in L. Linsky, (ed.), Semantics and the Philosophy of Language. Champaign-Urbana: University of Illinois Press.
McGinn, C., 2000: Logical Properties. Oxford: Blackwell.
Myro, G., 1985: "Identity and Time," in Philosophical Grounds of Rationality: Intentions, Categories, Ends, R. Grandy and R. Warner, (eds.). New York and Oxford: Oxford University Press.
Noonan, H., 1980: Objects and Identity. The Hague:
–––, 1983: "The Necessity of Origin," Mind, 92: 1-20.
–––, 1991: "Indeterminate Identity, Contingent Identity and Abelardian Predicates," The Philosophical Quarterly, 41: 183-193.
–––, 1993: "Constitution is Identity," Mind, 102: 133-146
–––, 1997: "Relative Identity." In B. Hale and C. Wright (eds), A Companion to the Philosophy of Language. Oxford: Blackwell.
Nozick. R., 1982: Philosophical Explanations. Cambridge, Mass.: Harvard University Press.
O'Connor, D.J., 1967: "Substance and Attribute." In P. Edwards, (ed.), The Encyclopedia of Philosophy, New York: Macmillan.
Oderberg, D., 1996: "Coincidence under a Sortal," The Philosophical Review, 105: 145-171.
Parsons, T., 2000: Indeterminate Identity. Oxford: Oxford University Press.
Parfit, D., 1984: Reasons and Persons. Oxford: Oxford University Press.
Perry, J., 1970: "The Same F," The Philosophical Review, 64: 181-200.
–––, 1978: "Relative Identity and Number," Canadian Journal of Philosophy 8: 1-15.
Quine, W. V. O., 1960: Word and Object. Cambridge, MA: MIT Press.
–––, 1963: From a Logical Point of View. New York: Harper and Row.
–––, 1970: Philosophy of Logic. Englewood Cliffs, N.J.: Prentice Hall.
Rea, M., 1995: "The Problem of Material Constitution," The Philosophical Review, 104: 525-552.
Rea, M. (ed.), 1997: Material Constitution: A Reader. Lanham, MD: Rowman and Littlefield.
Read, S., 1995: Thinking About Logic. Oxford: Oxford University Press.
Salmon, N., 1979: "How Not to Derive Essentialism from the Theory of Reference," The Journal of Philosophy, 76: 703-725.
–––, 1986: "Reflexivity," Notre Dame Journal of Formal Logic, 27: 401-429. Reprinted in Salmon and Soames, 1988.
–––, 1989: "The Logic of What Might Have Been," Philosophical Review, 98: 3-34.
Salmon, N., and Soames, S. (eds.), 1988: Propositions and Attitudes. Oxford: Oxford University Press.
Sedley, D., 1982: "The Stoic Criterion of Identity," Phronesis, 27: 255-275.
Silver, C., 1994: From Symbolic Logic…to Mathematical Logic. Melbourne: Wm. C. Brown, Publishers.
Simons, P., 1987: Parts: A Study in Ontology. Oxford: Clarendon Press.
Swindler, J. K., 1991: Weaving: An Analysis of the Constitution of Objects. Savage, MD.: Rowman & Littlefield.
Thompson, J., 1998: "The Statue and the Clay," Noûs, 32: 149-173.
Unger, P., 1980: "The Problem of the Many," Midwest Studies in Philosophy, 5: 411-467.
Van Inwagen, P., 1981: "The Doctrine of Arbitrary Undetached Parts," Pacific Philosophical Quarterly, 62: 123-137.
–––, 1990: Material Beings. Ithaca, NY: Cornell University Press.
Wiggins, D., 1967: Identity and Spatio-Temporal Continuity. Oxford: Blackwell.
–––, 1968: "On Being in the Same Place at the Same Time," Philosophical Review, 77: 90-95.
–––, 1980: Sameness and Substance. Oxford: Blackwell.
Williams, C.J.F., 1990: What is Identity. Oxford: Oxford University Press.
Williamson, T., 1988: "First-order Logics for Comparative Similarity," Notre Dame Journal of Formal Logic, 29: 457-481.
–––, 1990: Identity and Discrimination. Oxford: Blackwell.
Yablo, S., 1987: "Identity, Essence and Indiscernibility," Journal of Philosophy, 84: 293-314.
Zalabardo, J., 2000: Introduction to the Theory of Logic. Boulder, Colorado: Westview Press.
Zemach, E., 1974: "In Defense of Relative Identity," Philosophical Studies, 26: 207-218.
Academic Tools
Open access to the SEP is made possible by a world-wide funding initiative.
Please Read How You Can Help Keep the Encyclopedia Free
The SEP would like to congratulate the National Endowment for the Humanities on its 50th anniversary and express our indebtedness for the five generous grants it awarded our project from 1997 to 2007. Readers who have benefited from the SEP are encouraged to examine the NEH’s anniversary page and, if inspired to do so, send a testimonial to neh50@neh.gov.